[INFO] 2019-01-19 11:32:24,873 myLogger main - start
[INFO] 2019-01-19 11:32:26,306 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 11:32:26,788 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 11:32:26,790 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 11:32:26,790 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 11:32:26,850 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 11:32:26,851 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 11:32:26,851 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 11:32:26,852 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 11:32:26,853 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 11:32:27,582 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 55766.
[INFO] 2019-01-19 11:32:27,599 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 11:32:27,614 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 11:32:27,617 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 11:32:27,618 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 11:32:27,629 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-2cab0772-e0f6-4ef7-9115-25a367e10e15
[INFO] 2019-01-19 11:32:27,650 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 11:32:27,688 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 11:32:27,890 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 11:32:27,891 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 11:32:27,980 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 11:32:28,003 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55779.
[INFO] 2019-01-19 11:32:28,004 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:55779
[INFO] 2019-01-19 11:32:28,006 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 11:32:28,007 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 55779, None)
[INFO] 2019-01-19 11:32:28,009 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:55779 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 55779, None)
[INFO] 2019-01-19 11:32:28,013 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 55779, None)
[INFO] 2019-01-19 11:32:28,013 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 55779, None)
[INFO] 2019-01-19 11:32:28,370 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 11:32:29,313 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 11:32:29,328 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 11:32:29,329 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 11:32:29,329 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 11:32:29,330 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 11:32:29,336 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 11:32:29,434 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 11:32:29,483 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 11:32:29,486 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:55779 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 11:32:29,489 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 11:32:29,493 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 11:32:29,494 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 11:32:29,550 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 11:32:29,558 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 11:32:29,654 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 11:32:29,774 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 11:32:29,783 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 266 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 11:32:29,784 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 11:32:29,787 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.283 s
[INFO] 2019-01-19 11:32:29,792 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.477913 s
[INFO] 2019-01-19 11:32:30,187 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:55779 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:13:17,722 myLogger main - alignedSample start
[INFO] 2019-01-19 12:13:18,557 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 12:13:19,121 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 12:13:19,123 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 12:13:19,124 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 12:13:19,210 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 12:13:19,211 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 12:13:19,212 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 12:13:19,213 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 12:13:19,214 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 12:13:20,151 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 56518.
[INFO] 2019-01-19 12:13:20,190 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 12:13:20,230 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 12:13:20,238 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 12:13:20,239 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 12:13:20,258 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-0d5e34f5-803f-434e-8073-197f4f7389b5
[INFO] 2019-01-19 12:13:20,293 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 12:13:20,362 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 12:13:20,730 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 12:13:20,734 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 12:13:20,904 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 12:13:20,958 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56531.
[INFO] 2019-01-19 12:13:20,959 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:56531
[INFO] 2019-01-19 12:13:20,962 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 12:13:20,965 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:13:20,970 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:56531 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:13:20,975 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:13:20,976 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:13:21,407 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 12:13:21,857 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 12:13:22,830 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 12:13:22,865 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 12:13:22,866 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 12:13:22,867 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 12:13:22,870 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 12:13:22,884 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 12:13:23,100 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 12:13:23,188 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 12:13:23,193 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:56531 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:13:23,197 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:13:23,204 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 12:13:23,207 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 12:13:23,300 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 12:13:23,317 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 12:13:23,456 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 12:13:23,657 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 12:13:23,669 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 422 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:13:23,671 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:13:23,675 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.450 s
[INFO] 2019-01-19 12:13:23,684 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.852837 s
[INFO] 2019-01-19 12:13:24,137 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:56531 in memory (size: 24.8 KB, free: 1992.0 MB)
[WARN] 2019-01-19 12:15:29,125 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6f5c87b2,BlockManagerId(driver, 192.168.99.1, 56531, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[WARN] 2019-01-19 12:15:33,507 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored message: HeartbeatResponse(false)
[WARN] 2019-01-19 12:17:03,216 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6f5c87b2,BlockManagerId(driver, 192.168.99.1, 56531, None))] in 2 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[WARN] 2019-01-19 12:17:03,217 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored message: HeartbeatResponse(false)
[WARN] 2019-01-19 12:52:37,485 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6f5c87b2,BlockManagerId(driver, 192.168.99.1, 56531, None))] in 3 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[WARN] 2019-01-19 12:52:37,504 org.apache.spark.HeartbeatReceiver logWarning - Removing executor driver with no recent heartbeats: 2110198 ms exceeds timeout 120000 ms
[ERROR] 2019-01-19 12:52:37,506 org.apache.spark.scheduler.TaskSchedulerImpl logError - Lost executor driver on localhost: Executor heartbeat timed out after 2110198 ms
[WARN] 2019-01-19 12:52:37,508 org.apache.spark.executor.Executor logWarning - Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6f5c87b2,BlockManagerId(driver, 192.168.99.1, 56531, None))]
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:119)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	... 14 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[WARN] 2019-01-19 12:52:37,512 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored message: HeartbeatResponse(true)
[INFO] 2019-01-19 12:52:37,513 org.apache.spark.scheduler.DAGScheduler logInfo - Executor lost: driver (epoch 0)
[INFO] 2019-01-19 12:52:37,515 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Trying to remove executor driver from BlockManagerMaster.
[WARN] 2019-01-19 12:52:37,517 org.apache.spark.SparkContext logWarning - Killing executors is only supported in coarse-grained mode
[INFO] 2019-01-19 12:52:37,517 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Removing block manager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,518 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,519 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,519 org.apache.spark.storage.BlockManagerMaster logInfo - Removed driver successfully in removeExecutor
[INFO] 2019-01-19 12:52:37,519 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,520 org.apache.spark.scheduler.DAGScheduler logInfo - Shuffle files lost for executor: driver (epoch 0)
[INFO] 2019-01-19 12:52:37,520 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:56531 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,520 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,521 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,522 org.apache.spark.scheduler.DAGScheduler logInfo - Host added was in lost list earlier: localhost
[INFO] 2019-01-19 12:52:37,522 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,523 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,523 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,523 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,523 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,524 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,524 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,524 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,524 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,524 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,525 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,525 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,525 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,526 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,526 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,526 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,526 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,526 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,527 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,527 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,527 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,527 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,528 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,528 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,528 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,529 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,529 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,529 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,530 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,530 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,530 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,530 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,530 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,531 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,531 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,531 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,531 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,532 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,532 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,532 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,532 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,533 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,533 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,533 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,533 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,534 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,534 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,534 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,534 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,534 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,535 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,535 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,535 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,536 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,536 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,536 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,537 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,537 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,537 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,537 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,538 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,538 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,538 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,538 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,538 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,539 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,539 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,539 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,539 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,539 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,539 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,540 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,540 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,540 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,540 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,540 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,541 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,541 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,541 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,541 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,541 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,542 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,542 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,542 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,542 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,542 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,543 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,543 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,543 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,543 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,544 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,544 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,544 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,544 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,544 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,545 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,545 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,545 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,545 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,545 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,546 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,546 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,546 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,547 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,547 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,547 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,547 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,547 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,548 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,548 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,548 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,548 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,549 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,549 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,549 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,550 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,550 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,550 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,556 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,557 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,557 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,558 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,558 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,558 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,558 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,559 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,559 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,559 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,559 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,559 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,560 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,560 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,560 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,560 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,560 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,561 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,561 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,561 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,561 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,561 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,562 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,562 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,562 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,562 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,562 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,563 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,563 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,563 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,563 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,563 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,564 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,564 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,564 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,564 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,564 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,565 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,565 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,565 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,565 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,565 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,566 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,566 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,566 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,566 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,566 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,567 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,567 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,567 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,568 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,568 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,568 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,569 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,569 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,569 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,569 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,573 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,574 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,574 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,574 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,574 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,575 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,576 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,576 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,576 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,576 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,576 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,577 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,577 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,577 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,577 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,577 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,578 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,578 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,578 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,579 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,579 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,579 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,579 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,579 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,580 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,580 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,580 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,580 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,580 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,580 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,581 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,581 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,581 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,581 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,581 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,581 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,582 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,582 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,582 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,582 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,582 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,583 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,583 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,583 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[WARN] 2019-01-19 12:52:37,583 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2019-01-19 12:52:37,583 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,583 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,584 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,584 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,584 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,584 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,584 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,585 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,585 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,585 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,585 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,585 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,586 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,586 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,586 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,586 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,586 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,587 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,587 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,587 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,587 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,587 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,588 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,588 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,588 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,588 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,588 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,589 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,589 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,589 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,589 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,589 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,589 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,590 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,591 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,591 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,591 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,591 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,591 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,591 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,592 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,592 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,592 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,592 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,592 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,593 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,593 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,593 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,593 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,593 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,593 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,594 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,594 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,594 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,594 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,595 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,595 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,595 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,595 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,595 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,595 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,596 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,596 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,596 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,596 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,596 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,597 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,597 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,597 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,597 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,597 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,598 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,598 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,598 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,598 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,599 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,599 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 12:52:37,599 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,599 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,599 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,599 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,600 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,600 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,600 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,600 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,601 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,601 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,601 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,601 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,601 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,601 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,602 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,602 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,602 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,602 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,603 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,604 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,604 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,604 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,604 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,604 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,605 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,605 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,605 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,605 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,605 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,606 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,606 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,606 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,606 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,606 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,607 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,607 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,607 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,607 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,607 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,607 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,608 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,608 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,608 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,608 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,608 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,609 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,609 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,609 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,609 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,610 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,610 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,610 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,610 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,610 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,611 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,611 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,611 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,611 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,611 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,611 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,612 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,612 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,612 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,612 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,613 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,613 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,613 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,613 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,613 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,614 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,614 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,614 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,614 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,615 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,615 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,615 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,615 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,615 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,615 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,616 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,616 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,616 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,616 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,616 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,617 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,617 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,617 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,618 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,618 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,618 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,618 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,619 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,619 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,619 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,619 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,619 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,619 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,620 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,621 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,621 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,621 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,621 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,622 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,622 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,623 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,623 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,623 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,623 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,623 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,624 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,624 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,624 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,624 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,625 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,625 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,625 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,625 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,625 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,626 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,627 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,627 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,627 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,628 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 12:52:37,628 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,628 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,628 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,629 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,629 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,629 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,629 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,629 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,629 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,630 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,630 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,630 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,630 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,631 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,632 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,632 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[INFO] 2019-01-19 12:52:37,634 org.apache.spark.executor.Executor logInfo - Told to re-register on heartbeat
[INFO] 2019-01-19 12:52:37,634 org.apache.spark.storage.BlockManager logInfo - BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None) re-registering with master
[INFO] 2019-01-19 12:52:37,634 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[ERROR] 2019-01-19 12:52:37,635 org.apache.spark.scheduler.LiveListenerBus logError - SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerAdded(1547873557635,BlockManagerId(driver, 192.168.99.1, 56531, None),2088763392)
[INFO] 2019-01-19 12:52:37,636 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 56531, None)
[INFO] 2019-01-19 12:52:37,637 org.apache.spark.storage.BlockManager logInfo - Reporting 0 blocks to the master.
[WARN] 2019-01-19 12:52:37,639 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@407de33b,BlockManagerId(driver, 192.168.99.1, 56531, None))] in 1 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Could not find HeartbeatReceiver.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 14 more
[INFO] 2019-01-19 12:52:37,646 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2019-01-19 12:52:37,661 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 12:52:37,661 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 12:52:37,662 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 12:52:37,666 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[WARN] 2019-01-19 12:52:40,641 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3438b734 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4e17ab8[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 3]
[WARN] 2019-01-19 12:52:40,641 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@407de33b,BlockManagerId(driver, 192.168.99.1, 56531, None))] in 2 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 14 more
[WARN] 2019-01-19 12:52:43,642 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5ca9f876 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4e17ab8[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 3]
[WARN] 2019-01-19 12:52:43,642 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@407de33b,BlockManagerId(driver, 192.168.99.1, 56531, None))] in 3 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 14 more
[WARN] 2019-01-19 12:52:43,642 org.apache.spark.executor.Executor logWarning - Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@407de33b,BlockManagerId(driver, 192.168.99.1, 56531, None))]
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:119)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	... 14 more
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 14 more
[INFO] 2019-01-19 12:52:43,645 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 12:52:43,645 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 12:52:43,646 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-8d18f8c2-74fe-41b9-a49b-43f99cd69327\userFiles-2c6fb72f-2872-483c-9b0d-da3bd8ab24ef
[INFO] 2019-01-19 12:52:43,647 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-8d18f8c2-74fe-41b9-a49b-43f99cd69327
[INFO] 2019-01-19 12:56:52,849 myLogger main - LayerSample start
[INFO] 2019-01-19 12:56:54,304 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 12:56:54,785 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 12:56:54,786 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 12:56:54,786 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 12:56:54,845 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 12:56:54,846 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 12:56:54,846 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 12:56:54,847 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 12:56:54,847 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 12:56:55,568 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 57173.
[INFO] 2019-01-19 12:56:55,586 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 12:56:55,604 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 12:56:55,607 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 12:56:55,607 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 12:56:55,620 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-e490c86a-0c58-4dad-abba-627214d01072
[INFO] 2019-01-19 12:56:55,641 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 12:56:55,673 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 12:56:55,877 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 12:56:55,880 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 12:56:55,963 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 12:56:55,993 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57186.
[INFO] 2019-01-19 12:56:55,994 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:57186
[INFO] 2019-01-19 12:56:55,996 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 12:56:55,998 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 57186, None)
[INFO] 2019-01-19 12:56:56,001 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:57186 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 57186, None)
[INFO] 2019-01-19 12:56:56,006 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 57186, None)
[INFO] 2019-01-19 12:56:56,006 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 57186, None)
[INFO] 2019-01-19 12:56:56,252 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 12:56:56,485 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 12:56:57,064 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 12:56:57,081 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 12:56:57,082 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 12:56:57,082 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 12:56:57,083 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 12:56:57,090 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 12:56:57,194 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 12:56:57,245 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 12:56:57,247 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:57186 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:56:57,250 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:56:57,254 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 12:56:57,256 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 12:56:57,321 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 12:56:57,331 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 12:56:57,417 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 12:56:57,543 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 12:56:57,552 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 269 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:56:57,554 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:56:57,556 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.288 s
[INFO] 2019-01-19 12:56:57,562 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.497667 s
[INFO] 2019-01-19 12:56:57,964 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:57186 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:56:59,176 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:56:59,180 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 12:56:59,182 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 12:56:59,183 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 12:56:59,227 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 12:56:59,348 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 48
[INFO] 2019-01-19 12:56:59,601 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 216.994518 ms
[INFO] 2019-01-19 12:56:59,604 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 12:56:59,642 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 31.177339 ms
[INFO] 2019-01-19 12:56:59,671 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 278.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 12:56:59,687 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 12:56:59,688 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on 192.168.99.1:57186 (size: 23.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:56:59,690 org.apache.spark.SparkContext logInfo - Created broadcast 1 from rdd at LayerSample.scala:49
[INFO] 2019-01-19 12:56:59,700 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:56:59,795 org.apache.spark.SparkContext logInfo - Starting job: collect at LayerSample.scala:49
[INFO] 2019-01-19 12:56:59,798 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 6 (rdd at LayerSample.scala:49)
[INFO] 2019-01-19 12:56:59,799 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at LayerSample.scala:49) with 200 output partitions
[INFO] 2019-01-19 12:56:59,799 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 2 (collect at LayerSample.scala:49)
[INFO] 2019-01-19 12:56:59,800 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 1)
[INFO] 2019-01-19 12:56:59,800 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 1)
[INFO] 2019-01-19 12:56:59,801 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at rdd at LayerSample.scala:49), which has no missing parents
[INFO] 2019-01-19 12:56:59,808 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2 stored as values in memory (estimated size 17.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 12:56:59,810 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 1991.7 MB)
[INFO] 2019-01-19 12:56:59,811 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_2_piece0 in memory on 192.168.99.1:57186 (size: 8.0 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:56:59,812 org.apache.spark.SparkContext logInfo - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:56:59,813 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at rdd at LayerSample.scala:49)
[INFO] 2019-01-19 12:56:59,814 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2019-01-19 12:56:59,818 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6622 bytes)
[INFO] 2019-01-19 12:56:59,819 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2019-01-19 12:56:59,854 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.084494 ms
[INFO] 2019-01-19 12:56:59,869 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.07169 ms
[INFO] 2019-01-19 12:56:59,879 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.257564 ms
[INFO] 2019-01-19 12:56:59,888 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:56:59,978 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 12:57:00,430 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 2617 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,432 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 618 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:00,433 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:00,434 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 1 (rdd at LayerSample.scala:49) finished in 0.620 s
[INFO] 2019-01-19 12:57:00,434 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:00,435 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:00,436 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 2)
[INFO] 2019-01-19 12:57:00,437 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:00,440 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 2 (MapPartitionsRDD[11] at map at LayerSample.scala:49), which has no missing parents
[INFO] 2019-01-19 12:57:00,457 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3 stored as values in memory (estimated size 19.5 KB, free 1991.7 MB)
[INFO] 2019-01-19 12:57:00,458 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 12:57:00,459 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_3_piece0 in memory on 192.168.99.1:57186 (size: 9.4 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:57:00,460 org.apache.spark.SparkContext logInfo - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:00,461 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at LayerSample.scala:49)
[INFO] 2019-01-19 12:57:00,461 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 2.0 with 200 tasks
[INFO] 2019-01-19 12:57:00,467 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,468 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,470 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 2.0 (TID 2)
[INFO] 2019-01-19 12:57:00,485 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 2.0 (TID 3)
[INFO] 2019-01-19 12:57:00,490 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,495 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 10 ms
[INFO] 2019-01-19 12:57:00,500 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,501 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,518 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 8.397221 ms
[INFO] 2019-01-19 12:57:00,529 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 2.0 (TID 3). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,530 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 2.0 (TID 2). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,531 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,533 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,533 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 2.0 (TID 3) in 65 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 12:57:00,534 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 2.0 (TID 4)
[INFO] 2019-01-19 12:57:00,535 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 2.0 (TID 5)
[INFO] 2019-01-19 12:57:00,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,545 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 2.0 (TID 4). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,546 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,547 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 2.0 (TID 4) in 16 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 12:57:00,548 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 2.0 (TID 6)
[INFO] 2019-01-19 12:57:00,551 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,552 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,551 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,554 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 12:57:00,556 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 2.0 (TID 5). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,558 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 2.0 (TID 6). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,559 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,560 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,561 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 2.0 (TID 5) in 29 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 12:57:00,562 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 2.0 (TID 6) in 17 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 12:57:00,562 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 2.0 (TID 7)
[INFO] 2019-01-19 12:57:00,564 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 2.0 (TID 8)
[INFO] 2019-01-19 12:57:00,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,571 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,571 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,573 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 2.0 (TID 8). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,576 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,577 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 2.0 (TID 2) in 111 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 12:57:00,577 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 2.0 (TID 7). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,578 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 2.0 (TID 9)
[INFO] 2019-01-19 12:57:00,578 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 2.0 (TID 8) in 18 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 12:57:00,581 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,584 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,584 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,586 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 2.0 (TID 7) in 27 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 12:57:00,587 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 2.0 (TID 9). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,587 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 2.0 (TID 10)
[INFO] 2019-01-19 12:57:00,589 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,590 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 2.0 (TID 9) in 15 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 12:57:00,591 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 2.0 (TID 11)
[INFO] 2019-01-19 12:57:00,592 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,592 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,594 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,594 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,597 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 2.0 (TID 11). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,598 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,599 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 2.0 (TID 12)
[INFO] 2019-01-19 12:57:00,599 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 2.0 (TID 11) in 11 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 12:57:00,602 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,603 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,604 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 2.0 (TID 10). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,605 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,606 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 2.0 (TID 10) in 26 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 12:57:00,606 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 2.0 (TID 13)
[INFO] 2019-01-19 12:57:00,610 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,611 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,614 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 2.0 (TID 13). 2834 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,615 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,615 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 2.0 (TID 14)
[INFO] 2019-01-19 12:57:00,615 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 2.0 (TID 13) in 11 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 12:57:00,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,620 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 2.0 (TID 12). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,623 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 2.0 (TID 14). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,624 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,625 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 2.0 (TID 15)
[INFO] 2019-01-19 12:57:00,625 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,628 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 2.0 (TID 12) in 30 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 12:57:00,628 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 2.0 (TID 16)
[INFO] 2019-01-19 12:57:00,630 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,632 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:00,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,647 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 2.0 (TID 14) in 33 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 12:57:00,647 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 2.0 (TID 16). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,648 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 2.0 (TID 15). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,649 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,650 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,651 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 2.0 (TID 16) in 27 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 12:57:00,655 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 2.0 (TID 15) in 33 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 12:57:00,655 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 2.0 (TID 17)
[INFO] 2019-01-19 12:57:00,658 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 2.0 (TID 18)
[INFO] 2019-01-19 12:57:00,660 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,660 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,663 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,663 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,667 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 2.0 (TID 18). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,672 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,673 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 2.0 (TID 18) in 23 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 12:57:00,673 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 2.0 (TID 19)
[INFO] 2019-01-19 12:57:00,680 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 2.0 (TID 17). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,681 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,682 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:00,685 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 2.0 (TID 19). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,685 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 2.0 (TID 20)
[INFO] 2019-01-19 12:57:00,685 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 2.0 (TID 17) in 36 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 12:57:00,688 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,689 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 2.0 (TID 19) in 21 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 12:57:00,690 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,690 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:00,694 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 2.0 (TID 21)
[INFO] 2019-01-19 12:57:00,696 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 2.0 (TID 20). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,698 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,698 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,698 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 2.0 (TID 20) in 18 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 12:57:00,701 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 2.0 (TID 22)
[INFO] 2019-01-19 12:57:00,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,709 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 2.0 (TID 22). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,710 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,711 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 2.0 (TID 22) in 13 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 12:57:00,711 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 2.0 (TID 23)
[INFO] 2019-01-19 12:57:00,715 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,715 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,719 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 2.0 (TID 23). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,719 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,720 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 2.0 (TID 23) in 10 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 12:57:00,720 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 2.0 (TID 24)
[INFO] 2019-01-19 12:57:00,723 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,724 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,728 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 2.0 (TID 24). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,730 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 2.0 (TID 24) in 11 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 12:57:00,730 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 2.0 (TID 25)
[INFO] 2019-01-19 12:57:00,732 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 2.0 (TID 21). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,733 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,733 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 2.0 (TID 26)
[INFO] 2019-01-19 12:57:00,733 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 2.0 (TID 21) in 46 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 12:57:00,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,742 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 2.0 (TID 26). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,743 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,744 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 2.0 (TID 27)
[INFO] 2019-01-19 12:57:00,744 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 2.0 (TID 26) in 12 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 12:57:00,747 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,747 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,748 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,748 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,751 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 2.0 (TID 27). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,753 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 2.0 (TID 25). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,753 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,754 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 2.0 (TID 28)
[INFO] 2019-01-19 12:57:00,754 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,756 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 2.0 (TID 25) in 27 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 12:57:00,756 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 2.0 (TID 29)
[INFO] 2019-01-19 12:57:00,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,759 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,760 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,760 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,762 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 2.0 (TID 28). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,763 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 2.0 (TID 27) in 20 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 12:57:00,765 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,766 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 2.0 (TID 28) in 13 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 12:57:00,766 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 2.0 (TID 30)
[INFO] 2019-01-19 12:57:00,766 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 2.0 (TID 29). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,769 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,772 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 2.0 (TID 29) in 17 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 12:57:00,772 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 2.0 (TID 30). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,773 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 2.0 (TID 31)
[INFO] 2019-01-19 12:57:00,776 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,776 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 2.0 (TID 30) in 12 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 12:57:00,777 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,777 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,777 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 2.0 (TID 32)
[INFO] 2019-01-19 12:57:00,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,784 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 2.0 (TID 32). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,785 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,785 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 2.0 (TID 31). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,785 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 2.0 (TID 32) in 10 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 12:57:00,786 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 2.0 (TID 33)
[INFO] 2019-01-19 12:57:00,787 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,789 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 2.0 (TID 31) in 21 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 12:57:00,789 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 2.0 (TID 34)
[INFO] 2019-01-19 12:57:00,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,793 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,793 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,797 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 2.0 (TID 34). 2823 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,797 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 2.0 (TID 33). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,798 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,799 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,799 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 2.0 (TID 35)
[INFO] 2019-01-19 12:57:00,800 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 2.0 (TID 33) in 16 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 12:57:00,802 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 2.0 (TID 34) in 16 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 12:57:00,802 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 2.0 (TID 36)
[INFO] 2019-01-19 12:57:00,803 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,803 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,805 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 2.0 (TID 35). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,807 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,808 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 2.0 (TID 35) in 10 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 12:57:00,809 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,809 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,810 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 2.0 (TID 37)
[INFO] 2019-01-19 12:57:00,811 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 2.0 (TID 36). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,812 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,814 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 2.0 (TID 36) in 15 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 12:57:00,814 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 2.0 (TID 38)
[INFO] 2019-01-19 12:57:00,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,816 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:00,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,819 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 2.0 (TID 37). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,821 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 2.0 (TID 38). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 2.0 (TID 37) in 16 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 12:57:00,822 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 2.0 (TID 39)
[INFO] 2019-01-19 12:57:00,826 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,826 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,831 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 2.0 (TID 39). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,832 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,833 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,850 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 2.0 (TID 38) in 38 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 12:57:00,851 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 2.0 (TID 39) in 32 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 12:57:00,851 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 2.0 (TID 40)
[INFO] 2019-01-19 12:57:00,855 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,855 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,861 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 2.0 (TID 41)
[INFO] 2019-01-19 12:57:00,861 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 2.0 (TID 40). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,865 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,867 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 2.0 (TID 40) in 35 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 12:57:00,867 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 2.0 (TID 42)
[INFO] 2019-01-19 12:57:00,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,867 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 2.0 (TID 41). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,874 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,874 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 2.0 (TID 41) in 41 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 12:57:00,875 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 2.0 (TID 43)
[INFO] 2019-01-19 12:57:00,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,884 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 2.0 (TID 43). 2744 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,885 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,886 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 2.0 (TID 43) in 12 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 12:57:00,886 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 2.0 (TID 44)
[INFO] 2019-01-19 12:57:00,889 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,890 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,890 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 2.0 (TID 42). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,893 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 2.0 (TID 45, localhost, executor driver, partition 44, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,894 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 2.0 (TID 44). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,895 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 2.0 (TID 42) in 31 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 12:57:00,898 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 2.0 (TID 46, localhost, executor driver, partition 45, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,898 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 2.0 (TID 46)
[INFO] 2019-01-19 12:57:00,898 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 2.0 (TID 44) in 14 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 12:57:00,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,904 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 2.0 (TID 46). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,905 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 2.0 (TID 47, localhost, executor driver, partition 46, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,905 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 2.0 (TID 47)
[INFO] 2019-01-19 12:57:00,905 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 2.0 (TID 46) in 7 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 12:57:00,910 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,910 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,913 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 2.0 (TID 47). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,913 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 2.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,914 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 2.0 (TID 47) in 10 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 12:57:00,914 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 2.0 (TID 48)
[INFO] 2019-01-19 12:57:00,915 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 2.0 (TID 45)
[INFO] 2019-01-19 12:57:00,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,921 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 2.0 (TID 48). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,923 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 2.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,924 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 2.0 (TID 48) in 11 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 12:57:00,926 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 2.0 (TID 49)
[INFO] 2019-01-19 12:57:00,929 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,929 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,930 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,932 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 12:57:00,933 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 2.0 (TID 49). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,934 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 2.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,935 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 2.0 (TID 49) in 12 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 12:57:00,935 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 2.0 (TID 50)
[INFO] 2019-01-19 12:57:00,938 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,938 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,940 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 2.0 (TID 50). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,943 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 2.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,944 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 2.0 (TID 50) in 10 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 12:57:00,945 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 2.0 (TID 45). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,946 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 2.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,947 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 2.0 (TID 45) in 55 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 12:57:00,948 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 2.0 (TID 52)
[INFO] 2019-01-19 12:57:00,951 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,951 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,955 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 2.0 (TID 52). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,956 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 2.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,956 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 2.0 (TID 53)
[INFO] 2019-01-19 12:57:00,956 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 2.0 (TID 52) in 10 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 12:57:00,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,963 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 2.0 (TID 53). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,964 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 2.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,964 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 2.0 (TID 53) in 8 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 12:57:00,964 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 2.0 (TID 54)
[INFO] 2019-01-19 12:57:00,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,970 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 2.0 (TID 54). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,971 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 2.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,971 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 2.0 (TID 54) in 8 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 12:57:00,971 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 2.0 (TID 55)
[INFO] 2019-01-19 12:57:00,975 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,975 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:00,978 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 2.0 (TID 55). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,978 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 2.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,979 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 2.0 (TID 55) in 9 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 12:57:00,979 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 2.0 (TID 56)
[INFO] 2019-01-19 12:57:00,981 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 2.0 (TID 51)
[INFO] 2019-01-19 12:57:00,984 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,985 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,987 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 2.0 (TID 51). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,988 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 2.0 (TID 57, localhost, executor driver, partition 56, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,989 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 2.0 (TID 51) in 47 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 12:57:00,989 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 2.0 (TID 57)
[INFO] 2019-01-19 12:57:00,991 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,992 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:00,994 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 2.0 (TID 57). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:00,995 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 2.0 (TID 58, localhost, executor driver, partition 57, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:00,995 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 2.0 (TID 57) in 8 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 12:57:00,995 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 2.0 (TID 58)
[INFO] 2019-01-19 12:57:00,999 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:00,999 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,019 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 2.0 (TID 58). 2809 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,021 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 2.0 (TID 59, localhost, executor driver, partition 58, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,023 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 2.0 (TID 56). 2730 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,023 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 2.0 (TID 59)
[INFO] 2019-01-19 12:57:01,024 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_2_piece0 on 192.168.99.1:57186 in memory (size: 8.0 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:57:01,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,027 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 2.0 (TID 60, localhost, executor driver, partition 59, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,028 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 2.0 (TID 59). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,028 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 2.0 (TID 56) in 50 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 12:57:01,029 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 2.0 (TID 61, localhost, executor driver, partition 60, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,030 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 2.0 (TID 58) in 36 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 12:57:01,030 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 2.0 (TID 59) in 10 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 12:57:01,031 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 2.0 (TID 60)
[INFO] 2019-01-19 12:57:01,031 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 2.0 (TID 61)
[INFO] 2019-01-19 12:57:01,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,034 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,035 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 2.0 (TID 60). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,037 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 2.0 (TID 62, localhost, executor driver, partition 61, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,038 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 2.0 (TID 61). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,039 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 2.0 (TID 60) in 15 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 12:57:01,039 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 2.0 (TID 62)
[INFO] 2019-01-19 12:57:01,039 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 2.0 (TID 63, localhost, executor driver, partition 62, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,041 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 2.0 (TID 61) in 12 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 12:57:01,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,042 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,042 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 2.0 (TID 63)
[INFO] 2019-01-19 12:57:01,048 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,048 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,051 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 2.0 (TID 63). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,054 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 2.0 (TID 62). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,055 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 2.0 (TID 64, localhost, executor driver, partition 63, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,057 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 2.0 (TID 65, localhost, executor driver, partition 64, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,058 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 2.0 (TID 63) in 19 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 12:57:01,059 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 2.0 (TID 62) in 22 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 12:57:01,060 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 2.0 (TID 65)
[INFO] 2019-01-19 12:57:01,063 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 2.0 (TID 64)
[INFO] 2019-01-19 12:57:01,065 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,065 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,066 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,066 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,068 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 2.0 (TID 64). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,069 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 2.0 (TID 66, localhost, executor driver, partition 65, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,070 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 2.0 (TID 64) in 15 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 12:57:01,071 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 2.0 (TID 66)
[INFO] 2019-01-19 12:57:01,074 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,075 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:01,077 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 2.0 (TID 65). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,077 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 2.0 (TID 66). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,078 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 2.0 (TID 67, localhost, executor driver, partition 66, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,079 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 2.0 (TID 67)
[INFO] 2019-01-19 12:57:01,079 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 2.0 (TID 66) in 11 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 12:57:01,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,082 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 2.0 (TID 68, localhost, executor driver, partition 67, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,083 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 2.0 (TID 65) in 27 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 12:57:01,083 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 2.0 (TID 68)
[INFO] 2019-01-19 12:57:01,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,088 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 2.0 (TID 68). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,089 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 2.0 (TID 69, localhost, executor driver, partition 68, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,089 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 2.0 (TID 69)
[INFO] 2019-01-19 12:57:01,090 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 2.0 (TID 68) in 9 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 12:57:01,092 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,094 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 2.0 (TID 67). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,095 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 2.0 (TID 69). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,095 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 2.0 (TID 70, localhost, executor driver, partition 69, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,095 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 2.0 (TID 67) in 17 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 12:57:01,096 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 2.0 (TID 70)
[INFO] 2019-01-19 12:57:01,099 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,100 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 2.0 (TID 71, localhost, executor driver, partition 70, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,101 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 2.0 (TID 69) in 12 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 12:57:01,101 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 2.0 (TID 71)
[INFO] 2019-01-19 12:57:01,101 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 2.0 (TID 70). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,102 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 2.0 (TID 72, localhost, executor driver, partition 71, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,104 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 2.0 (TID 70) in 8 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 12:57:01,104 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 2.0 (TID 72)
[INFO] 2019-01-19 12:57:01,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,105 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,107 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,107 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,109 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 2.0 (TID 71). 2744 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,111 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 2.0 (TID 72). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,112 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 2.0 (TID 73, localhost, executor driver, partition 72, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,112 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 2.0 (TID 73)
[INFO] 2019-01-19 12:57:01,112 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 2.0 (TID 74, localhost, executor driver, partition 73, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 2.0 (TID 72) in 12 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 12:57:01,115 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 2.0 (TID 71) in 15 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 12:57:01,114 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,115 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,115 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 2.0 (TID 74)
[INFO] 2019-01-19 12:57:01,117 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 2.0 (TID 73). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,118 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,118 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,119 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 2.0 (TID 75, localhost, executor driver, partition 74, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,120 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 2.0 (TID 73) in 9 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 12:57:01,122 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 2.0 (TID 74). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,122 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 2.0 (TID 75)
[INFO] 2019-01-19 12:57:01,124 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 2.0 (TID 76, localhost, executor driver, partition 75, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,126 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 2.0 (TID 74) in 14 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 12:57:01,127 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 2.0 (TID 76)
[INFO] 2019-01-19 12:57:01,126 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,127 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,129 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 2.0 (TID 75). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,130 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 2.0 (TID 77, localhost, executor driver, partition 76, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,132 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 2.0 (TID 75) in 15 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 12:57:01,136 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 2.0 (TID 77)
[INFO] 2019-01-19 12:57:01,139 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,139 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,156 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 2.0 (TID 77). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,156 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 2.0 (TID 78, localhost, executor driver, partition 77, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,157 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 2.0 (TID 77) in 27 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 12:57:01,158 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 2.0 (TID 78)
[INFO] 2019-01-19 12:57:01,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,163 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 2.0 (TID 78). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,165 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 2.0 (TID 79, localhost, executor driver, partition 78, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,165 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 2.0 (TID 76). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,166 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 2.0 (TID 79)
[INFO] 2019-01-19 12:57:01,166 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 2.0 (TID 78) in 10 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 12:57:01,168 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 2.0 (TID 80, localhost, executor driver, partition 79, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,168 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,168 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,169 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 2.0 (TID 76) in 46 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 12:57:01,170 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 2.0 (TID 79). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,171 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 2.0 (TID 80)
[INFO] 2019-01-19 12:57:01,171 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 2.0 (TID 81, localhost, executor driver, partition 80, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,172 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 2.0 (TID 79) in 7 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 12:57:01,173 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 2.0 (TID 81)
[INFO] 2019-01-19 12:57:01,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,176 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,176 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,178 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 2.0 (TID 81). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,179 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 2.0 (TID 80). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,180 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 2.0 (TID 82, localhost, executor driver, partition 81, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,180 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 2.0 (TID 82)
[INFO] 2019-01-19 12:57:01,180 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 2.0 (TID 80) in 14 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 12:57:01,182 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 2.0 (TID 83, localhost, executor driver, partition 82, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,182 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 2.0 (TID 81) in 11 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 12:57:01,183 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,183 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,183 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 2.0 (TID 83)
[INFO] 2019-01-19 12:57:01,185 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 2.0 (TID 82). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,186 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 2.0 (TID 84, localhost, executor driver, partition 83, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,187 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,187 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,188 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 2.0 (TID 82) in 8 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 12:57:01,188 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 2.0 (TID 84)
[INFO] 2019-01-19 12:57:01,190 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 2.0 (TID 83). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,191 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,192 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,194 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 2.0 (TID 84). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,195 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 2.0 (TID 85, localhost, executor driver, partition 84, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,195 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 2.0 (TID 86, localhost, executor driver, partition 85, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,196 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 2.0 (TID 85)
[INFO] 2019-01-19 12:57:01,196 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 2.0 (TID 83) in 15 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 12:57:01,196 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 2.0 (TID 84) in 10 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 12:57:01,197 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 2.0 (TID 86)
[INFO] 2019-01-19 12:57:01,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,200 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 2.0 (TID 85). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,201 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,201 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,202 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 2.0 (TID 87, localhost, executor driver, partition 86, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,204 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 2.0 (TID 85) in 10 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 12:57:01,205 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 2.0 (TID 87)
[INFO] 2019-01-19 12:57:01,204 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 2.0 (TID 86). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,206 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 2.0 (TID 88, localhost, executor driver, partition 87, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,207 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 2.0 (TID 86) in 12 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 12:57:01,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,208 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,208 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 2.0 (TID 88)
[INFO] 2019-01-19 12:57:01,209 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 2.0 (TID 87). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,210 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 2.0 (TID 89, localhost, executor driver, partition 88, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,211 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 2.0 (TID 87) in 9 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 12:57:01,211 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,211 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,213 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 2.0 (TID 88). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,214 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 2.0 (TID 89)
[INFO] 2019-01-19 12:57:01,215 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 2.0 (TID 90, localhost, executor driver, partition 89, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,215 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 2.0 (TID 88) in 9 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 12:57:01,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,216 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 2.0 (TID 90)
[INFO] 2019-01-19 12:57:01,218 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 2.0 (TID 89). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,219 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 2.0 (TID 91, localhost, executor driver, partition 90, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,219 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,219 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,219 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 2.0 (TID 89) in 9 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 12:57:01,220 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 2.0 (TID 91)
[INFO] 2019-01-19 12:57:01,222 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 2.0 (TID 90). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,222 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 2.0 (TID 92, localhost, executor driver, partition 91, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,223 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 2.0 (TID 90) in 8 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 12:57:01,223 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 2.0 (TID 92)
[INFO] 2019-01-19 12:57:01,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,227 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 2.0 (TID 92). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,228 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 2.0 (TID 93, localhost, executor driver, partition 92, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,228 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 2.0 (TID 91). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,228 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 2.0 (TID 93)
[INFO] 2019-01-19 12:57:01,228 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 2.0 (TID 92) in 6 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 12:57:01,230 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 2.0 (TID 94, localhost, executor driver, partition 93, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,231 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 2.0 (TID 91) in 13 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 12:57:01,231 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 2.0 (TID 94)
[INFO] 2019-01-19 12:57:01,233 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 2.0 (TID 93). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,233 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 2.0 (TID 95, localhost, executor driver, partition 94, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,234 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 2.0 (TID 93) in 7 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 12:57:01,236 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 2.0 (TID 94). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,237 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 2.0 (TID 95)
[INFO] 2019-01-19 12:57:01,238 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 2.0 (TID 96, localhost, executor driver, partition 95, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,240 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,240 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 2.0 (TID 96)
[INFO] 2019-01-19 12:57:01,242 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 2.0 (TID 95). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,239 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 2.0 (TID 94) in 9 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 12:57:01,243 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 2.0 (TID 97, localhost, executor driver, partition 96, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,246 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 2.0 (TID 96). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,244 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 2.0 (TID 95) in 11 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 12:57:01,247 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 2.0 (TID 98, localhost, executor driver, partition 97, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,247 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 2.0 (TID 98)
[INFO] 2019-01-19 12:57:01,247 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 2.0 (TID 96) in 9 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 12:57:01,249 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,250 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,252 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 2.0 (TID 98). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,252 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 2.0 (TID 97)
[INFO] 2019-01-19 12:57:01,252 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 2.0 (TID 99, localhost, executor driver, partition 98, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,254 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 2.0 (TID 99)
[INFO] 2019-01-19 12:57:01,257 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,258 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,254 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 2.0 (TID 98) in 8 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 12:57:01,260 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 2.0 (TID 99). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,260 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,260 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,261 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 2.0 (TID 100, localhost, executor driver, partition 99, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,263 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 2.0 (TID 97). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,264 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 2.0 (TID 99) in 12 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 12:57:01,265 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 2.0 (TID 100)
[INFO] 2019-01-19 12:57:01,268 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,268 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,271 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 2.0 (TID 100). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,271 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 2.0 (TID 101, localhost, executor driver, partition 100, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,272 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 2.0 (TID 101)
[INFO] 2019-01-19 12:57:01,272 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 2.0 (TID 102, localhost, executor driver, partition 101, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,273 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 2.0 (TID 100) in 12 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 12:57:01,273 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 2.0 (TID 102)
[INFO] 2019-01-19 12:57:01,274 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,275 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,277 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 2.0 (TID 97) in 34 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 12:57:01,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,279 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 2.0 (TID 102). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,283 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 2.0 (TID 103, localhost, executor driver, partition 102, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,284 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 2.0 (TID 103)
[INFO] 2019-01-19 12:57:01,284 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 2.0 (TID 102) in 12 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 12:57:01,286 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,287 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,287 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 2.0 (TID 101). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,287 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 2.0 (TID 104, localhost, executor driver, partition 103, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,289 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 2.0 (TID 101) in 18 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 12:57:01,289 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 2.0 (TID 104)
[INFO] 2019-01-19 12:57:01,289 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 2.0 (TID 103). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,290 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 2.0 (TID 105, localhost, executor driver, partition 104, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,290 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 2.0 (TID 103) in 7 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 12:57:01,291 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 2.0 (TID 105)
[INFO] 2019-01-19 12:57:01,295 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,295 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,295 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,296 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,298 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 2.0 (TID 105). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,299 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 2.0 (TID 104). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,299 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 2.0 (TID 106, localhost, executor driver, partition 105, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,300 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 2.0 (TID 106)
[INFO] 2019-01-19 12:57:01,300 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 2.0 (TID 107, localhost, executor driver, partition 106, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,302 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 2.0 (TID 105) in 13 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 12:57:01,302 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,302 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,303 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 2.0 (TID 104) in 16 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 12:57:01,303 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 2.0 (TID 107)
[INFO] 2019-01-19 12:57:01,305 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 2.0 (TID 106). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,308 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,308 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,309 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 2.0 (TID 108, localhost, executor driver, partition 107, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,310 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 2.0 (TID 107). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,310 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 2.0 (TID 108)
[INFO] 2019-01-19 12:57:01,310 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 2.0 (TID 106) in 11 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 12:57:01,312 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 2.0 (TID 109, localhost, executor driver, partition 108, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,312 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 2.0 (TID 107) in 12 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 12:57:01,312 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,313 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,313 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 2.0 (TID 109)
[INFO] 2019-01-19 12:57:01,314 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 2.0 (TID 108). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,316 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,316 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,319 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 2.0 (TID 110, localhost, executor driver, partition 109, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,319 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 2.0 (TID 109). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,320 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 2.0 (TID 110)
[INFO] 2019-01-19 12:57:01,320 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 2.0 (TID 108) in 11 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 12:57:01,321 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 2.0 (TID 111, localhost, executor driver, partition 110, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,322 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 2.0 (TID 109) in 11 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 12:57:01,322 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 2.0 (TID 111)
[INFO] 2019-01-19 12:57:01,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,323 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,325 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 2.0 (TID 110). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,326 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 2.0 (TID 112, localhost, executor driver, partition 111, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,326 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,327 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,329 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 2.0 (TID 110) in 10 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 12:57:01,329 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 2.0 (TID 112)
[INFO] 2019-01-19 12:57:01,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,333 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 2.0 (TID 111). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,335 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 2.0 (TID 112). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,336 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 2.0 (TID 113, localhost, executor driver, partition 112, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,336 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 2.0 (TID 114, localhost, executor driver, partition 113, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,337 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 2.0 (TID 111) in 17 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 12:57:01,337 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 2.0 (TID 112) in 11 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 12:57:01,337 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 2.0 (TID 113)
[INFO] 2019-01-19 12:57:01,338 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 2.0 (TID 114)
[INFO] 2019-01-19 12:57:01,343 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,343 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,343 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,344 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,346 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 2.0 (TID 114). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,346 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 2.0 (TID 113). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 2.0 (TID 115, localhost, executor driver, partition 114, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,348 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 2.0 (TID 116, localhost, executor driver, partition 115, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,348 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 2.0 (TID 115)
[INFO] 2019-01-19 12:57:01,349 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 2.0 (TID 116)
[INFO] 2019-01-19 12:57:01,350 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,350 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,348 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 2.0 (TID 113) in 13 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 12:57:01,353 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,353 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,355 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 2.0 (TID 115). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,356 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 2.0 (TID 114) in 20 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 12:57:01,358 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 2.0 (TID 117, localhost, executor driver, partition 116, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,359 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 2.0 (TID 116). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,360 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 2.0 (TID 118, localhost, executor driver, partition 117, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 2.0 (TID 115) in 15 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 12:57:01,362 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 2.0 (TID 117)
[INFO] 2019-01-19 12:57:01,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 2.0 (TID 116) in 15 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 12:57:01,363 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 2.0 (TID 118)
[INFO] 2019-01-19 12:57:01,366 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,366 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,368 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 2.0 (TID 118). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,368 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 2.0 (TID 119, localhost, executor driver, partition 118, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,369 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 2.0 (TID 118) in 10 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 12:57:01,369 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 2.0 (TID 119)
[INFO] 2019-01-19 12:57:01,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,374 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 2.0 (TID 119). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,375 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 2.0 (TID 120, localhost, executor driver, partition 119, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,376 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 2.0 (TID 119) in 8 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 12:57:01,376 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 2.0 (TID 120)
[INFO] 2019-01-19 12:57:01,378 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 2.0 (TID 117). 2744 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,378 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,379 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 2.0 (TID 121, localhost, executor driver, partition 120, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,379 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 2.0 (TID 117) in 22 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 12:57:01,380 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 2.0 (TID 121)
[INFO] 2019-01-19 12:57:01,381 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 2.0 (TID 120). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,381 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 2.0 (TID 122, localhost, executor driver, partition 121, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,382 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 2.0 (TID 120) in 7 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 12:57:01,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,385 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 2.0 (TID 122)
[INFO] 2019-01-19 12:57:01,386 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 2.0 (TID 121). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,387 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 2.0 (TID 123, localhost, executor driver, partition 122, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,387 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 2.0 (TID 121) in 8 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 12:57:01,388 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 2.0 (TID 123)
[INFO] 2019-01-19 12:57:01,390 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,390 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,390 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,391 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,394 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 2.0 (TID 122). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,393 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 2.0 (TID 123). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,395 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 2.0 (TID 122) in 14 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 12:57:01,396 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 2.0 (TID 124, localhost, executor driver, partition 123, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,397 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 2.0 (TID 125, localhost, executor driver, partition 124, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,397 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 2.0 (TID 124)
[INFO] 2019-01-19 12:57:01,398 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 2.0 (TID 123) in 11 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 12:57:01,399 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 2.0 (TID 125)
[INFO] 2019-01-19 12:57:01,399 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,399 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,401 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 2.0 (TID 124). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,405 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 2.0 (TID 125). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,405 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 2.0 (TID 126, localhost, executor driver, partition 125, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,406 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 2.0 (TID 127, localhost, executor driver, partition 126, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,407 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 2.0 (TID 124) in 12 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 12:57:01,407 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 2.0 (TID 125) in 11 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 12:57:01,407 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 2.0 (TID 126)
[INFO] 2019-01-19 12:57:01,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,411 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 2.0 (TID 127)
[INFO] 2019-01-19 12:57:01,412 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 2.0 (TID 126). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,414 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 2.0 (TID 128, localhost, executor driver, partition 127, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,415 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 2.0 (TID 126) in 10 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 12:57:01,415 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 2.0 (TID 128)
[INFO] 2019-01-19 12:57:01,417 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 2.0 (TID 127). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,418 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 2.0 (TID 129, localhost, executor driver, partition 128, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,419 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 2.0 (TID 127) in 13 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 12:57:01,420 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,420 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,422 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 2.0 (TID 129)
[INFO] 2019-01-19 12:57:01,424 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 2.0 (TID 128). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,425 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 2.0 (TID 130, localhost, executor driver, partition 129, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,427 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 2.0 (TID 128) in 14 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 12:57:01,427 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 2.0 (TID 130)
[INFO] 2019-01-19 12:57:01,429 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 2.0 (TID 129). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,431 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 2.0 (TID 131, localhost, executor driver, partition 130, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,431 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 2.0 (TID 129) in 13 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 12:57:01,431 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,432 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,433 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 2.0 (TID 131)
[INFO] 2019-01-19 12:57:01,433 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 2.0 (TID 130). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,434 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 2.0 (TID 132, localhost, executor driver, partition 131, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,435 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 2.0 (TID 130) in 10 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 12:57:01,435 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,435 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,435 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 2.0 (TID 132)
[INFO] 2019-01-19 12:57:01,437 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 2.0 (TID 131). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,437 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 2.0 (TID 133, localhost, executor driver, partition 132, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,437 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,438 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,438 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 2.0 (TID 133)
[INFO] 2019-01-19 12:57:01,439 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 2.0 (TID 132). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,440 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,440 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,438 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 2.0 (TID 131) in 8 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 12:57:01,441 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 2.0 (TID 134, localhost, executor driver, partition 133, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,442 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 2.0 (TID 133). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,442 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 2.0 (TID 134)
[INFO] 2019-01-19 12:57:01,442 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 2.0 (TID 132) in 8 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 12:57:01,443 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 2.0 (TID 135, localhost, executor driver, partition 134, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,443 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 2.0 (TID 133) in 6 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 12:57:01,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,444 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 2.0 (TID 135)
[INFO] 2019-01-19 12:57:01,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,447 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 2.0 (TID 134). 2744 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,447 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 2.0 (TID 136, localhost, executor driver, partition 135, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,448 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 2.0 (TID 134) in 7 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 12:57:01,448 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 2.0 (TID 136)
[INFO] 2019-01-19 12:57:01,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:01,450 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,450 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,451 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 2.0 (TID 135). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,451 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 2.0 (TID 137, localhost, executor driver, partition 136, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,451 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 2.0 (TID 137)
[INFO] 2019-01-19 12:57:01,452 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 2.0 (TID 135) in 8 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 12:57:01,454 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 2.0 (TID 136). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,454 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,454 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,454 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 2.0 (TID 138, localhost, executor driver, partition 137, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,456 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 2.0 (TID 137). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,456 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 2.0 (TID 136) in 9 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 12:57:01,456 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 2.0 (TID 138)
[INFO] 2019-01-19 12:57:01,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,461 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 2.0 (TID 138). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,461 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 2.0 (TID 139, localhost, executor driver, partition 138, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,462 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 2.0 (TID 140, localhost, executor driver, partition 139, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,463 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 2.0 (TID 138) in 8 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 12:57:01,463 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 2.0 (TID 137) in 12 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 12:57:01,463 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 2.0 (TID 139)
[INFO] 2019-01-19 12:57:01,466 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,467 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,469 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 2.0 (TID 139). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,469 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 2.0 (TID 140)
[INFO] 2019-01-19 12:57:01,471 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,471 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,474 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 2.0 (TID 140). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,474 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 2.0 (TID 141, localhost, executor driver, partition 140, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,475 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 2.0 (TID 141)
[INFO] 2019-01-19 12:57:01,475 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 2.0 (TID 142, localhost, executor driver, partition 141, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 2.0 (TID 140) in 14 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 12:57:01,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 2.0 (TID 139) in 15 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 12:57:01,476 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 2.0 (TID 142)
[INFO] 2019-01-19 12:57:01,477 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,477 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,478 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,478 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,478 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 2.0 (TID 141). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,479 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 2.0 (TID 143, localhost, executor driver, partition 142, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,480 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 2.0 (TID 141) in 6 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 12:57:01,480 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 2.0 (TID 142). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,480 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 2.0 (TID 143)
[INFO] 2019-01-19 12:57:01,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,486 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 2.0 (TID 144, localhost, executor driver, partition 143, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,486 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 2.0 (TID 142) in 11 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 12:57:01,486 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 2.0 (TID 144)
[INFO] 2019-01-19 12:57:01,486 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 2.0 (TID 143). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,487 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 2.0 (TID 145, localhost, executor driver, partition 144, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,488 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 2.0 (TID 143) in 9 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 12:57:01,488 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 2.0 (TID 145)
[INFO] 2019-01-19 12:57:01,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,490 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,490 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,491 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 2.0 (TID 144). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,492 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 2.0 (TID 146, localhost, executor driver, partition 145, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,493 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 2.0 (TID 145). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,493 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 2.0 (TID 146)
[INFO] 2019-01-19 12:57:01,493 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 2.0 (TID 144) in 8 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 12:57:01,497 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,497 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,499 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 2.0 (TID 146). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,497 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 2.0 (TID 147, localhost, executor driver, partition 146, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,500 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 2.0 (TID 148, localhost, executor driver, partition 147, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,500 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 2.0 (TID 147)
[INFO] 2019-01-19 12:57:01,501 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 2.0 (TID 148)
[INFO] 2019-01-19 12:57:01,502 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,503 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,500 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 2.0 (TID 145) in 13 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 12:57:01,503 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 2.0 (TID 146) in 11 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 12:57:01,502 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:01,504 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 2.0 (TID 147). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,505 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 2.0 (TID 148). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,506 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 2.0 (TID 149, localhost, executor driver, partition 148, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,507 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 2.0 (TID 150, localhost, executor driver, partition 149, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,508 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 2.0 (TID 147) in 15 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 12:57:01,509 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 2.0 (TID 148) in 9 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 12:57:01,509 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 2.0 (TID 149)
[INFO] 2019-01-19 12:57:01,510 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 2.0 (TID 150)
[INFO] 2019-01-19 12:57:01,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,513 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 2.0 (TID 149). 2744 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,514 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 2.0 (TID 151, localhost, executor driver, partition 150, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,514 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 2.0 (TID 150). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,515 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 2.0 (TID 152, localhost, executor driver, partition 151, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,516 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 2.0 (TID 149) in 11 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 12:57:01,516 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 2.0 (TID 150) in 10 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 12:57:01,516 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 2.0 (TID 151)
[INFO] 2019-01-19 12:57:01,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,526 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 2.0 (TID 151). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,527 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 2.0 (TID 153, localhost, executor driver, partition 152, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,528 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 2.0 (TID 151) in 14 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 12:57:01,529 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 2.0 (TID 152)
[INFO] 2019-01-19 12:57:01,535 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,536 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 2.0 (TID 153)
[INFO] 2019-01-19 12:57:01,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,558 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 5 ms
[INFO] 2019-01-19 12:57:01,561 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 2.0 (TID 153). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,562 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 2.0 (TID 154, localhost, executor driver, partition 153, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,562 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 2.0 (TID 153) in 35 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 12:57:01,562 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 2.0 (TID 154)
[INFO] 2019-01-19 12:57:01,564 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,565 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 30 ms
[INFO] 2019-01-19 12:57:01,570 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 2.0 (TID 152). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,571 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 2.0 (TID 155, localhost, executor driver, partition 154, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,571 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 2.0 (TID 152) in 56 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 12:57:01,572 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 2.0 (TID 155)
[INFO] 2019-01-19 12:57:01,574 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,576 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 2.0 (TID 155). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,578 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 2.0 (TID 156, localhost, executor driver, partition 155, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,578 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 2.0 (TID 155) in 8 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 12:57:01,579 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 2.0 (TID 156)
[INFO] 2019-01-19 12:57:01,581 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,581 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,583 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 2.0 (TID 156). 2744 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,584 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 2.0 (TID 157, localhost, executor driver, partition 156, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,584 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 2.0 (TID 156) in 7 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 12:57:01,585 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 2.0 (TID 157)
[INFO] 2019-01-19 12:57:01,585 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 21 ms
[INFO] 2019-01-19 12:57:01,587 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,587 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,588 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 2.0 (TID 154). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,588 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 2.0 (TID 158, localhost, executor driver, partition 157, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,588 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 2.0 (TID 157). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,589 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 2.0 (TID 158)
[INFO] 2019-01-19 12:57:01,589 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 2.0 (TID 154) in 28 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 12:57:01,590 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 2.0 (TID 159, localhost, executor driver, partition 158, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,591 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,591 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,591 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 2.0 (TID 157) in 8 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 12:57:01,593 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 2.0 (TID 158). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,593 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 2.0 (TID 159)
[INFO] 2019-01-19 12:57:01,594 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 2.0 (TID 160, localhost, executor driver, partition 159, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,595 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 2.0 (TID 158) in 7 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 12:57:01,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,597 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 2.0 (TID 160)
[INFO] 2019-01-19 12:57:01,597 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 2.0 (TID 159). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,599 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 2.0 (TID 161, localhost, executor driver, partition 160, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,599 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 2.0 (TID 159) in 9 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 12:57:01,599 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,599 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,599 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 2.0 (TID 161)
[INFO] 2019-01-19 12:57:01,601 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 2.0 (TID 160). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,601 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 2.0 (TID 162, localhost, executor driver, partition 161, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,602 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 2.0 (TID 160) in 9 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 12:57:01,602 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 2.0 (TID 162)
[INFO] 2019-01-19 12:57:01,602 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,603 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,604 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 2.0 (TID 161). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,606 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,606 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,608 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 2.0 (TID 162). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 2.0 (TID 163, localhost, executor driver, partition 162, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 2.0 (TID 164, localhost, executor driver, partition 163, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,610 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 2.0 (TID 161) in 12 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 12:57:01,610 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 2.0 (TID 162) in 9 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 12:57:01,610 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 2.0 (TID 164)
[INFO] 2019-01-19 12:57:01,610 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 2.0 (TID 163)
[INFO] 2019-01-19 12:57:01,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,614 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 2.0 (TID 163). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,614 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 2.0 (TID 164). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,614 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 2.0 (TID 165, localhost, executor driver, partition 164, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,615 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 2.0 (TID 166, localhost, executor driver, partition 165, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,615 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 2.0 (TID 163) in 7 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 12:57:01,616 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 2.0 (TID 164) in 7 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 12:57:01,616 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 2.0 (TID 165)
[INFO] 2019-01-19 12:57:01,616 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 2.0 (TID 166)
[INFO] 2019-01-19 12:57:01,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,620 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 2.0 (TID 165). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,620 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 2.0 (TID 166). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,621 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 2.0 (TID 167, localhost, executor driver, partition 166, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,621 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 2.0 (TID 167)
[INFO] 2019-01-19 12:57:01,621 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 2.0 (TID 168, localhost, executor driver, partition 167, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,622 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 2.0 (TID 166) in 7 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 12:57:01,622 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 2.0 (TID 165) in 8 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 12:57:01,622 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 2.0 (TID 168)
[INFO] 2019-01-19 12:57:01,623 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,623 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,624 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,624 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,625 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 2.0 (TID 167). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,626 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 2.0 (TID 168). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,627 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 2.0 (TID 169, localhost, executor driver, partition 168, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,627 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 2.0 (TID 170, localhost, executor driver, partition 169, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,628 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 2.0 (TID 170)
[INFO] 2019-01-19 12:57:01,628 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 2.0 (TID 168) in 7 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 12:57:01,629 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 2.0 (TID 167) in 8 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 12:57:01,629 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,630 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,630 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 2.0 (TID 169)
[INFO] 2019-01-19 12:57:01,632 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 2.0 (TID 170). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,632 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,632 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,633 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 2.0 (TID 171, localhost, executor driver, partition 170, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,634 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 2.0 (TID 169). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,635 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 2.0 (TID 172, localhost, executor driver, partition 171, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,635 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 2.0 (TID 170) in 8 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 12:57:01,635 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 2.0 (TID 169) in 9 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 12:57:01,636 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 2.0 (TID 171)
[INFO] 2019-01-19 12:57:01,636 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 2.0 (TID 172)
[INFO] 2019-01-19 12:57:01,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,639 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 2.0 (TID 171). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,641 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 2.0 (TID 172). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,641 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 2.0 (TID 173, localhost, executor driver, partition 172, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,643 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 2.0 (TID 173)
[INFO] 2019-01-19 12:57:01,644 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 2.0 (TID 174, localhost, executor driver, partition 173, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,644 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 2.0 (TID 172) in 10 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 12:57:01,644 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 2.0 (TID 174)
[INFO] 2019-01-19 12:57:01,645 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,645 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,646 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,646 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,647 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 2.0 (TID 173). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,647 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 2.0 (TID 174). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,647 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 2.0 (TID 171) in 14 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 12:57:01,648 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 2.0 (TID 175, localhost, executor driver, partition 174, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,648 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 2.0 (TID 175)
[INFO] 2019-01-19 12:57:01,649 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 2.0 (TID 176, localhost, executor driver, partition 175, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,649 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 2.0 (TID 174) in 6 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 12:57:01,650 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,651 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,650 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 2.0 (TID 176)
[INFO] 2019-01-19 12:57:01,652 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 2.0 (TID 175). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,654 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,654 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,650 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 2.0 (TID 173) in 9 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 12:57:01,655 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 2.0 (TID 177, localhost, executor driver, partition 176, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,655 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 2.0 (TID 175) in 7 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 12:57:01,656 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 2.0 (TID 176). 2736 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,656 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 2.0 (TID 177)
[INFO] 2019-01-19 12:57:01,656 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 2.0 (TID 178, localhost, executor driver, partition 177, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,657 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 2.0 (TID 176) in 9 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 12:57:01,657 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 2.0 (TID 178)
[INFO] 2019-01-19 12:57:01,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,660 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,661 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 2.0 (TID 178). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,662 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,662 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,664 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 2.0 (TID 177). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,665 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 2.0 (TID 179, localhost, executor driver, partition 178, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,665 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 2.0 (TID 180, localhost, executor driver, partition 179, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,666 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 2.0 (TID 178) in 10 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 12:57:01,666 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 2.0 (TID 177) in 11 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 12:57:01,666 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 2.0 (TID 179)
[INFO] 2019-01-19 12:57:01,669 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,669 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,670 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 2.0 (TID 180)
[INFO] 2019-01-19 12:57:01,673 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,674 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,677 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 2.0 (TID 180). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,677 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 2.0 (TID 181, localhost, executor driver, partition 180, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,678 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 2.0 (TID 179). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,678 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 2.0 (TID 180) in 13 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 12:57:01,679 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 2.0 (TID 182, localhost, executor driver, partition 181, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,679 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 2.0 (TID 181)
[INFO] 2019-01-19 12:57:01,680 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 2.0 (TID 179) in 16 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 12:57:01,680 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 2.0 (TID 182)
[INFO] 2019-01-19 12:57:01,681 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,681 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,682 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,682 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,683 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 2.0 (TID 181). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,684 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 2.0 (TID 182). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 2.0 (TID 183, localhost, executor driver, partition 182, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,685 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 2.0 (TID 183)
[INFO] 2019-01-19 12:57:01,685 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 2.0 (TID 181) in 8 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 12:57:01,687 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,687 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,688 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 2.0 (TID 184, localhost, executor driver, partition 183, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,688 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 2.0 (TID 182) in 10 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 12:57:01,688 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 2.0 (TID 183). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,689 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 2.0 (TID 184)
[INFO] 2019-01-19 12:57:01,691 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 2.0 (TID 185, localhost, executor driver, partition 184, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,691 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 2.0 (TID 183) in 7 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 12:57:01,692 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 2.0 (TID 185)
[INFO] 2019-01-19 12:57:01,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,692 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,694 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 2.0 (TID 184). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,695 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 2.0 (TID 186, localhost, executor driver, partition 185, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,695 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 2.0 (TID 184) in 8 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 12:57:01,695 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 2.0 (TID 186)
[INFO] 2019-01-19 12:57:01,695 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 2.0 (TID 185). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,699 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 2.0 (TID 187, localhost, executor driver, partition 186, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,697 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 12:57:01,700 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 2.0 (TID 185) in 10 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 12:57:01,700 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 2.0 (TID 187)
[INFO] 2019-01-19 12:57:01,701 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 2.0 (TID 186). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,704 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 2.0 (TID 187). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,704 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 2.0 (TID 188, localhost, executor driver, partition 187, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,705 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 2.0 (TID 189, localhost, executor driver, partition 188, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,706 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 2.0 (TID 186) in 12 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 12:57:01,706 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 2.0 (TID 187) in 8 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 12:57:01,706 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 2.0 (TID 188)
[INFO] 2019-01-19 12:57:01,711 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 2.0 (TID 189)
[INFO] 2019-01-19 12:57:01,712 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,712 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,715 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 2.0 (TID 189). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,716 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 2.0 (TID 190, localhost, executor driver, partition 189, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,716 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 2.0 (TID 190)
[INFO] 2019-01-19 12:57:01,716 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 2.0 (TID 189) in 11 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 12:57:01,718 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,718 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,719 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 2.0 (TID 188). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,720 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 2.0 (TID 190). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,720 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 2.0 (TID 191, localhost, executor driver, partition 190, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,725 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 2.0 (TID 192, localhost, executor driver, partition 192, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,725 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 2.0 (TID 191)
[INFO] 2019-01-19 12:57:01,728 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,728 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 2.0 (TID 192)
[INFO] 2019-01-19 12:57:01,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,728 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 2.0 (TID 188) in 26 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 12:57:01,737 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 2.0 (TID 192). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,737 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 2.0 (TID 190) in 21 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 12:57:01,738 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 2.0 (TID 193, localhost, executor driver, partition 193, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,738 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 2.0 (TID 192) in 15 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 12:57:01,739 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 2.0 (TID 193)
[INFO] 2019-01-19 12:57:01,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,742 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,744 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 2.0 (TID 193). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,745 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 2.0 (TID 194, localhost, executor driver, partition 194, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,745 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 2.0 (TID 194)
[INFO] 2019-01-19 12:57:01,745 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 2.0 (TID 193) in 8 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 12:57:01,747 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,748 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,751 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 2.0 (TID 194). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,751 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 2.0 (TID 195, localhost, executor driver, partition 195, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,752 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 2.0 (TID 194) in 8 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 12:57:01,752 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 2.0 (TID 195)
[INFO] 2019-01-19 12:57:01,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 25 ms
[INFO] 2019-01-19 12:57:01,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,755 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,756 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 2.0 (TID 195). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,756 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 2.0 (TID 196, localhost, executor driver, partition 196, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,757 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 2.0 (TID 195) in 6 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 12:57:01,757 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 2.0 (TID 196)
[INFO] 2019-01-19 12:57:01,759 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,760 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,761 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 2.0 (TID 196). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,762 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 2.0 (TID 197, localhost, executor driver, partition 197, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,762 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 2.0 (TID 197)
[INFO] 2019-01-19 12:57:01,762 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 2.0 (TID 196) in 6 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 12:57:01,763 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 2.0 (TID 191). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,763 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 2.0 (TID 198, localhost, executor driver, partition 198, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,764 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,764 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,764 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 2.0 (TID 198)
[INFO] 2019-01-19 12:57:01,764 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 2.0 (TID 191) in 44 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 12:57:01,766 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 2.0 (TID 197). 2747 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,766 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 2.0 (TID 199, localhost, executor driver, partition 199, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 12:57:01,766 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 2.0 (TID 197) in 4 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 12:57:01,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,767 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 2.0 (TID 199)
[INFO] 2019-01-19 12:57:01,768 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 2.0 (TID 198). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,769 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 2.0 (TID 200, localhost, executor driver, partition 43, ANY, 5870 bytes)
[INFO] 2019-01-19 12:57:01,769 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 2.0 (TID 198) in 6 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 12:57:01,769 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:01,772 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 2.0 (TID 200)
[INFO] 2019-01-19 12:57:01,773 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 2.0 (TID 199). 2657 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,774 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 2.0 (TID 201, localhost, executor driver, partition 191, ANY, 5870 bytes)
[INFO] 2019-01-19 12:57:01,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,775 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 2.0 (TID 199) in 9 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 12:57:01,775 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 2.0 (TID 201)
[INFO] 2019-01-19 12:57:01,778 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:01,778 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:01,797 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 2.0 (TID 200). 2740 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,797 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 2.0 (TID 201). 2740 bytes result sent to driver
[INFO] 2019-01-19 12:57:01,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 2.0 (TID 200) in 30 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 12:57:01,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 2.0 (TID 201) in 25 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 12:57:01,798 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:01,798 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 2 (collect at LayerSample.scala:49) finished in 1.332 s
[INFO] 2019-01-19 12:57:01,799 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at LayerSample.scala:49, took 2.004175 s
[INFO] 2019-01-19 12:57:01,878 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag==1
[INFO] 2019-01-19 12:57:02,122 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:02,125 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 12:57:02,126 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 12:57:02,128 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[WARN] 2019-01-19 12:57:02,152 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2019-01-19 12:57:02,192 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 9.961783 ms
[INFO] 2019-01-19 12:57:02,233 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 28.743929 ms
[INFO] 2019-01-19 12:57:02,254 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4 stored as values in memory (estimated size 278.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:02,268 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:02,269 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_4_piece0 in memory on 192.168.99.1:57186 (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,270 org.apache.spark.SparkContext logInfo - Created broadcast 4 from count at LayerSample.scala:54
[INFO] 2019-01-19 12:57:02,270 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:02,293 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:54
[INFO] 2019-01-19 12:57:02,293 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 14 (count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,294 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 2 (count at LayerSample.scala:54) with 1 output partitions
[INFO] 2019-01-19 12:57:02,294 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 4 (count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,294 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 3)
[INFO] 2019-01-19 12:57:02,294 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 3)
[INFO] 2019-01-19 12:57:02,294 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 3 (MapPartitionsRDD[14] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 12:57:02,303 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5 stored as values in memory (estimated size 13.5 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:02,306 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:02,306 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_5_piece0 in memory on 192.168.99.1:57186 (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,307 org.apache.spark.SparkContext logInfo - Created broadcast 5 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:02,307 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[14] at count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,307 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 3.0 with 1 tasks
[INFO] 2019-01-19 12:57:02,308 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 12:57:02,309 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 3.0 (TID 202)
[INFO] 2019-01-19 12:57:02,312 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:02,333 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 12:57:02,367 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 3.0 (TID 202). 2032 bytes result sent to driver
[INFO] 2019-01-19 12:57:02,368 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 3.0 (TID 202) in 60 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:02,368 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:02,368 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 3 (count at LayerSample.scala:54) finished in 0.060 s
[INFO] 2019-01-19 12:57:02,369 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:02,369 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:02,369 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 4)
[INFO] 2019-01-19 12:57:02,369 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:02,370 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 4 (MapPartitionsRDD[17] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 12:57:02,371 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:02,385 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:02,388 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_3_piece0 on 192.168.99.1:57186 in memory (size: 9.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,391 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4934
[INFO] 2019-01-19 12:57:02,392 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_6_piece0 in memory on 192.168.99.1:57186 (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,393 org.apache.spark.SparkContext logInfo - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:02,393 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,393 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 4.0 with 1 tasks
[INFO] 2019-01-19 12:57:02,394 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 12:57:02,394 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 4.0 (TID 203)
[INFO] 2019-01-19 12:57:02,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:02,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:02,400 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 4.0 (TID 203). 1960 bytes result sent to driver
[INFO] 2019-01-19 12:57:02,401 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 4.0 (TID 203) in 7 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:02,401 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:02,402 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 4 (count at LayerSample.scala:54) finished in 0.009 s
[INFO] 2019-01-19 12:57:02,403 org.apache.spark.scheduler.DAGScheduler logInfo - Job 2 finished: count at LayerSample.scala:54, took 0.109448 s
[INFO] 2019-01-19 12:57:02,418 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.57181 ms
[INFO] 2019-01-19 12:57:02,484 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag==0
[INFO] 2019-01-19 12:57:02,516 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:02,517 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 12:57:02,518 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 12:57:02,518 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 12:57:02,544 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.000019 ms
[INFO] 2019-01-19 12:57:02,560 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7 stored as values in memory (estimated size 278.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:02,578 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:02,579 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_7_piece0 in memory on 192.168.99.1:57186 (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,579 org.apache.spark.SparkContext logInfo - Created broadcast 7 from count at LayerSample.scala:54
[INFO] 2019-01-19 12:57:02,580 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:02,604 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:54
[INFO] 2019-01-19 12:57:02,604 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 20 (count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,604 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 3 (count at LayerSample.scala:54) with 1 output partitions
[INFO] 2019-01-19 12:57:02,604 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 6 (count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,605 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 5)
[INFO] 2019-01-19 12:57:02,605 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 5)
[INFO] 2019-01-19 12:57:02,605 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 12:57:02,607 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8 stored as values in memory (estimated size 13.5 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:02,608 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:02,609 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_8_piece0 in memory on 192.168.99.1:57186 (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,609 org.apache.spark.SparkContext logInfo - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:02,610 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,610 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 5.0 with 1 tasks
[INFO] 2019-01-19 12:57:02,611 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 12:57:02,611 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 5.0 (TID 204)
[INFO] 2019-01-19 12:57:02,614 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:02,620 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 12:57:02,641 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 5.0 (TID 204). 2032 bytes result sent to driver
[INFO] 2019-01-19 12:57:02,641 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 5.0 (TID 204) in 31 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:02,641 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:02,641 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 5 (count at LayerSample.scala:54) finished in 0.031 s
[INFO] 2019-01-19 12:57:02,642 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:02,642 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:02,642 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 6)
[INFO] 2019-01-19 12:57:02,642 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:02,642 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 6 (MapPartitionsRDD[23] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 12:57:02,643 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:02,645 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:02,646 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_9_piece0 in memory on 192.168.99.1:57186 (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:02,646 org.apache.spark.SparkContext logInfo - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:02,646 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at LayerSample.scala:54)
[INFO] 2019-01-19 12:57:02,646 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 6.0 with 1 tasks
[INFO] 2019-01-19 12:57:02,647 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 12:57:02,647 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 6.0 (TID 205)
[INFO] 2019-01-19 12:57:02,649 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:02,649 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:02,650 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 6.0 (TID 205). 1873 bytes result sent to driver
[INFO] 2019-01-19 12:57:02,651 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 6.0 (TID 205) in 4 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:02,651 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:02,651 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 6 (count at LayerSample.scala:54) finished in 0.004 s
[INFO] 2019-01-19 12:57:02,652 org.apache.spark.scheduler.DAGScheduler logInfo - Job 3 finished: count at LayerSample.scala:54, took 0.047710 s
[INFO] 2019-01-19 12:57:04,122 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:04,124 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 12:57:04,124 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:04,125 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 12:57:04,126 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:04,127 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 12:57:04,128 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:04,128 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 12:57:04,292 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4939
[INFO] 2019-01-19 12:57:04,292 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4935
[INFO] 2019-01-19 12:57:04,292 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4936
[INFO] 2019-01-19 12:57:04,292 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4937
[INFO] 2019-01-19 12:57:04,292 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4938
[INFO] 2019-01-19 12:57:04,292 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4940
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4941
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4942
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4943
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4944
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4945
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4946
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4947
[INFO] 2019-01-19 12:57:04,293 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4948
[INFO] 2019-01-19 12:57:04,295 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_4_piece0 on 192.168.99.1:57186 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:04,299 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 1
[INFO] 2019-01-19 12:57:04,301 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_5_piece0 on 192.168.99.1:57186 in memory (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:04,314 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_6_piece0 on 192.168.99.1:57186 in memory (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:04,315 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5045
[INFO] 2019-01-19 12:57:04,315 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5046
[INFO] 2019-01-19 12:57:04,315 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5047
[INFO] 2019-01-19 12:57:04,315 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5048
[INFO] 2019-01-19 12:57:04,315 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5049
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5050
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5051
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5052
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5053
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5054
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5055
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5056
[INFO] 2019-01-19 12:57:04,316 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5057
[INFO] 2019-01-19 12:57:04,317 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5058
[INFO] 2019-01-19 12:57:04,317 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5059
[INFO] 2019-01-19 12:57:04,319 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_7_piece0 on 192.168.99.1:57186 in memory (size: 23.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:57:04,320 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 2
[INFO] 2019-01-19 12:57:04,323 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_8_piece0 on 192.168.99.1:57186 in memory (size: 6.3 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:57:04,325 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_9_piece0 on 192.168.99.1:57186 in memory (size: 3.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:57:04,327 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5156
[INFO] 2019-01-19 12:57:04,328 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5157
[INFO] 2019-01-19 12:57:04,328 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5158
[INFO] 2019-01-19 12:57:04,328 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5159
[INFO] 2019-01-19 12:57:04,432 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 39.097117 ms
[INFO] 2019-01-19 12:57:04,507 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 55.633445 ms
[INFO] 2019-01-19 12:57:04,518 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10 stored as values in memory (estimated size 292.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:04,531 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.4 MB)
[INFO] 2019-01-19 12:57:04,532 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_10_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1992.0 MB)
[INFO] 2019-01-19 12:57:04,533 org.apache.spark.SparkContext logInfo - Created broadcast 10 from head at DecoupJson.scala:139
[INFO] 2019-01-19 12:57:04,534 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:04,622 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 53.097071 ms
[INFO] 2019-01-19 12:57:04,634 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11 stored as values in memory (estimated size 292.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:04,661 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.1 MB)
[INFO] 2019-01-19 12:57:04,662 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_11_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:04,663 org.apache.spark.SparkContext logInfo - Created broadcast 11 from head at DecoupJson.scala:139
[INFO] 2019-01-19 12:57:04,664 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:04,762 org.apache.spark.SparkContext logInfo - Starting job: head at DecoupJson.scala:139
[INFO] 2019-01-19 12:57:04,765 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 27 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,767 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 32 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,767 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 39 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,768 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 44 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,768 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 4 (head at DecoupJson.scala:139) with 1 output partitions
[INFO] 2019-01-19 12:57:04,768 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 11 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,768 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 10)
[INFO] 2019-01-19 12:57:04,768 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 10)
[INFO] 2019-01-19 12:57:04,769 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 12:57:04,771 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12 stored as values in memory (estimated size 39.9 KB, free 1991.0 MB)
[INFO] 2019-01-19 12:57:04,774 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 12:57:04,775 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_12_piece0 in memory on 192.168.99.1:57186 (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:04,776 org.apache.spark.SparkContext logInfo - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:04,776 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,776 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 7.0 with 1 tasks
[INFO] 2019-01-19 12:57:04,776 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 8 (MapPartitionsRDD[32] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 12:57:04,780 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13 stored as values in memory (estimated size 39.9 KB, free 1991.0 MB)
[INFO] 2019-01-19 12:57:04,781 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 12:57:04,781 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 7.0 (TID 206)
[INFO] 2019-01-19 12:57:04,783 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 12:57:04,784 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_13_piece0 in memory on 192.168.99.1:57186 (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:04,784 org.apache.spark.SparkContext logInfo - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:04,784 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[32] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:04,785 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 8.0 with 1 tasks
[INFO] 2019-01-19 12:57:04,786 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 8.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 12:57:04,786 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 8.0 (TID 207)
[INFO] 2019-01-19 12:57:04,854 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:04,854 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:04,862 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 12:57:04,866 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 12:57:04,900 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 12:57:04,986 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 7.0 (TID 206). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:04,986 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 7.0 (TID 206) in 208 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:04,987 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:04,987 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 7 (head at DecoupJson.scala:139) finished in 0.211 s
[INFO] 2019-01-19 12:57:04,987 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:04,987 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 8)
[INFO] 2019-01-19 12:57:04,987 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 9, ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 12:57:04,987 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:04,994 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 8.0 (TID 207). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:04,995 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 8.0 (TID 207) in 210 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:04,995 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:04,995 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 8 (head at DecoupJson.scala:139) finished in 0.210 s
[INFO] 2019-01-19 12:57:04,995 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:04,995 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:04,996 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 9, ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 12:57:04,996 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:04,996 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 12:57:05,068 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14 stored as values in memory (estimated size 301.7 KB, free 1990.7 MB)
[INFO] 2019-01-19 12:57:05,070 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14_piece0 stored as bytes in memory (estimated size 66.6 KB, free 1990.6 MB)
[INFO] 2019-01-19 12:57:05,072 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_14_piece0 in memory on 192.168.99.1:57186 (size: 66.6 KB, free: 1991.8 MB)
[INFO] 2019-01-19 12:57:05,073 org.apache.spark.SparkContext logInfo - Created broadcast 14 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:05,074 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:05,074 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 9.0 with 2 tasks
[INFO] 2019-01-19 12:57:05,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 9.0 (TID 208, localhost, executor driver, partition 0, ANY, 5898 bytes)
[INFO] 2019-01-19 12:57:05,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 9.0 (TID 209, localhost, executor driver, partition 1, ANY, 5898 bytes)
[INFO] 2019-01-19 12:57:05,077 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 9.0 (TID 208)
[INFO] 2019-01-19 12:57:05,077 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 9.0 (TID 209)
[INFO] 2019-01-19 12:57:05,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:05,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:05,110 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:05,110 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:05,190 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 70.558665 ms
[INFO] 2019-01-19 12:57:05,236 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 37.844622 ms
[INFO] 2019-01-19 12:57:05,281 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 37.714858 ms
[INFO] 2019-01-19 12:57:05,338 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 50.775793 ms
[INFO] 2019-01-19 12:57:05,402 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 55.079484 ms
[INFO] 2019-01-19 12:57:05,453 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 38.4952 ms
[INFO] 2019-01-19 12:57:05,497 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 34.140733 ms
[INFO] 2019-01-19 12:57:05,537 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 33.986991 ms
[INFO] 2019-01-19 12:57:05,587 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 42.60072 ms
[INFO] 2019-01-19 12:57:05,626 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 32.287025 ms
[INFO] 2019-01-19 12:57:05,659 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.571808 ms
[INFO] 2019-01-19 12:57:05,687 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.025164 ms
[INFO] 2019-01-19 12:57:05,720 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.418773 ms
[INFO] 2019-01-19 12:57:05,760 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 30.770066 ms
[INFO] 2019-01-19 12:57:05,801 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 36.047332 ms
[INFO] 2019-01-19 12:57:05,831 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.73496 ms
[INFO] 2019-01-19 12:57:05,875 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_12_piece0 on 192.168.99.1:57186 in memory (size: 12.5 KB, free: 1991.8 MB)
[INFO] 2019-01-19 12:57:05,877 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_13_piece0 on 192.168.99.1:57186 in memory (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:05,887 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 47.729182 ms
[INFO] 2019-01-19 12:57:05,907 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.10825 ms
[INFO] 2019-01-19 12:57:05,925 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.170599 ms
[INFO] 2019-01-19 12:57:05,947 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.025782 ms
[INFO] 2019-01-19 12:57:05,970 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.597727 ms
[INFO] 2019-01-19 12:57:05,990 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.744703 ms
[INFO] 2019-01-19 12:57:06,010 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.333198 ms
[INFO] 2019-01-19 12:57:06,030 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.882929 ms
[INFO] 2019-01-19 12:57:06,050 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.825761 ms
[INFO] 2019-01-19 12:57:06,067 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.803546 ms
[INFO] 2019-01-19 12:57:06,094 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.467677 ms
[INFO] 2019-01-19 12:57:06,127 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 27.074993 ms
[INFO] 2019-01-19 12:57:06,162 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 27.869086 ms
[INFO] 2019-01-19 12:57:06,185 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.678498 ms
[INFO] 2019-01-19 12:57:06,206 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.279248 ms
[INFO] 2019-01-19 12:57:06,222 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.546819 ms
[INFO] 2019-01-19 12:57:06,237 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.56899 ms
[INFO] 2019-01-19 12:57:06,258 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.269066 ms
[INFO] 2019-01-19 12:57:06,287 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 23.209605 ms
[INFO] 2019-01-19 12:57:06,323 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 28.473824 ms
[INFO] 2019-01-19 12:57:06,353 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 23.406718 ms
[INFO] 2019-01-19 12:57:06,377 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.789463 ms
[INFO] 2019-01-19 12:57:06,391 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.926191 ms
[INFO] 2019-01-19 12:57:06,409 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.974543 ms
[INFO] 2019-01-19 12:57:06,426 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.62651 ms
[INFO] 2019-01-19 12:57:06,441 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 9.755855 ms
[INFO] 2019-01-19 12:57:06,456 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.07429 ms
[INFO] 2019-01-19 12:57:06,472 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.091238 ms
[INFO] 2019-01-19 12:57:06,494 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.689385 ms
[INFO] 2019-01-19 12:57:06,514 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.30111 ms
[INFO] 2019-01-19 12:57:06,532 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.997485 ms
[INFO] 2019-01-19 12:57:06,561 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.334144 ms
[INFO] 2019-01-19 12:57:06,597 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 27.335929 ms
[INFO] 2019-01-19 12:57:06,650 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 48.089909 ms
[INFO] 2019-01-19 12:57:06,678 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.324228 ms
[INFO] 2019-01-19 12:57:06,735 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 41.499144 ms
[INFO] 2019-01-19 12:57:06,753 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 4.398192 ms
[INFO] 2019-01-19 12:57:07,235 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 39.052687 ms
[INFO] 2019-01-19 12:57:07,713 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 293.54873 ms
[INFO] 2019-01-19 12:57:07,790 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.731964 ms
[INFO] 2019-01-19 12:57:07,962 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 90.330254 ms
[INFO] 2019-01-19 12:57:08,004 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.682068 ms
[INFO] 2019-01-19 12:57:08,028 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.739435 ms
[INFO] 2019-01-19 12:57:09,050 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 0
[INFO] 2019-01-19 12:57:09,066 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_1_piece0 on 192.168.99.1:57186 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 12:57:09,071 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 61
[INFO] 2019-01-19 12:57:09,071 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 60
[INFO] 2019-01-19 12:57:09,071 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 59
[INFO] 2019-01-19 12:57:09,072 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 58
[INFO] 2019-01-19 12:57:09,072 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 57
[INFO] 2019-01-19 12:57:09,073 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 56
[INFO] 2019-01-19 12:57:09,074 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 55
[INFO] 2019-01-19 12:57:09,074 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 54
[INFO] 2019-01-19 12:57:09,074 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 53
[INFO] 2019-01-19 12:57:09,074 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 52
[INFO] 2019-01-19 12:57:09,074 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 51
[INFO] 2019-01-19 12:57:09,074 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 50
[INFO] 2019-01-19 12:57:09,075 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 49
[INFO] 2019-01-19 12:57:10,239 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 9.0 (TID 208). 3877 bytes result sent to driver
[INFO] 2019-01-19 12:57:10,240 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 9.0 (TID 208) in 5166 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 12:57:10,305 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 9.0 (TID 209). 3967 bytes result sent to driver
[INFO] 2019-01-19 12:57:10,305 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 9.0 (TID 209) in 5229 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 12:57:10,305 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:10,306 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 9 (head at DecoupJson.scala:139) finished in 5.232 s
[INFO] 2019-01-19 12:57:10,306 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:10,306 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:10,306 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 12:57:10,306 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:10,306 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 10 (MapPartitionsRDD[44] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 12:57:10,338 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15 stored as values in memory (estimated size 531.2 KB, free 1990.5 MB)
[INFO] 2019-01-19 12:57:10,340 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15_piece0 stored as bytes in memory (estimated size 132.7 KB, free 1990.4 MB)
[INFO] 2019-01-19 12:57:10,341 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_15_piece0 in memory on 192.168.99.1:57186 (size: 132.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 12:57:10,341 org.apache.spark.SparkContext logInfo - Created broadcast 15 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:10,342 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[44] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:10,343 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 10.0 with 200 tasks
[INFO] 2019-01-19 12:57:10,344 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 10.0 (TID 210, localhost, executor driver, partition 0, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:10,345 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 10.0 (TID 211, localhost, executor driver, partition 1, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:10,345 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 10.0 (TID 210)
[INFO] 2019-01-19 12:57:10,345 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 10.0 (TID 211)
[INFO] 2019-01-19 12:57:10,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:10,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:10,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:10,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:10,612 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 98.620986 ms
[INFO] 2019-01-19 12:57:10,775 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 61.66919 ms
[INFO] 2019-01-19 12:57:10,929 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 89.234673 ms
[INFO] 2019-01-19 12:57:10,997 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 49.405876 ms
[INFO] 2019-01-19 12:57:11,085 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 66.2786 ms
[INFO] 2019-01-19 12:57:11,668 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 307.063835 ms
[INFO] 2019-01-19 12:57:12,039 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 104.890516 ms
[INFO] 2019-01-19 12:57:12,115 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 52.587891 ms
[INFO] 2019-01-19 12:57:12,163 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 10.0 (TID 210). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:12,164 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 10.0 (TID 212, localhost, executor driver, partition 2, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:12,165 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 10.0 (TID 210) in 1821 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 12:57:12,165 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 10.0 (TID 212)
[INFO] 2019-01-19 12:57:12,171 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 10.0 (TID 211). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:12,172 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 10.0 (TID 213, localhost, executor driver, partition 3, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:12,172 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 10.0 (TID 211) in 1827 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 12:57:12,173 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 10.0 (TID 213)
[INFO] 2019-01-19 12:57:12,181 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:12,181 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:12,200 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:12,200 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:12,694 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 10.0 (TID 212). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:12,695 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 10.0 (TID 214, localhost, executor driver, partition 4, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:12,695 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 10.0 (TID 212) in 532 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 12:57:12,695 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 10.0 (TID 214)
[INFO] 2019-01-19 12:57:12,710 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:12,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:12,735 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 10.0 (TID 213). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:12,736 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 10.0 (TID 215, localhost, executor driver, partition 5, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:12,736 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 10.0 (TID 215)
[INFO] 2019-01-19 12:57:12,736 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 10.0 (TID 213) in 565 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 12:57:12,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:12,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:13,318 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 10.0 (TID 214). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:13,319 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 10.0 (TID 216, localhost, executor driver, partition 6, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:13,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 10.0 (TID 214) in 624 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 12:57:13,320 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 10.0 (TID 216)
[INFO] 2019-01-19 12:57:13,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:13,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:13,373 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 10.0 (TID 215). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:13,374 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 10.0 (TID 217, localhost, executor driver, partition 7, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:13,374 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 10.0 (TID 215) in 639 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 12:57:13,374 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 10.0 (TID 217)
[INFO] 2019-01-19 12:57:13,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:13,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:14,009 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 10.0 (TID 216). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:14,010 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 10.0 (TID 218, localhost, executor driver, partition 8, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:14,010 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 10.0 (TID 218)
[INFO] 2019-01-19 12:57:14,010 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 10.0 (TID 216) in 692 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 12:57:14,027 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:14,027 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:14,060 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 10.0 (TID 217). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:14,061 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 10.0 (TID 219, localhost, executor driver, partition 9, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:14,062 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 10.0 (TID 219)
[INFO] 2019-01-19 12:57:14,063 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 10.0 (TID 217) in 688 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 12:57:14,083 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:14,083 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:14,514 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 10.0 (TID 219). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:14,515 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 10.0 (TID 220, localhost, executor driver, partition 10, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:14,516 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 10.0 (TID 219) in 455 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 12:57:14,516 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 10.0 (TID 220)
[INFO] 2019-01-19 12:57:14,523 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 10.0 (TID 218). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:14,524 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 10.0 (TID 221, localhost, executor driver, partition 11, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:14,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 10.0 (TID 218) in 515 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 12:57:14,524 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 10.0 (TID 221)
[INFO] 2019-01-19 12:57:14,534 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:14,535 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:14,542 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:14,542 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:15,014 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 10.0 (TID 221). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:15,015 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 10.0 (TID 222, localhost, executor driver, partition 12, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:15,015 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 10.0 (TID 221) in 492 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 12:57:15,016 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 10.0 (TID 222)
[INFO] 2019-01-19 12:57:15,023 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 10.0 (TID 220). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:15,024 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 10.0 (TID 223, localhost, executor driver, partition 13, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:15,025 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 10.0 (TID 220) in 510 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 12:57:15,025 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 10.0 (TID 223)
[INFO] 2019-01-19 12:57:15,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:15,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:15,056 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:15,057 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:15,497 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 10.0 (TID 222). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:15,498 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 10.0 (TID 224, localhost, executor driver, partition 14, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:15,498 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 10.0 (TID 224)
[INFO] 2019-01-19 12:57:15,498 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 10.0 (TID 222) in 483 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 12:57:15,507 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 10.0 (TID 223). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:15,507 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 10.0 (TID 225, localhost, executor driver, partition 15, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:15,508 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 10.0 (TID 223) in 484 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 12:57:15,509 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 10.0 (TID 225)
[INFO] 2019-01-19 12:57:15,514 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:15,514 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:15,524 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:15,524 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:15,852 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 10.0 (TID 225). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:15,853 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 10.0 (TID 226, localhost, executor driver, partition 16, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:15,853 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 10.0 (TID 226)
[INFO] 2019-01-19 12:57:15,853 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 10.0 (TID 225) in 346 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 12:57:15,862 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:15,862 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:15,866 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 10.0 (TID 224). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:15,866 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 10.0 (TID 227, localhost, executor driver, partition 17, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:15,867 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 10.0 (TID 227)
[INFO] 2019-01-19 12:57:15,867 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 10.0 (TID 224) in 369 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 12:57:15,880 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:15,880 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:16,238 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 10.0 (TID 226). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:16,238 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 10.0 (TID 228, localhost, executor driver, partition 18, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:16,239 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 10.0 (TID 226) in 387 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 12:57:16,239 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 10.0 (TID 228)
[INFO] 2019-01-19 12:57:16,254 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:16,254 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:16,292 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 10.0 (TID 227). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:16,293 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 10.0 (TID 229, localhost, executor driver, partition 19, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:16,293 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 10.0 (TID 229)
[INFO] 2019-01-19 12:57:16,293 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 10.0 (TID 227) in 427 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 12:57:16,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:16,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:16,578 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 10.0 (TID 228). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:16,579 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 10.0 (TID 230, localhost, executor driver, partition 20, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:16,579 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 10.0 (TID 230)
[INFO] 2019-01-19 12:57:16,579 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 10.0 (TID 228) in 341 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 12:57:16,593 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:16,593 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:16,630 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 10.0 (TID 229). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:16,630 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 10.0 (TID 231, localhost, executor driver, partition 21, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:16,630 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 10.0 (TID 231)
[INFO] 2019-01-19 12:57:16,630 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 10.0 (TID 229) in 337 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 12:57:16,645 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:16,645 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:16,956 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 10.0 (TID 230). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:16,957 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 10.0 (TID 232, localhost, executor driver, partition 22, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:16,957 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 10.0 (TID 232)
[INFO] 2019-01-19 12:57:16,957 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 10.0 (TID 230) in 379 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 12:57:16,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:16,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:16,992 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 10.0 (TID 231). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:16,992 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 10.0 (TID 233, localhost, executor driver, partition 23, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:16,993 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 10.0 (TID 233)
[INFO] 2019-01-19 12:57:16,993 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 10.0 (TID 231) in 363 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 12:57:17,002 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:17,002 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:17,285 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 10.0 (TID 232). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:17,285 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 10.0 (TID 234, localhost, executor driver, partition 24, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:17,285 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 10.0 (TID 234)
[INFO] 2019-01-19 12:57:17,285 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 10.0 (TID 232) in 328 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 12:57:17,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:17,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:17,347 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 10.0 (TID 233). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:17,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 10.0 (TID 235, localhost, executor driver, partition 25, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:17,347 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 10.0 (TID 235)
[INFO] 2019-01-19 12:57:17,347 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 10.0 (TID 233) in 355 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 12:57:17,360 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:17,360 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:17,639 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 10.0 (TID 234). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:17,639 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 10.0 (TID 236, localhost, executor driver, partition 26, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:17,640 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 10.0 (TID 236)
[INFO] 2019-01-19 12:57:17,640 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 10.0 (TID 234) in 355 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 12:57:17,648 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:17,648 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:17,694 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 10.0 (TID 235). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:17,694 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 10.0 (TID 237, localhost, executor driver, partition 27, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:17,694 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 10.0 (TID 237)
[INFO] 2019-01-19 12:57:17,694 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 10.0 (TID 235) in 347 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 12:57:17,706 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:17,707 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:17,972 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 10.0 (TID 236). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:17,972 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 10.0 (TID 238, localhost, executor driver, partition 28, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:17,972 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 10.0 (TID 238)
[INFO] 2019-01-19 12:57:17,972 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 10.0 (TID 236) in 333 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 12:57:17,980 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:17,980 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:18,021 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 10.0 (TID 237). 4270 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,021 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 10.0 (TID 239, localhost, executor driver, partition 29, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,021 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 10.0 (TID 239)
[INFO] 2019-01-19 12:57:18,022 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 10.0 (TID 237) in 328 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 12:57:18,030 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,030 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:18,294 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 10.0 (TID 238). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,294 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 10.0 (TID 240, localhost, executor driver, partition 30, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,295 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 10.0 (TID 240)
[INFO] 2019-01-19 12:57:18,295 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 10.0 (TID 238) in 323 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 12:57:18,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:18,347 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 10.0 (TID 239). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 10.0 (TID 241, localhost, executor driver, partition 31, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,348 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 10.0 (TID 241)
[INFO] 2019-01-19 12:57:18,348 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 10.0 (TID 239) in 327 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 12:57:18,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,357 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:18,608 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 10.0 (TID 240). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 10.0 (TID 242, localhost, executor driver, partition 32, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,609 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 10.0 (TID 242)
[INFO] 2019-01-19 12:57:18,609 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 10.0 (TID 240) in 315 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 12:57:18,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,619 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:18,653 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 10.0 (TID 241). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,653 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 10.0 (TID 243, localhost, executor driver, partition 33, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,653 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 10.0 (TID 243)
[INFO] 2019-01-19 12:57:18,653 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 10.0 (TID 241) in 306 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 12:57:18,665 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,666 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:18,911 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 10.0 (TID 242). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,912 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 10.0 (TID 244, localhost, executor driver, partition 34, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,912 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 10.0 (TID 244)
[INFO] 2019-01-19 12:57:18,912 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 10.0 (TID 242) in 303 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 12:57:18,926 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,926 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:18,956 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 10.0 (TID 243). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:18,957 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 10.0 (TID 245, localhost, executor driver, partition 35, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:18,957 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 10.0 (TID 245)
[INFO] 2019-01-19 12:57:18,957 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 10.0 (TID 243) in 304 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 12:57:18,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:18,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:19,243 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 10.0 (TID 244). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:19,243 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 10.0 (TID 246, localhost, executor driver, partition 36, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:19,244 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 10.0 (TID 246)
[INFO] 2019-01-19 12:57:19,244 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 10.0 (TID 244) in 332 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 12:57:19,255 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:19,256 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:19,288 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 10.0 (TID 245). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:19,288 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 10.0 (TID 247, localhost, executor driver, partition 37, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:19,289 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 10.0 (TID 245) in 333 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 12:57:19,289 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 10.0 (TID 247)
[INFO] 2019-01-19 12:57:19,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:19,300 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:19,589 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 10.0 (TID 246). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:19,590 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 10.0 (TID 248, localhost, executor driver, partition 38, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:19,590 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 10.0 (TID 248)
[INFO] 2019-01-19 12:57:19,590 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 10.0 (TID 246) in 347 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 12:57:19,601 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:19,601 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:19,615 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 10.0 (TID 247). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:19,615 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 10.0 (TID 249, localhost, executor driver, partition 39, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:19,615 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 10.0 (TID 249)
[INFO] 2019-01-19 12:57:19,615 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 10.0 (TID 247) in 327 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 12:57:19,624 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:19,624 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:19,897 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 10.0 (TID 248). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:19,897 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 10.0 (TID 250, localhost, executor driver, partition 40, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:19,898 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 10.0 (TID 250)
[INFO] 2019-01-19 12:57:19,898 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 10.0 (TID 248) in 308 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 12:57:19,908 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:19,908 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:19,923 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 10.0 (TID 249). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:19,924 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 10.0 (TID 251, localhost, executor driver, partition 41, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:19,924 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 10.0 (TID 251)
[INFO] 2019-01-19 12:57:19,924 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 10.0 (TID 249) in 309 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 12:57:19,936 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:19,936 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:20,220 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 10.0 (TID 250). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:20,221 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 10.0 (TID 252, localhost, executor driver, partition 42, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:20,221 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 10.0 (TID 252)
[INFO] 2019-01-19 12:57:20,221 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 10.0 (TID 250) in 324 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 12:57:20,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:20,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:20,242 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 10.0 (TID 251). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:20,242 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 10.0 (TID 253, localhost, executor driver, partition 43, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:20,242 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 10.0 (TID 253)
[INFO] 2019-01-19 12:57:20,242 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 10.0 (TID 251) in 318 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 12:57:20,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:20,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:20,534 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 10.0 (TID 252). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:20,535 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 10.0 (TID 254, localhost, executor driver, partition 44, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:20,535 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 10.0 (TID 254)
[INFO] 2019-01-19 12:57:20,535 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 10.0 (TID 252) in 315 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 12:57:20,548 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:20,548 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:20,556 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 10.0 (TID 253). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:20,557 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 10.0 (TID 255, localhost, executor driver, partition 45, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:20,557 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 10.0 (TID 253) in 315 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 12:57:20,557 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 10.0 (TID 255)
[INFO] 2019-01-19 12:57:20,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:20,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:20,844 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 10.0 (TID 254). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:20,844 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 10.0 (TID 256, localhost, executor driver, partition 46, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:20,845 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 10.0 (TID 256)
[INFO] 2019-01-19 12:57:20,845 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 10.0 (TID 254) in 311 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 12:57:20,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:20,861 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:20,873 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 10.0 (TID 255). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:20,873 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 10.0 (TID 257, localhost, executor driver, partition 47, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:20,874 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 10.0 (TID 257)
[INFO] 2019-01-19 12:57:20,874 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 10.0 (TID 255) in 318 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 12:57:20,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:20,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:21,184 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 10.0 (TID 256). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:21,184 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 10.0 (TID 258, localhost, executor driver, partition 48, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:21,185 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 10.0 (TID 258)
[INFO] 2019-01-19 12:57:21,185 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 10.0 (TID 256) in 341 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 12:57:21,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:21,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:21,197 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 10.0 (TID 257). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:21,198 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 10.0 (TID 259, localhost, executor driver, partition 49, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:21,198 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 10.0 (TID 257) in 325 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 12:57:21,198 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 10.0 (TID 259)
[INFO] 2019-01-19 12:57:21,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:21,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:21,510 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 10.0 (TID 258). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:21,510 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 10.0 (TID 260, localhost, executor driver, partition 50, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:21,510 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 10.0 (TID 260)
[INFO] 2019-01-19 12:57:21,510 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 10.0 (TID 258) in 326 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 12:57:21,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:21,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:21,555 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 10.0 (TID 259). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:21,556 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 10.0 (TID 261, localhost, executor driver, partition 51, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:21,556 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 10.0 (TID 261)
[INFO] 2019-01-19 12:57:21,556 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 10.0 (TID 259) in 359 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 12:57:21,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:21,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:21,831 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 10.0 (TID 260). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:21,832 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 10.0 (TID 262, localhost, executor driver, partition 52, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:21,832 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 10.0 (TID 262)
[INFO] 2019-01-19 12:57:21,832 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 10.0 (TID 260) in 322 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 12:57:21,845 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:21,845 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:21,881 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 10.0 (TID 261). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:21,881 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 10.0 (TID 263, localhost, executor driver, partition 53, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:21,882 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 10.0 (TID 263)
[INFO] 2019-01-19 12:57:21,882 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 10.0 (TID 261) in 326 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 12:57:21,892 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:21,893 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:22,219 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 10.0 (TID 262). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:22,219 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 10.0 (TID 264, localhost, executor driver, partition 54, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:22,219 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 10.0 (TID 264)
[INFO] 2019-01-19 12:57:22,219 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 10.0 (TID 262) in 387 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 12:57:22,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:22,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:22,258 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 10.0 (TID 263). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:22,259 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 10.0 (TID 265, localhost, executor driver, partition 55, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:22,259 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 10.0 (TID 265)
[INFO] 2019-01-19 12:57:22,259 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 10.0 (TID 263) in 378 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 12:57:22,271 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:22,271 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:22,559 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 10.0 (TID 264). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:22,559 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 10.0 (TID 266, localhost, executor driver, partition 56, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:22,559 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 10.0 (TID 266)
[INFO] 2019-01-19 12:57:22,559 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 10.0 (TID 264) in 340 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 12:57:22,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:22,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:22,600 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 10.0 (TID 265). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:22,600 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 10.0 (TID 267, localhost, executor driver, partition 57, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:22,601 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 10.0 (TID 267)
[INFO] 2019-01-19 12:57:22,601 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 10.0 (TID 265) in 342 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 12:57:22,610 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:22,610 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:22,868 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 10.0 (TID 266). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:22,869 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 10.0 (TID 268, localhost, executor driver, partition 58, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:22,869 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 10.0 (TID 268)
[INFO] 2019-01-19 12:57:22,869 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 10.0 (TID 266) in 310 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 12:57:22,878 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:22,878 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:22,904 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 10.0 (TID 267). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:22,904 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 10.0 (TID 269, localhost, executor driver, partition 59, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:22,905 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 10.0 (TID 269)
[INFO] 2019-01-19 12:57:22,905 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 10.0 (TID 267) in 305 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 12:57:22,916 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:22,916 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:23,167 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 10.0 (TID 268). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:23,168 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 10.0 (TID 270, localhost, executor driver, partition 60, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:23,168 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 10.0 (TID 270)
[INFO] 2019-01-19 12:57:23,168 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 10.0 (TID 268) in 299 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 12:57:23,178 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:23,178 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:23,214 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 10.0 (TID 269). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:23,215 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 10.0 (TID 271, localhost, executor driver, partition 61, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:23,215 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 10.0 (TID 271)
[INFO] 2019-01-19 12:57:23,215 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 10.0 (TID 269) in 311 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 12:57:23,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:23,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:23,502 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 10.0 (TID 270). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:23,502 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 10.0 (TID 272, localhost, executor driver, partition 62, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:23,503 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 10.0 (TID 272)
[INFO] 2019-01-19 12:57:23,503 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 10.0 (TID 270) in 335 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 12:57:23,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:23,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:23,561 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 10.0 (TID 271). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:23,561 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 10.0 (TID 273, localhost, executor driver, partition 63, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:23,561 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 10.0 (TID 273)
[INFO] 2019-01-19 12:57:23,561 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 10.0 (TID 271) in 346 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 12:57:23,571 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:23,571 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:23,811 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 10.0 (TID 272). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:23,812 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 10.0 (TID 274, localhost, executor driver, partition 64, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:23,812 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 10.0 (TID 274)
[INFO] 2019-01-19 12:57:23,812 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 10.0 (TID 272) in 310 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 12:57:23,821 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:23,821 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:23,862 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 10.0 (TID 273). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:23,863 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 10.0 (TID 275, localhost, executor driver, partition 65, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:23,863 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 10.0 (TID 275)
[INFO] 2019-01-19 12:57:23,863 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 10.0 (TID 273) in 302 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 12:57:23,873 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:23,873 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:24,115 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 10.0 (TID 274). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:24,116 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 10.0 (TID 276, localhost, executor driver, partition 66, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:24,116 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 10.0 (TID 276)
[INFO] 2019-01-19 12:57:24,116 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 10.0 (TID 274) in 304 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 12:57:24,126 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:24,126 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:24,167 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 10.0 (TID 275). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:24,167 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 10.0 (TID 277, localhost, executor driver, partition 67, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:24,168 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 10.0 (TID 277)
[INFO] 2019-01-19 12:57:24,168 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 10.0 (TID 275) in 305 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 12:57:24,177 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:24,177 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:24,436 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 10.0 (TID 276). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:24,437 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 10.0 (TID 278, localhost, executor driver, partition 68, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:24,437 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 10.0 (TID 278)
[INFO] 2019-01-19 12:57:24,437 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 10.0 (TID 276) in 322 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 12:57:24,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:24,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:24,494 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 10.0 (TID 277). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:24,495 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 10.0 (TID 279, localhost, executor driver, partition 69, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:24,495 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 10.0 (TID 279)
[INFO] 2019-01-19 12:57:24,495 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 10.0 (TID 277) in 328 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 12:57:24,506 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:24,506 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:24,749 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 10.0 (TID 278). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:24,749 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 10.0 (TID 280, localhost, executor driver, partition 70, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:24,749 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 10.0 (TID 278) in 312 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 12:57:24,749 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 10.0 (TID 280)
[INFO] 2019-01-19 12:57:24,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:24,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:24,794 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 10.0 (TID 279). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:24,795 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 10.0 (TID 281, localhost, executor driver, partition 71, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:24,795 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 10.0 (TID 279) in 300 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 12:57:24,795 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 10.0 (TID 281)
[INFO] 2019-01-19 12:57:24,804 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:24,804 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:25,053 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 10.0 (TID 280). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,053 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 10.0 (TID 282, localhost, executor driver, partition 72, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,053 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 10.0 (TID 282)
[INFO] 2019-01-19 12:57:25,053 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 10.0 (TID 280) in 304 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 12:57:25,063 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:25,063 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:25,100 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 10.0 (TID 281). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,100 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 10.0 (TID 283, localhost, executor driver, partition 73, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,101 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 10.0 (TID 283)
[INFO] 2019-01-19 12:57:25,101 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 10.0 (TID 281) in 307 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 12:57:25,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:25,112 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:25,367 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 10.0 (TID 282). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,368 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 10.0 (TID 284, localhost, executor driver, partition 74, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,368 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 10.0 (TID 284)
[INFO] 2019-01-19 12:57:25,368 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 10.0 (TID 282) in 315 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 12:57:25,377 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:25,378 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:25,423 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 10.0 (TID 283). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,424 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 10.0 (TID 285, localhost, executor driver, partition 75, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,424 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 10.0 (TID 285)
[INFO] 2019-01-19 12:57:25,424 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 10.0 (TID 283) in 324 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 12:57:25,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:25,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:25,692 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 10.0 (TID 284). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,693 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 10.0 (TID 286, localhost, executor driver, partition 76, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,693 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 10.0 (TID 286)
[INFO] 2019-01-19 12:57:25,693 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 10.0 (TID 284) in 325 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 12:57:25,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:25,703 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:25,723 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 10.0 (TID 285). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,723 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 10.0 (TID 287, localhost, executor driver, partition 77, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,723 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 10.0 (TID 287)
[INFO] 2019-01-19 12:57:25,723 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 10.0 (TID 285) in 299 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 12:57:25,734 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:25,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:25,995 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 10.0 (TID 286). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:25,996 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 10.0 (TID 288, localhost, executor driver, partition 78, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:25,996 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 10.0 (TID 288)
[INFO] 2019-01-19 12:57:25,996 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 10.0 (TID 286) in 303 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 12:57:26,009 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:26,040 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 10.0 (TID 287). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,041 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 10.0 (TID 289, localhost, executor driver, partition 79, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,041 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 10.0 (TID 289)
[INFO] 2019-01-19 12:57:26,041 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 10.0 (TID 287) in 318 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 12:57:26,052 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,053 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:26,322 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 10.0 (TID 288). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,322 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 10.0 (TID 290, localhost, executor driver, partition 80, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,322 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 10.0 (TID 290)
[INFO] 2019-01-19 12:57:26,323 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 10.0 (TID 288) in 327 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 12:57:26,335 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,335 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:26,373 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 10.0 (TID 289). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,373 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 10.0 (TID 291, localhost, executor driver, partition 81, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,374 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 10.0 (TID 291)
[INFO] 2019-01-19 12:57:26,374 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 10.0 (TID 289) in 333 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 12:57:26,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:26,641 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 10.0 (TID 290). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,641 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 10.0 (TID 292, localhost, executor driver, partition 82, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,641 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 10.0 (TID 292)
[INFO] 2019-01-19 12:57:26,641 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 10.0 (TID 290) in 319 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 12:57:26,650 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,651 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:26,697 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 10.0 (TID 291). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,698 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 10.0 (TID 293, localhost, executor driver, partition 83, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,698 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 10.0 (TID 293)
[INFO] 2019-01-19 12:57:26,698 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 10.0 (TID 291) in 325 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 12:57:26,707 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,707 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:26,949 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 10.0 (TID 292). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,949 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 10.0 (TID 294, localhost, executor driver, partition 84, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,949 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 10.0 (TID 294)
[INFO] 2019-01-19 12:57:26,949 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 10.0 (TID 292) in 308 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 12:57:26,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:26,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:26,997 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 10.0 (TID 293). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:26,998 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 10.0 (TID 295, localhost, executor driver, partition 85, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:26,998 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 10.0 (TID 295)
[INFO] 2019-01-19 12:57:26,998 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 10.0 (TID 293) in 300 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 12:57:27,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:27,274 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 10.0 (TID 294). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:27,274 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 10.0 (TID 296, localhost, executor driver, partition 86, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:27,274 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 10.0 (TID 296)
[INFO] 2019-01-19 12:57:27,274 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 10.0 (TID 294) in 325 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 12:57:27,283 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,283 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:27,321 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 10.0 (TID 295). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:27,321 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 10.0 (TID 297, localhost, executor driver, partition 87, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:27,321 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 10.0 (TID 297)
[INFO] 2019-01-19 12:57:27,321 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 10.0 (TID 295) in 323 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 12:57:27,333 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:27,601 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 10.0 (TID 296). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:27,601 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 10.0 (TID 298, localhost, executor driver, partition 88, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:27,601 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 10.0 (TID 298)
[INFO] 2019-01-19 12:57:27,601 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 10.0 (TID 296) in 327 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 12:57:27,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:27,652 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 10.0 (TID 297). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:27,652 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 10.0 (TID 299, localhost, executor driver, partition 89, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:27,652 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 10.0 (TID 299)
[INFO] 2019-01-19 12:57:27,652 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 10.0 (TID 297) in 331 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 12:57:27,663 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,664 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:27,915 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 10.0 (TID 298). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:27,916 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 10.0 (TID 300, localhost, executor driver, partition 90, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:27,916 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 10.0 (TID 300)
[INFO] 2019-01-19 12:57:27,916 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 10.0 (TID 298) in 315 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 12:57:27,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,935 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:27,968 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 10.0 (TID 299). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:27,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 10.0 (TID 301, localhost, executor driver, partition 91, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:27,969 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 10.0 (TID 301)
[INFO] 2019-01-19 12:57:27,969 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 10.0 (TID 299) in 317 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 12:57:27,977 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:27,977 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:28,237 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 10.0 (TID 300). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:28,238 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 10.0 (TID 302, localhost, executor driver, partition 92, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:28,238 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 10.0 (TID 302)
[INFO] 2019-01-19 12:57:28,238 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 10.0 (TID 300) in 322 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 12:57:28,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:28,247 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:28,276 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 10.0 (TID 301). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:28,276 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 10.0 (TID 303, localhost, executor driver, partition 93, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:28,276 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 10.0 (TID 303)
[INFO] 2019-01-19 12:57:28,276 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 10.0 (TID 301) in 307 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 12:57:28,287 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:28,287 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:28,565 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 10.0 (TID 302). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:28,566 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 10.0 (TID 304, localhost, executor driver, partition 94, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:28,566 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 10.0 (TID 304)
[INFO] 2019-01-19 12:57:28,566 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 10.0 (TID 302) in 328 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 12:57:28,578 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:28,579 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:28,607 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 10.0 (TID 303). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:28,607 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 10.0 (TID 305, localhost, executor driver, partition 95, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:28,608 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 10.0 (TID 305)
[INFO] 2019-01-19 12:57:28,608 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 10.0 (TID 303) in 332 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 12:57:28,616 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:28,616 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:28,877 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 10.0 (TID 304). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:28,878 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 10.0 (TID 306, localhost, executor driver, partition 96, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:28,878 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 10.0 (TID 306)
[INFO] 2019-01-19 12:57:28,878 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 10.0 (TID 304) in 312 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 12:57:28,889 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:28,889 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:28,926 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 10.0 (TID 305). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:28,927 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 10.0 (TID 307, localhost, executor driver, partition 97, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:28,927 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 10.0 (TID 307)
[INFO] 2019-01-19 12:57:28,927 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 10.0 (TID 305) in 320 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 12:57:28,937 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:28,937 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:29,192 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 10.0 (TID 306). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:29,192 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 10.0 (TID 308, localhost, executor driver, partition 98, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:29,192 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 10.0 (TID 308)
[INFO] 2019-01-19 12:57:29,192 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 10.0 (TID 306) in 314 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 12:57:29,203 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:29,203 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:29,232 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 10.0 (TID 307). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:29,233 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 10.0 (TID 309, localhost, executor driver, partition 99, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:29,233 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 10.0 (TID 309)
[INFO] 2019-01-19 12:57:29,233 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 10.0 (TID 307) in 307 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 12:57:29,242 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:29,242 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:29,488 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 10.0 (TID 308). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:29,489 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 10.0 (TID 310, localhost, executor driver, partition 100, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:29,489 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 10.0 (TID 310)
[INFO] 2019-01-19 12:57:29,489 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 10.0 (TID 308) in 297 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 12:57:29,502 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:29,502 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:29,543 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 10.0 (TID 309). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:29,544 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 10.0 (TID 311, localhost, executor driver, partition 101, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:29,544 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 10.0 (TID 311)
[INFO] 2019-01-19 12:57:29,544 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 10.0 (TID 309) in 311 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 12:57:29,564 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:29,564 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:29,834 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 10.0 (TID 310). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:29,834 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 10.0 (TID 312, localhost, executor driver, partition 102, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:29,834 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 10.0 (TID 312)
[INFO] 2019-01-19 12:57:29,834 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 10.0 (TID 310) in 345 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 12:57:29,845 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:29,845 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:29,896 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 10.0 (TID 311). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:29,896 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 10.0 (TID 313, localhost, executor driver, partition 103, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:29,896 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 10.0 (TID 313)
[INFO] 2019-01-19 12:57:29,896 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 10.0 (TID 311) in 353 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 12:57:29,909 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:29,909 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:30,174 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 10.0 (TID 312). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:30,174 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 10.0 (TID 314, localhost, executor driver, partition 104, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:30,174 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 10.0 (TID 314)
[INFO] 2019-01-19 12:57:30,174 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 10.0 (TID 312) in 340 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 12:57:30,183 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:30,184 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:30,227 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 10.0 (TID 313). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:30,228 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 10.0 (TID 315, localhost, executor driver, partition 105, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:30,228 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 10.0 (TID 315)
[INFO] 2019-01-19 12:57:30,228 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 10.0 (TID 313) in 332 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 12:57:30,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:30,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:30,508 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 10.0 (TID 314). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:30,509 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 10.0 (TID 316, localhost, executor driver, partition 106, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:30,509 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 10.0 (TID 316)
[INFO] 2019-01-19 12:57:30,509 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 10.0 (TID 314) in 335 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 12:57:30,518 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:30,518 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:30,550 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 10.0 (TID 315). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:30,550 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 10.0 (TID 317, localhost, executor driver, partition 107, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:30,550 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 10.0 (TID 317)
[INFO] 2019-01-19 12:57:30,550 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 10.0 (TID 315) in 322 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 12:57:30,563 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:30,563 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:30,855 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 10.0 (TID 316). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:30,855 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 10.0 (TID 318, localhost, executor driver, partition 108, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:30,856 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 10.0 (TID 318)
[INFO] 2019-01-19 12:57:30,856 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 10.0 (TID 316) in 348 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 12:57:30,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:30,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:30,897 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 10.0 (TID 317). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:30,897 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 10.0 (TID 319, localhost, executor driver, partition 109, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:30,898 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 10.0 (TID 319)
[INFO] 2019-01-19 12:57:30,898 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 10.0 (TID 317) in 348 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 12:57:30,908 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:30,908 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:31,169 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 10.0 (TID 318). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:31,169 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 10.0 (TID 320, localhost, executor driver, partition 110, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:31,170 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 10.0 (TID 320)
[INFO] 2019-01-19 12:57:31,170 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 10.0 (TID 318) in 315 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 12:57:31,180 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:31,181 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:31,209 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 10.0 (TID 319). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:31,210 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 10.0 (TID 321, localhost, executor driver, partition 111, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:31,210 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 10.0 (TID 321)
[INFO] 2019-01-19 12:57:31,210 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 10.0 (TID 319) in 313 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 12:57:31,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:31,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:31,502 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 10.0 (TID 320). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:31,503 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 10.0 (TID 322, localhost, executor driver, partition 112, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:31,503 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 10.0 (TID 322)
[INFO] 2019-01-19 12:57:31,503 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 10.0 (TID 320) in 334 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 12:57:31,515 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:31,516 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:31,561 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 10.0 (TID 321). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:31,562 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 10.0 (TID 323, localhost, executor driver, partition 113, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:31,562 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 10.0 (TID 323)
[INFO] 2019-01-19 12:57:31,562 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 10.0 (TID 321) in 352 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 12:57:31,577 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:31,578 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:31,832 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 10.0 (TID 322). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:31,835 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 10.0 (TID 324, localhost, executor driver, partition 114, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:31,836 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 10.0 (TID 324)
[INFO] 2019-01-19 12:57:31,836 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 10.0 (TID 322) in 333 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 12:57:31,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:31,850 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:31,887 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 10.0 (TID 323). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:31,888 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 10.0 (TID 325, localhost, executor driver, partition 115, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:31,888 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 10.0 (TID 325)
[INFO] 2019-01-19 12:57:31,888 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 10.0 (TID 323) in 326 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 12:57:31,897 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:31,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:32,168 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 10.0 (TID 324). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:32,168 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 10.0 (TID 326, localhost, executor driver, partition 116, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:32,169 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 10.0 (TID 326)
[INFO] 2019-01-19 12:57:32,169 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 10.0 (TID 324) in 334 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 12:57:32,181 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:32,181 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:32,223 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 10.0 (TID 325). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:32,224 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 10.0 (TID 327, localhost, executor driver, partition 117, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:32,224 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 10.0 (TID 327)
[INFO] 2019-01-19 12:57:32,224 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 10.0 (TID 325) in 337 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 12:57:32,237 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:32,238 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:32,502 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 10.0 (TID 326). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:32,502 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 10.0 (TID 328, localhost, executor driver, partition 118, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:32,502 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 10.0 (TID 328)
[INFO] 2019-01-19 12:57:32,502 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 10.0 (TID 326) in 334 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 12:57:32,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:32,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:32,561 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 10.0 (TID 327). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:32,561 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 10.0 (TID 329, localhost, executor driver, partition 119, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:32,561 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 10.0 (TID 329)
[INFO] 2019-01-19 12:57:32,561 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 10.0 (TID 327) in 337 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 12:57:32,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:32,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:32,836 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 10.0 (TID 328). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:32,836 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 10.0 (TID 330, localhost, executor driver, partition 120, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:32,836 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 10.0 (TID 330)
[INFO] 2019-01-19 12:57:32,837 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 10.0 (TID 328) in 335 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 12:57:32,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:32,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:32,890 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 10.0 (TID 329). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:32,891 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 10.0 (TID 331, localhost, executor driver, partition 121, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:32,891 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 10.0 (TID 331)
[INFO] 2019-01-19 12:57:32,891 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 10.0 (TID 329) in 330 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 12:57:32,903 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:32,903 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:33,154 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 10.0 (TID 330). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:33,155 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 10.0 (TID 332, localhost, executor driver, partition 122, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:33,155 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 10.0 (TID 332)
[INFO] 2019-01-19 12:57:33,155 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 10.0 (TID 330) in 319 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 12:57:33,166 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:33,166 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:33,221 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 10.0 (TID 331). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:33,221 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 10.0 (TID 333, localhost, executor driver, partition 123, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:33,221 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 10.0 (TID 333)
[INFO] 2019-01-19 12:57:33,221 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 10.0 (TID 331) in 331 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 12:57:33,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:33,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:33,489 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 10.0 (TID 332). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:33,489 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 10.0 (TID 334, localhost, executor driver, partition 124, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:33,490 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 10.0 (TID 334)
[INFO] 2019-01-19 12:57:33,490 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 10.0 (TID 332) in 336 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 12:57:33,500 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:33,501 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:33,546 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 10.0 (TID 333). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:33,547 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 10.0 (TID 335, localhost, executor driver, partition 125, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:33,547 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 10.0 (TID 335)
[INFO] 2019-01-19 12:57:33,547 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 10.0 (TID 333) in 326 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 12:57:33,560 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:33,560 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:33,820 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 10.0 (TID 334). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:33,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 10.0 (TID 336, localhost, executor driver, partition 126, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:33,821 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 10.0 (TID 336)
[INFO] 2019-01-19 12:57:33,821 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 10.0 (TID 334) in 332 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 12:57:33,831 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:33,831 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:33,868 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 10.0 (TID 335). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:33,869 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 10.0 (TID 337, localhost, executor driver, partition 127, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:33,869 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 10.0 (TID 337)
[INFO] 2019-01-19 12:57:33,869 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 10.0 (TID 335) in 322 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 12:57:33,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:33,880 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:34,139 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 10.0 (TID 336). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:34,140 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 10.0 (TID 338, localhost, executor driver, partition 128, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:34,140 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 10.0 (TID 338)
[INFO] 2019-01-19 12:57:34,140 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 10.0 (TID 336) in 320 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 12:57:34,158 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:34,158 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:34,213 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 10.0 (TID 337). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:34,213 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 10.0 (TID 339, localhost, executor driver, partition 129, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:34,213 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 10.0 (TID 339)
[INFO] 2019-01-19 12:57:34,213 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 10.0 (TID 337) in 344 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 12:57:34,224 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:34,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:34,484 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 10.0 (TID 338). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:34,484 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 10.0 (TID 340, localhost, executor driver, partition 130, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:34,484 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 10.0 (TID 340)
[INFO] 2019-01-19 12:57:34,484 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 10.0 (TID 338) in 344 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 12:57:34,497 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:34,497 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:34,553 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 10.0 (TID 339). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:34,554 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 10.0 (TID 341, localhost, executor driver, partition 131, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:34,554 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 10.0 (TID 341)
[INFO] 2019-01-19 12:57:34,554 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 10.0 (TID 339) in 341 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 12:57:34,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:34,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:34,810 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 10.0 (TID 340). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:34,811 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 10.0 (TID 342, localhost, executor driver, partition 132, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:34,811 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 10.0 (TID 342)
[INFO] 2019-01-19 12:57:34,811 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 10.0 (TID 340) in 327 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 12:57:34,824 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:34,824 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:34,876 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 10.0 (TID 341). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:34,876 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 10.0 (TID 343, localhost, executor driver, partition 133, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:34,876 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 10.0 (TID 343)
[INFO] 2019-01-19 12:57:34,876 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 10.0 (TID 341) in 323 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 12:57:34,890 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:34,890 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:35,139 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 10.0 (TID 342). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:35,140 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 10.0 (TID 344, localhost, executor driver, partition 134, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:35,140 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 10.0 (TID 344)
[INFO] 2019-01-19 12:57:35,140 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 10.0 (TID 342) in 329 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 12:57:35,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:35,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:35,193 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 10.0 (TID 343). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:35,194 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 10.0 (TID 345, localhost, executor driver, partition 135, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:35,194 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 10.0 (TID 345)
[INFO] 2019-01-19 12:57:35,194 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 10.0 (TID 343) in 318 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 12:57:35,204 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:35,204 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:35,471 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 10.0 (TID 344). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:35,471 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 10.0 (TID 346, localhost, executor driver, partition 136, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:35,472 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 10.0 (TID 346)
[INFO] 2019-01-19 12:57:35,472 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 10.0 (TID 344) in 332 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 12:57:35,482 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:35,482 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:35,516 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 10.0 (TID 345). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:35,516 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 10.0 (TID 347, localhost, executor driver, partition 137, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:35,516 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 10.0 (TID 347)
[INFO] 2019-01-19 12:57:35,516 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 10.0 (TID 345) in 323 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 12:57:35,525 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:35,526 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:35,804 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 10.0 (TID 346). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:35,805 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 10.0 (TID 348, localhost, executor driver, partition 138, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:35,805 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 10.0 (TID 348)
[INFO] 2019-01-19 12:57:35,805 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 10.0 (TID 346) in 334 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 12:57:35,815 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:35,815 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:35,837 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 10.0 (TID 347). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:35,837 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 10.0 (TID 349, localhost, executor driver, partition 139, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:35,837 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 10.0 (TID 349)
[INFO] 2019-01-19 12:57:35,837 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 10.0 (TID 347) in 321 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 12:57:35,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:35,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:36,177 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 10.0 (TID 348). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:36,178 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 10.0 (TID 350, localhost, executor driver, partition 140, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:36,178 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 10.0 (TID 350)
[INFO] 2019-01-19 12:57:36,178 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 10.0 (TID 348) in 373 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 12:57:36,193 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:36,193 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:36,197 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 10.0 (TID 349). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:36,197 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 10.0 (TID 351, localhost, executor driver, partition 141, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:36,197 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 10.0 (TID 351)
[INFO] 2019-01-19 12:57:36,198 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 10.0 (TID 349) in 360 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 12:57:36,211 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:36,211 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:36,579 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 10.0 (TID 350). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:36,579 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 10.0 (TID 352, localhost, executor driver, partition 142, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:36,580 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 10.0 (TID 352)
[INFO] 2019-01-19 12:57:36,580 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 10.0 (TID 350) in 403 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 12:57:36,583 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 10.0 (TID 351). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:36,584 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 10.0 (TID 353, localhost, executor driver, partition 143, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:36,584 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 10.0 (TID 353)
[INFO] 2019-01-19 12:57:36,584 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 10.0 (TID 351) in 387 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 12:57:36,592 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:36,592 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:36,597 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:36,597 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:36,967 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 10.0 (TID 352). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:36,968 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 10.0 (TID 354, localhost, executor driver, partition 144, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:36,968 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 10.0 (TID 354)
[INFO] 2019-01-19 12:57:36,968 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 10.0 (TID 352) in 389 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 12:57:36,972 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 10.0 (TID 353). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:36,972 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 10.0 (TID 355, localhost, executor driver, partition 145, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:36,972 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 10.0 (TID 355)
[INFO] 2019-01-19 12:57:36,973 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 10.0 (TID 353) in 389 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 12:57:36,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:36,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:36,985 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:36,986 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:37,307 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 10.0 (TID 354). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:37,308 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 10.0 (TID 356, localhost, executor driver, partition 146, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:37,308 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 10.0 (TID 356)
[INFO] 2019-01-19 12:57:37,308 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 10.0 (TID 354) in 340 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 12:57:37,319 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 10.0 (TID 355). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:37,320 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 10.0 (TID 357, localhost, executor driver, partition 147, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:37,320 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 10.0 (TID 357)
[INFO] 2019-01-19 12:57:37,320 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 10.0 (TID 355) in 348 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 12:57:37,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:37,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:37,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:37,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:37,666 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 10.0 (TID 356). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:37,666 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 10.0 (TID 358, localhost, executor driver, partition 148, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:37,667 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 10.0 (TID 356) in 359 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 12:57:37,667 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 10.0 (TID 358)
[INFO] 2019-01-19 12:57:37,670 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 10.0 (TID 357). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:37,670 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 10.0 (TID 359, localhost, executor driver, partition 149, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:37,671 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 10.0 (TID 359)
[INFO] 2019-01-19 12:57:37,671 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 10.0 (TID 357) in 351 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 12:57:37,677 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:37,677 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:37,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:37,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:37,988 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 10.0 (TID 358). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:37,989 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 10.0 (TID 360, localhost, executor driver, partition 150, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:37,989 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 10.0 (TID 360)
[INFO] 2019-01-19 12:57:37,989 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 10.0 (TID 358) in 323 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 12:57:37,999 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 10.0 (TID 359). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:37,999 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:38,000 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:38,000 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 10.0 (TID 361, localhost, executor driver, partition 151, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:38,000 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 10.0 (TID 361)
[INFO] 2019-01-19 12:57:38,000 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 10.0 (TID 359) in 330 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 12:57:38,011 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:38,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:38,313 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 10.0 (TID 360). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:38,314 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 10.0 (TID 362, localhost, executor driver, partition 152, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:38,314 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 10.0 (TID 362)
[INFO] 2019-01-19 12:57:38,314 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 10.0 (TID 360) in 325 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 12:57:38,324 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:38,324 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:38,335 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 10.0 (TID 361). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:38,335 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 10.0 (TID 363, localhost, executor driver, partition 153, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:38,336 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 10.0 (TID 361) in 337 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 12:57:38,336 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 10.0 (TID 363)
[INFO] 2019-01-19 12:57:38,351 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:38,352 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:38,659 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 10.0 (TID 362). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:38,659 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 10.0 (TID 364, localhost, executor driver, partition 154, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:38,659 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 10.0 (TID 364)
[INFO] 2019-01-19 12:57:38,659 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 10.0 (TID 362) in 346 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 12:57:38,671 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:38,672 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:38,678 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 10.0 (TID 363). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:38,678 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 10.0 (TID 365, localhost, executor driver, partition 155, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:38,678 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 10.0 (TID 365)
[INFO] 2019-01-19 12:57:38,678 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 10.0 (TID 363) in 343 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 12:57:38,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:38,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:38,987 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 10.0 (TID 364). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:38,987 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 10.0 (TID 366, localhost, executor driver, partition 156, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:38,987 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 10.0 (TID 366)
[INFO] 2019-01-19 12:57:38,987 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 10.0 (TID 364) in 328 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 12:57:38,999 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,000 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:39,010 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 10.0 (TID 365). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:39,011 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 10.0 (TID 367, localhost, executor driver, partition 157, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:39,011 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 10.0 (TID 367)
[INFO] 2019-01-19 12:57:39,011 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 10.0 (TID 365) in 333 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 12:57:39,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:39,308 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 10.0 (TID 366). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:39,309 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 10.0 (TID 368, localhost, executor driver, partition 158, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:39,309 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 10.0 (TID 368)
[INFO] 2019-01-19 12:57:39,309 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 10.0 (TID 366) in 322 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 12:57:39,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:39,335 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 10.0 (TID 367). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:39,336 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 10.0 (TID 369, localhost, executor driver, partition 159, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:39,336 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 10.0 (TID 369)
[INFO] 2019-01-19 12:57:39,336 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 10.0 (TID 367) in 326 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 12:57:39,346 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,346 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:39,635 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 10.0 (TID 368). 4270 bytes result sent to driver
[INFO] 2019-01-19 12:57:39,635 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 10.0 (TID 370, localhost, executor driver, partition 160, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:39,635 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 10.0 (TID 370)
[INFO] 2019-01-19 12:57:39,635 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 10.0 (TID 368) in 327 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 12:57:39,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:39,661 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 10.0 (TID 369). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:39,661 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 10.0 (TID 371, localhost, executor driver, partition 161, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:39,661 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 10.0 (TID 371)
[INFO] 2019-01-19 12:57:39,662 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 10.0 (TID 369) in 325 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 12:57:39,676 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,676 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:39,978 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 10.0 (TID 370). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:39,978 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 10.0 (TID 372, localhost, executor driver, partition 162, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:39,978 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 10.0 (TID 372)
[INFO] 2019-01-19 12:57:39,978 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 10.0 (TID 370) in 343 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 12:57:39,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:39,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:40,019 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 10.0 (TID 371). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:40,020 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 10.0 (TID 373, localhost, executor driver, partition 163, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:40,020 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 10.0 (TID 373)
[INFO] 2019-01-19 12:57:40,020 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 10.0 (TID 371) in 359 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 12:57:40,032 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:40,032 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:40,341 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 10.0 (TID 372). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:40,341 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 10.0 (TID 374, localhost, executor driver, partition 164, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:40,342 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 10.0 (TID 374)
[INFO] 2019-01-19 12:57:40,342 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 10.0 (TID 372) in 364 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 12:57:40,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:40,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:40,373 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 10.0 (TID 373). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:40,374 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 10.0 (TID 375, localhost, executor driver, partition 165, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:40,374 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 10.0 (TID 373) in 354 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 12:57:40,374 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 10.0 (TID 375)
[INFO] 2019-01-19 12:57:40,383 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:40,383 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:40,684 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 10.0 (TID 374). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:40,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 10.0 (TID 376, localhost, executor driver, partition 166, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:40,684 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 10.0 (TID 376)
[INFO] 2019-01-19 12:57:40,684 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 10.0 (TID 374) in 343 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 12:57:40,697 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:40,698 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:40,725 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 10.0 (TID 375). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:40,726 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 10.0 (TID 377, localhost, executor driver, partition 167, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:40,726 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 10.0 (TID 377)
[INFO] 2019-01-19 12:57:40,726 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 10.0 (TID 375) in 352 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 12:57:40,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:40,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:41,026 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 10.0 (TID 376). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:41,027 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 10.0 (TID 378, localhost, executor driver, partition 168, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:41,027 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 10.0 (TID 378)
[INFO] 2019-01-19 12:57:41,027 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 10.0 (TID 376) in 343 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 12:57:41,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:41,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:41,056 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 10.0 (TID 377). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:41,057 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 10.0 (TID 379, localhost, executor driver, partition 169, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:41,057 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 10.0 (TID 379)
[INFO] 2019-01-19 12:57:41,057 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 10.0 (TID 377) in 331 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 12:57:41,066 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:41,066 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:41,356 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 10.0 (TID 378). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:41,357 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 10.0 (TID 380, localhost, executor driver, partition 170, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:41,357 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 10.0 (TID 380)
[INFO] 2019-01-19 12:57:41,357 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 10.0 (TID 378) in 330 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 12:57:41,368 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:41,369 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:41,387 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 10.0 (TID 379). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:41,387 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 10.0 (TID 381, localhost, executor driver, partition 171, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:41,387 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 10.0 (TID 381)
[INFO] 2019-01-19 12:57:41,388 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 10.0 (TID 379) in 332 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 12:57:41,398 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:41,399 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:41,701 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 10.0 (TID 380). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:41,701 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 10.0 (TID 382, localhost, executor driver, partition 172, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:41,701 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 10.0 (TID 382)
[INFO] 2019-01-19 12:57:41,701 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 10.0 (TID 380) in 344 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 12:57:41,712 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:41,712 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:41,722 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 10.0 (TID 381). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:41,723 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 10.0 (TID 383, localhost, executor driver, partition 173, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:41,723 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 10.0 (TID 383)
[INFO] 2019-01-19 12:57:41,723 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 10.0 (TID 381) in 336 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 12:57:41,738 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:41,738 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:42,012 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 10.0 (TID 382). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:42,013 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 10.0 (TID 384, localhost, executor driver, partition 174, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:42,013 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 10.0 (TID 384)
[INFO] 2019-01-19 12:57:42,013 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 10.0 (TID 382) in 312 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 12:57:42,028 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:42,029 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:42,051 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 10.0 (TID 383). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:42,052 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 10.0 (TID 385, localhost, executor driver, partition 175, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:42,052 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 10.0 (TID 385)
[INFO] 2019-01-19 12:57:42,052 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 10.0 (TID 383) in 329 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 12:57:42,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:42,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:42,354 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 10.0 (TID 384). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:42,354 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 10.0 (TID 386, localhost, executor driver, partition 176, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:42,354 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 10.0 (TID 386)
[INFO] 2019-01-19 12:57:42,355 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 10.0 (TID 384) in 341 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 12:57:42,368 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:42,369 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:42,395 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 10.0 (TID 385). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:42,395 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 10.0 (TID 387, localhost, executor driver, partition 177, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:42,395 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 10.0 (TID 387)
[INFO] 2019-01-19 12:57:42,396 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 10.0 (TID 385) in 345 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 12:57:42,411 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:42,411 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:42,693 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 10.0 (TID 386). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:42,693 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 10.0 (TID 388, localhost, executor driver, partition 178, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:42,693 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 10.0 (TID 388)
[INFO] 2019-01-19 12:57:42,693 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 10.0 (TID 386) in 339 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 12:57:42,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:42,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:42,740 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 10.0 (TID 387). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:42,740 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 10.0 (TID 389, localhost, executor driver, partition 179, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:42,740 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 10.0 (TID 389)
[INFO] 2019-01-19 12:57:42,740 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 10.0 (TID 387) in 345 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 12:57:42,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:42,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:43,014 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 10.0 (TID 388). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:43,015 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 10.0 (TID 390, localhost, executor driver, partition 180, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:43,015 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 10.0 (TID 390)
[INFO] 2019-01-19 12:57:43,015 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 10.0 (TID 388) in 322 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 12:57:43,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:43,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:43,072 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 10.0 (TID 389). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:43,072 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 10.0 (TID 391, localhost, executor driver, partition 181, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:43,072 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 10.0 (TID 391)
[INFO] 2019-01-19 12:57:43,073 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 10.0 (TID 389) in 332 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 12:57:43,081 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:43,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:43,334 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 10.0 (TID 390). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:43,334 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 10.0 (TID 392, localhost, executor driver, partition 182, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:43,335 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 10.0 (TID 392)
[INFO] 2019-01-19 12:57:43,335 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 10.0 (TID 390) in 321 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 12:57:43,348 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:43,349 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:43,392 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 10.0 (TID 391). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:43,393 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 10.0 (TID 393, localhost, executor driver, partition 183, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:43,393 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 10.0 (TID 393)
[INFO] 2019-01-19 12:57:43,393 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 10.0 (TID 391) in 321 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 12:57:43,407 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:43,407 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:43,672 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 10.0 (TID 392). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:43,672 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 10.0 (TID 394, localhost, executor driver, partition 184, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:43,672 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 10.0 (TID 394)
[INFO] 2019-01-19 12:57:43,672 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 10.0 (TID 392) in 338 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 12:57:43,683 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:43,683 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:43,734 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 10.0 (TID 393). 4253 bytes result sent to driver
[INFO] 2019-01-19 12:57:43,734 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 10.0 (TID 395, localhost, executor driver, partition 185, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:43,734 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 10.0 (TID 395)
[INFO] 2019-01-19 12:57:43,734 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 10.0 (TID 393) in 341 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 12:57:43,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:43,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:44,002 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 10.0 (TID 394). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:44,003 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 10.0 (TID 396, localhost, executor driver, partition 186, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:44,003 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 10.0 (TID 396)
[INFO] 2019-01-19 12:57:44,003 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 10.0 (TID 394) in 331 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 12:57:44,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:44,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:44,059 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 10.0 (TID 395). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:44,060 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 10.0 (TID 397, localhost, executor driver, partition 187, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:44,060 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 10.0 (TID 397)
[INFO] 2019-01-19 12:57:44,060 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 10.0 (TID 395) in 326 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 12:57:44,068 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:44,069 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:44,331 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 10.0 (TID 396). 4093 bytes result sent to driver
[INFO] 2019-01-19 12:57:44,332 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 10.0 (TID 398, localhost, executor driver, partition 188, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:44,332 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 10.0 (TID 398)
[INFO] 2019-01-19 12:57:44,332 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 10.0 (TID 396) in 329 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 12:57:44,341 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:44,341 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:44,387 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 10.0 (TID 397). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:44,387 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 10.0 (TID 399, localhost, executor driver, partition 189, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:44,388 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 10.0 (TID 397) in 328 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 12:57:44,388 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 10.0 (TID 399)
[INFO] 2019-01-19 12:57:44,400 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:44,400 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:44,663 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 10.0 (TID 398). 4166 bytes result sent to driver
[INFO] 2019-01-19 12:57:44,663 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 10.0 (TID 400, localhost, executor driver, partition 190, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:44,663 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 10.0 (TID 400)
[INFO] 2019-01-19 12:57:44,663 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 10.0 (TID 398) in 332 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 12:57:44,675 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:44,675 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:44,709 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 10.0 (TID 399). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:44,709 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 10.0 (TID 401, localhost, executor driver, partition 191, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:44,709 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 10.0 (TID 401)
[INFO] 2019-01-19 12:57:44,710 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 10.0 (TID 399) in 322 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 12:57:44,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:44,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:45,002 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 10.0 (TID 400). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:45,003 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 10.0 (TID 402, localhost, executor driver, partition 192, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:45,003 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 10.0 (TID 402)
[INFO] 2019-01-19 12:57:45,003 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 10.0 (TID 400) in 340 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 12:57:45,018 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:45,018 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:45,113 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 10.0 (TID 401). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:45,113 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 10.0 (TID 403, localhost, executor driver, partition 193, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:45,114 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 10.0 (TID 403)
[INFO] 2019-01-19 12:57:45,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 10.0 (TID 401) in 405 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 12:57:45,129 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:45,129 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:45,399 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 10.0 (TID 402). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:45,399 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 10.0 (TID 404, localhost, executor driver, partition 194, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:45,399 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 10.0 (TID 404)
[INFO] 2019-01-19 12:57:45,400 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 10.0 (TID 402) in 397 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 12:57:45,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:45,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:45,459 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 10.0 (TID 403). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:45,460 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 10.0 (TID 405, localhost, executor driver, partition 195, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:45,460 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 10.0 (TID 405)
[INFO] 2019-01-19 12:57:45,460 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 10.0 (TID 403) in 347 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 12:57:45,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:45,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:45,740 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 10.0 (TID 404). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:45,741 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 10.0 (TID 406, localhost, executor driver, partition 196, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:45,741 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 10.0 (TID 406)
[INFO] 2019-01-19 12:57:45,741 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 10.0 (TID 404) in 342 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 12:57:45,752 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:45,752 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:45,813 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 10.0 (TID 405). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:45,814 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 10.0 (TID 407, localhost, executor driver, partition 197, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:45,814 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 10.0 (TID 407)
[INFO] 2019-01-19 12:57:45,814 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 10.0 (TID 405) in 354 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 12:57:45,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:45,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:46,089 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 10.0 (TID 406). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:46,090 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 10.0 (TID 408, localhost, executor driver, partition 198, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:46,090 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 10.0 (TID 408)
[INFO] 2019-01-19 12:57:46,090 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 10.0 (TID 406) in 350 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 12:57:46,103 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:46,103 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:46,164 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 10.0 (TID 407). 4256 bytes result sent to driver
[INFO] 2019-01-19 12:57:46,164 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 10.0 (TID 409, localhost, executor driver, partition 199, ANY, 5789 bytes)
[INFO] 2019-01-19 12:57:46,165 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 10.0 (TID 409)
[INFO] 2019-01-19 12:57:46,165 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 10.0 (TID 407) in 351 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 12:57:46,174 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:46,174 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:46,422 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 10.0 (TID 408). 4270 bytes result sent to driver
[INFO] 2019-01-19 12:57:46,422 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 10.0 (TID 408) in 332 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 12:57:46,471 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 10.0 (TID 409). 4183 bytes result sent to driver
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 10.0 (TID 409) in 308 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 10 (head at DecoupJson.scala:139) finished in 36.128 s
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 11)
[INFO] 2019-01-19 12:57:46,472 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:46,473 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 11 (MapPartitionsRDD[47] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 12:57:46,494 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16 stored as values in memory (estimated size 672.0 KB, free 1989.7 MB)
[INFO] 2019-01-19 12:57:46,496 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16_piece0 stored as bytes in memory (estimated size 158.5 KB, free 1989.6 MB)
[INFO] 2019-01-19 12:57:46,497 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_16_piece0 in memory on 192.168.99.1:57186 (size: 158.5 KB, free: 1991.6 MB)
[INFO] 2019-01-19 12:57:46,497 org.apache.spark.SparkContext logInfo - Created broadcast 16 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:46,497 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[47] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 12:57:46,497 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 11.0 with 1 tasks
[INFO] 2019-01-19 12:57:46,498 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 11.0 (TID 410, localhost, executor driver, partition 0, ANY, 5800 bytes)
[INFO] 2019-01-19 12:57:46,498 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 11.0 (TID 410)
[INFO] 2019-01-19 12:57:46,508 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 200 non-empty blocks out of 200 blocks
[INFO] 2019-01-19 12:57:46,508 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:46,835 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 212.793439 ms
[INFO] 2019-01-19 12:57:46,959 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 40.452577 ms
[INFO] 2019-01-19 12:57:47,070 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 59.273511 ms
[INFO] 2019-01-19 12:57:47,167 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 83.198223 ms
[INFO] 2019-01-19 12:57:47,317 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 11.0 (TID 410). 8407 bytes result sent to driver
[INFO] 2019-01-19 12:57:47,318 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 11.0 (TID 410) in 820 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:47,318 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:47,318 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 11 (head at DecoupJson.scala:139) finished in 0.820 s
[INFO] 2019-01-19 12:57:47,319 org.apache.spark.scheduler.DAGScheduler logInfo - Job 4 finished: head at DecoupJson.scala:139, took 42.556323 s
[INFO] 2019-01-19 12:57:47,403 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 62.851515 ms
[INFO] 2019-01-19 12:57:47,511 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:47,512 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 12:57:47,513 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:47,513 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 12:57:47,514 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:47,515 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 12:57:47,516 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:47,516 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 12:57:47,571 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.933902 ms
[INFO] 2019-01-19 12:57:47,633 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 40.202571 ms
[INFO] 2019-01-19 12:57:47,652 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17 stored as values in memory (estimated size 292.7 KB, free 1989.3 MB)
[INFO] 2019-01-19 12:57:47,669 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1989.2 MB)
[INFO] 2019-01-19 12:57:47,670 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_17_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 12:57:47,671 org.apache.spark.SparkContext logInfo - Created broadcast 17 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 12:57:47,671 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:47,703 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18 stored as values in memory (estimated size 292.7 KB, free 1989.0 MB)
[INFO] 2019-01-19 12:57:47,719 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.9 MB)
[INFO] 2019-01-19 12:57:47,720 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_18_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 12:57:47,720 org.apache.spark.SparkContext logInfo - Created broadcast 18 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 12:57:47,721 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:47,792 org.apache.spark.SparkContext logInfo - Starting job: first at DecoupJson.scala:146
[INFO] 2019-01-19 12:57:47,793 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 56 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:47,793 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 51 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:47,793 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 61 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:47,794 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 5 (first at DecoupJson.scala:146) with 1 output partitions
[INFO] 2019-01-19 12:57:47,794 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 15 (first at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:47,794 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 14)
[INFO] 2019-01-19 12:57:47,794 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 14)
[INFO] 2019-01-19 12:57:47,794 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 12 (MapPartitionsRDD[56] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 12:57:47,797 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19 stored as values in memory (estimated size 39.9 KB, free 1988.9 MB)
[INFO] 2019-01-19 12:57:47,798 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1988.9 MB)
[INFO] 2019-01-19 12:57:47,804 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_19_piece0 in memory on 192.168.99.1:57186 (size: 12.5 KB, free: 1991.5 MB)
[INFO] 2019-01-19 12:57:47,805 org.apache.spark.SparkContext logInfo - Created broadcast 19 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:47,805 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[56] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:47,805 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 12.0 with 1 tasks
[INFO] 2019-01-19 12:57:47,805 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 13 (MapPartitionsRDD[51] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 12:57:47,806 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 12.0 (TID 411, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 12:57:47,806 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 12.0 (TID 411)
[INFO] 2019-01-19 12:57:47,807 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20 stored as values in memory (estimated size 39.9 KB, free 1988.8 MB)
[INFO] 2019-01-19 12:57:47,808 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1988.8 MB)
[INFO] 2019-01-19 12:57:47,809 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:47,809 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_20_piece0 in memory on 192.168.99.1:57186 (size: 12.5 KB, free: 1991.5 MB)
[INFO] 2019-01-19 12:57:47,810 org.apache.spark.SparkContext logInfo - Created broadcast 20 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:47,810 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[51] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:47,810 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 13.0 with 1 tasks
[INFO] 2019-01-19 12:57:47,819 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 12:57:47,832 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 13.0 (TID 412, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 12:57:47,832 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 13.0 (TID 412)
[INFO] 2019-01-19 12:57:47,842 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:47,857 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 12:57:47,942 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 13.0 (TID 412). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:47,946 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 12.0 (TID 411). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 13.0 (TID 412) in 176 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,006 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,006 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 13 (rdd at DecoupJson.scala:146) finished in 0.195 s
[INFO] 2019-01-19 12:57:48,006 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,007 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 12)
[INFO] 2019-01-19 12:57:48,007 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15, ShuffleMapStage 14)
[INFO] 2019-01-19 12:57:48,007 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 12.0 (TID 411) in 201 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,007 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,007 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 12 (rdd at DecoupJson.scala:146) finished in 0.202 s
[INFO] 2019-01-19 12:57:48,007 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,008 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:48,008 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15, ShuffleMapStage 14)
[INFO] 2019-01-19 12:57:48,008 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,008 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 12:57:48,011 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21 stored as values in memory (estimated size 139.7 KB, free 1988.7 MB)
[INFO] 2019-01-19 12:57:48,012 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21_piece0 stored as bytes in memory (estimated size 37.1 KB, free 1988.7 MB)
[INFO] 2019-01-19 12:57:48,013 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_21_piece0 in memory on 192.168.99.1:57186 (size: 37.1 KB, free: 1991.5 MB)
[INFO] 2019-01-19 12:57:48,014 org.apache.spark.SparkContext logInfo - Created broadcast 21 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,014 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:48,014 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 14.0 with 2 tasks
[INFO] 2019-01-19 12:57:48,015 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 14.0 (TID 413, localhost, executor driver, partition 0, ANY, 5967 bytes)
[INFO] 2019-01-19 12:57:48,016 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 14.0 (TID 414, localhost, executor driver, partition 1, ANY, 5967 bytes)
[INFO] 2019-01-19 12:57:48,016 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 14.0 (TID 413)
[INFO] 2019-01-19 12:57:48,016 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 14.0 (TID 414)
[INFO] 2019-01-19 12:57:48,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:48,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:48,021 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:48,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:48,087 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 14.0 (TID 413). 2633 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,087 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 14.0 (TID 413) in 72 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 12:57:48,094 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 14.0 (TID 414). 2633 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,094 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 14.0 (TID 414) in 78 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 12:57:48,094 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,094 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 14 (rdd at DecoupJson.scala:146) finished in 0.079 s
[INFO] 2019-01-19 12:57:48,095 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,095 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:48,095 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15)
[INFO] 2019-01-19 12:57:48,095 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,095 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 15 (MapPartitionsRDD[66] at map at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 12:57:48,100 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22 stored as values in memory (estimated size 155.4 KB, free 1988.5 MB)
[INFO] 2019-01-19 12:57:48,102 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22_piece0 stored as bytes in memory (estimated size 47.4 KB, free 1988.5 MB)
[INFO] 2019-01-19 12:57:48,103 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_22_piece0 in memory on 192.168.99.1:57186 (size: 47.4 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,103 org.apache.spark.SparkContext logInfo - Created broadcast 22 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,104 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[66] at map at DecoupJson.scala:146)
[INFO] 2019-01-19 12:57:48,104 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 15.0 with 1 tasks
[INFO] 2019-01-19 12:57:48,104 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 15.0 (TID 415, localhost, executor driver, partition 0, ANY, 5869 bytes)
[INFO] 2019-01-19 12:57:48,105 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 15.0 (TID 415)
[INFO] 2019-01-19 12:57:48,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:48,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:48,123 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.799183 ms
[INFO] 2019-01-19 12:57:48,127 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 15.0 (TID 415). 4133 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,128 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 15.0 (TID 415) in 24 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,128 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,128 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 15 (first at DecoupJson.scala:146) finished in 0.024 s
[INFO] 2019-01-19 12:57:48,128 org.apache.spark.scheduler.DAGScheduler logInfo - Job 5 finished: first at DecoupJson.scala:146, took 0.336321 s
[INFO] 2019-01-19 12:57:48,172 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:48,173 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 12:57:48,174 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 12:57:48,174 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 12:57:48,175 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:48,177 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 12:57:48,178 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 12:57:48,178 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 12:57:48,201 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.436253 ms
[INFO] 2019-01-19 12:57:48,205 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.098799 ms
[INFO] 2019-01-19 12:57:48,221 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 4.524428 ms
[INFO] 2019-01-19 12:57:48,230 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.401078 ms
[INFO] 2019-01-19 12:57:48,235 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23 stored as values in memory (estimated size 278.7 KB, free 1988.2 MB)
[INFO] 2019-01-19 12:57:48,251 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1988.2 MB)
[INFO] 2019-01-19 12:57:48,253 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_23_piece0 in memory on 192.168.99.1:57186 (size: 23.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,255 org.apache.spark.SparkContext logInfo - Created broadcast 23 from count at DecoupJson.scala:75
[INFO] 2019-01-19 12:57:48,256 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:48,275 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.775911 ms
[INFO] 2019-01-19 12:57:48,281 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24 stored as values in memory (estimated size 278.7 KB, free 1987.9 MB)
[INFO] 2019-01-19 12:57:48,296 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1987.9 MB)
[INFO] 2019-01-19 12:57:48,297 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_24_piece0 in memory on 192.168.99.1:57186 (size: 23.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,298 org.apache.spark.SparkContext logInfo - Created broadcast 24 from count at DecoupJson.scala:75
[INFO] 2019-01-19 12:57:48,298 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:48,329 org.apache.spark.SparkContext logInfo - Starting job: count at DecoupJson.scala:75
[INFO] 2019-01-19 12:57:48,329 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 71 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,330 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 76 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,330 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 81 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,330 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 6 (count at DecoupJson.scala:75) with 1 output partitions
[INFO] 2019-01-19 12:57:48,330 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 19 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,330 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 18)
[INFO] 2019-01-19 12:57:48,331 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 18)
[INFO] 2019-01-19 12:57:48,331 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 16 (MapPartitionsRDD[71] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 12:57:48,332 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25 stored as values in memory (estimated size 12.2 KB, free 1987.9 MB)
[INFO] 2019-01-19 12:57:48,334 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1987.9 MB)
[INFO] 2019-01-19 12:57:48,334 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_25_piece0 in memory on 192.168.99.1:57186 (size: 5.9 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,335 org.apache.spark.SparkContext logInfo - Created broadcast 25 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,335 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[71] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,335 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 16.0 with 1 tasks
[INFO] 2019-01-19 12:57:48,335 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 17 (MapPartitionsRDD[76] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 12:57:48,336 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 16.0 (TID 416, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 12:57:48,337 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 16.0 (TID 416)
[INFO] 2019-01-19 12:57:48,338 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26 stored as values in memory (estimated size 12.2 KB, free 1987.8 MB)
[INFO] 2019-01-19 12:57:48,339 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 12:57:48,340 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_26_piece0 in memory on 192.168.99.1:57186 (size: 5.9 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,341 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:48,342 org.apache.spark.SparkContext logInfo - Created broadcast 26 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,342 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[76] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,342 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 17.0 with 1 tasks
[INFO] 2019-01-19 12:57:48,344 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 17.0 (TID 417, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 12:57:48,346 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 17.0 (TID 417)
[INFO] 2019-01-19 12:57:48,348 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 12:57:48,356 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:48,367 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 12:57:48,389 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 16.0 (TID 416). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,389 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 16.0 (TID 416) in 54 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,389 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 16.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,389 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 16 (count at DecoupJson.scala:75) finished in 0.054 s
[INFO] 2019-01-19 12:57:48,390 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,390 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 17)
[INFO] 2019-01-19 12:57:48,390 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 19, ShuffleMapStage 18)
[INFO] 2019-01-19 12:57:48,390 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,399 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 17.0 (TID 417). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,399 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 17.0 (TID 417) in 56 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 17.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 17 (count at DecoupJson.scala:75) finished in 0.058 s
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 19, ShuffleMapStage 18)
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,400 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 18 (MapPartitionsRDD[81] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 12:57:48,403 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27 stored as values in memory (estimated size 39.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 12:57:48,404 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1987.8 MB)
[INFO] 2019-01-19 12:57:48,405 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_27_piece0 in memory on 192.168.99.1:57186 (size: 13.6 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,405 org.apache.spark.SparkContext logInfo - Created broadcast 27 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,406 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[81] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,406 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 18.0 with 2 tasks
[INFO] 2019-01-19 12:57:48,407 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 18.0 (TID 418, localhost, executor driver, partition 0, ANY, 5998 bytes)
[INFO] 2019-01-19 12:57:48,407 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 18.0 (TID 419, localhost, executor driver, partition 1, ANY, 5998 bytes)
[INFO] 2019-01-19 12:57:48,407 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 18.0 (TID 418)
[INFO] 2019-01-19 12:57:48,407 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 18.0 (TID 419)
[INFO] 2019-01-19 12:57:48,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:48,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:48,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:48,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:48,429 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 18.0 (TID 419). 2644 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,430 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 18.0 (TID 419) in 23 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 12:57:48,441 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 18.0 (TID 418). 2723 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,442 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 18.0 (TID 418) in 36 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 12:57:48,442 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 18.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,442 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 18 (count at DecoupJson.scala:75) finished in 0.036 s
[INFO] 2019-01-19 12:57:48,442 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,442 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:48,442 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 19)
[INFO] 2019-01-19 12:57:48,443 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,443 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 19 (MapPartitionsRDD[84] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 12:57:48,444 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 1987.8 MB)
[INFO] 2019-01-19 12:57:48,446 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1987.8 MB)
[INFO] 2019-01-19 12:57:48,447 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_28_piece0 in memory on 192.168.99.1:57186 (size: 3.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 12:57:48,449 org.apache.spark.SparkContext logInfo - Created broadcast 28 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,450 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[84] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 12:57:48,450 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 19.0 with 1 tasks
[INFO] 2019-01-19 12:57:48,450 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 19.0 (TID 420, localhost, executor driver, partition 0, ANY, 5900 bytes)
[INFO] 2019-01-19 12:57:48,451 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 19.0 (TID 420)
[INFO] 2019-01-19 12:57:48,452 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:48,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:48,456 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 19.0 (TID 420). 1963 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,456 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 19.0 (TID 420) in 6 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,456 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 19.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,456 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 19 (count at DecoupJson.scala:75) finished in 0.006 s
[INFO] 2019-01-19 12:57:48,462 org.apache.spark.scheduler.DAGScheduler logInfo - Job 6 finished: count at DecoupJson.scala:75, took 0.129932 s
[INFO] 2019-01-19 12:57:48,500 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:48,501 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 12:57:48,502 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:48,502 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 12:57:48,504 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:48,505 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 12:57:48,505 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:48,506 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 12:57:48,524 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 9.174037 ms
[INFO] 2019-01-19 12:57:48,535 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 8.208924 ms
[INFO] 2019-01-19 12:57:48,565 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.948803 ms
[INFO] 2019-01-19 12:57:48,573 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29 stored as values in memory (estimated size 292.7 KB, free 1987.5 MB)
[INFO] 2019-01-19 12:57:48,586 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.5 MB)
[INFO] 2019-01-19 12:57:48,587 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_29_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 12:57:48,588 org.apache.spark.SparkContext logInfo - Created broadcast 29 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 12:57:48,588 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:48,610 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.654698 ms
[INFO] 2019-01-19 12:57:48,617 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30 stored as values in memory (estimated size 292.7 KB, free 1987.2 MB)
[INFO] 2019-01-19 12:57:48,633 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.2 MB)
[INFO] 2019-01-19 12:57:48,634 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_30_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 12:57:48,635 org.apache.spark.SparkContext logInfo - Created broadcast 30 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 12:57:48,637 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:48,682 org.apache.spark.SparkContext logInfo - Starting job: collect at DecoupJson.scala:95
[INFO] 2019-01-19 12:57:48,682 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 93 (rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 12:57:48,683 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 7 (collect at DecoupJson.scala:95) with 1 output partitions
[INFO] 2019-01-19 12:57:48,683 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 21 (collect at DecoupJson.scala:95)
[INFO] 2019-01-19 12:57:48,683 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 20)
[INFO] 2019-01-19 12:57:48,683 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 20)
[INFO] 2019-01-19 12:57:48,684 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 20 (MapPartitionsRDD[93] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 12:57:48,688 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31 stored as values in memory (estimated size 123.7 KB, free 1987.0 MB)
[INFO] 2019-01-19 12:57:48,690 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1987.0 MB)
[INFO] 2019-01-19 12:57:48,691 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_31_piece0 in memory on 192.168.99.1:57186 (size: 32.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 12:57:48,691 org.apache.spark.SparkContext logInfo - Created broadcast 31 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,691 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[93] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 12:57:48,692 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 20.0 with 2 tasks
[INFO] 2019-01-19 12:57:48,693 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 20.0 (TID 421, localhost, executor driver, partition 0, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 12:57:48,693 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 20.0 (TID 422, localhost, executor driver, partition 1, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 12:57:48,693 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 20.0 (TID 421)
[INFO] 2019-01-19 12:57:48,693 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 20.0 (TID 422)
[INFO] 2019-01-19 12:57:48,705 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:48,705 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:48,717 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 12:57:48,720 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 12:57:48,783 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 20.0 (TID 421). 2545 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,784 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 20.0 (TID 421) in 92 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 12:57:48,788 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 20.0 (TID 422). 2545 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 20.0 (TID 422) in 96 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 20.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 20 (rdd at DecoupJson.scala:95) finished in 0.097 s
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 21)
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:48,789 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 21 (MapPartitionsRDD[97] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 12:57:48,791 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_32 stored as values in memory (estimated size 65.9 KB, free 1986.9 MB)
[INFO] 2019-01-19 12:57:48,792 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_32_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1986.9 MB)
[INFO] 2019-01-19 12:57:48,793 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_32_piece0 in memory on 192.168.99.1:57186 (size: 21.2 KB, free: 1991.3 MB)
[INFO] 2019-01-19 12:57:48,794 org.apache.spark.SparkContext logInfo - Created broadcast 32 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:48,794 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[97] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 12:57:48,794 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 21.0 with 1 tasks
[INFO] 2019-01-19 12:57:48,795 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 21.0 (TID 423, localhost, executor driver, partition 0, ANY, 5871 bytes)
[INFO] 2019-01-19 12:57:48,795 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 21.0 (TID 423)
[INFO] 2019-01-19 12:57:48,798 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 12:57:48,798 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:48,809 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 8.067878 ms
[INFO] 2019-01-19 12:57:48,816 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 21.0 (TID 423). 7362 bytes result sent to driver
[INFO] 2019-01-19 12:57:48,817 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 21.0 (TID 423) in 23 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:48,818 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 21 (collect at DecoupJson.scala:95) finished in 0.024 s
[INFO] 2019-01-19 12:57:48,818 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 21.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:48,818 org.apache.spark.scheduler.DAGScheduler logInfo - Job 7 finished: collect at DecoupJson.scala:95, took 0.136551 s
[INFO] 2019-01-19 12:57:48,848 myLogger setOutputDataTable - outputPath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train22
[INFO] 2019-01-19 12:57:48,931 org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat logInfo - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:48,953 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:48,955 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 12:57:48,956 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:48,956 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 12:57:48,957 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 12:57:48,958 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 12:57:48,959 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 12:57:48,959 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 12:57:48,971 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO] 2019-01-19 12:57:48,972 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO] 2019-01-19 12:57:48,973 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO] 2019-01-19 12:57:48,973 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO] 2019-01-19 12:57:48,973 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO] 2019-01-19 12:57:48,974 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 12:57:48,975 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:48,976 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 12:57:48,977 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:48,996 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_33 stored as values in memory (estimated size 292.7 KB, free 1986.6 MB)
[INFO] 2019-01-19 12:57:49,009 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_33_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1986.6 MB)
[INFO] 2019-01-19 12:57:49,009 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_33_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.2 MB)
[INFO] 2019-01-19 12:57:49,010 org.apache.spark.SparkContext logInfo - Created broadcast 33 from save at DecoupJson.scala:166
[INFO] 2019-01-19 12:57:49,010 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:49,034 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_34 stored as values in memory (estimated size 292.7 KB, free 1986.3 MB)
[INFO] 2019-01-19 12:57:49,047 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_34_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1986.3 MB)
[INFO] 2019-01-19 12:57:49,048 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_34_piece0 in memory on 192.168.99.1:57186 (size: 25.4 KB, free: 1991.2 MB)
[INFO] 2019-01-19 12:57:49,048 org.apache.spark.SparkContext logInfo - Created broadcast 34 from save at DecoupJson.scala:166
[INFO] 2019-01-19 12:57:49,049 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 12:57:49,097 org.apache.spark.SparkContext logInfo - Starting job: save at DecoupJson.scala:166
[INFO] 2019-01-19 12:57:49,098 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 106 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 12:57:49,098 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 101 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 12:57:49,099 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 8 (save at DecoupJson.scala:166) with 2 output partitions
[INFO] 2019-01-19 12:57:49,099 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 24 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 12:57:49,099 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 22, ShuffleMapStage 23)
[INFO] 2019-01-19 12:57:49,099 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 22, ShuffleMapStage 23)
[INFO] 2019-01-19 12:57:49,100 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 22 (MapPartitionsRDD[106] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 12:57:49,101 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_35 stored as values in memory (estimated size 39.9 KB, free 1986.3 MB)
[INFO] 2019-01-19 12:57:49,104 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_35_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1986.2 MB)
[INFO] 2019-01-19 12:57:49,105 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_35_piece0 in memory on 192.168.99.1:57186 (size: 12.5 KB, free: 1991.2 MB)
[INFO] 2019-01-19 12:57:49,106 org.apache.spark.SparkContext logInfo - Created broadcast 35 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:49,107 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[106] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 12:57:49,107 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 22.0 with 1 tasks
[INFO] 2019-01-19 12:57:49,107 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 23 (MapPartitionsRDD[101] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 12:57:49,108 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 22.0 (TID 424, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 12:57:49,108 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 22.0 (TID 424)
[INFO] 2019-01-19 12:57:49,109 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_36 stored as values in memory (estimated size 39.9 KB, free 1986.2 MB)
[INFO] 2019-01-19 12:57:49,110 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1986.2 MB)
[INFO] 2019-01-19 12:57:49,111 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_36_piece0 in memory on 192.168.99.1:57186 (size: 12.5 KB, free: 1991.2 MB)
[INFO] 2019-01-19 12:57:49,112 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:49,112 org.apache.spark.SparkContext logInfo - Created broadcast 36 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:49,112 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[101] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 12:57:49,112 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 23.0 with 1 tasks
[INFO] 2019-01-19 12:57:49,118 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 23.0 (TID 425, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 12:57:49,120 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 12:57:49,124 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 23.0 (TID 425)
[INFO] 2019-01-19 12:57:49,127 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 12:57:49,135 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 12:57:49,240 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 23.0 (TID 425). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:49,241 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 23.0 (TID 425) in 123 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:49,241 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 23.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:49,242 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 23 (save at DecoupJson.scala:166) finished in 0.128 s
[INFO] 2019-01-19 12:57:49,242 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:49,242 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 22)
[INFO] 2019-01-19 12:57:49,242 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 24)
[INFO] 2019-01-19 12:57:49,242 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:49,247 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 22.0 (TID 424). 1936 bytes result sent to driver
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 22.0 (TID 424) in 140 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 22 (save at DecoupJson.scala:166) finished in 0.141 s
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 24)
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 22.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:49,248 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 24 (UnionRDD[109] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 12:57:49,262 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_37 stored as values in memory (estimated size 140.7 KB, free 1986.1 MB)
[INFO] 2019-01-19 12:57:49,263 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_37_piece0 stored as bytes in memory (estimated size 41.7 KB, free 1986.0 MB)
[INFO] 2019-01-19 12:57:49,264 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_37_piece0 in memory on 192.168.99.1:57186 (size: 41.7 KB, free: 1991.2 MB)
[INFO] 2019-01-19 12:57:49,264 org.apache.spark.SparkContext logInfo - Created broadcast 37 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 12:57:49,264 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ResultStage 24 (UnionRDD[109] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 12:57:49,264 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 24.0 with 2 tasks
[INFO] 2019-01-19 12:57:49,265 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 24.0 (TID 426, localhost, executor driver, partition 0, ANY, 6017 bytes)
[INFO] 2019-01-19 12:57:49,266 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 24.0 (TID 427, localhost, executor driver, partition 1, ANY, 6017 bytes)
[INFO] 2019-01-19 12:57:49,266 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 24.0 (TID 426)
[INFO] 2019-01-19 12:57:49,266 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 24.0 (TID 427)
[INFO] 2019-01-19 12:57:49,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:49,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 12:57:49,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 12:57:49,278 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 12:57:49,280 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 12:57:49,281 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:49,282 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 12:57:49,282 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 12:57:49,283 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:49,283 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 12:57:49,283 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:49,283 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 12:57:49,286 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 12:57:49,286 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 12:57:49,289 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 12:57:49,289 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 12:57:49,306 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 12:57:49,307 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 12:57:49,307 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 12:57:49,307 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 12:57:49,309 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 12:57:49,314 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 12:57:49,314 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 12:57:49,314 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 12:57:49,314 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 12:57:49,314 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 12:57:49,315 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 12:57:49,315 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 12:57:49,315 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 12:57:49,315 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 12:57:49,325 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 12:57:49,329 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 12:57:49,357 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 12:57:49,363 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 12:57:49,456 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 32,866
[INFO] 2019-01-19 12:57:49,468 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 30,263
[INFO] 2019-01-19 12:57:49,530 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 1,520B for [crm_cust_no] BINARY: 111 values, 3,226B raw, 1,442B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 12:57:49,531 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 102B for [stat_mth] INT32: 111 values, 65B raw, 66B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 12:57:49,531 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [ast_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 96 entries, 768B raw, 96B comp}
[INFO] 2019-01-19 12:57:49,531 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 768B for [std_cred_curr_bal] DOUBLE: 111 values, 895B raw, 724B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 12:57:49,532 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 12:57:49,532 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 751B for [std_cred_bill_amt] DOUBLE: 111 values, 895B raw, 707B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 12:57:49,532 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [ln_curr_bal] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 12:57:49,533 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_ln_davg_bal] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 30 entries, 240B raw, 30B comp}
[INFO] 2019-01-19 12:57:49,534 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 43 entries, 344B raw, 43B comp}
[INFO] 2019-01-19 12:57:49,535 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 147B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 89 entries, 1,151B raw, 89B comp}
[INFO] 2019-01-19 12:57:49,537 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 60B for [std_cred_auto_repay_flag] INT32: 111 values, 24B raw, 26B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 12:57:49,538 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 489B for [std_cred_1st_biz_days] INT32: 111 values, 451B raw, 453B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 12:57:49,538 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [std_cred_lst_biz_days] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 12:57:49,539 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 91B for [std_cred_1stbiz_op_days] BINARY: 111 values, 59B raw, 59B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 103B raw, 16B comp}
[INFO] 2019-01-19 12:57:49,540 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 76B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 32B raw, 34B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,541 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_std_cred_znamt] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 12:57:49,541 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 137B for [l6m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 93B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 38 entries, 304B raw, 38B comp}
[INFO] 2019-01-19 12:57:49,541 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l12m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 54 entries, 432B raw, 54B comp}
[INFO] 2019-01-19 12:57:49,542 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l3m_ln_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,542 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,542 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,543 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,543 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,543 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,544 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [nty] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 12:57:49,544 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 30B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,544 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 59B raw, 10B comp}
[INFO] 2019-01-19 12:57:49,545 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [yg_flag] BINARY: 111 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 11B raw, 2B comp}
[INFO] 2019-01-19 12:57:49,545 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,545 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [house_stt] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 16B raw, 3B comp}
[INFO] 2019-01-19 12:57:49,546 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [work_years] INT32: 111 values, 62B raw, 62B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 12:57:49,546 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 72B for [unit_kind] BINARY: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 32B raw, 4B comp}
[INFO] 2019-01-19 12:57:49,546 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [title] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,551 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 90B for [occp] BINARY: 111 values, 56B raw, 58B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 163B raw, 19B comp}
[INFO] 2019-01-19 12:57:49,551 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,551 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 113B for [idy] BINARY: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 135B raw, 23B comp}
[INFO] 2019-01-19 12:57:49,553 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 27 entries, 216B raw, 27B comp}
[INFO] 2019-01-19 12:57:49,553 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 111B for [cp_y_income] BINARY: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 160B raw, 19B comp}
[INFO] 2019-01-19 12:57:49,553 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 15 entries, 60B raw, 15B comp}
[INFO] 2019-01-19 12:57:49,554 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 12:57:49,554 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 174B for [crm_cust_no] BINARY: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 57 entries, 1,653B raw, 57B comp}
[INFO] 2019-01-19 12:57:49,555 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [stat_mth] INT32: 111 values, 65B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 12:57:49,555 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [ast_curr_bal] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 52 entries, 416B raw, 52B comp}
[INFO] 2019-01-19 12:57:49,556 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [std_cred_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 688B raw, 86B comp}
[INFO] 2019-01-19 12:57:49,556 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ovd_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 12:57:49,556 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 129B for [zx_ln_max_ovd_amt] INT32: 111 values, 90B raw, 93B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 42 entries, 168B raw, 42B comp}
[INFO] 2019-01-19 12:57:49,556 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [zx_ln_tot_ovd_mths] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 92B raw, 23B comp}
[INFO] 2019-01-19 12:57:49,557 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,557 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_creds] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 12:57:49,557 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_cred_banks] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,557 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 12:57:49,559 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [std_cred_bill_amt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 688B raw, 86B comp}
[INFO] 2019-01-19 12:57:49,560 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 97B for [ln_curr_bal] DOUBLE: 111 values, 53B raw, 55B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 128B raw, 16B comp}
[INFO] 2019-01-19 12:57:49,560 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 108B for [l3m_ln_davg_bal] DOUBLE: 111 values, 62B raw, 65B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 152B raw, 19B comp}
[INFO] 2019-01-19 12:57:49,561 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 124B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 79B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 184B raw, 23B comp}
[INFO] 2019-01-19 12:57:49,563 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 63 entries, 798B raw, 63B comp}
[INFO] 2019-01-19 12:57:49,563 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 64B for [std_cred_auto_repay_flag] INT32: 111 values, 28B raw, 30B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 12:57:49,564 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 146B for [std_cred_1st_biz_days] INT32: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 332B raw, 83B comp}
[INFO] 2019-01-19 12:57:49,564 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_lst_biz_days] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 64B raw, 16B comp}
[INFO] 2019-01-19 12:57:49,564 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 63B for [std_cred_1stbiz_op_days] BINARY: 111 values, 31B raw, 33B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 31B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,564 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 30B raw, 32B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,565 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l3m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 79 entries, 632B raw, 79B comp}
[INFO] 2019-01-19 12:57:49,565 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l6m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 82 entries, 656B raw, 82B comp}
[INFO] 2019-01-19 12:57:49,565 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 48B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,565 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l12m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 664B raw, 83B comp}
[INFO] 2019-01-19 12:57:49,566 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 99B for [zx_cred_max_ovd_amt] INT64: 111 values, 58B raw, 57B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 12 entries, 96B raw, 12B comp}
[INFO] 2019-01-19 12:57:49,566 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [l3m_ln_ovd_days_bm] INT32: 111 values, 32B raw, 34B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,566 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [zx_cred_tot_ovd_mths] INT32: 111 values, 48B raw, 50B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 12:57:49,566 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 71B for [l12m_ln_ovd_days_bm] INT32: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 12:57:49,566 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [zx_cred_max_ovd_duration] INT32: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 12:57:49,566 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 65B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 29B raw, 31B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 12:57:49,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 71B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [nty] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 12:57:49,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 35B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 58B raw, 10B comp}
[INFO] 2019-01-19 12:57:49,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [yg_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,569 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 12:57:49,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [house_stt] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 12:57:49,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 81B for [work_years] INT32: 111 values, 45B raw, 47B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,574 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 66B for [unit_kind] BINARY: 111 values, 29B raw, 31B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 16B raw, 2B comp}
[INFO] 2019-01-19 12:57:49,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [title] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 12:57:49,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 75B for [occp] BINARY: 111 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 59B raw, 7B comp}
[INFO] 2019-01-19 12:57:49,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 12:57:49,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 78B for [idy] BINARY: 111 values, 46B raw, 48B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 42B raw, 7B comp}
[INFO] 2019-01-19 12:57:49,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 136B raw, 17B comp}
[INFO] 2019-01-19 12:57:49,577 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [cp_y_income] BINARY: 111 values, 53B raw, 55B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 86B raw, 11B comp}
[INFO] 2019-01-19 12:57:49,578 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 115B for [zx_max_lns] INT32: 111 values, 79B raw, 79B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 12:57:49,578 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 12:57:49,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 103B for [zx_max_ovd_lns] INT32: 111 values, 64B raw, 67B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 12:57:49,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 116B for [zx_ln_max_ovd_amt] INT32: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 30 entries, 120B raw, 30B comp}
[INFO] 2019-01-19 12:57:49,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 116B for [zx_ln_tot_ovd_mths] INT32: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 76B raw, 19B comp}
[INFO] 2019-01-19 12:57:49,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 12:57:49,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 99B for [zx_max_creds] INT32: 111 values, 61B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 12:57:49,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 86B for [zx_max_cred_banks] INT32: 111 values, 50B raw, 52B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 12:57:49,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 12:57:49,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [zx_cred_max_ovd_amt] INT64: 111 values, 53B raw, 54B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 14 entries, 112B raw, 14B comp}
[INFO] 2019-01-19 12:57:49,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 93B for [zx_cred_tot_ovd_mths] INT32: 111 values, 57B raw, 59B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 12:57:49,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_cred_max_ovd_duration] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 12:57:49,594 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119125749_0024_m_000000_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119125749_0024_m_000000
[INFO] 2019-01-19 12:57:49,595 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119125749_0024_m_000000_0: Committed
[INFO] 2019-01-19 12:57:49,597 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 24.0 (TID 426). 2289 bytes result sent to driver
[INFO] 2019-01-19 12:57:49,599 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 24.0 (TID 426) in 333 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 12:57:49,600 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119125749_0024_m_000001_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119125749_0024_m_000001
[INFO] 2019-01-19 12:57:49,600 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119125749_0024_m_000001_0: Committed
[INFO] 2019-01-19 12:57:49,600 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 24.0 (TID 427). 2202 bytes result sent to driver
[INFO] 2019-01-19 12:57:49,601 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 24.0 (TID 427) in 335 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 12:57:49,601 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 24.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 12:57:49,601 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 24 (save at DecoupJson.scala:166) finished in 0.336 s
[INFO] 2019-01-19 12:57:49,601 org.apache.spark.scheduler.DAGScheduler logInfo - Job 8 finished: save at DecoupJson.scala:166, took 0.504308 s
[WARN] 2019-01-19 12:57:49,633 org.apache.parquet.hadoop.ParquetOutputFormat warn - Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level
[INFO] 2019-01-19 12:57:49,638 org.apache.spark.sql.execution.datasources.FileFormatWriter logInfo - Job null committed.
[INFO] 2019-01-19 12:57:49,660 myLogger setOutputDataTable - summaryFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\summary
[INFO] 2019-01-19 12:57:49,662 myLogger main - LayerSample end
[INFO] 2019-01-19 12:57:49,666 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 12:57:49,681 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 12:57:49,695 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[ERROR] 2019-01-19 12:57:50,504 org.apache.spark.storage.DiskBlockManager logError - Exception while deleting local spark dir: C:\Users\dell\AppData\Local\Temp\blockmgr-e490c86a-0c58-4dad-abba-627214d01072
java.io.IOException: Failed to delete: C:\Users\dell\AppData\Local\Temp\blockmgr-e490c86a-0c58-4dad-abba-627214d01072
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:169)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:165)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:165)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:160)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1361)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:89)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
[INFO] 2019-01-19 12:57:50,510 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 12:57:50,511 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 12:57:50,512 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 12:57:50,516 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 12:57:50,521 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 12:57:50,522 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 12:57:50,524 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-26168980-766e-4642-864f-767dfe7ce38c
[INFO] 2019-01-19 13:18:18,769 myLogger main - LayerSample start
[INFO] 2019-01-19 13:18:20,477 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 13:18:21,058 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 13:18:21,060 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 13:18:21,060 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 13:18:21,128 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 13:18:21,128 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 13:18:21,129 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 13:18:21,129 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 13:18:21,129 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 13:18:21,988 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 57645.
[INFO] 2019-01-19 13:18:22,009 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 13:18:22,033 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 13:18:22,037 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 13:18:22,037 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 13:18:22,050 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-5960ed9e-261b-4fe6-98f5-e89d92986d99
[INFO] 2019-01-19 13:18:22,076 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 13:18:22,125 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 13:18:22,389 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 13:18:22,392 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 13:18:22,489 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 13:18:22,519 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57658.
[INFO] 2019-01-19 13:18:22,520 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:57658
[INFO] 2019-01-19 13:18:22,521 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 13:18:22,523 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 57658, None)
[INFO] 2019-01-19 13:18:22,526 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:57658 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 57658, None)
[INFO] 2019-01-19 13:18:22,530 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 57658, None)
[INFO] 2019-01-19 13:18:22,531 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 57658, None)
[INFO] 2019-01-19 13:18:22,869 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 13:18:23,168 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 13:18:23,901 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 13:18:23,924 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 13:18:23,925 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:18:23,926 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:18:23,927 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:18:23,936 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 13:18:24,051 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:18:24,106 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:18:24,112 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:57658 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:24,118 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:24,122 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:18:24,125 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 13:18:24,217 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 13:18:24,235 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 13:18:24,390 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 13:18:24,518 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 13:18:24,529 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 365 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:24,530 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:24,533 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.383 s
[INFO] 2019-01-19 13:18:24,540 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.638059 s
[INFO] 2019-01-19 13:18:25,220 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:57658 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:26,785 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:18:26,790 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 13:18:26,792 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:18:26,793 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 13:18:26,844 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 13:18:26,965 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 48
[INFO] 2019-01-19 13:18:27,280 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 262.922885 ms
[INFO] 2019-01-19 13:18:27,283 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 13:18:27,324 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 32.750011 ms
[INFO] 2019-01-19 13:18:27,357 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 278.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:18:27,373 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:18:27,374 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on 192.168.99.1:57658 (size: 23.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:27,376 org.apache.spark.SparkContext logInfo - Created broadcast 1 from rdd at LayerSample.scala:49
[INFO] 2019-01-19 13:18:27,390 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:18:27,521 org.apache.spark.SparkContext logInfo - Starting job: collect at LayerSample.scala:49
[INFO] 2019-01-19 13:18:27,526 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 6 (rdd at LayerSample.scala:49)
[INFO] 2019-01-19 13:18:27,528 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at LayerSample.scala:49) with 200 output partitions
[INFO] 2019-01-19 13:18:27,528 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 2 (collect at LayerSample.scala:49)
[INFO] 2019-01-19 13:18:27,528 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 1)
[INFO] 2019-01-19 13:18:27,529 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 1)
[INFO] 2019-01-19 13:18:27,530 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at rdd at LayerSample.scala:49), which has no missing parents
[INFO] 2019-01-19 13:18:27,540 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2 stored as values in memory (estimated size 17.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:18:27,547 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:18:27,549 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_2_piece0 in memory on 192.168.99.1:57658 (size: 8.0 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:27,550 org.apache.spark.SparkContext logInfo - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:27,552 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at rdd at LayerSample.scala:49)
[INFO] 2019-01-19 13:18:27,553 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2019-01-19 13:18:27,559 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6622 bytes)
[INFO] 2019-01-19 13:18:27,561 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2019-01-19 13:18:27,600 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.28553 ms
[INFO] 2019-01-19 13:18:27,617 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.479316 ms
[INFO] 2019-01-19 13:18:27,627 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.409894 ms
[INFO] 2019-01-19 13:18:27,637 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:18:27,746 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 13:18:28,234 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 2527 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,235 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 682 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:28,236 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:28,237 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 1 (rdd at LayerSample.scala:49) finished in 0.684 s
[INFO] 2019-01-19 13:18:28,238 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:18:28,238 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:18:28,239 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 2)
[INFO] 2019-01-19 13:18:28,239 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:18:28,243 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 2 (MapPartitionsRDD[11] at map at LayerSample.scala:49), which has no missing parents
[INFO] 2019-01-19 13:18:28,261 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3 stored as values in memory (estimated size 19.5 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:18:28,263 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:18:28,264 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_3_piece0 in memory on 192.168.99.1:57658 (size: 9.4 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:28,265 org.apache.spark.SparkContext logInfo - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:28,266 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at LayerSample.scala:49)
[INFO] 2019-01-19 13:18:28,267 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 2.0 with 200 tasks
[INFO] 2019-01-19 13:18:28,274 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,274 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,275 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 2.0 (TID 2)
[INFO] 2019-01-19 13:18:28,290 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 2.0 (TID 3)
[INFO] 2019-01-19 13:18:28,301 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,302 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 13 ms
[INFO] 2019-01-19 13:18:28,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 6 ms
[INFO] 2019-01-19 13:18:28,324 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.299172 ms
[INFO] 2019-01-19 13:18:28,336 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 2.0 (TID 3). 2826 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,336 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 2.0 (TID 2). 2826 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,338 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,339 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 2.0 (TID 4)
[INFO] 2019-01-19 13:18:28,342 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,343 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,346 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,346 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 2.0 (TID 3) in 72 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 13:18:28,347 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 2.0 (TID 4). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,348 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,349 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 2.0 (TID 4) in 12 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 13:18:28,350 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 2.0 (TID 6)
[INFO] 2019-01-19 13:18:28,353 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,353 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,356 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 2.0 (TID 5)
[INFO] 2019-01-19 13:18:28,356 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 2.0 (TID 6). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,357 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,358 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 2.0 (TID 6) in 10 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 13:18:28,359 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 2.0 (TID 7)
[INFO] 2019-01-19 13:18:28,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,363 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,366 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 2.0 (TID 7). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,367 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,367 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 2.0 (TID 8)
[INFO] 2019-01-19 13:18:28,369 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 2.0 (TID 7) in 12 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 13:18:28,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,373 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 2.0 (TID 8). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,374 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,376 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 2.0 (TID 9)
[INFO] 2019-01-19 13:18:28,376 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 2.0 (TID 8) in 10 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 13:18:28,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,383 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,386 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 2.0 (TID 5). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,388 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 2.0 (TID 9). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,388 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 2.0 (TID 2) in 116 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 13:18:28,389 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,390 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 2.0 (TID 10)
[INFO] 2019-01-19 13:18:28,393 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,394 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,394 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 2.0 (TID 11)
[INFO] 2019-01-19 13:18:28,394 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 2.0 (TID 9) in 20 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 13:18:28,397 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,397 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,400 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 2.0 (TID 11). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,400 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 2.0 (TID 10). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,401 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 2.0 (TID 5) in 62 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 13:18:28,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,403 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 2.0 (TID 12)
[INFO] 2019-01-19 13:18:28,405 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,405 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,406 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 2.0 (TID 11) in 16 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 13:18:28,406 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 2.0 (TID 10) in 17 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 13:18:28,406 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 2.0 (TID 13)
[INFO] 2019-01-19 13:18:28,406 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,409 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 2.0 (TID 12). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,413 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,415 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 2.0 (TID 12) in 14 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 13:18:28,416 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 2.0 (TID 13). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,416 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 2.0 (TID 14)
[INFO] 2019-01-19 13:18:28,420 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,420 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,422 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,423 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 2.0 (TID 13) in 19 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 13:18:28,425 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 2.0 (TID 14). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,426 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 2.0 (TID 15)
[INFO] 2019-01-19 13:18:28,428 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,429 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 2.0 (TID 14) in 16 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 13:18:28,430 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 2.0 (TID 16)
[INFO] 2019-01-19 13:18:28,434 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,434 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,437 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 2.0 (TID 15). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,437 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,437 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,445 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,447 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 2.0 (TID 15) in 28 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 13:18:28,449 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 2.0 (TID 17)
[INFO] 2019-01-19 13:18:28,464 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,464 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,469 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 2.0 (TID 17). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,449 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 2.0 (TID 16). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,728 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,730 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 2.0 (TID 17) in 289 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 13:18:28,732 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 2.0 (TID 16) in 305 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 13:18:28,734 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 2.0 (TID 19)
[INFO] 2019-01-19 13:18:28,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,748 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 2.0 (TID 19). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,749 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,750 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 2.0 (TID 18)
[INFO] 2019-01-19 13:18:28,755 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,755 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,760 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 2.0 (TID 18). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,762 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,763 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 2.0 (TID 19) in 35 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 13:18:28,764 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 2.0 (TID 18) in 37 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 13:18:28,768 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 2.0 (TID 20)
[INFO] 2019-01-19 13:18:28,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,777 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 2.0 (TID 20). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,785 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,786 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 2.0 (TID 21)
[INFO] 2019-01-19 13:18:28,789 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,789 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,795 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 2.0 (TID 21). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,795 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 2.0 (TID 20) in 47 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 13:18:28,796 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,798 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 2.0 (TID 22)
[INFO] 2019-01-19 13:18:28,800 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,801 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,803 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 2.0 (TID 22). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,804 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 2.0 (TID 21) in 43 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 13:18:28,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,808 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 2.0 (TID 23)
[INFO] 2019-01-19 13:18:28,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,815 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 2.0 (TID 23). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,817 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 2.0 (TID 22) in 32 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 13:18:28,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,822 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 2.0 (TID 24)
[INFO] 2019-01-19 13:18:28,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,829 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 2.0 (TID 24). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,830 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 2.0 (TID 23) in 34 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 13:18:28,833 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,834 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 2.0 (TID 25)
[INFO] 2019-01-19 13:18:28,836 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,837 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,844 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 2.0 (TID 25). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,845 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 2.0 (TID 24) in 38 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 13:18:28,845 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,846 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 2.0 (TID 26)
[INFO] 2019-01-19 13:18:28,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,854 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 2.0 (TID 26). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,856 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 2.0 (TID 25) in 34 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 13:18:28,859 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,859 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 2.0 (TID 27)
[INFO] 2019-01-19 13:18:28,860 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 2.0 (TID 26) in 28 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 13:18:28,862 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,863 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,865 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 2.0 (TID 27). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,866 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,866 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 2.0 (TID 28)
[INFO] 2019-01-19 13:18:28,867 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 2.0 (TID 29)
[INFO] 2019-01-19 13:18:28,867 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 2.0 (TID 27) in 22 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 13:18:28,870 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,870 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,912 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,913 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,919 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 2.0 (TID 29). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,920 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 2.0 (TID 28). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,921 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,921 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,922 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 2.0 (TID 29) in 57 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 13:18:28,923 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 2.0 (TID 28) in 65 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 13:18:28,924 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 2.0 (TID 30)
[INFO] 2019-01-19 13:18:28,928 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,928 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,934 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 2.0 (TID 30). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,934 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 2.0 (TID 31)
[INFO] 2019-01-19 13:18:28,938 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,938 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,941 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,942 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 2.0 (TID 30) in 22 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 13:18:28,943 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 2.0 (TID 32)
[INFO] 2019-01-19 13:18:28,946 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 2.0 (TID 31). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,946 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,947 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,949 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,950 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 2.0 (TID 33)
[INFO] 2019-01-19 13:18:28,951 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 2.0 (TID 31) in 30 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 13:18:28,953 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 2.0 (TID 32). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,954 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,955 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,955 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,957 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 2.0 (TID 34)
[INFO] 2019-01-19 13:18:28,959 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 2.0 (TID 33). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,960 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,962 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 2.0 (TID 33) in 14 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 13:18:28,962 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 2.0 (TID 35)
[INFO] 2019-01-19 13:18:28,962 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 2.0 (TID 32) in 21 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 13:18:28,962 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,964 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:18:28,964 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,964 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,968 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 2.0 (TID 34). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,969 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 2.0 (TID 35). 2823 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,969 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 2.0 (TID 36)
[INFO] 2019-01-19 13:18:28,970 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,971 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 2.0 (TID 35) in 11 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 13:18:28,972 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 2.0 (TID 37)
[INFO] 2019-01-19 13:18:28,972 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,972 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,975 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 2.0 (TID 36). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,976 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,976 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:28,977 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 2.0 (TID 34) in 24 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 13:18:28,979 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,979 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 2.0 (TID 37). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,981 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,981 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 2.0 (TID 38)
[INFO] 2019-01-19 13:18:28,982 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 2.0 (TID 37) in 11 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 13:18:28,982 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 2.0 (TID 39)
[INFO] 2019-01-19 13:18:28,982 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,985 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 2.0 (TID 36) in 17 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 13:18:28,985 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:28,986 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:28,994 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 2.0 (TID 39). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:28,995 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:28,996 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 2.0 (TID 39) in 16 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 13:18:28,996 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 2.0 (TID 40)
[INFO] 2019-01-19 13:18:29,003 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 2.0 (TID 38). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,005 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 2.0 (TID 38) in 28 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 13:18:29,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,024 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 2.0 (TID 40). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,025 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,025 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 2.0 (TID 40) in 30 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 13:18:29,025 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 2.0 (TID 42)
[INFO] 2019-01-19 13:18:29,028 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,028 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,030 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 2.0 (TID 42). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,032 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,032 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 2.0 (TID 42) in 8 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 13:18:29,032 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 2.0 (TID 43)
[INFO] 2019-01-19 13:18:29,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,037 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 2.0 (TID 43). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,038 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,039 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 2.0 (TID 43) in 8 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 13:18:29,039 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 2.0 (TID 44)
[INFO] 2019-01-19 13:18:29,042 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,042 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,045 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 2.0 (TID 44). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,046 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 2.0 (TID 45, localhost, executor driver, partition 44, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,046 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 2.0 (TID 44) in 8 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 13:18:29,047 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 2.0 (TID 45)
[INFO] 2019-01-19 13:18:29,049 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,049 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,052 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 2.0 (TID 45). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,053 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 2.0 (TID 46, localhost, executor driver, partition 45, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,053 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 2.0 (TID 45) in 8 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 13:18:29,053 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 2.0 (TID 46)
[INFO] 2019-01-19 13:18:29,056 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,056 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,059 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 2.0 (TID 46). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,060 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 2.0 (TID 47, localhost, executor driver, partition 46, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,060 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 2.0 (TID 46) in 7 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 13:18:29,060 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 2.0 (TID 47)
[INFO] 2019-01-19 13:18:29,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,083 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,086 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 2.0 (TID 47). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,087 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 2.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,087 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 2.0 (TID 48)
[INFO] 2019-01-19 13:18:29,087 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 2.0 (TID 47) in 27 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 13:18:29,096 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,096 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,098 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 2.0 (TID 48). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,099 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 2.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,100 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 2.0 (TID 48) in 14 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 13:18:29,100 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 2.0 (TID 49)
[INFO] 2019-01-19 13:18:29,103 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,103 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,105 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 2.0 (TID 49). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,106 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 2.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,106 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 2.0 (TID 50)
[INFO] 2019-01-19 13:18:29,107 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 2.0 (TID 49) in 7 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 13:18:29,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,111 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 2.0 (TID 50). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,112 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 2.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,113 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 2.0 (TID 50) in 6 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 13:18:29,113 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 2.0 (TID 51)
[INFO] 2019-01-19 13:18:29,115 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,116 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,118 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 2.0 (TID 51). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,119 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 2.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,119 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 2.0 (TID 51) in 7 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 13:18:29,127 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 2.0 (TID 41)
[INFO] 2019-01-19 13:18:29,130 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,130 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,133 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 2.0 (TID 41). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,134 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 2.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,136 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 2.0 (TID 53)
[INFO] 2019-01-19 13:18:29,144 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,144 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,147 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 2.0 (TID 53). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,144 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 2.0 (TID 41) in 139 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 13:18:29,149 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 2.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,150 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 2.0 (TID 53) in 15 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 13:18:29,150 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 2.0 (TID 54)
[INFO] 2019-01-19 13:18:29,153 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,153 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,155 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 2.0 (TID 54). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,156 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 2.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,157 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 2.0 (TID 55)
[INFO] 2019-01-19 13:18:29,158 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 2.0 (TID 54) in 9 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 13:18:29,168 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,173 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 2.0 (TID 55). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,175 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 2.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,175 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 2.0 (TID 55) in 19 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 13:18:29,176 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 2.0 (TID 56)
[INFO] 2019-01-19 13:18:29,179 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,179 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,182 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 2.0 (TID 56). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,184 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 2.0 (TID 57, localhost, executor driver, partition 56, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,185 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 2.0 (TID 56) in 11 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 13:18:29,185 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 2.0 (TID 57)
[INFO] 2019-01-19 13:18:29,188 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,188 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,206 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 2.0 (TID 52)
[INFO] 2019-01-19 13:18:29,209 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,209 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,212 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 2.0 (TID 52). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,213 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 2.0 (TID 58, localhost, executor driver, partition 57, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,214 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 2.0 (TID 52) in 96 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 13:18:29,214 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 2.0 (TID 58)
[INFO] 2019-01-19 13:18:29,218 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,219 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,222 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 2.0 (TID 58). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,223 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 2.0 (TID 59, localhost, executor driver, partition 58, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,223 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 2.0 (TID 58) in 10 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 13:18:29,224 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 2.0 (TID 59)
[INFO] 2019-01-19 13:18:29,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,230 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 2.0 (TID 59). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,232 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 2.0 (TID 60, localhost, executor driver, partition 59, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,233 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 2.0 (TID 59) in 10 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 13:18:29,233 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 2.0 (TID 60)
[INFO] 2019-01-19 13:18:29,236 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,236 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,239 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 2.0 (TID 60). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,241 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 2.0 (TID 61, localhost, executor driver, partition 60, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,241 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 2.0 (TID 60) in 10 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 13:18:29,242 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 2.0 (TID 61)
[INFO] 2019-01-19 13:18:29,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,247 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 2.0 (TID 61). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,248 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 2.0 (TID 62, localhost, executor driver, partition 61, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,249 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 2.0 (TID 61) in 9 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 13:18:29,250 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 2.0 (TID 62)
[INFO] 2019-01-19 13:18:29,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,256 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 2.0 (TID 62). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,258 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 2.0 (TID 63, localhost, executor driver, partition 62, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,258 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 2.0 (TID 62) in 10 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 13:18:29,259 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 2.0 (TID 63)
[INFO] 2019-01-19 13:18:29,261 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,262 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,267 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 2.0 (TID 63). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,270 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 2.0 (TID 64, localhost, executor driver, partition 63, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,271 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 2.0 (TID 63) in 14 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 13:18:29,271 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 2.0 (TID 64)
[INFO] 2019-01-19 13:18:29,275 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,275 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,318 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 2.0 (TID 57). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,319 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 2.0 (TID 65, localhost, executor driver, partition 64, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 2.0 (TID 57) in 135 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 13:18:29,319 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 2.0 (TID 65)
[INFO] 2019-01-19 13:18:29,323 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,323 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,347 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 2.0 (TID 65). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,354 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 2.0 (TID 66, localhost, executor driver, partition 65, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,357 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 2.0 (TID 65) in 39 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 13:18:29,359 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 2.0 (TID 66)
[INFO] 2019-01-19 13:18:29,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,365 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 2.0 (TID 66). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,368 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 2.0 (TID 67, localhost, executor driver, partition 66, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,374 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 2.0 (TID 66) in 20 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 13:18:29,375 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 2.0 (TID 67)
[INFO] 2019-01-19 13:18:29,377 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,377 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,387 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 2.0 (TID 67). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,388 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 2.0 (TID 68, localhost, executor driver, partition 67, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,394 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 2.0 (TID 67) in 27 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 13:18:29,395 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 2.0 (TID 68)
[INFO] 2019-01-19 13:18:29,398 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,398 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,401 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 2.0 (TID 68). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 2.0 (TID 69, localhost, executor driver, partition 68, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,411 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 2.0 (TID 68) in 23 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 13:18:29,416 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 2.0 (TID 69)
[INFO] 2019-01-19 13:18:29,419 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,419 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,510 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 2.0 (TID 64). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,510 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 2.0 (TID 70, localhost, executor driver, partition 69, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,511 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 2.0 (TID 64) in 243 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 13:18:29,512 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 2.0 (TID 70)
[INFO] 2019-01-19 13:18:29,514 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,515 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,517 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 2.0 (TID 70). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,517 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 2.0 (TID 71, localhost, executor driver, partition 70, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,518 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 2.0 (TID 70) in 8 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 13:18:29,519 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 2.0 (TID 71)
[INFO] 2019-01-19 13:18:29,522 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,522 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,527 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 2.0 (TID 71). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,529 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 2.0 (TID 72, localhost, executor driver, partition 71, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,529 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 2.0 (TID 71) in 12 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 13:18:29,530 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 2.0 (TID 72)
[INFO] 2019-01-19 13:18:29,533 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,534 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,538 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 2.0 (TID 72). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,539 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 2.0 (TID 73, localhost, executor driver, partition 72, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,540 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 2.0 (TID 72) in 12 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 13:18:29,540 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 2.0 (TID 73)
[INFO] 2019-01-19 13:18:29,543 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,544 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,547 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 2.0 (TID 73). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,549 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 2.0 (TID 74, localhost, executor driver, partition 73, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,549 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 2.0 (TID 73) in 11 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 13:18:29,551 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 2.0 (TID 74)
[INFO] 2019-01-19 13:18:29,555 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,555 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,559 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 2.0 (TID 74). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,561 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 2.0 (TID 75, localhost, executor driver, partition 74, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,563 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 2.0 (TID 74) in 14 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 13:18:29,564 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 2.0 (TID 75)
[INFO] 2019-01-19 13:18:29,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,574 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 2.0 (TID 75). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,576 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 2.0 (TID 76, localhost, executor driver, partition 75, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,577 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 2.0 (TID 75) in 18 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 13:18:29,579 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 2.0 (TID 76)
[INFO] 2019-01-19 13:18:29,586 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,587 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,625 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 2.0 (TID 69). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,626 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 2.0 (TID 77, localhost, executor driver, partition 76, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,627 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 2.0 (TID 69) in 225 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 13:18:29,627 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 2.0 (TID 77)
[INFO] 2019-01-19 13:18:29,632 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,632 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,637 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 2.0 (TID 77). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,638 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 2.0 (TID 78, localhost, executor driver, partition 77, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,638 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 2.0 (TID 77) in 12 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 13:18:29,640 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 2.0 (TID 78)
[INFO] 2019-01-19 13:18:29,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,656 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 2.0 (TID 78). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,657 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 2.0 (TID 79, localhost, executor driver, partition 78, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,657 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 2.0 (TID 78) in 20 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 13:18:29,658 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 2.0 (TID 79)
[INFO] 2019-01-19 13:18:29,661 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,661 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,664 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 2.0 (TID 79). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,665 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 2.0 (TID 80, localhost, executor driver, partition 79, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,665 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 2.0 (TID 79) in 9 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 13:18:29,666 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 2.0 (TID 80)
[INFO] 2019-01-19 13:18:29,669 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,669 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,672 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 2.0 (TID 80). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,675 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 2.0 (TID 81, localhost, executor driver, partition 80, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,677 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 2.0 (TID 80) in 12 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 13:18:29,678 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 2.0 (TID 81)
[INFO] 2019-01-19 13:18:29,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,681 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,685 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 2.0 (TID 81). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,686 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 2.0 (TID 82, localhost, executor driver, partition 81, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,689 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 2.0 (TID 81) in 14 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 13:18:29,690 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 2.0 (TID 82)
[INFO] 2019-01-19 13:18:29,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,698 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 2.0 (TID 82). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,699 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 2.0 (TID 83, localhost, executor driver, partition 82, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,701 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 2.0 (TID 82) in 15 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 13:18:29,702 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 2.0 (TID 83)
[INFO] 2019-01-19 13:18:29,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,706 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,712 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 2.0 (TID 83). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,714 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 2.0 (TID 84, localhost, executor driver, partition 83, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,717 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 2.0 (TID 83) in 18 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 13:18:29,718 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 2.0 (TID 84)
[INFO] 2019-01-19 13:18:29,771 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 2.0 (TID 76). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,773 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 2.0 (TID 85, localhost, executor driver, partition 84, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,774 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 2.0 (TID 76) in 198 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 13:18:29,774 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 2.0 (TID 85)
[INFO] 2019-01-19 13:18:29,777 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,777 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,786 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 2.0 (TID 85). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,787 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 2.0 (TID 86, localhost, executor driver, partition 85, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,788 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 2.0 (TID 86)
[INFO] 2019-01-19 13:18:29,788 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 2.0 (TID 85) in 16 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 13:18:29,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,795 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 2.0 (TID 86). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,797 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 2.0 (TID 87, localhost, executor driver, partition 86, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,800 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 2.0 (TID 86) in 12 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 13:18:29,801 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 2.0 (TID 87)
[INFO] 2019-01-19 13:18:29,805 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,805 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,810 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 2.0 (TID 87). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,811 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 2.0 (TID 88, localhost, executor driver, partition 87, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,812 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 2.0 (TID 87) in 15 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 13:18:29,813 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 2.0 (TID 88)
[INFO] 2019-01-19 13:18:29,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,821 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 2.0 (TID 88). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 2.0 (TID 89, localhost, executor driver, partition 88, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,822 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 2.0 (TID 89)
[INFO] 2019-01-19 13:18:29,827 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 2.0 (TID 88) in 11 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 13:18:29,827 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,833 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 2.0 (TID 89). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,834 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 2.0 (TID 90, localhost, executor driver, partition 89, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,835 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 2.0 (TID 89) in 14 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 13:18:29,836 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 2.0 (TID 90)
[INFO] 2019-01-19 13:18:29,839 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,839 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,877 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 2.0 (TID 84). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,878 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 2.0 (TID 91, localhost, executor driver, partition 90, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,879 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 2.0 (TID 84) in 165 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 13:18:29,879 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 2.0 (TID 91)
[INFO] 2019-01-19 13:18:29,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,885 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 2.0 (TID 91). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,886 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 2.0 (TID 92, localhost, executor driver, partition 91, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,887 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 2.0 (TID 91) in 9 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 13:18:29,887 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 2.0 (TID 92)
[INFO] 2019-01-19 13:18:29,894 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,895 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,900 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 2.0 (TID 92). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,902 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 2.0 (TID 93, localhost, executor driver, partition 92, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,903 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 2.0 (TID 92) in 18 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 13:18:29,904 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 2.0 (TID 93)
[INFO] 2019-01-19 13:18:29,907 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,907 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,912 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 2.0 (TID 93). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,915 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 2.0 (TID 94, localhost, executor driver, partition 93, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,916 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 2.0 (TID 93) in 14 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 13:18:29,916 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 2.0 (TID 94)
[INFO] 2019-01-19 13:18:29,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,925 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 2.0 (TID 94). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,951 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 2.0 (TID 90). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,952 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 2.0 (TID 95, localhost, executor driver, partition 94, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,953 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 2.0 (TID 96, localhost, executor driver, partition 95, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,955 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 2.0 (TID 94) in 43 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 13:18:29,956 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 2.0 (TID 90) in 122 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 13:18:29,958 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 2.0 (TID 95)
[INFO] 2019-01-19 13:18:29,958 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 2.0 (TID 96)
[INFO] 2019-01-19 13:18:29,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,962 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 2.0 (TID 95). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,963 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 2.0 (TID 97, localhost, executor driver, partition 96, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,964 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:18:29,964 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 2.0 (TID 95) in 12 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 13:18:29,966 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 2.0 (TID 96). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,966 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 2.0 (TID 97)
[INFO] 2019-01-19 13:18:29,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 2.0 (TID 98, localhost, executor driver, partition 97, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,970 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 2.0 (TID 97). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,970 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 2.0 (TID 96) in 18 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 13:18:29,971 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 2.0 (TID 98)
[INFO] 2019-01-19 13:18:29,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,975 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 2.0 (TID 98). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,976 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 2.0 (TID 99, localhost, executor driver, partition 98, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,976 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 2.0 (TID 100, localhost, executor driver, partition 99, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,977 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 2.0 (TID 97) in 14 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 13:18:29,978 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 2.0 (TID 98) in 11 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 13:18:29,978 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 2.0 (TID 99)
[INFO] 2019-01-19 13:18:29,978 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 2.0 (TID 100)
[INFO] 2019-01-19 13:18:29,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:29,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,983 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 2.0 (TID 100). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,984 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 2.0 (TID 101, localhost, executor driver, partition 100, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,984 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 2.0 (TID 100) in 8 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 13:18:29,985 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 2.0 (TID 101)
[INFO] 2019-01-19 13:18:29,987 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:29,988 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:29,990 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 2.0 (TID 101). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:29,991 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 2.0 (TID 102, localhost, executor driver, partition 101, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:29,991 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 2.0 (TID 101) in 7 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 13:18:29,991 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 2.0 (TID 102)
[INFO] 2019-01-19 13:18:30,045 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 2.0 (TID 99). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,050 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 2.0 (TID 103, localhost, executor driver, partition 102, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,052 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 2.0 (TID 99) in 76 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 13:18:30,052 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 2.0 (TID 103)
[INFO] 2019-01-19 13:18:30,053 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 2.0 (TID 102). 2730 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,052 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_2_piece0 on 192.168.99.1:57658 in memory (size: 8.0 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:30,054 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 2.0 (TID 104, localhost, executor driver, partition 103, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,054 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 2.0 (TID 102) in 64 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 13:18:30,055 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,055 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,055 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 2.0 (TID 104)
[INFO] 2019-01-19 13:18:30,058 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,058 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,061 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 2.0 (TID 103). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,061 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 2.0 (TID 105, localhost, executor driver, partition 104, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,062 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 2.0 (TID 103) in 12 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 13:18:30,062 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 2.0 (TID 105)
[INFO] 2019-01-19 13:18:30,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,067 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 2.0 (TID 105). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,065 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 2.0 (TID 104). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,067 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 2.0 (TID 106, localhost, executor driver, partition 105, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,068 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 2.0 (TID 106)
[INFO] 2019-01-19 13:18:30,068 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 2.0 (TID 107, localhost, executor driver, partition 106, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,068 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 2.0 (TID 104) in 14 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 13:18:30,070 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,070 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,071 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 2.0 (TID 105) in 10 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 13:18:30,071 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 2.0 (TID 107)
[INFO] 2019-01-19 13:18:30,073 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,073 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,074 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 2.0 (TID 106). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,076 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 2.0 (TID 107). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 2.0 (TID 108, localhost, executor driver, partition 107, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 2.0 (TID 109, localhost, executor driver, partition 108, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,077 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 2.0 (TID 106) in 10 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 13:18:30,077 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 2.0 (TID 107) in 9 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 13:18:30,077 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 2.0 (TID 109)
[INFO] 2019-01-19 13:18:30,077 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 2.0 (TID 108)
[INFO] 2019-01-19 13:18:30,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,082 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 2.0 (TID 108). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,082 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 2.0 (TID 109). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,082 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 2.0 (TID 110, localhost, executor driver, partition 109, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,083 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 2.0 (TID 111, localhost, executor driver, partition 110, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,083 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 2.0 (TID 108) in 8 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 13:18:30,084 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 2.0 (TID 109) in 7 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 13:18:30,084 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 2.0 (TID 111)
[INFO] 2019-01-19 13:18:30,084 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 2.0 (TID 110)
[INFO] 2019-01-19 13:18:30,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,088 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 2.0 (TID 110). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,089 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 2.0 (TID 112, localhost, executor driver, partition 111, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,089 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 2.0 (TID 110) in 7 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 13:18:30,089 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 2.0 (TID 111). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,089 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 2.0 (TID 112)
[INFO] 2019-01-19 13:18:30,090 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 2.0 (TID 113, localhost, executor driver, partition 112, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,092 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,092 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,094 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 2.0 (TID 112). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,095 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 2.0 (TID 114, localhost, executor driver, partition 113, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,095 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 2.0 (TID 111) in 12 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 13:18:30,095 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 2.0 (TID 112) in 7 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 13:18:30,096 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 2.0 (TID 113)
[INFO] 2019-01-19 13:18:30,097 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 2.0 (TID 114)
[INFO] 2019-01-19 13:18:30,098 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,098 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,100 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 2.0 (TID 113). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,104 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 2.0 (TID 114). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,104 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 2.0 (TID 115, localhost, executor driver, partition 114, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,105 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 2.0 (TID 116, localhost, executor driver, partition 115, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,105 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 2.0 (TID 113) in 15 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 13:18:30,105 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 2.0 (TID 115)
[INFO] 2019-01-19 13:18:30,106 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 2.0 (TID 116)
[INFO] 2019-01-19 13:18:30,108 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,108 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,105 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 2.0 (TID 114) in 11 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 13:18:30,110 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 2.0 (TID 116). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,110 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,110 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,112 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 2.0 (TID 115). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,112 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 2.0 (TID 117, localhost, executor driver, partition 116, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,113 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 2.0 (TID 118, localhost, executor driver, partition 117, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 2.0 (TID 116) in 9 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 13:18:30,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 2.0 (TID 115) in 10 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 13:18:30,115 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 2.0 (TID 117)
[INFO] 2019-01-19 13:18:30,116 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 2.0 (TID 118)
[INFO] 2019-01-19 13:18:30,116 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,118 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,127 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 10 ms
[INFO] 2019-01-19 13:18:30,128 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 12 ms
[INFO] 2019-01-19 13:18:30,129 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 2.0 (TID 118). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,129 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 2.0 (TID 119, localhost, executor driver, partition 118, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,130 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 2.0 (TID 118) in 17 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 13:18:30,130 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 2.0 (TID 119)
[INFO] 2019-01-19 13:18:30,134 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 2.0 (TID 117). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,134 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 2.0 (TID 120, localhost, executor driver, partition 119, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,135 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 2.0 (TID 120)
[INFO] 2019-01-19 13:18:30,135 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 2.0 (TID 117) in 23 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 13:18:30,138 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,138 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,140 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 2.0 (TID 120). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,141 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 2.0 (TID 121, localhost, executor driver, partition 120, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,141 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 2.0 (TID 121)
[INFO] 2019-01-19 13:18:30,141 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 2.0 (TID 120) in 7 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 13:18:30,144 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,144 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,145 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 2.0 (TID 121). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,146 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 2.0 (TID 122, localhost, executor driver, partition 121, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,146 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 2.0 (TID 121) in 5 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 13:18:30,146 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 2.0 (TID 122)
[INFO] 2019-01-19 13:18:30,148 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,148 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,148 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,149 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,149 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 2.0 (TID 119). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,150 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 2.0 (TID 123, localhost, executor driver, partition 122, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,150 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 2.0 (TID 122). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,151 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 2.0 (TID 123)
[INFO] 2019-01-19 13:18:30,150 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 2.0 (TID 119) in 21 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 13:18:30,152 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,153 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,154 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 2.0 (TID 123). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,154 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 2.0 (TID 124, localhost, executor driver, partition 123, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,155 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 2.0 (TID 125, localhost, executor driver, partition 124, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,156 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 2.0 (TID 122) in 10 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 13:18:30,156 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 2.0 (TID 123) in 6 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 13:18:30,161 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 2.0 (TID 124)
[INFO] 2019-01-19 13:18:30,163 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,164 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,166 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 2.0 (TID 124). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,167 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 2.0 (TID 125)
[INFO] 2019-01-19 13:18:30,168 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 2.0 (TID 126, localhost, executor driver, partition 125, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,169 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 2.0 (TID 124) in 18 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 13:18:30,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,169 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 2.0 (TID 126)
[INFO] 2019-01-19 13:18:30,171 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 2.0 (TID 125). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,172 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,172 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,175 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 2.0 (TID 126). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,175 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 2.0 (TID 127, localhost, executor driver, partition 126, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,177 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 2.0 (TID 127)
[INFO] 2019-01-19 13:18:30,177 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 2.0 (TID 128, localhost, executor driver, partition 127, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,178 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 2.0 (TID 126) in 10 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 13:18:30,178 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 2.0 (TID 128)
[INFO] 2019-01-19 13:18:30,179 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,179 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,180 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,180 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,181 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 2.0 (TID 127). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,181 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 2.0 (TID 125) in 26 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 13:18:30,182 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 2.0 (TID 129, localhost, executor driver, partition 128, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,182 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 2.0 (TID 128). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,183 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 2.0 (TID 130, localhost, executor driver, partition 129, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,183 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 2.0 (TID 129)
[INFO] 2019-01-19 13:18:30,183 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 2.0 (TID 128) in 6 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 13:18:30,184 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 2.0 (TID 127) in 10 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 13:18:30,184 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 2.0 (TID 130)
[INFO] 2019-01-19 13:18:30,184 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,185 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,187 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 2.0 (TID 129). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,187 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,187 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,189 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 2.0 (TID 131, localhost, executor driver, partition 130, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,189 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 2.0 (TID 130). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,189 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 2.0 (TID 129) in 7 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 13:18:30,189 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 2.0 (TID 131)
[INFO] 2019-01-19 13:18:30,190 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 2.0 (TID 132, localhost, executor driver, partition 131, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,191 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 2.0 (TID 130) in 9 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 13:18:30,192 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,192 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,192 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 2.0 (TID 132)
[INFO] 2019-01-19 13:18:30,193 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 2.0 (TID 131). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,194 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 2.0 (TID 133, localhost, executor driver, partition 132, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,194 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 2.0 (TID 131) in 6 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 13:18:30,195 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 2.0 (TID 133)
[INFO] 2019-01-19 13:18:30,194 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,195 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,196 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 2.0 (TID 132). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,197 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 2.0 (TID 134, localhost, executor driver, partition 133, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,198 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 2.0 (TID 132) in 8 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 13:18:30,198 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 2.0 (TID 134)
[INFO] 2019-01-19 13:18:30,198 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 2.0 (TID 133). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,199 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 2.0 (TID 135, localhost, executor driver, partition 134, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,200 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 2.0 (TID 133) in 6 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 13:18:30,200 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,200 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,200 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 2.0 (TID 135)
[INFO] 2019-01-19 13:18:30,202 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 2.0 (TID 134). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,203 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 2.0 (TID 136, localhost, executor driver, partition 135, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,203 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 2.0 (TID 134) in 6 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 13:18:30,204 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 2.0 (TID 136)
[INFO] 2019-01-19 13:18:30,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,209 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 2.0 (TID 135). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,210 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 2.0 (TID 137, localhost, executor driver, partition 136, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,210 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 2.0 (TID 137)
[INFO] 2019-01-19 13:18:30,210 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 2.0 (TID 135) in 11 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 13:18:30,213 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,213 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,214 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 2.0 (TID 137). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,215 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 2.0 (TID 138, localhost, executor driver, partition 137, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,215 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 2.0 (TID 138)
[INFO] 2019-01-19 13:18:30,215 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 2.0 (TID 137) in 5 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 13:18:30,217 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,217 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,219 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 2.0 (TID 138). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,220 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 2.0 (TID 139, localhost, executor driver, partition 138, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,220 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,220 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 2.0 (TID 138) in 5 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 13:18:30,220 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 2.0 (TID 139)
[INFO] 2019-01-19 13:18:30,220 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,221 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 2.0 (TID 136). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,222 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,222 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,222 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 2.0 (TID 140, localhost, executor driver, partition 139, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,222 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 2.0 (TID 140)
[INFO] 2019-01-19 13:18:30,222 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 2.0 (TID 136) in 19 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 13:18:30,223 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 2.0 (TID 139). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,224 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 2.0 (TID 141, localhost, executor driver, partition 140, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,224 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,224 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 2.0 (TID 139) in 5 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 13:18:30,225 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 2.0 (TID 141)
[INFO] 2019-01-19 13:18:30,226 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 2.0 (TID 140). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,227 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 2.0 (TID 142, localhost, executor driver, partition 141, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,227 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,227 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,227 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 2.0 (TID 142)
[INFO] 2019-01-19 13:18:30,227 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 2.0 (TID 140) in 5 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 13:18:30,229 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 2.0 (TID 141). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,229 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 2.0 (TID 143, localhost, executor driver, partition 142, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,229 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,230 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,230 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 2.0 (TID 141) in 6 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 13:18:30,230 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 2.0 (TID 143)
[INFO] 2019-01-19 13:18:30,231 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 2.0 (TID 142). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,232 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 2.0 (TID 144, localhost, executor driver, partition 143, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,232 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 2.0 (TID 142) in 6 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 13:18:30,233 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 2.0 (TID 144)
[INFO] 2019-01-19 13:18:30,234 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 2.0 (TID 143). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,234 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 2.0 (TID 145, localhost, executor driver, partition 144, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,235 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,235 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,236 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 2.0 (TID 144). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,236 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 2.0 (TID 143) in 7 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 13:18:30,237 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 2.0 (TID 145)
[INFO] 2019-01-19 13:18:30,237 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 2.0 (TID 146, localhost, executor driver, partition 145, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,238 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 2.0 (TID 144) in 6 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 13:18:30,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,239 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 2.0 (TID 146)
[INFO] 2019-01-19 13:18:30,240 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 2.0 (TID 145). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,241 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 2.0 (TID 147, localhost, executor driver, partition 146, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,241 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,241 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,242 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 2.0 (TID 145) in 8 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 13:18:30,242 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 2.0 (TID 147)
[INFO] 2019-01-19 13:18:30,243 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 2.0 (TID 146). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,244 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 2.0 (TID 148, localhost, executor driver, partition 147, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,244 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 2.0 (TID 148)
[INFO] 2019-01-19 13:18:30,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,244 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 2.0 (TID 146) in 7 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 13:18:30,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,246 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 2.0 (TID 147). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,247 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 2.0 (TID 149, localhost, executor driver, partition 148, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,247 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 2.0 (TID 147) in 6 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 13:18:30,247 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 2.0 (TID 149)
[INFO] 2019-01-19 13:18:30,248 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 2.0 (TID 148). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,249 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 2.0 (TID 150, localhost, executor driver, partition 149, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,249 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 2.0 (TID 148) in 5 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 13:18:30,249 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 2.0 (TID 150)
[INFO] 2019-01-19 13:18:30,251 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,251 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,253 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 2.0 (TID 150). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,249 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:18:30,255 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 2.0 (TID 149). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,256 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 2.0 (TID 151, localhost, executor driver, partition 150, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,256 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 2.0 (TID 151)
[INFO] 2019-01-19 13:18:30,257 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 2.0 (TID 152, localhost, executor driver, partition 151, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,257 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 2.0 (TID 149) in 10 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 13:18:30,258 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 2.0 (TID 150) in 10 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 13:18:30,258 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 2.0 (TID 152)
[INFO] 2019-01-19 13:18:30,258 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,258 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,260 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,260 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,261 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 2.0 (TID 152). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,262 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 2.0 (TID 153, localhost, executor driver, partition 152, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,263 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 2.0 (TID 152) in 7 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 13:18:30,264 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 2.0 (TID 153)
[INFO] 2019-01-19 13:18:30,265 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,266 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,274 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 2.0 (TID 151). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,275 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 2.0 (TID 154, localhost, executor driver, partition 153, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,275 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 2.0 (TID 154)
[INFO] 2019-01-19 13:18:30,275 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 2.0 (TID 151) in 19 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 13:18:30,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,279 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 2.0 (TID 154). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,279 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 2.0 (TID 155, localhost, executor driver, partition 154, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,279 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 2.0 (TID 155)
[INFO] 2019-01-19 13:18:30,279 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 2.0 (TID 154) in 5 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 13:18:30,281 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,281 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,284 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 2.0 (TID 155). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,285 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 2.0 (TID 156, localhost, executor driver, partition 155, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,286 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 2.0 (TID 155) in 7 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 13:18:30,286 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 2.0 (TID 156)
[INFO] 2019-01-19 13:18:30,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,289 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 2.0 (TID 156). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,290 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 2.0 (TID 157, localhost, executor driver, partition 156, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,291 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 2.0 (TID 157)
[INFO] 2019-01-19 13:18:30,291 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 2.0 (TID 156) in 7 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 13:18:30,293 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,293 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,294 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 2.0 (TID 157). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,295 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 2.0 (TID 158, localhost, executor driver, partition 157, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,295 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 2.0 (TID 157) in 5 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 13:18:30,296 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 2.0 (TID 158)
[INFO] 2019-01-19 13:18:30,298 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,298 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,300 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 2.0 (TID 153). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,300 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 2.0 (TID 158). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,300 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 2.0 (TID 159, localhost, executor driver, partition 158, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,300 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 2.0 (TID 159)
[INFO] 2019-01-19 13:18:30,300 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 2.0 (TID 160, localhost, executor driver, partition 159, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,301 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 2.0 (TID 158) in 6 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 13:18:30,302 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,302 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,303 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 2.0 (TID 153) in 41 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 13:18:30,303 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 2.0 (TID 160)
[INFO] 2019-01-19 13:18:30,304 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 2.0 (TID 159). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,305 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,305 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,306 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 2.0 (TID 161, localhost, executor driver, partition 160, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,306 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 2.0 (TID 160). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,307 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 2.0 (TID 159) in 7 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 13:18:30,307 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 2.0 (TID 161)
[INFO] 2019-01-19 13:18:30,309 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 2.0 (TID 162, localhost, executor driver, partition 161, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,312 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,313 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,316 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 2.0 (TID 161). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,318 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 2.0 (TID 163, localhost, executor driver, partition 162, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,318 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 2.0 (TID 160) in 18 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 13:18:30,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 2.0 (TID 161) in 14 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 13:18:30,319 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 2.0 (TID 162)
[INFO] 2019-01-19 13:18:30,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,327 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 2.0 (TID 163)
[INFO] 2019-01-19 13:18:30,327 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 2.0 (TID 162). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,328 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 2.0 (TID 164, localhost, executor driver, partition 163, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,329 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,329 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,329 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 2.0 (TID 162) in 20 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 13:18:30,329 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 2.0 (TID 164)
[INFO] 2019-01-19 13:18:30,331 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 2.0 (TID 163). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,332 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 2.0 (TID 165, localhost, executor driver, partition 164, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,332 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 2.0 (TID 163) in 15 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 13:18:30,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,337 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 5 ms
[INFO] 2019-01-19 13:18:30,339 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 2.0 (TID 164). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,341 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 2.0 (TID 165)
[INFO] 2019-01-19 13:18:30,343 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,343 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,345 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 2.0 (TID 165). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,346 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 2.0 (TID 166, localhost, executor driver, partition 165, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 2.0 (TID 167, localhost, executor driver, partition 166, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,351 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 2.0 (TID 164) in 23 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 13:18:30,353 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 2.0 (TID 165) in 22 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 13:18:30,354 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 2.0 (TID 166)
[INFO] 2019-01-19 13:18:30,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,357 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,359 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 2.0 (TID 166). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,360 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 2.0 (TID 167)
[INFO] 2019-01-19 13:18:30,362 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 2.0 (TID 168, localhost, executor driver, partition 167, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,364 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 2.0 (TID 166) in 18 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 13:18:30,365 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 2.0 (TID 168)
[INFO] 2019-01-19 13:18:30,366 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,367 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,368 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 2.0 (TID 168). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,369 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 2.0 (TID 169, localhost, executor driver, partition 168, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,369 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 2.0 (TID 169)
[INFO] 2019-01-19 13:18:30,369 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 2.0 (TID 168) in 8 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 13:18:30,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,372 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 2.0 (TID 169). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,373 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 2.0 (TID 170, localhost, executor driver, partition 169, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,373 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 2.0 (TID 170)
[INFO] 2019-01-19 13:18:30,373 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 2.0 (TID 169) in 5 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 13:18:30,375 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,377 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 2.0 (TID 170). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,378 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 2.0 (TID 171, localhost, executor driver, partition 170, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,378 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 2.0 (TID 171)
[INFO] 2019-01-19 13:18:30,378 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 2.0 (TID 170) in 5 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 13:18:30,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 18 ms
[INFO] 2019-01-19 13:18:30,381 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 2.0 (TID 167). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,382 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 2.0 (TID 172, localhost, executor driver, partition 171, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,382 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 2.0 (TID 172)
[INFO] 2019-01-19 13:18:30,382 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 2.0 (TID 167) in 35 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 13:18:30,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,386 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 2.0 (TID 172). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,387 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 2.0 (TID 173, localhost, executor driver, partition 172, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,387 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 2.0 (TID 173)
[INFO] 2019-01-19 13:18:30,387 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 2.0 (TID 172) in 6 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 13:18:30,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,390 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 2.0 (TID 173). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,391 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 2.0 (TID 174, localhost, executor driver, partition 173, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,391 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 2.0 (TID 174)
[INFO] 2019-01-19 13:18:30,391 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 2.0 (TID 173) in 5 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 13:18:30,391 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 2.0 (TID 171). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,392 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 2.0 (TID 175, localhost, executor driver, partition 174, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,392 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 2.0 (TID 175)
[INFO] 2019-01-19 13:18:30,392 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 2.0 (TID 171) in 15 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 13:18:30,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,394 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,394 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,394 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 2.0 (TID 174). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,395 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 2.0 (TID 175). 2570 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,396 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 2.0 (TID 176, localhost, executor driver, partition 175, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,396 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 2.0 (TID 177, localhost, executor driver, partition 176, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,396 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 2.0 (TID 174) in 6 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 13:18:30,397 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 2.0 (TID 175) in 5 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 13:18:30,397 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 2.0 (TID 176)
[INFO] 2019-01-19 13:18:30,397 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 2.0 (TID 177)
[INFO] 2019-01-19 13:18:30,399 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,399 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,399 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,400 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,401 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 2.0 (TID 176). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,402 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 2.0 (TID 177). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 2.0 (TID 178, localhost, executor driver, partition 177, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,403 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 2.0 (TID 178)
[INFO] 2019-01-19 13:18:30,403 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 2.0 (TID 179, localhost, executor driver, partition 178, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,403 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 2.0 (TID 177) in 7 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 13:18:30,404 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 2.0 (TID 176) in 9 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 13:18:30,404 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 2.0 (TID 179)
[INFO] 2019-01-19 13:18:30,404 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,404 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,406 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,406 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 2.0 (TID 178). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,406 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,406 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 2.0 (TID 180, localhost, executor driver, partition 179, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,407 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 2.0 (TID 178) in 5 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 13:18:30,408 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 2.0 (TID 179). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,408 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 2.0 (TID 180)
[INFO] 2019-01-19 13:18:30,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,410 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 2.0 (TID 181, localhost, executor driver, partition 180, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,411 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 2.0 (TID 179) in 8 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 13:18:30,412 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 2.0 (TID 181)
[INFO] 2019-01-19 13:18:30,412 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 2.0 (TID 180). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,412 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 2.0 (TID 182, localhost, executor driver, partition 181, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,413 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 2.0 (TID 182)
[INFO] 2019-01-19 13:18:30,413 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 2.0 (TID 180) in 7 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 13:18:30,413 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,413 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,415 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 2.0 (TID 181). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,415 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 2.0 (TID 183, localhost, executor driver, partition 182, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,415 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 2.0 (TID 183)
[INFO] 2019-01-19 13:18:30,415 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 2.0 (TID 182). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,415 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 2.0 (TID 181) in 5 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 13:18:30,417 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 2.0 (TID 184, localhost, executor driver, partition 183, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,417 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,417 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,418 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 2.0 (TID 184)
[INFO] 2019-01-19 13:18:30,419 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 2.0 (TID 183). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,418 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 2.0 (TID 182) in 6 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 13:18:30,420 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,420 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,420 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 2.0 (TID 185, localhost, executor driver, partition 184, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,421 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 2.0 (TID 183) in 6 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 13:18:30,421 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 2.0 (TID 185)
[INFO] 2019-01-19 13:18:30,421 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 2.0 (TID 184). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,422 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 2.0 (TID 186, localhost, executor driver, partition 185, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,422 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 2.0 (TID 186)
[INFO] 2019-01-19 13:18:30,422 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 2.0 (TID 184) in 6 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 13:18:30,423 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,423 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,424 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,424 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,425 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 2.0 (TID 185). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,425 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 2.0 (TID 187, localhost, executor driver, partition 186, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,426 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 2.0 (TID 187)
[INFO] 2019-01-19 13:18:30,426 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 2.0 (TID 185) in 6 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 13:18:30,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,429 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 2.0 (TID 187). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,429 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 2.0 (TID 188, localhost, executor driver, partition 187, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,430 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 2.0 (TID 188)
[INFO] 2019-01-19 13:18:30,430 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 2.0 (TID 187) in 5 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 13:18:30,431 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,432 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,433 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 2.0 (TID 188). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,434 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 2.0 (TID 189, localhost, executor driver, partition 188, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,434 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 2.0 (TID 189)
[INFO] 2019-01-19 13:18:30,434 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 2.0 (TID 188) in 5 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 13:18:30,434 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 2.0 (TID 186). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,435 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 2.0 (TID 190, localhost, executor driver, partition 189, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,435 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 2.0 (TID 190)
[INFO] 2019-01-19 13:18:30,435 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 2.0 (TID 186) in 13 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 13:18:30,437 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,437 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,439 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 2.0 (TID 190). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,440 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 2.0 (TID 191, localhost, executor driver, partition 190, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,440 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,440 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 2.0 (TID 190) in 5 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 13:18:30,440 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 2.0 (TID 191)
[INFO] 2019-01-19 13:18:30,442 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 2.0 (TID 189). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,442 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 2.0 (TID 192, localhost, executor driver, partition 192, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,442 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 2.0 (TID 192)
[INFO] 2019-01-19 13:18:30,442 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,443 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,442 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 2.0 (TID 189) in 9 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 13:18:30,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,444 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 2.0 (TID 191). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,445 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 2.0 (TID 193, localhost, executor driver, partition 193, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,445 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 2.0 (TID 191) in 6 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 13:18:30,445 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 2.0 (TID 193)
[INFO] 2019-01-19 13:18:30,446 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 2.0 (TID 192). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,446 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 2.0 (TID 194, localhost, executor driver, partition 194, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,447 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 2.0 (TID 194)
[INFO] 2019-01-19 13:18:30,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,447 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 2.0 (TID 192) in 5 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 13:18:30,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,448 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 2.0 (TID 193). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,449 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 2.0 (TID 195, localhost, executor driver, partition 195, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,449 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 2.0 (TID 193) in 5 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 13:18:30,449 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 2.0 (TID 195)
[INFO] 2019-01-19 13:18:30,450 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 2.0 (TID 194). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,450 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 2.0 (TID 196, localhost, executor driver, partition 196, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,450 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 2.0 (TID 196)
[INFO] 2019-01-19 13:18:30,450 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 2.0 (TID 194) in 4 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 13:18:30,451 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,451 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,452 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,452 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,452 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 2.0 (TID 195). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,453 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 2.0 (TID 197, localhost, executor driver, partition 197, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,453 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 2.0 (TID 196). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,453 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 2.0 (TID 195) in 4 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 13:18:30,453 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 2.0 (TID 197)
[INFO] 2019-01-19 13:18:30,454 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 2.0 (TID 198, localhost, executor driver, partition 198, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,454 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 2.0 (TID 198)
[INFO] 2019-01-19 13:18:30,454 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 2.0 (TID 196) in 4 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 13:18:30,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,457 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 2.0 (TID 197). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,457 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 2.0 (TID 198). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,458 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 2.0 (TID 199, localhost, executor driver, partition 199, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:18:30,458 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 2.0 (TID 199)
[INFO] 2019-01-19 13:18:30,459 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 2.0 (TID 200, localhost, executor driver, partition 43, ANY, 5870 bytes)
[INFO] 2019-01-19 13:18:30,459 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 2.0 (TID 198) in 6 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 13:18:30,460 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 2.0 (TID 197) in 7 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 13:18:30,460 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 2.0 (TID 200)
[INFO] 2019-01-19 13:18:30,461 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,461 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,462 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,462 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:30,462 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 2.0 (TID 199). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,463 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 2.0 (TID 201, localhost, executor driver, partition 191, ANY, 5870 bytes)
[INFO] 2019-01-19 13:18:30,463 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 2.0 (TID 201)
[INFO] 2019-01-19 13:18:30,465 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:30,465 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:30,463 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 2.0 (TID 199) in 5 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 13:18:30,488 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 2.0 (TID 200). 2740 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,488 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 2.0 (TID 200) in 30 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 13:18:30,516 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 2.0 (TID 201). 2740 bytes result sent to driver
[INFO] 2019-01-19 13:18:30,516 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 2.0 (TID 201) in 53 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 13:18:30,516 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:30,516 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 2 (collect at LayerSample.scala:49) finished in 2.244 s
[INFO] 2019-01-19 13:18:30,518 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at LayerSample.scala:49, took 2.996543 s
[INFO] 2019-01-19 13:18:30,633 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag==1
[INFO] 2019-01-19 13:18:30,994 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:18:30,997 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:18:30,997 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:18:30,999 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[WARN] 2019-01-19 13:18:31,027 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2019-01-19 13:18:31,099 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.583204 ms
[INFO] 2019-01-19 13:18:31,143 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.68542 ms
[INFO] 2019-01-19 13:18:31,188 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4 stored as values in memory (estimated size 278.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:31,201 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:31,202 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_4_piece0 in memory on 192.168.99.1:57658 (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:31,203 org.apache.spark.SparkContext logInfo - Created broadcast 4 from count at LayerSample.scala:54
[INFO] 2019-01-19 13:18:31,204 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:18:31,241 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:54
[INFO] 2019-01-19 13:18:31,242 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 14 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,242 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 2 (count at LayerSample.scala:54) with 1 output partitions
[INFO] 2019-01-19 13:18:31,243 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 4 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,243 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 3)
[INFO] 2019-01-19 13:18:31,243 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 3)
[INFO] 2019-01-19 13:18:31,243 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 3 (MapPartitionsRDD[14] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:18:31,254 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5 stored as values in memory (estimated size 13.5 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:31,256 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:31,257 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_5_piece0 in memory on 192.168.99.1:57658 (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:31,258 org.apache.spark.SparkContext logInfo - Created broadcast 5 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:31,258 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[14] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,258 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 3.0 with 1 tasks
[INFO] 2019-01-19 13:18:31,260 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 13:18:31,261 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 3.0 (TID 202)
[INFO] 2019-01-19 13:18:31,265 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:18:31,287 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:18:31,336 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 3.0 (TID 202). 2119 bytes result sent to driver
[INFO] 2019-01-19 13:18:31,337 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 3.0 (TID 202) in 78 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:31,337 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:31,341 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 3 (count at LayerSample.scala:54) finished in 0.082 s
[INFO] 2019-01-19 13:18:31,342 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:18:31,342 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:18:31,342 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 4)
[INFO] 2019-01-19 13:18:31,342 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:18:31,343 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 4 (MapPartitionsRDD[17] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:18:31,345 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:31,347 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:31,348 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_6_piece0 in memory on 192.168.99.1:57658 (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:31,348 org.apache.spark.SparkContext logInfo - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:31,348 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,349 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 4.0 with 1 tasks
[INFO] 2019-01-19 13:18:31,350 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 13:18:31,350 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 4.0 (TID 203)
[INFO] 2019-01-19 13:18:31,353 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:31,353 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:31,361 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 4.0 (TID 203). 1952 bytes result sent to driver
[INFO] 2019-01-19 13:18:31,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 4.0 (TID 203) in 13 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:31,363 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:31,363 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 4 (count at LayerSample.scala:54) finished in 0.014 s
[INFO] 2019-01-19 13:18:31,364 org.apache.spark.scheduler.DAGScheduler logInfo - Job 2 finished: count at LayerSample.scala:54, took 0.121956 s
[INFO] 2019-01-19 13:18:31,387 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.367998 ms
[INFO] 2019-01-19 13:18:31,574 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag==0
[INFO] 2019-01-19 13:18:31,638 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:18:31,640 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:18:31,641 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:18:31,641 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:18:31,696 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 40.569293 ms
[INFO] 2019-01-19 13:18:31,701 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7 stored as values in memory (estimated size 278.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:18:31,714 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:18:31,715 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_7_piece0 in memory on 192.168.99.1:57658 (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:31,716 org.apache.spark.SparkContext logInfo - Created broadcast 7 from count at LayerSample.scala:54
[INFO] 2019-01-19 13:18:31,717 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:18:31,745 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:54
[INFO] 2019-01-19 13:18:31,746 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 20 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,746 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 3 (count at LayerSample.scala:54) with 1 output partitions
[INFO] 2019-01-19 13:18:31,746 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 6 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,746 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 5)
[INFO] 2019-01-19 13:18:31,746 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 5)
[INFO] 2019-01-19 13:18:31,747 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:18:31,748 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8 stored as values in memory (estimated size 13.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:31,752 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:31,753 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_8_piece0 in memory on 192.168.99.1:57658 (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:31,753 org.apache.spark.SparkContext logInfo - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:31,753 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,754 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 5.0 with 1 tasks
[INFO] 2019-01-19 13:18:31,755 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 13:18:31,755 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 5.0 (TID 204)
[INFO] 2019-01-19 13:18:31,759 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:18:31,766 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:18:31,893 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 5.0 (TID 204). 2032 bytes result sent to driver
[INFO] 2019-01-19 13:18:31,894 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 5.0 (TID 204) in 140 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:31,894 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:31,894 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 5 (count at LayerSample.scala:54) finished in 0.140 s
[INFO] 2019-01-19 13:18:31,894 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:18:31,894 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:18:31,895 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 6)
[INFO] 2019-01-19 13:18:31,895 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:18:31,895 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 6 (MapPartitionsRDD[23] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:18:31,897 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:31,902 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:31,903 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_9_piece0 in memory on 192.168.99.1:57658 (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:31,904 org.apache.spark.SparkContext logInfo - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:31,904 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:18:31,904 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 6.0 with 1 tasks
[INFO] 2019-01-19 13:18:31,907 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 13:18:31,908 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 6.0 (TID 205)
[INFO] 2019-01-19 13:18:31,910 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:31,911 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:31,914 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 6.0 (TID 205). 1873 bytes result sent to driver
[INFO] 2019-01-19 13:18:31,916 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 6.0 (TID 205) in 10 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:31,916 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:31,917 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 6 (count at LayerSample.scala:54) finished in 0.012 s
[INFO] 2019-01-19 13:18:31,917 org.apache.spark.scheduler.DAGScheduler logInfo - Job 3 finished: count at LayerSample.scala:54, took 0.171575 s
[INFO] 2019-01-19 13:18:33,351 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_9_piece0 on 192.168.99.1:57658 in memory (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:33,353 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4934
[INFO] 2019-01-19 13:18:33,353 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4935
[INFO] 2019-01-19 13:18:33,353 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4936
[INFO] 2019-01-19 13:18:33,353 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4937
[INFO] 2019-01-19 13:18:33,353 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4938
[INFO] 2019-01-19 13:18:33,353 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4939
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4940
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4941
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4942
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4943
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4944
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4945
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4946
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4947
[INFO] 2019-01-19 13:18:33,354 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4948
[INFO] 2019-01-19 13:18:33,357 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_4_piece0 on 192.168.99.1:57658 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:33,361 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 1
[INFO] 2019-01-19 13:18:33,363 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_5_piece0 on 192.168.99.1:57658 in memory (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:33,379 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_6_piece0 on 192.168.99.1:57658 in memory (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5045
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5046
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5047
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5048
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5049
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5050
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5051
[INFO] 2019-01-19 13:18:33,380 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5052
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5053
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5054
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5055
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5056
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5057
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5058
[INFO] 2019-01-19 13:18:33,381 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5059
[INFO] 2019-01-19 13:18:33,382 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_7_piece0 on 192.168.99.1:57658 in memory (size: 23.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:33,383 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 2
[INFO] 2019-01-19 13:18:33,384 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_8_piece0 on 192.168.99.1:57658 in memory (size: 6.3 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:18:34,110 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:18:34,111 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:18:34,112 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:18:34,112 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:18:34,113 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:18:34,114 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:18:34,114 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:18:34,114 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:18:34,446 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 43.541855 ms
[INFO] 2019-01-19 13:18:34,525 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 59.841223 ms
[INFO] 2019-01-19 13:18:34,540 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10 stored as values in memory (estimated size 292.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:34,553 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:18:34,554 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_10_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:34,556 org.apache.spark.SparkContext logInfo - Created broadcast 10 from head at DecoupJson.scala:139
[INFO] 2019-01-19 13:18:34,557 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:18:34,645 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 57.20118 ms
[INFO] 2019-01-19 13:18:34,656 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11 stored as values in memory (estimated size 292.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:18:34,680 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:18:34,682 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_11_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:34,686 org.apache.spark.SparkContext logInfo - Created broadcast 11 from head at DecoupJson.scala:139
[INFO] 2019-01-19 13:18:34,689 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:18:34,818 org.apache.spark.SparkContext logInfo - Starting job: head at DecoupJson.scala:139
[INFO] 2019-01-19 13:18:34,820 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 32 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,820 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 27 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,821 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 39 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,822 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 44 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,822 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 4 (head at DecoupJson.scala:139) with 1 output partitions
[INFO] 2019-01-19 13:18:34,822 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 11 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,822 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 10)
[INFO] 2019-01-19 13:18:34,822 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 10)
[INFO] 2019-01-19 13:18:34,824 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 7 (MapPartitionsRDD[32] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:18:34,825 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12 stored as values in memory (estimated size 39.9 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:34,827 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:34,828 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_12_piece0 in memory on 192.168.99.1:57658 (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:34,830 org.apache.spark.SparkContext logInfo - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:34,830 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[32] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,830 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 7.0 with 1 tasks
[INFO] 2019-01-19 13:18:34,831 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 8 (MapPartitionsRDD[27] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:18:34,832 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13 stored as values in memory (estimated size 39.9 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:34,834 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:18:34,834 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 7.0 (TID 206)
[INFO] 2019-01-19 13:18:34,836 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:18:34,837 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_13_piece0 in memory on 192.168.99.1:57658 (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:34,837 org.apache.spark.SparkContext logInfo - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:34,837 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[27] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:34,838 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 8.0 with 1 tasks
[INFO] 2019-01-19 13:18:34,840 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 8.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:18:34,840 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 8.0 (TID 207)
[INFO] 2019-01-19 13:18:34,874 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:18:34,874 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:18:34,882 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:18:34,888 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:18:34,917 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 13:18:35,006 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 8.0 (TID 207). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 8.0 (TID 207) in 168 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 8 (head at DecoupJson.scala:139) finished in 0.169 s
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 7)
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 9, ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 13:18:35,007 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:18:35,061 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 7.0 (TID 206). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 7.0 (TID 206) in 229 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 7 (head at DecoupJson.scala:139) finished in 0.232 s
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 9, ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 13:18:35,062 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:18:35,063 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:18:35,128 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14 stored as values in memory (estimated size 301.7 KB, free 1990.7 MB)
[INFO] 2019-01-19 13:18:35,131 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14_piece0 stored as bytes in memory (estimated size 66.8 KB, free 1990.6 MB)
[INFO] 2019-01-19 13:18:35,132 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_14_piece0 in memory on 192.168.99.1:57658 (size: 66.8 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:18:35,133 org.apache.spark.SparkContext logInfo - Created broadcast 14 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:35,133 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:35,133 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 9.0 with 2 tasks
[INFO] 2019-01-19 13:18:35,139 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 9.0 (TID 208, localhost, executor driver, partition 0, ANY, 5898 bytes)
[INFO] 2019-01-19 13:18:35,140 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 9.0 (TID 209, localhost, executor driver, partition 1, ANY, 5898 bytes)
[INFO] 2019-01-19 13:18:35,140 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 9.0 (TID 208)
[INFO] 2019-01-19 13:18:35,140 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 9.0 (TID 209)
[INFO] 2019-01-19 13:18:35,197 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:35,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:35,199 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:18:35,199 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:35,327 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 117.189797 ms
[INFO] 2019-01-19 13:18:35,386 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 52.610106 ms
[INFO] 2019-01-19 13:18:35,428 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_12_piece0 on 192.168.99.1:57658 in memory (size: 12.5 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:18:35,439 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_13_piece0 on 192.168.99.1:57658 in memory (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:35,441 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5156
[INFO] 2019-01-19 13:18:35,441 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5157
[INFO] 2019-01-19 13:18:35,441 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5158
[INFO] 2019-01-19 13:18:35,441 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5159
[INFO] 2019-01-19 13:18:35,455 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 35.0459 ms
[INFO] 2019-01-19 13:18:35,482 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.615445 ms
[INFO] 2019-01-19 13:18:35,534 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 48.029259 ms
[INFO] 2019-01-19 13:18:35,577 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 37.616831 ms
[INFO] 2019-01-19 13:18:35,674 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 91.236833 ms
[INFO] 2019-01-19 13:18:35,773 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 44.919881 ms
[INFO] 2019-01-19 13:18:35,843 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 65.666457 ms
[INFO] 2019-01-19 13:18:35,865 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.643523 ms
[INFO] 2019-01-19 13:18:35,899 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 30.460822 ms
[INFO] 2019-01-19 13:18:35,920 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.892096 ms
[INFO] 2019-01-19 13:18:35,940 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.636801 ms
[INFO] 2019-01-19 13:18:35,962 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.154134 ms
[INFO] 2019-01-19 13:18:35,989 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.562178 ms
[INFO] 2019-01-19 13:18:36,009 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.552879 ms
[INFO] 2019-01-19 13:18:36,033 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.570928 ms
[INFO] 2019-01-19 13:18:36,054 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.394928 ms
[INFO] 2019-01-19 13:18:36,075 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.705584 ms
[INFO] 2019-01-19 13:18:36,096 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.322333 ms
[INFO] 2019-01-19 13:18:36,127 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.362 ms
[INFO] 2019-01-19 13:18:36,183 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 38.207112 ms
[INFO] 2019-01-19 13:18:36,221 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 32.657625 ms
[INFO] 2019-01-19 13:18:36,243 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.15376 ms
[INFO] 2019-01-19 13:18:36,264 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.897739 ms
[INFO] 2019-01-19 13:18:36,289 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.026178 ms
[INFO] 2019-01-19 13:18:36,308 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.424174 ms
[INFO] 2019-01-19 13:18:36,327 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.788757 ms
[INFO] 2019-01-19 13:18:36,357 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.425825 ms
[INFO] 2019-01-19 13:18:36,378 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.305694 ms
[INFO] 2019-01-19 13:18:36,398 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.856834 ms
[INFO] 2019-01-19 13:18:36,418 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.28348 ms
[INFO] 2019-01-19 13:18:36,437 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.604692 ms
[INFO] 2019-01-19 13:18:36,456 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.701662 ms
[INFO] 2019-01-19 13:18:36,477 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.221132 ms
[INFO] 2019-01-19 13:18:36,496 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.842356 ms
[INFO] 2019-01-19 13:18:36,514 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.774631 ms
[INFO] 2019-01-19 13:18:36,533 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.904416 ms
[INFO] 2019-01-19 13:18:36,552 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.806014 ms
[INFO] 2019-01-19 13:18:36,586 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 28.866639 ms
[INFO] 2019-01-19 13:18:36,609 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.941462 ms
[INFO] 2019-01-19 13:18:36,634 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.755721 ms
[INFO] 2019-01-19 13:18:36,680 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 38.610858 ms
[INFO] 2019-01-19 13:18:36,711 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.800965 ms
[INFO] 2019-01-19 13:18:36,733 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.297253 ms
[INFO] 2019-01-19 13:18:36,754 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.483061 ms
[INFO] 2019-01-19 13:18:36,776 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.898466 ms
[INFO] 2019-01-19 13:18:36,811 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.15649 ms
[INFO] 2019-01-19 13:18:36,844 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.22102 ms
[INFO] 2019-01-19 13:18:36,863 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.448482 ms
[INFO] 2019-01-19 13:18:36,883 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.375534 ms
[INFO] 2019-01-19 13:18:36,945 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 50.55576 ms
[INFO] 2019-01-19 13:18:36,964 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.194798 ms
[INFO] 2019-01-19 13:18:37,397 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 47.371275 ms
[INFO] 2019-01-19 13:18:37,731 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 179.482062 ms
[INFO] 2019-01-19 13:18:37,787 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.311514 ms
[INFO] 2019-01-19 13:18:37,876 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 46.881843 ms
[INFO] 2019-01-19 13:18:37,916 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.971853 ms
[INFO] 2019-01-19 13:18:37,937 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.96824 ms
[INFO] 2019-01-19 13:18:39,236 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 53
[INFO] 2019-01-19 13:18:39,239 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_3_piece0 on 192.168.99.1:57658 in memory (size: 9.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:39,241 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 0
[INFO] 2019-01-19 13:18:39,247 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_1_piece0 on 192.168.99.1:57658 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:18:39,247 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 61
[INFO] 2019-01-19 13:18:39,247 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 60
[INFO] 2019-01-19 13:18:39,247 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 59
[INFO] 2019-01-19 13:18:39,247 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 58
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 57
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 56
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 55
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 54
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 52
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 51
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 50
[INFO] 2019-01-19 13:18:39,248 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 49
[INFO] 2019-01-19 13:18:40,270 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 9.0 (TID 209). 3877 bytes result sent to driver
[INFO] 2019-01-19 13:18:40,272 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 9.0 (TID 209) in 5131 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:18:40,283 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 9.0 (TID 208). 3967 bytes result sent to driver
[INFO] 2019-01-19 13:18:40,284 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 9.0 (TID 208) in 5150 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:18:40,284 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:18:40,285 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 9 (head at DecoupJson.scala:139) finished in 5.152 s
[INFO] 2019-01-19 13:18:40,285 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:18:40,285 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:18:40,285 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 13:18:40,286 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:18:40,286 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 10 (MapPartitionsRDD[44] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:18:40,327 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15 stored as values in memory (estimated size 531.2 KB, free 1990.5 MB)
[INFO] 2019-01-19 13:18:40,329 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15_piece0 stored as bytes in memory (estimated size 132.5 KB, free 1990.4 MB)
[INFO] 2019-01-19 13:18:40,329 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_15_piece0 in memory on 192.168.99.1:57658 (size: 132.5 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:18:40,330 org.apache.spark.SparkContext logInfo - Created broadcast 15 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:18:40,331 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[44] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:18:40,331 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 10.0 with 200 tasks
[INFO] 2019-01-19 13:18:40,332 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 10.0 (TID 210, localhost, executor driver, partition 0, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:40,333 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 10.0 (TID 211, localhost, executor driver, partition 1, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:40,333 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 10.0 (TID 210)
[INFO] 2019-01-19 13:18:40,333 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 10.0 (TID 211)
[INFO] 2019-01-19 13:18:40,354 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:40,354 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:40,363 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:40,363 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:40,754 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 207.203049 ms
[INFO] 2019-01-19 13:18:40,942 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 105.600334 ms
[INFO] 2019-01-19 13:18:41,114 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 111.398768 ms
[INFO] 2019-01-19 13:18:41,213 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 73.535105 ms
[INFO] 2019-01-19 13:18:41,337 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 93.62546 ms
[INFO] 2019-01-19 13:18:41,883 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 223.516523 ms
[INFO] 2019-01-19 13:18:42,222 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 132.370313 ms
[INFO] 2019-01-19 13:18:42,340 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 76.212526 ms
[INFO] 2019-01-19 13:18:42,385 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 10.0 (TID 210). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:42,386 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 10.0 (TID 212, localhost, executor driver, partition 2, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:42,387 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 10.0 (TID 210) in 2055 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 13:18:42,387 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 10.0 (TID 212)
[INFO] 2019-01-19 13:18:42,396 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 10.0 (TID 211). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:42,397 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 10.0 (TID 213, localhost, executor driver, partition 3, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:42,397 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 10.0 (TID 211) in 2064 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 13:18:42,398 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 10.0 (TID 213)
[INFO] 2019-01-19 13:18:42,407 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:42,407 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:42,413 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:42,413 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:42,983 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 10.0 (TID 213). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:42,984 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 10.0 (TID 214, localhost, executor driver, partition 4, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:42,985 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 10.0 (TID 213) in 589 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 13:18:42,985 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 10.0 (TID 214)
[INFO] 2019-01-19 13:18:42,999 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 10.0 (TID 212). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:43,000 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 10.0 (TID 215, localhost, executor driver, partition 5, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:43,000 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 10.0 (TID 212) in 614 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 13:18:43,001 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 10.0 (TID 215)
[INFO] 2019-01-19 13:18:43,003 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:43,003 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:43,018 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:43,018 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:43,577 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 10.0 (TID 215). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:43,578 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 10.0 (TID 216, localhost, executor driver, partition 6, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:43,578 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 10.0 (TID 216)
[INFO] 2019-01-19 13:18:43,578 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 10.0 (TID 215) in 578 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 13:18:43,589 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 10.0 (TID 214). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:43,590 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 10.0 (TID 217, localhost, executor driver, partition 7, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:43,590 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 10.0 (TID 214) in 606 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 13:18:43,590 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 10.0 (TID 217)
[INFO] 2019-01-19 13:18:43,601 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:43,601 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:43,607 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:43,607 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:44,154 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 10.0 (TID 216). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:44,155 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 10.0 (TID 218, localhost, executor driver, partition 8, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:44,155 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 10.0 (TID 218)
[INFO] 2019-01-19 13:18:44,155 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 10.0 (TID 216) in 577 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 13:18:44,167 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 10.0 (TID 217). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:44,170 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 10.0 (TID 219, localhost, executor driver, partition 9, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:44,170 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 10.0 (TID 217) in 581 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 13:18:44,171 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 10.0 (TID 219)
[INFO] 2019-01-19 13:18:44,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:44,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:44,188 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:44,188 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:44,678 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 10.0 (TID 218). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:18:44,678 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 10.0 (TID 220, localhost, executor driver, partition 10, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:44,679 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 10.0 (TID 220)
[INFO] 2019-01-19 13:18:44,679 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 10.0 (TID 218) in 525 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 13:18:44,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:44,694 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 10.0 (TID 219). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:44,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:44,695 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 10.0 (TID 221, localhost, executor driver, partition 11, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:44,695 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 10.0 (TID 221)
[INFO] 2019-01-19 13:18:44,695 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 10.0 (TID 219) in 526 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 13:18:44,715 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:44,715 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:45,202 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 10.0 (TID 221). 4343 bytes result sent to driver
[INFO] 2019-01-19 13:18:45,203 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 10.0 (TID 222, localhost, executor driver, partition 12, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:45,203 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 10.0 (TID 222)
[INFO] 2019-01-19 13:18:45,203 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 10.0 (TID 221) in 509 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 13:18:45,212 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 10.0 (TID 220). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:45,213 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 10.0 (TID 223, localhost, executor driver, partition 13, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:45,213 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 10.0 (TID 223)
[INFO] 2019-01-19 13:18:45,213 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 10.0 (TID 220) in 535 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 13:18:45,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:45,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:45,229 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:45,229 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:45,658 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 10.0 (TID 223). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:45,659 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 10.0 (TID 224, localhost, executor driver, partition 14, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:45,659 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 10.0 (TID 224)
[INFO] 2019-01-19 13:18:45,659 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 10.0 (TID 223) in 447 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 13:18:45,678 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:45,678 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:45,688 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 10.0 (TID 222). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:45,689 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 10.0 (TID 225, localhost, executor driver, partition 15, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:45,689 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 10.0 (TID 222) in 486 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 13:18:45,689 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 10.0 (TID 225)
[INFO] 2019-01-19 13:18:45,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:45,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:46,086 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 10.0 (TID 225). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:46,087 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 10.0 (TID 226, localhost, executor driver, partition 16, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:46,087 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 10.0 (TID 225) in 399 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 13:18:46,088 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 10.0 (TID 226)
[INFO] 2019-01-19 13:18:46,091 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 10.0 (TID 224). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:46,091 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 10.0 (TID 227, localhost, executor driver, partition 17, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:46,092 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 10.0 (TID 224) in 433 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 13:18:46,092 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 10.0 (TID 227)
[INFO] 2019-01-19 13:18:46,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:46,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:46,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:46,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:46,470 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 10.0 (TID 227). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:46,471 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 10.0 (TID 228, localhost, executor driver, partition 18, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:46,471 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 10.0 (TID 227) in 380 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 13:18:46,471 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 10.0 (TID 228)
[INFO] 2019-01-19 13:18:46,481 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 10.0 (TID 226). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:46,481 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 10.0 (TID 229, localhost, executor driver, partition 19, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:46,481 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 10.0 (TID 229)
[INFO] 2019-01-19 13:18:46,481 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 10.0 (TID 226) in 394 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 13:18:46,487 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:46,487 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:46,498 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:46,498 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:46,858 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 10.0 (TID 229). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:46,859 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 10.0 (TID 230, localhost, executor driver, partition 20, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:46,859 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 10.0 (TID 230)
[INFO] 2019-01-19 13:18:46,859 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 10.0 (TID 229) in 378 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 13:18:46,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:46,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:46,875 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 10.0 (TID 228). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:46,875 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 10.0 (TID 231, localhost, executor driver, partition 21, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:46,875 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 10.0 (TID 231)
[INFO] 2019-01-19 13:18:46,876 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 10.0 (TID 228) in 404 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 13:18:46,886 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:46,886 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:47,199 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 10.0 (TID 230). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:47,200 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 10.0 (TID 232, localhost, executor driver, partition 22, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:47,200 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 10.0 (TID 232)
[INFO] 2019-01-19 13:18:47,200 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 10.0 (TID 230) in 341 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 13:18:47,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:47,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:47,219 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 10.0 (TID 231). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:47,219 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 10.0 (TID 233, localhost, executor driver, partition 23, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:47,219 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 10.0 (TID 233)
[INFO] 2019-01-19 13:18:47,219 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 10.0 (TID 231) in 344 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 13:18:47,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:47,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:47,596 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 10.0 (TID 232). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:47,596 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 10.0 (TID 234, localhost, executor driver, partition 24, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:47,596 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 10.0 (TID 234)
[INFO] 2019-01-19 13:18:47,596 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 10.0 (TID 232) in 397 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 13:18:47,609 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:47,609 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:47,618 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 10.0 (TID 233). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:47,618 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 10.0 (TID 235, localhost, executor driver, partition 25, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:47,618 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 10.0 (TID 235)
[INFO] 2019-01-19 13:18:47,618 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 10.0 (TID 233) in 399 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 13:18:47,635 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:47,636 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:47,952 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 10.0 (TID 234). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:47,953 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 10.0 (TID 236, localhost, executor driver, partition 26, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:47,953 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 10.0 (TID 236)
[INFO] 2019-01-19 13:18:47,953 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 10.0 (TID 234) in 357 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 13:18:47,965 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:47,965 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:47,991 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 10.0 (TID 235). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:47,992 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 10.0 (TID 237, localhost, executor driver, partition 27, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:47,992 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 10.0 (TID 237)
[INFO] 2019-01-19 13:18:47,992 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 10.0 (TID 235) in 374 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 13:18:48,006 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:48,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:48,350 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 10.0 (TID 236). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:48,350 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 10.0 (TID 238, localhost, executor driver, partition 28, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:48,351 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 10.0 (TID 238)
[INFO] 2019-01-19 13:18:48,351 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 10.0 (TID 236) in 399 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 13:18:48,365 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:48,366 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:48,398 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 10.0 (TID 237). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:48,399 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 10.0 (TID 239, localhost, executor driver, partition 29, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:48,399 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 10.0 (TID 239)
[INFO] 2019-01-19 13:18:48,400 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 10.0 (TID 237) in 408 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 13:18:48,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:48,411 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:48,718 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 10.0 (TID 238). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:48,718 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 10.0 (TID 240, localhost, executor driver, partition 30, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:48,719 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 10.0 (TID 240)
[INFO] 2019-01-19 13:18:48,719 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 10.0 (TID 238) in 369 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 13:18:48,729 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:48,729 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:48,752 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 10.0 (TID 239). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:48,752 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 10.0 (TID 241, localhost, executor driver, partition 31, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:48,752 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 10.0 (TID 241)
[INFO] 2019-01-19 13:18:48,753 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 10.0 (TID 239) in 354 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 13:18:48,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:48,771 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:49,050 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 10.0 (TID 240). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:49,051 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 10.0 (TID 242, localhost, executor driver, partition 32, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:49,051 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 10.0 (TID 242)
[INFO] 2019-01-19 13:18:49,051 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 10.0 (TID 240) in 333 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 13:18:49,061 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:49,061 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:49,082 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 10.0 (TID 241). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:49,082 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 10.0 (TID 243, localhost, executor driver, partition 33, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:49,083 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 10.0 (TID 243)
[INFO] 2019-01-19 13:18:49,083 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 10.0 (TID 241) in 331 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 13:18:49,095 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:49,095 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:49,366 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 10.0 (TID 242). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:49,367 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 10.0 (TID 244, localhost, executor driver, partition 34, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:49,367 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 10.0 (TID 244)
[INFO] 2019-01-19 13:18:49,367 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 10.0 (TID 242) in 317 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 13:18:49,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:49,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:49,413 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 10.0 (TID 243). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:49,413 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 10.0 (TID 245, localhost, executor driver, partition 35, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:49,413 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 10.0 (TID 245)
[INFO] 2019-01-19 13:18:49,413 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 10.0 (TID 243) in 331 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 13:18:49,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:49,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:49,691 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 10.0 (TID 244). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:49,691 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 10.0 (TID 246, localhost, executor driver, partition 36, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:49,692 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 10.0 (TID 246)
[INFO] 2019-01-19 13:18:49,692 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 10.0 (TID 244) in 326 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 13:18:49,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:49,706 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:49,747 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 10.0 (TID 245). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:49,747 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 10.0 (TID 247, localhost, executor driver, partition 37, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:49,747 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 10.0 (TID 247)
[INFO] 2019-01-19 13:18:49,747 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 10.0 (TID 245) in 334 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 13:18:49,756 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:49,756 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:50,026 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 10.0 (TID 246). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:50,027 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 10.0 (TID 248, localhost, executor driver, partition 38, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:50,027 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 10.0 (TID 248)
[INFO] 2019-01-19 13:18:50,027 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 10.0 (TID 246) in 336 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 13:18:50,037 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:50,037 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:50,070 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 10.0 (TID 247). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:50,071 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 10.0 (TID 249, localhost, executor driver, partition 39, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:50,071 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 10.0 (TID 249)
[INFO] 2019-01-19 13:18:50,071 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 10.0 (TID 247) in 324 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 13:18:50,081 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:50,081 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:50,359 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 10.0 (TID 248). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:50,360 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 10.0 (TID 250, localhost, executor driver, partition 40, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:50,360 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 10.0 (TID 250)
[INFO] 2019-01-19 13:18:50,360 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 10.0 (TID 248) in 333 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 13:18:50,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:50,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:50,398 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 10.0 (TID 249). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:50,398 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 10.0 (TID 251, localhost, executor driver, partition 41, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:50,398 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 10.0 (TID 251)
[INFO] 2019-01-19 13:18:50,398 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 10.0 (TID 249) in 328 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 13:18:50,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:50,413 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:50,702 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 10.0 (TID 250). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:18:50,702 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 10.0 (TID 252, localhost, executor driver, partition 42, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:50,703 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 10.0 (TID 252)
[INFO] 2019-01-19 13:18:50,703 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 10.0 (TID 250) in 344 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 13:18:50,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:50,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:50,760 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 10.0 (TID 251). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:50,760 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 10.0 (TID 253, localhost, executor driver, partition 43, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:50,761 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 10.0 (TID 251) in 363 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 13:18:50,761 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 10.0 (TID 253)
[INFO] 2019-01-19 13:18:50,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:50,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:51,043 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 10.0 (TID 252). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:51,044 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 10.0 (TID 254, localhost, executor driver, partition 44, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:51,044 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 10.0 (TID 254)
[INFO] 2019-01-19 13:18:51,044 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 10.0 (TID 252) in 342 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 13:18:51,053 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:51,054 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:51,091 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 10.0 (TID 253). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:51,092 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 10.0 (TID 255, localhost, executor driver, partition 45, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:51,092 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 10.0 (TID 255)
[INFO] 2019-01-19 13:18:51,092 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 10.0 (TID 253) in 332 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 13:18:51,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:51,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:51,370 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 10.0 (TID 254). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:51,371 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 10.0 (TID 256, localhost, executor driver, partition 46, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:51,371 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 10.0 (TID 256)
[INFO] 2019-01-19 13:18:51,371 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 10.0 (TID 254) in 327 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 13:18:51,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:51,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:51,436 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 10.0 (TID 255). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:51,436 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 10.0 (TID 257, localhost, executor driver, partition 47, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:51,437 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 10.0 (TID 257)
[INFO] 2019-01-19 13:18:51,437 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 10.0 (TID 255) in 346 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 13:18:51,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:51,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:51,712 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 10.0 (TID 256). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:51,712 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 10.0 (TID 258, localhost, executor driver, partition 48, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:51,712 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 10.0 (TID 258)
[INFO] 2019-01-19 13:18:51,712 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 10.0 (TID 256) in 342 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 13:18:51,723 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:51,723 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:51,780 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 10.0 (TID 257). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:51,780 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 10.0 (TID 259, localhost, executor driver, partition 49, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:51,781 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 10.0 (TID 257) in 345 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 13:18:51,781 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 10.0 (TID 259)
[INFO] 2019-01-19 13:18:51,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:51,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:52,082 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 10.0 (TID 258). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:52,083 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 10.0 (TID 260, localhost, executor driver, partition 50, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:52,083 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 10.0 (TID 260)
[INFO] 2019-01-19 13:18:52,083 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 10.0 (TID 258) in 371 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 13:18:52,094 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:52,094 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:52,130 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 10.0 (TID 259). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:18:52,130 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 10.0 (TID 261, localhost, executor driver, partition 51, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:52,131 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 10.0 (TID 261)
[INFO] 2019-01-19 13:18:52,131 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 10.0 (TID 259) in 351 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 13:18:52,142 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:52,142 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:52,429 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 10.0 (TID 260). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:52,429 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 10.0 (TID 262, localhost, executor driver, partition 52, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:52,430 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 10.0 (TID 262)
[INFO] 2019-01-19 13:18:52,430 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 10.0 (TID 260) in 348 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 13:18:52,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:52,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:52,488 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 10.0 (TID 261). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:52,489 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 10.0 (TID 263, localhost, executor driver, partition 53, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:52,489 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 10.0 (TID 263)
[INFO] 2019-01-19 13:18:52,489 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 10.0 (TID 261) in 359 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 13:18:52,499 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:52,499 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:52,784 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 10.0 (TID 262). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:52,784 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 10.0 (TID 264, localhost, executor driver, partition 54, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:52,785 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 10.0 (TID 264)
[INFO] 2019-01-19 13:18:52,785 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 10.0 (TID 262) in 356 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 13:18:52,799 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:52,800 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:52,856 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 10.0 (TID 263). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:52,856 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 10.0 (TID 265, localhost, executor driver, partition 55, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:52,857 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 10.0 (TID 265)
[INFO] 2019-01-19 13:18:52,857 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 10.0 (TID 263) in 369 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 13:18:52,868 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:52,868 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:53,146 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 10.0 (TID 264). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:53,147 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 10.0 (TID 266, localhost, executor driver, partition 56, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:53,147 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 10.0 (TID 266)
[INFO] 2019-01-19 13:18:53,148 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 10.0 (TID 264) in 363 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 13:18:53,156 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:53,156 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:53,203 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 10.0 (TID 265). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:53,204 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 10.0 (TID 267, localhost, executor driver, partition 57, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:53,204 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 10.0 (TID 267)
[INFO] 2019-01-19 13:18:53,204 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 10.0 (TID 265) in 348 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 13:18:53,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:53,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:53,461 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 10.0 (TID 266). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:53,461 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 10.0 (TID 268, localhost, executor driver, partition 58, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:53,461 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 10.0 (TID 268)
[INFO] 2019-01-19 13:18:53,461 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 10.0 (TID 266) in 314 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 13:18:53,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:53,473 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:53,520 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 10.0 (TID 267). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:53,520 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 10.0 (TID 269, localhost, executor driver, partition 59, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:53,520 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 10.0 (TID 269)
[INFO] 2019-01-19 13:18:53,521 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 10.0 (TID 267) in 318 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 13:18:53,529 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:53,529 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:53,797 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 10.0 (TID 268). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:53,798 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 10.0 (TID 270, localhost, executor driver, partition 60, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:53,798 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 10.0 (TID 270)
[INFO] 2019-01-19 13:18:53,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 10.0 (TID 268) in 337 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 13:18:53,809 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:53,809 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:53,862 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 10.0 (TID 269). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:53,863 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 10.0 (TID 271, localhost, executor driver, partition 61, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:53,863 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 10.0 (TID 271)
[INFO] 2019-01-19 13:18:53,863 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 10.0 (TID 269) in 343 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 13:18:53,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:53,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:54,146 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 10.0 (TID 270). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:54,147 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 10.0 (TID 272, localhost, executor driver, partition 62, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:54,147 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 10.0 (TID 272)
[INFO] 2019-01-19 13:18:54,147 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 10.0 (TID 270) in 349 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 13:18:54,160 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:54,160 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:54,205 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 10.0 (TID 271). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:54,205 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 10.0 (TID 273, localhost, executor driver, partition 63, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:54,205 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 10.0 (TID 273)
[INFO] 2019-01-19 13:18:54,205 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 10.0 (TID 271) in 343 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 13:18:54,218 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:54,218 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:54,491 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 10.0 (TID 272). 4343 bytes result sent to driver
[INFO] 2019-01-19 13:18:54,491 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 10.0 (TID 274, localhost, executor driver, partition 64, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:54,492 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 10.0 (TID 274)
[INFO] 2019-01-19 13:18:54,492 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 10.0 (TID 272) in 346 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 13:18:54,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:54,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:54,556 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 10.0 (TID 273). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:54,557 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 10.0 (TID 275, localhost, executor driver, partition 65, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:54,557 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 10.0 (TID 275)
[INFO] 2019-01-19 13:18:54,557 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 10.0 (TID 273) in 352 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 13:18:54,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:54,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:54,887 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 10.0 (TID 274). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:54,888 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 10.0 (TID 276, localhost, executor driver, partition 66, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:54,888 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 10.0 (TID 276)
[INFO] 2019-01-19 13:18:54,888 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 10.0 (TID 274) in 397 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 13:18:54,902 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:54,903 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:54,957 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 10.0 (TID 275). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:54,958 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 10.0 (TID 277, localhost, executor driver, partition 67, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:54,958 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 10.0 (TID 277)
[INFO] 2019-01-19 13:18:54,958 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 10.0 (TID 275) in 401 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 13:18:54,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:54,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:55,303 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 10.0 (TID 276). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:55,303 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 10.0 (TID 278, localhost, executor driver, partition 68, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:55,304 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 10.0 (TID 278)
[INFO] 2019-01-19 13:18:55,304 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 10.0 (TID 276) in 417 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 13:18:55,319 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:55,319 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:55,377 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 10.0 (TID 277). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:55,378 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 10.0 (TID 279, localhost, executor driver, partition 69, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:55,378 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 10.0 (TID 279)
[INFO] 2019-01-19 13:18:55,378 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 10.0 (TID 277) in 421 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 13:18:55,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:55,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:55,687 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 10.0 (TID 278). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:55,688 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 10.0 (TID 280, localhost, executor driver, partition 70, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:55,688 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 10.0 (TID 280)
[INFO] 2019-01-19 13:18:55,688 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 10.0 (TID 278) in 385 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 13:18:55,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:55,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:55,752 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 10.0 (TID 279). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:55,753 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 10.0 (TID 281, localhost, executor driver, partition 71, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:55,753 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 10.0 (TID 281)
[INFO] 2019-01-19 13:18:55,753 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 10.0 (TID 279) in 375 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 13:18:55,766 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:55,766 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:56,034 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 10.0 (TID 280). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:18:56,035 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 10.0 (TID 282, localhost, executor driver, partition 72, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:56,035 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 10.0 (TID 282)
[INFO] 2019-01-19 13:18:56,035 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 10.0 (TID 280) in 347 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 13:18:56,044 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:56,044 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:56,085 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 10.0 (TID 281). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:56,086 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 10.0 (TID 283, localhost, executor driver, partition 73, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:56,086 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 10.0 (TID 283)
[INFO] 2019-01-19 13:18:56,086 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 10.0 (TID 281) in 334 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 13:18:56,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:56,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:56,370 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 10.0 (TID 282). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:56,371 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 10.0 (TID 284, localhost, executor driver, partition 74, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:56,371 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 10.0 (TID 284)
[INFO] 2019-01-19 13:18:56,371 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 10.0 (TID 282) in 336 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 13:18:56,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:56,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:56,422 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 10.0 (TID 283). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:56,422 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 10.0 (TID 285, localhost, executor driver, partition 75, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:56,423 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 10.0 (TID 285)
[INFO] 2019-01-19 13:18:56,423 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 10.0 (TID 283) in 337 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 13:18:56,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:56,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:56,728 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 10.0 (TID 284). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:56,728 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 10.0 (TID 286, localhost, executor driver, partition 76, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:56,728 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 10.0 (TID 286)
[INFO] 2019-01-19 13:18:56,729 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 10.0 (TID 284) in 359 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 13:18:56,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:56,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:56,769 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 10.0 (TID 285). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:56,769 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 10.0 (TID 287, localhost, executor driver, partition 77, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:56,769 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 10.0 (TID 287)
[INFO] 2019-01-19 13:18:56,769 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 10.0 (TID 285) in 347 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 13:18:56,784 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:56,784 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:57,105 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 10.0 (TID 286). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:57,105 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 10.0 (TID 288, localhost, executor driver, partition 78, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:57,106 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 10.0 (TID 288)
[INFO] 2019-01-19 13:18:57,106 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 10.0 (TID 286) in 378 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 13:18:57,117 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:57,117 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:57,132 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 10.0 (TID 287). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:57,133 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 10.0 (TID 289, localhost, executor driver, partition 79, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:57,133 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 10.0 (TID 289)
[INFO] 2019-01-19 13:18:57,133 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 10.0 (TID 287) in 364 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 13:18:57,146 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:57,146 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:57,450 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 10.0 (TID 288). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:57,451 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 10.0 (TID 290, localhost, executor driver, partition 80, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:57,451 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 10.0 (TID 290)
[INFO] 2019-01-19 13:18:57,451 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 10.0 (TID 288) in 346 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 13:18:57,461 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 10.0 (TID 289). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:57,462 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 10.0 (TID 291, localhost, executor driver, partition 81, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:57,462 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 10.0 (TID 291)
[INFO] 2019-01-19 13:18:57,462 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 10.0 (TID 289) in 329 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 13:18:57,464 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:57,464 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:57,471 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:57,471 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:57,766 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 10.0 (TID 290). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:57,766 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 10.0 (TID 292, localhost, executor driver, partition 82, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:57,767 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 10.0 (TID 292)
[INFO] 2019-01-19 13:18:57,767 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 10.0 (TID 290) in 316 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 13:18:57,770 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 10.0 (TID 291). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:57,771 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 10.0 (TID 293, localhost, executor driver, partition 83, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:57,771 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 10.0 (TID 293)
[INFO] 2019-01-19 13:18:57,771 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 10.0 (TID 291) in 309 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 13:18:57,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:57,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:57,779 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:57,779 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:58,090 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 10.0 (TID 293). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:18:58,090 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 10.0 (TID 294, localhost, executor driver, partition 84, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:58,091 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 10.0 (TID 294)
[INFO] 2019-01-19 13:18:58,091 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 10.0 (TID 293) in 321 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 13:18:58,099 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 10.0 (TID 292). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:18:58,099 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 10.0 (TID 295, localhost, executor driver, partition 85, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:58,100 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 10.0 (TID 295)
[INFO] 2019-01-19 13:18:58,100 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 10.0 (TID 292) in 334 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 13:18:58,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:58,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:58,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:58,110 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:58,431 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 10.0 (TID 294). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:58,432 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 10.0 (TID 296, localhost, executor driver, partition 86, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:58,432 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 10.0 (TID 296)
[INFO] 2019-01-19 13:18:58,432 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 10.0 (TID 294) in 342 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 13:18:58,436 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 10.0 (TID 295). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:58,436 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 10.0 (TID 297, localhost, executor driver, partition 87, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:58,437 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 10.0 (TID 295) in 338 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 13:18:58,437 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 10.0 (TID 297)
[INFO] 2019-01-19 13:18:58,443 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:58,443 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:58,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:58,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:58,757 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 10.0 (TID 297). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:18:58,758 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 10.0 (TID 298, localhost, executor driver, partition 88, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:58,758 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 10.0 (TID 298)
[INFO] 2019-01-19 13:18:58,758 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 10.0 (TID 297) in 322 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 13:18:58,762 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 10.0 (TID 296). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:58,762 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 10.0 (TID 299, localhost, executor driver, partition 89, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:58,763 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 10.0 (TID 299)
[INFO] 2019-01-19 13:18:58,763 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 10.0 (TID 296) in 332 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 13:18:58,769 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:58,769 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:58,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:58,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:18:59,087 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 10.0 (TID 299). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:59,088 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 10.0 (TID 300, localhost, executor driver, partition 90, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:59,088 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 10.0 (TID 300)
[INFO] 2019-01-19 13:18:59,088 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 10.0 (TID 299) in 326 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 13:18:59,091 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 10.0 (TID 298). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:18:59,092 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 10.0 (TID 301, localhost, executor driver, partition 91, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:59,092 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 10.0 (TID 301)
[INFO] 2019-01-19 13:18:59,092 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 10.0 (TID 298) in 334 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 13:18:59,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:59,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:59,105 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:59,105 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:59,416 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 10.0 (TID 300). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:59,416 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 10.0 (TID 302, localhost, executor driver, partition 92, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:59,416 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 10.0 (TID 302)
[INFO] 2019-01-19 13:18:59,417 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 10.0 (TID 300) in 330 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 13:18:59,420 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 10.0 (TID 301). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:59,420 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 10.0 (TID 303, localhost, executor driver, partition 93, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:59,420 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 10.0 (TID 303)
[INFO] 2019-01-19 13:18:59,420 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 10.0 (TID 301) in 328 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 13:18:59,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:59,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:59,434 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:59,434 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:59,784 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 10.0 (TID 302). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:59,784 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 10.0 (TID 304, localhost, executor driver, partition 94, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:59,785 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 10.0 (TID 304)
[INFO] 2019-01-19 13:18:59,785 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 10.0 (TID 302) in 369 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 13:18:59,792 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 10.0 (TID 303). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:18:59,793 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 10.0 (TID 305, localhost, executor driver, partition 95, ANY, 5789 bytes)
[INFO] 2019-01-19 13:18:59,793 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 10.0 (TID 305)
[INFO] 2019-01-19 13:18:59,793 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 10.0 (TID 303) in 373 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 13:18:59,796 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:59,796 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:18:59,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:18:59,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:00,136 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 10.0 (TID 304). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:00,136 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 10.0 (TID 306, localhost, executor driver, partition 96, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:00,137 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 10.0 (TID 306)
[INFO] 2019-01-19 13:19:00,137 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 10.0 (TID 304) in 353 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 13:19:00,141 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 10.0 (TID 305). 4270 bytes result sent to driver
[INFO] 2019-01-19 13:19:00,141 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 10.0 (TID 307, localhost, executor driver, partition 97, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:00,142 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 10.0 (TID 305) in 349 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 13:19:00,142 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 10.0 (TID 307)
[INFO] 2019-01-19 13:19:00,148 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:00,149 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:00,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:00,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:00,474 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 10.0 (TID 307). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:00,475 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 10.0 (TID 308, localhost, executor driver, partition 98, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:00,475 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 10.0 (TID 308)
[INFO] 2019-01-19 13:19:00,475 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 10.0 (TID 307) in 334 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 13:19:00,481 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 10.0 (TID 306). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:00,482 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 10.0 (TID 309, localhost, executor driver, partition 99, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:00,482 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 10.0 (TID 309)
[INFO] 2019-01-19 13:19:00,482 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 10.0 (TID 306) in 346 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 13:19:00,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:00,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:00,494 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:00,495 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:00,812 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 10.0 (TID 308). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:00,813 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 10.0 (TID 310, localhost, executor driver, partition 100, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:00,813 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 10.0 (TID 308) in 339 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 13:19:00,813 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 10.0 (TID 310)
[INFO] 2019-01-19 13:19:00,818 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 10.0 (TID 309). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:00,819 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 10.0 (TID 311, localhost, executor driver, partition 101, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:00,819 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 10.0 (TID 311)
[INFO] 2019-01-19 13:19:00,819 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 10.0 (TID 309) in 337 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 13:19:00,826 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:00,826 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:00,833 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:00,833 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:01,141 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 10.0 (TID 310). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:01,142 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 10.0 (TID 312, localhost, executor driver, partition 102, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:01,142 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 10.0 (TID 312)
[INFO] 2019-01-19 13:19:01,142 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 10.0 (TID 310) in 329 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 13:19:01,155 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 10.0 (TID 311). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:01,156 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 10.0 (TID 313, localhost, executor driver, partition 103, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:01,156 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:01,156 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 10.0 (TID 311) in 338 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 13:19:01,156 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 10.0 (TID 313)
[INFO] 2019-01-19 13:19:01,156 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:01,170 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:01,170 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:01,467 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 10.0 (TID 312). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:01,467 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 10.0 (TID 314, localhost, executor driver, partition 104, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:01,467 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 10.0 (TID 314)
[INFO] 2019-01-19 13:19:01,467 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 10.0 (TID 312) in 325 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 13:19:01,470 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 10.0 (TID 313). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:01,471 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 10.0 (TID 315, localhost, executor driver, partition 105, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:01,471 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 10.0 (TID 315)
[INFO] 2019-01-19 13:19:01,471 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 10.0 (TID 313) in 315 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 13:19:01,478 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:01,478 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:01,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:01,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:01,812 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 10.0 (TID 315). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:01,812 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 10.0 (TID 316, localhost, executor driver, partition 106, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:01,813 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 10.0 (TID 316)
[INFO] 2019-01-19 13:19:01,813 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 10.0 (TID 315) in 342 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 13:19:01,823 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 10.0 (TID 314). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:01,824 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 10.0 (TID 317, localhost, executor driver, partition 107, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:01,824 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 10.0 (TID 317)
[INFO] 2019-01-19 13:19:01,824 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 10.0 (TID 314) in 357 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 13:19:01,828 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:01,828 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:01,834 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:01,835 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:02,137 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 10.0 (TID 316). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:02,137 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 10.0 (TID 318, localhost, executor driver, partition 108, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:02,138 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 10.0 (TID 318)
[INFO] 2019-01-19 13:19:02,138 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 10.0 (TID 316) in 326 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 13:19:02,145 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 10.0 (TID 317). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:02,146 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 10.0 (TID 319, localhost, executor driver, partition 109, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:02,146 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 10.0 (TID 319)
[INFO] 2019-01-19 13:19:02,146 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 10.0 (TID 317) in 323 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 13:19:02,152 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:02,152 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:02,157 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:02,157 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:02,491 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 10.0 (TID 318). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:02,492 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 10.0 (TID 320, localhost, executor driver, partition 110, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:02,492 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 10.0 (TID 318) in 355 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 13:19:02,493 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 10.0 (TID 320)
[INFO] 2019-01-19 13:19:02,496 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 10.0 (TID 319). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:02,497 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 10.0 (TID 321, localhost, executor driver, partition 111, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:02,497 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 10.0 (TID 321)
[INFO] 2019-01-19 13:19:02,497 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 10.0 (TID 319) in 352 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 13:19:02,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:02,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:02,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:02,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:02,834 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 10.0 (TID 320). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:02,834 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 10.0 (TID 322, localhost, executor driver, partition 112, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:02,835 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 10.0 (TID 322)
[INFO] 2019-01-19 13:19:02,835 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 10.0 (TID 320) in 343 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 13:19:02,838 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 10.0 (TID 321). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:02,838 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 10.0 (TID 323, localhost, executor driver, partition 113, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:02,838 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 10.0 (TID 323)
[INFO] 2019-01-19 13:19:02,839 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 10.0 (TID 321) in 341 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 13:19:02,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:02,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:02,852 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:02,852 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:03,157 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 10.0 (TID 322). 4343 bytes result sent to driver
[INFO] 2019-01-19 13:19:03,157 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 10.0 (TID 324, localhost, executor driver, partition 114, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:03,158 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 10.0 (TID 324)
[INFO] 2019-01-19 13:19:03,158 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 10.0 (TID 322) in 324 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 13:19:03,175 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:03,175 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:03,180 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 10.0 (TID 323). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:03,181 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 10.0 (TID 325, localhost, executor driver, partition 115, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:03,181 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 10.0 (TID 325)
[INFO] 2019-01-19 13:19:03,181 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 10.0 (TID 323) in 343 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 13:19:03,194 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:03,194 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:03,512 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 10.0 (TID 324). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:03,512 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 10.0 (TID 326, localhost, executor driver, partition 116, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:03,513 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 10.0 (TID 326)
[INFO] 2019-01-19 13:19:03,513 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 10.0 (TID 324) in 356 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 13:19:03,522 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:03,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:03,527 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 10.0 (TID 325). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:03,527 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 10.0 (TID 327, localhost, executor driver, partition 117, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:03,528 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 10.0 (TID 327)
[INFO] 2019-01-19 13:19:03,528 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 10.0 (TID 325) in 347 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 13:19:03,537 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:03,537 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:03,828 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 10.0 (TID 326). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:03,828 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 10.0 (TID 328, localhost, executor driver, partition 118, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:03,829 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 10.0 (TID 328)
[INFO] 2019-01-19 13:19:03,829 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 10.0 (TID 326) in 317 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 13:19:03,842 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:03,842 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:03,845 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 10.0 (TID 327). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:03,846 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 10.0 (TID 329, localhost, executor driver, partition 119, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:03,846 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 10.0 (TID 327) in 319 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 13:19:03,847 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 10.0 (TID 329)
[INFO] 2019-01-19 13:19:03,861 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:03,861 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:04,158 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 10.0 (TID 328). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:04,158 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 10.0 (TID 330, localhost, executor driver, partition 120, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:04,160 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 10.0 (TID 328) in 332 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 13:19:04,160 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 10.0 (TID 330)
[INFO] 2019-01-19 13:19:04,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:04,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:04,185 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 10.0 (TID 329). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:04,185 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 10.0 (TID 331, localhost, executor driver, partition 121, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:04,185 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 10.0 (TID 331)
[INFO] 2019-01-19 13:19:04,186 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 10.0 (TID 329) in 339 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 13:19:04,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:04,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:04,499 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 10.0 (TID 330). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:04,499 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 10.0 (TID 332, localhost, executor driver, partition 122, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:04,500 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 10.0 (TID 332)
[INFO] 2019-01-19 13:19:04,500 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 10.0 (TID 330) in 342 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 13:19:04,510 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:04,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:04,523 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 10.0 (TID 331). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:04,524 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 10.0 (TID 333, localhost, executor driver, partition 123, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:04,524 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 10.0 (TID 333)
[INFO] 2019-01-19 13:19:04,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 10.0 (TID 331) in 339 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 13:19:04,532 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:04,533 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:04,835 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 10.0 (TID 332). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:04,836 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 10.0 (TID 334, localhost, executor driver, partition 124, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:04,836 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 10.0 (TID 334)
[INFO] 2019-01-19 13:19:04,836 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 10.0 (TID 332) in 337 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 13:19:04,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:04,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:04,866 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 10.0 (TID 333). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:04,866 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 10.0 (TID 335, localhost, executor driver, partition 125, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:04,866 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 10.0 (TID 335)
[INFO] 2019-01-19 13:19:04,866 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 10.0 (TID 333) in 343 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 13:19:04,878 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:04,878 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:05,165 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 10.0 (TID 334). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:05,165 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 10.0 (TID 336, localhost, executor driver, partition 126, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:05,166 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 10.0 (TID 336)
[INFO] 2019-01-19 13:19:05,166 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 10.0 (TID 334) in 330 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 13:19:05,179 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:05,179 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:05,193 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 10.0 (TID 335). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:05,194 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 10.0 (TID 337, localhost, executor driver, partition 127, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:05,194 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 10.0 (TID 337)
[INFO] 2019-01-19 13:19:05,194 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 10.0 (TID 335) in 328 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 13:19:05,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:05,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:05,481 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 10.0 (TID 336). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:05,481 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 10.0 (TID 338, localhost, executor driver, partition 128, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:05,482 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 10.0 (TID 338)
[INFO] 2019-01-19 13:19:05,482 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 10.0 (TID 336) in 317 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 13:19:05,490 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:05,491 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:05,516 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 10.0 (TID 337). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:05,516 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 10.0 (TID 339, localhost, executor driver, partition 129, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:05,517 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 10.0 (TID 339)
[INFO] 2019-01-19 13:19:05,517 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 10.0 (TID 337) in 323 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 13:19:05,527 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:05,527 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:05,808 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 10.0 (TID 338). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:05,809 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 10.0 (TID 340, localhost, executor driver, partition 130, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:05,809 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 10.0 (TID 340)
[INFO] 2019-01-19 13:19:05,809 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 10.0 (TID 338) in 328 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 13:19:05,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:05,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:05,855 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 10.0 (TID 339). 4180 bytes result sent to driver
[INFO] 2019-01-19 13:19:05,855 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 10.0 (TID 341, localhost, executor driver, partition 131, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:05,855 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 10.0 (TID 341)
[INFO] 2019-01-19 13:19:05,855 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 10.0 (TID 339) in 339 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 13:19:05,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:05,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:06,140 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 10.0 (TID 340). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:06,141 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 10.0 (TID 342, localhost, executor driver, partition 132, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:06,141 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 10.0 (TID 342)
[INFO] 2019-01-19 13:19:06,141 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 10.0 (TID 340) in 332 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 13:19:06,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:06,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:06,195 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 10.0 (TID 341). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:06,196 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 10.0 (TID 343, localhost, executor driver, partition 133, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:06,196 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 10.0 (TID 343)
[INFO] 2019-01-19 13:19:06,196 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 10.0 (TID 341) in 341 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 13:19:06,208 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:06,208 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:06,473 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 10.0 (TID 342). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:06,474 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 10.0 (TID 344, localhost, executor driver, partition 134, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:06,474 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 10.0 (TID 344)
[INFO] 2019-01-19 13:19:06,474 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 10.0 (TID 342) in 333 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 13:19:06,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:06,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:06,529 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 10.0 (TID 343). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:06,530 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 10.0 (TID 345, localhost, executor driver, partition 135, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:06,530 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 10.0 (TID 345)
[INFO] 2019-01-19 13:19:06,530 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 10.0 (TID 343) in 334 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 13:19:06,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:06,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:06,803 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 10.0 (TID 344). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:06,804 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 10.0 (TID 346, localhost, executor driver, partition 136, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:06,804 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 10.0 (TID 346)
[INFO] 2019-01-19 13:19:06,804 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 10.0 (TID 344) in 331 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 13:19:06,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:06,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:06,862 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 10.0 (TID 345). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:06,863 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 10.0 (TID 347, localhost, executor driver, partition 137, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:06,863 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 10.0 (TID 347)
[INFO] 2019-01-19 13:19:06,863 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 10.0 (TID 345) in 333 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 13:19:06,874 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:06,875 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:07,130 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 10.0 (TID 346). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:07,131 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 10.0 (TID 348, localhost, executor driver, partition 138, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:07,131 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 10.0 (TID 348)
[INFO] 2019-01-19 13:19:07,131 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 10.0 (TID 346) in 327 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 13:19:07,143 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:07,143 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:07,193 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 10.0 (TID 347). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:07,194 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 10.0 (TID 349, localhost, executor driver, partition 139, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:07,194 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 10.0 (TID 349)
[INFO] 2019-01-19 13:19:07,194 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 10.0 (TID 347) in 331 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 13:19:07,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:07,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:07,470 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 10.0 (TID 348). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:07,471 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 10.0 (TID 350, localhost, executor driver, partition 140, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:07,471 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 10.0 (TID 350)
[INFO] 2019-01-19 13:19:07,471 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 10.0 (TID 348) in 340 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 13:19:07,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:07,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:07,530 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 10.0 (TID 349). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:07,530 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 10.0 (TID 351, localhost, executor driver, partition 141, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:07,531 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 10.0 (TID 351)
[INFO] 2019-01-19 13:19:07,531 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 10.0 (TID 349) in 338 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 13:19:07,545 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:07,545 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:07,848 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 10.0 (TID 350). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:07,848 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 10.0 (TID 352, localhost, executor driver, partition 142, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:07,848 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 10.0 (TID 352)
[INFO] 2019-01-19 13:19:07,848 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 10.0 (TID 350) in 377 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 13:19:07,862 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:07,862 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:07,925 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 10.0 (TID 351). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:07,925 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 10.0 (TID 353, localhost, executor driver, partition 143, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:07,926 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 10.0 (TID 353)
[INFO] 2019-01-19 13:19:07,926 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 10.0 (TID 351) in 396 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 13:19:07,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:07,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:08,253 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 10.0 (TID 352). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:08,254 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 10.0 (TID 354, localhost, executor driver, partition 144, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:08,254 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 10.0 (TID 354)
[INFO] 2019-01-19 13:19:08,254 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 10.0 (TID 352) in 406 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 13:19:08,268 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:08,268 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:08,318 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 10.0 (TID 353). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:08,318 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 10.0 (TID 355, localhost, executor driver, partition 145, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:08,319 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 10.0 (TID 355)
[INFO] 2019-01-19 13:19:08,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 10.0 (TID 353) in 394 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 13:19:08,330 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:08,330 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:08,586 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 10.0 (TID 354). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:08,586 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 10.0 (TID 356, localhost, executor driver, partition 146, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:08,586 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 10.0 (TID 356)
[INFO] 2019-01-19 13:19:08,586 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 10.0 (TID 354) in 333 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 13:19:08,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:08,596 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:08,650 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 10.0 (TID 355). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:08,651 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 10.0 (TID 357, localhost, executor driver, partition 147, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:08,651 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 10.0 (TID 357)
[INFO] 2019-01-19 13:19:08,651 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 10.0 (TID 355) in 333 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 13:19:08,662 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:08,663 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:08,939 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 10.0 (TID 356). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:08,939 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 10.0 (TID 358, localhost, executor driver, partition 148, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:08,940 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 10.0 (TID 358)
[INFO] 2019-01-19 13:19:08,940 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 10.0 (TID 356) in 354 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 13:19:08,951 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:08,951 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:09,014 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 10.0 (TID 357). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:09,015 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 10.0 (TID 359, localhost, executor driver, partition 149, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:09,015 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 10.0 (TID 359)
[INFO] 2019-01-19 13:19:09,015 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 10.0 (TID 357) in 364 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 13:19:09,025 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:09,025 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:09,286 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 10.0 (TID 358). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:09,286 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 10.0 (TID 360, localhost, executor driver, partition 150, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:09,286 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 10.0 (TID 360)
[INFO] 2019-01-19 13:19:09,286 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 10.0 (TID 358) in 347 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 13:19:09,298 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:09,298 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:09,353 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 10.0 (TID 359). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:09,354 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 10.0 (TID 361, localhost, executor driver, partition 151, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:09,354 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 10.0 (TID 361)
[INFO] 2019-01-19 13:19:09,354 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 10.0 (TID 359) in 339 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 13:19:09,363 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:09,363 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:09,619 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 10.0 (TID 360). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:09,620 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 10.0 (TID 362, localhost, executor driver, partition 152, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:09,620 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 10.0 (TID 362)
[INFO] 2019-01-19 13:19:09,620 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 10.0 (TID 360) in 334 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 13:19:09,631 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:09,631 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:09,679 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 10.0 (TID 361). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:09,679 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 10.0 (TID 363, localhost, executor driver, partition 153, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:09,679 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 10.0 (TID 363)
[INFO] 2019-01-19 13:19:09,679 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 10.0 (TID 361) in 325 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 13:19:09,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:09,692 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:09,968 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 10.0 (TID 362). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:09,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 10.0 (TID 364, localhost, executor driver, partition 154, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:09,969 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 10.0 (TID 364)
[INFO] 2019-01-19 13:19:09,969 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 10.0 (TID 362) in 350 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 13:19:09,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:09,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:10,016 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 10.0 (TID 363). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:10,016 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 10.0 (TID 365, localhost, executor driver, partition 155, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:10,017 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 10.0 (TID 365)
[INFO] 2019-01-19 13:19:10,017 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 10.0 (TID 363) in 338 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 13:19:10,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:10,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:10,319 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 10.0 (TID 364). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:10,319 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 10.0 (TID 366, localhost, executor driver, partition 156, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:10,319 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 10.0 (TID 366)
[INFO] 2019-01-19 13:19:10,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 10.0 (TID 364) in 350 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 13:19:10,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:10,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:10,360 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 10.0 (TID 365). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:10,360 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 10.0 (TID 367, localhost, executor driver, partition 157, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:10,360 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 10.0 (TID 367)
[INFO] 2019-01-19 13:19:10,360 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 10.0 (TID 365) in 344 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 13:19:10,369 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:10,369 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:10,670 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 10.0 (TID 366). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:10,671 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 10.0 (TID 368, localhost, executor driver, partition 158, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:10,671 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 10.0 (TID 368)
[INFO] 2019-01-19 13:19:10,671 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 10.0 (TID 366) in 352 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 13:19:10,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:10,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:10,699 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 10.0 (TID 367). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:10,700 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 10.0 (TID 369, localhost, executor driver, partition 159, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:10,700 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 10.0 (TID 369)
[INFO] 2019-01-19 13:19:10,700 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 10.0 (TID 367) in 340 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 13:19:10,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:10,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:11,001 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 10.0 (TID 368). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:11,001 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 10.0 (TID 370, localhost, executor driver, partition 160, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:11,002 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 10.0 (TID 370)
[INFO] 2019-01-19 13:19:11,002 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 10.0 (TID 368) in 332 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 13:19:11,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:11,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:11,027 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 10.0 (TID 369). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:11,027 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 10.0 (TID 371, localhost, executor driver, partition 161, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:11,028 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 10.0 (TID 371)
[INFO] 2019-01-19 13:19:11,028 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 10.0 (TID 369) in 329 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 13:19:11,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:11,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:11,332 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 10.0 (TID 370). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:11,332 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 10.0 (TID 372, localhost, executor driver, partition 162, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:11,333 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 10.0 (TID 372)
[INFO] 2019-01-19 13:19:11,333 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 10.0 (TID 370) in 332 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 13:19:11,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:11,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:11,363 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 10.0 (TID 371). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:11,363 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 10.0 (TID 373, localhost, executor driver, partition 163, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:11,363 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 10.0 (TID 373)
[INFO] 2019-01-19 13:19:11,364 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 10.0 (TID 371) in 337 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 13:19:11,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:11,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:11,684 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 10.0 (TID 372). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:11,685 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 10.0 (TID 374, localhost, executor driver, partition 164, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:11,685 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 10.0 (TID 374)
[INFO] 2019-01-19 13:19:11,685 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 10.0 (TID 372) in 353 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 13:19:11,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:11,695 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:11,726 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 10.0 (TID 373). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:11,726 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 10.0 (TID 375, localhost, executor driver, partition 165, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:11,726 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 10.0 (TID 375)
[INFO] 2019-01-19 13:19:11,726 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 10.0 (TID 373) in 363 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 13:19:11,740 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:11,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:12,076 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 10.0 (TID 374). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:12,077 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 10.0 (TID 376, localhost, executor driver, partition 166, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:12,077 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 10.0 (TID 376)
[INFO] 2019-01-19 13:19:12,077 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 10.0 (TID 374) in 393 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 13:19:12,087 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:12,088 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:12,113 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 10.0 (TID 375). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:12,113 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 10.0 (TID 377, localhost, executor driver, partition 167, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:12,114 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 10.0 (TID 377)
[INFO] 2019-01-19 13:19:12,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 10.0 (TID 375) in 388 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 13:19:12,126 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:12,127 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:12,396 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 10.0 (TID 376). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:12,397 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 10.0 (TID 378, localhost, executor driver, partition 168, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:12,397 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 10.0 (TID 378)
[INFO] 2019-01-19 13:19:12,397 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 10.0 (TID 376) in 320 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 13:19:12,409 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:12,409 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:12,434 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 10.0 (TID 377). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:12,435 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 10.0 (TID 379, localhost, executor driver, partition 169, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:12,435 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 10.0 (TID 379)
[INFO] 2019-01-19 13:19:12,435 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 10.0 (TID 377) in 322 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 13:19:12,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:12,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:12,724 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 10.0 (TID 378). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:12,725 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 10.0 (TID 380, localhost, executor driver, partition 170, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:12,725 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 10.0 (TID 380)
[INFO] 2019-01-19 13:19:12,725 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 10.0 (TID 378) in 328 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 13:19:12,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:12,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:12,751 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 10.0 (TID 379). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:12,752 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 10.0 (TID 381, localhost, executor driver, partition 171, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:12,752 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 10.0 (TID 381)
[INFO] 2019-01-19 13:19:12,752 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 10.0 (TID 379) in 317 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 13:19:12,761 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:12,761 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:13,056 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 10.0 (TID 380). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:13,057 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 10.0 (TID 382, localhost, executor driver, partition 172, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:13,057 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 10.0 (TID 382)
[INFO] 2019-01-19 13:19:13,057 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 10.0 (TID 380) in 333 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 13:19:13,071 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:13,072 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:13,098 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 10.0 (TID 381). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:13,098 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 10.0 (TID 383, localhost, executor driver, partition 173, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:13,099 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 10.0 (TID 383)
[INFO] 2019-01-19 13:19:13,099 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 10.0 (TID 381) in 348 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 13:19:13,110 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:13,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:13,389 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 10.0 (TID 382). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:13,390 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 10.0 (TID 384, localhost, executor driver, partition 174, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:13,390 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 10.0 (TID 384)
[INFO] 2019-01-19 13:19:13,390 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 10.0 (TID 382) in 333 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 13:19:13,400 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:13,400 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:13,425 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 10.0 (TID 383). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:13,426 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 10.0 (TID 385, localhost, executor driver, partition 175, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:13,426 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 10.0 (TID 383) in 328 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 13:19:13,426 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 10.0 (TID 385)
[INFO] 2019-01-19 13:19:13,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:13,440 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:13,704 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 10.0 (TID 384). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:13,704 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 10.0 (TID 386, localhost, executor driver, partition 176, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:13,704 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 10.0 (TID 386)
[INFO] 2019-01-19 13:19:13,704 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 10.0 (TID 384) in 314 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 13:19:13,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:13,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:13,745 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 10.0 (TID 385). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:13,746 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 10.0 (TID 387, localhost, executor driver, partition 177, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:13,746 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 10.0 (TID 387)
[INFO] 2019-01-19 13:19:13,746 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 10.0 (TID 385) in 321 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 13:19:13,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:13,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:14,028 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 10.0 (TID 386). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:14,029 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 10.0 (TID 388, localhost, executor driver, partition 178, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:14,029 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 10.0 (TID 388)
[INFO] 2019-01-19 13:19:14,029 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 10.0 (TID 386) in 325 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 13:19:14,038 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:14,038 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:14,070 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 10.0 (TID 387). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:14,071 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 10.0 (TID 389, localhost, executor driver, partition 179, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:14,071 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 10.0 (TID 389)
[INFO] 2019-01-19 13:19:14,071 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 10.0 (TID 387) in 325 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 13:19:14,085 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:14,085 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:14,355 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 10.0 (TID 388). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:14,355 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 10.0 (TID 390, localhost, executor driver, partition 180, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:14,355 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 10.0 (TID 390)
[INFO] 2019-01-19 13:19:14,356 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 10.0 (TID 388) in 326 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 13:19:14,365 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:14,365 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:14,412 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 10.0 (TID 389). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:14,412 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 10.0 (TID 391, localhost, executor driver, partition 181, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:14,412 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 10.0 (TID 391)
[INFO] 2019-01-19 13:19:14,412 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 10.0 (TID 389) in 342 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 13:19:14,424 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:14,424 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:14,693 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 10.0 (TID 390). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:14,694 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 10.0 (TID 392, localhost, executor driver, partition 182, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:14,694 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 10.0 (TID 392)
[INFO] 2019-01-19 13:19:14,694 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 10.0 (TID 390) in 339 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 13:19:14,708 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:14,709 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:14,742 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 10.0 (TID 391). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:14,742 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 10.0 (TID 393, localhost, executor driver, partition 183, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:14,742 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 10.0 (TID 393)
[INFO] 2019-01-19 13:19:14,743 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 10.0 (TID 391) in 330 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 13:19:14,752 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:14,752 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:15,036 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 10.0 (TID 392). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:15,037 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 10.0 (TID 394, localhost, executor driver, partition 184, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:15,037 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 10.0 (TID 394)
[INFO] 2019-01-19 13:19:15,037 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 10.0 (TID 392) in 344 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 13:19:15,047 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:15,047 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:15,070 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 10.0 (TID 393). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:15,070 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 10.0 (TID 395, localhost, executor driver, partition 185, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:15,071 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 10.0 (TID 395)
[INFO] 2019-01-19 13:19:15,071 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 10.0 (TID 393) in 329 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 13:19:15,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:15,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:15,360 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 10.0 (TID 394). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:15,360 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 10.0 (TID 396, localhost, executor driver, partition 186, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:15,361 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 10.0 (TID 396)
[INFO] 2019-01-19 13:19:15,361 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 10.0 (TID 394) in 324 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 13:19:15,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:15,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:15,391 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 10.0 (TID 395). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:15,392 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 10.0 (TID 397, localhost, executor driver, partition 187, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:15,392 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 10.0 (TID 397)
[INFO] 2019-01-19 13:19:15,392 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 10.0 (TID 395) in 322 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 13:19:15,404 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:15,404 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:15,690 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 10.0 (TID 396). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:15,690 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 10.0 (TID 398, localhost, executor driver, partition 188, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:15,691 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 10.0 (TID 398)
[INFO] 2019-01-19 13:19:15,691 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 10.0 (TID 396) in 331 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 13:19:15,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:15,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:15,730 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 10.0 (TID 397). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:15,731 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 10.0 (TID 399, localhost, executor driver, partition 189, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:15,731 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 10.0 (TID 399)
[INFO] 2019-01-19 13:19:15,731 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 10.0 (TID 397) in 340 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 13:19:15,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:15,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:16,031 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 10.0 (TID 398). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:16,031 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 10.0 (TID 400, localhost, executor driver, partition 190, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:16,031 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 10.0 (TID 400)
[INFO] 2019-01-19 13:19:16,031 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 10.0 (TID 398) in 341 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 13:19:16,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:16,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:16,076 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 10.0 (TID 399). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:16,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 10.0 (TID 401, localhost, executor driver, partition 191, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:16,077 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 10.0 (TID 401)
[INFO] 2019-01-19 13:19:16,077 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 10.0 (TID 399) in 346 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 13:19:16,089 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:16,089 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:16,361 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 10.0 (TID 400). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:16,362 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 10.0 (TID 402, localhost, executor driver, partition 192, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:16,362 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 10.0 (TID 402)
[INFO] 2019-01-19 13:19:16,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 10.0 (TID 400) in 331 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 13:19:16,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:16,377 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:16,483 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 10.0 (TID 401). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:19:16,484 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 10.0 (TID 403, localhost, executor driver, partition 193, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:16,484 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 10.0 (TID 403)
[INFO] 2019-01-19 13:19:16,484 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 10.0 (TID 401) in 408 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 13:19:16,499 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:16,499 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:16,767 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 10.0 (TID 402). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:16,767 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 10.0 (TID 404, localhost, executor driver, partition 194, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:16,767 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 10.0 (TID 404)
[INFO] 2019-01-19 13:19:16,767 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 10.0 (TID 402) in 406 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 13:19:16,778 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:16,778 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:16,843 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 10.0 (TID 403). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:16,844 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 10.0 (TID 405, localhost, executor driver, partition 195, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:16,844 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 10.0 (TID 405)
[INFO] 2019-01-19 13:19:16,844 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 10.0 (TID 403) in 361 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 13:19:16,856 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:16,857 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:17,101 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 10.0 (TID 404). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:17,102 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 10.0 (TID 406, localhost, executor driver, partition 196, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:17,102 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 10.0 (TID 404) in 335 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 13:19:17,102 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 10.0 (TID 406)
[INFO] 2019-01-19 13:19:17,117 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:17,117 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:17,218 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 10.0 (TID 405). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:19:17,218 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 10.0 (TID 407, localhost, executor driver, partition 197, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:17,219 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 10.0 (TID 407)
[INFO] 2019-01-19 13:19:17,219 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 10.0 (TID 405) in 375 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 13:19:17,233 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:17,233 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:17,487 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 10.0 (TID 406). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:17,487 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 10.0 (TID 408, localhost, executor driver, partition 198, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:17,488 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 10.0 (TID 408)
[INFO] 2019-01-19 13:19:17,488 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 10.0 (TID 406) in 387 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 13:19:17,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:17,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:17,576 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 10.0 (TID 407). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:19:17,577 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 10.0 (TID 409, localhost, executor driver, partition 199, ANY, 5789 bytes)
[INFO] 2019-01-19 13:19:17,577 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 10.0 (TID 409)
[INFO] 2019-01-19 13:19:17,577 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 10.0 (TID 407) in 359 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 13:19:17,590 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:17,590 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:17,826 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 10.0 (TID 408). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:17,827 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 10.0 (TID 408) in 340 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 10.0 (TID 409). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 10.0 (TID 409) in 308 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 10 (head at DecoupJson.scala:139) finished in 37.553 s
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 11)
[INFO] 2019-01-19 13:19:17,885 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:17,886 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 11 (MapPartitionsRDD[47] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:19:17,908 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16 stored as values in memory (estimated size 672.0 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:19:17,910 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16_piece0 stored as bytes in memory (estimated size 158.3 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:19:17,911 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_16_piece0 in memory on 192.168.99.1:57658 (size: 158.3 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:19:17,912 org.apache.spark.SparkContext logInfo - Created broadcast 16 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:17,912 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[47] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:19:17,912 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 11.0 with 1 tasks
[INFO] 2019-01-19 13:19:17,913 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 11.0 (TID 410, localhost, executor driver, partition 0, ANY, 5800 bytes)
[INFO] 2019-01-19 13:19:17,913 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 11.0 (TID 410)
[INFO] 2019-01-19 13:19:17,924 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 200 non-empty blocks out of 200 blocks
[INFO] 2019-01-19 13:19:17,924 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:18,217 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 157.743223 ms
[INFO] 2019-01-19 13:19:18,340 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 36.850947 ms
[INFO] 2019-01-19 13:19:18,436 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 51.873137 ms
[INFO] 2019-01-19 13:19:18,523 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 73.362675 ms
[INFO] 2019-01-19 13:19:18,660 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 11.0 (TID 410). 8334 bytes result sent to driver
[INFO] 2019-01-19 13:19:18,660 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 11.0 (TID 410) in 748 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:18,660 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:18,661 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 11 (head at DecoupJson.scala:139) finished in 0.749 s
[INFO] 2019-01-19 13:19:18,661 org.apache.spark.scheduler.DAGScheduler logInfo - Job 4 finished: head at DecoupJson.scala:139, took 43.842536 s
[INFO] 2019-01-19 13:19:18,729 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 49.00354 ms
[INFO] 2019-01-19 13:19:18,838 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:18,839 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:19:18,840 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:19:18,840 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:19:18,841 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:18,842 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:19:18,843 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:19:18,843 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:19:18,886 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.613307 ms
[INFO] 2019-01-19 13:19:18,938 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 35.142164 ms
[INFO] 2019-01-19 13:19:18,963 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17 stored as values in memory (estimated size 292.7 KB, free 1989.3 MB)
[INFO] 2019-01-19 13:19:18,976 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1989.2 MB)
[INFO] 2019-01-19 13:19:18,978 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_17_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:19:18,979 org.apache.spark.SparkContext logInfo - Created broadcast 17 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 13:19:18,980 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:19,009 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18 stored as values in memory (estimated size 292.7 KB, free 1989.0 MB)
[INFO] 2019-01-19 13:19:19,026 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:19:19,027 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_18_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:19:19,028 org.apache.spark.SparkContext logInfo - Created broadcast 18 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 13:19:19,028 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:19,325 org.apache.spark.SparkContext logInfo - Starting job: first at DecoupJson.scala:146
[INFO] 2019-01-19 13:19:19,326 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 56 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,326 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 51 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,326 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 61 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,327 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 5 (first at DecoupJson.scala:146) with 1 output partitions
[INFO] 2019-01-19 13:19:19,327 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 15 (first at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,327 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 14)
[INFO] 2019-01-19 13:19:19,327 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 14)
[INFO] 2019-01-19 13:19:19,328 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 12 (MapPartitionsRDD[56] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:19:19,329 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19 stored as values in memory (estimated size 39.9 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:19:19,331 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:19:19,332 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_19_piece0 in memory on 192.168.99.1:57658 (size: 12.5 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:19:19,333 org.apache.spark.SparkContext logInfo - Created broadcast 19 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:19,333 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[56] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,333 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 12.0 with 1 tasks
[INFO] 2019-01-19 13:19:19,333 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 13 (MapPartitionsRDD[51] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:19:19,334 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20 stored as values in memory (estimated size 39.9 KB, free 1988.8 MB)
[INFO] 2019-01-19 13:19:19,336 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1988.8 MB)
[INFO] 2019-01-19 13:19:19,337 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 12.0 (TID 411, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 13:19:19,337 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_20_piece0 in memory on 192.168.99.1:57658 (size: 12.5 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:19:19,337 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 12.0 (TID 411)
[INFO] 2019-01-19 13:19:19,338 org.apache.spark.SparkContext logInfo - Created broadcast 20 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:19,338 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[51] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,338 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 13.0 with 1 tasks
[INFO] 2019-01-19 13:19:19,358 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 13.0 (TID 412, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 13:19:19,359 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 13.0 (TID 412)
[INFO] 2019-01-19 13:19:19,359 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:19,361 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:19,371 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:19:19,372 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:19:19,473 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 12.0 (TID 411). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:19:19,473 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 12.0 (TID 411) in 137 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:19,473 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:19,473 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 12 (rdd at DecoupJson.scala:146) finished in 0.140 s
[INFO] 2019-01-19 13:19:19,474 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:19,474 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 13)
[INFO] 2019-01-19 13:19:19,474 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15, ShuffleMapStage 14)
[INFO] 2019-01-19 13:19:19,474 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:19,479 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 13.0 (TID 412). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 13.0 (TID 412) in 142 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 13 (rdd at DecoupJson.scala:146) finished in 0.142 s
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15, ShuffleMapStage 14)
[INFO] 2019-01-19 13:19:19,480 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:19,481 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:19:19,483 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21 stored as values in memory (estimated size 139.7 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:19:19,485 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21_piece0 stored as bytes in memory (estimated size 37.1 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:19:19,505 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_21_piece0 in memory on 192.168.99.1:57658 (size: 37.1 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:19:19,508 org.apache.spark.SparkContext logInfo - Created broadcast 21 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:19,508 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:19,508 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 14.0 with 2 tasks
[INFO] 2019-01-19 13:19:19,509 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 14.0 (TID 413, localhost, executor driver, partition 0, ANY, 5967 bytes)
[INFO] 2019-01-19 13:19:19,509 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 14.0 (TID 414, localhost, executor driver, partition 1, ANY, 5967 bytes)
[INFO] 2019-01-19 13:19:19,510 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 14.0 (TID 413)
[INFO] 2019-01-19 13:19:19,510 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 14.0 (TID 414)
[INFO] 2019-01-19 13:19:19,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:19:19,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:19,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:19:19,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:19,813 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 14.0 (TID 413). 2633 bytes result sent to driver
[INFO] 2019-01-19 13:19:19,814 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 14.0 (TID 413) in 306 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:19:19,967 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 14.0 (TID 414). 2633 bytes result sent to driver
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 14.0 (TID 414) in 458 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 14 (rdd at DecoupJson.scala:146) finished in 0.460 s
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15)
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:19,968 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 15 (MapPartitionsRDD[66] at map at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:19:19,994 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22 stored as values in memory (estimated size 155.4 KB, free 1988.5 MB)
[INFO] 2019-01-19 13:19:20,040 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22_piece0 stored as bytes in memory (estimated size 47.4 KB, free 1988.5 MB)
[INFO] 2019-01-19 13:19:20,041 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_22_piece0 in memory on 192.168.99.1:57658 (size: 47.4 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,043 org.apache.spark.SparkContext logInfo - Created broadcast 22 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:20,043 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[66] at map at DecoupJson.scala:146)
[INFO] 2019-01-19 13:19:20,043 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 15.0 with 1 tasks
[INFO] 2019-01-19 13:19:20,044 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 15.0 (TID 415, localhost, executor driver, partition 0, ANY, 5869 bytes)
[INFO] 2019-01-19 13:19:20,044 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 15.0 (TID 415)
[INFO] 2019-01-19 13:19:20,050 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:20,050 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:20,130 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.182937 ms
[INFO] 2019-01-19 13:19:20,302 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 15.0 (TID 415). 4220 bytes result sent to driver
[INFO] 2019-01-19 13:19:20,303 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 15.0 (TID 415) in 260 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:20,303 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:20,303 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 15 (first at DecoupJson.scala:146) finished in 0.254 s
[INFO] 2019-01-19 13:19:20,304 org.apache.spark.scheduler.DAGScheduler logInfo - Job 5 finished: first at DecoupJson.scala:146, took 0.979506 s
[INFO] 2019-01-19 13:19:20,393 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:20,394 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:19:20,394 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:19:20,398 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:19:20,398 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:20,400 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:19:20,400 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:19:20,400 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:19:20,463 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.116932 ms
[INFO] 2019-01-19 13:19:20,467 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 2.836098 ms
[INFO] 2019-01-19 13:19:20,482 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 4.293465 ms
[INFO] 2019-01-19 13:19:20,492 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.551646 ms
[INFO] 2019-01-19 13:19:20,497 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23 stored as values in memory (estimated size 278.7 KB, free 1988.2 MB)
[INFO] 2019-01-19 13:19:20,524 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1988.2 MB)
[INFO] 2019-01-19 13:19:20,525 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_23_piece0 in memory on 192.168.99.1:57658 (size: 23.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,527 org.apache.spark.SparkContext logInfo - Created broadcast 23 from count at DecoupJson.scala:75
[INFO] 2019-01-19 13:19:20,527 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:20,549 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 8.060473 ms
[INFO] 2019-01-19 13:19:20,554 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24 stored as values in memory (estimated size 278.7 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:19:20,570 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:19:20,571 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_24_piece0 in memory on 192.168.99.1:57658 (size: 23.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,571 org.apache.spark.SparkContext logInfo - Created broadcast 24 from count at DecoupJson.scala:75
[INFO] 2019-01-19 13:19:20,573 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:20,602 org.apache.spark.SparkContext logInfo - Starting job: count at DecoupJson.scala:75
[INFO] 2019-01-19 13:19:20,602 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 76 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,602 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 71 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,603 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 81 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,603 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 6 (count at DecoupJson.scala:75) with 1 output partitions
[INFO] 2019-01-19 13:19:20,603 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 19 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,603 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 18)
[INFO] 2019-01-19 13:19:20,603 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 18)
[INFO] 2019-01-19 13:19:20,603 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 16 (MapPartitionsRDD[76] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:19:20,604 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25 stored as values in memory (estimated size 12.2 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:19:20,606 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:19:20,607 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_25_piece0 in memory on 192.168.99.1:57658 (size: 5.9 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,607 org.apache.spark.SparkContext logInfo - Created broadcast 25 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:20,607 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[76] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,607 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 16.0 with 1 tasks
[INFO] 2019-01-19 13:19:20,608 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 17 (MapPartitionsRDD[71] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:19:20,609 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26 stored as values in memory (estimated size 12.2 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:19:20,611 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:19:20,611 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 16.0 (TID 416, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:19:20,612 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 16.0 (TID 416)
[INFO] 2019-01-19 13:19:20,612 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_26_piece0 in memory on 192.168.99.1:57658 (size: 5.9 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,612 org.apache.spark.SparkContext logInfo - Created broadcast 26 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:20,613 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[71] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,613 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 17.0 with 1 tasks
[INFO] 2019-01-19 13:19:20,614 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 17.0 (TID 417, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:19:20,614 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 17.0 (TID 417)
[INFO] 2019-01-19 13:19:20,615 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:20,619 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:20,625 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:19:20,627 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:19:20,655 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 17.0 (TID 417). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:19:20,657 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 17.0 (TID 417) in 44 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:20,657 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 17.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:20,658 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 17 (count at DecoupJson.scala:75) finished in 0.045 s
[INFO] 2019-01-19 13:19:20,658 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:20,658 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 16)
[INFO] 2019-01-19 13:19:20,658 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 19, ShuffleMapStage 18)
[INFO] 2019-01-19 13:19:20,658 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 16.0 (TID 416). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 16.0 (TID 416) in 54 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 16.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 16 (count at DecoupJson.scala:75) finished in 0.054 s
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 19, ShuffleMapStage 18)
[INFO] 2019-01-19 13:19:20,662 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:20,663 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 18 (MapPartitionsRDD[81] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:19:20,665 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27 stored as values in memory (estimated size 39.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:19:20,666 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:19:20,667 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_27_piece0 in memory on 192.168.99.1:57658 (size: 13.6 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,668 org.apache.spark.SparkContext logInfo - Created broadcast 27 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:20,668 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[81] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,668 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 18.0 with 2 tasks
[INFO] 2019-01-19 13:19:20,669 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 18.0 (TID 418, localhost, executor driver, partition 0, ANY, 5998 bytes)
[INFO] 2019-01-19 13:19:20,669 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 18.0 (TID 419, localhost, executor driver, partition 1, ANY, 5998 bytes)
[INFO] 2019-01-19 13:19:20,669 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 18.0 (TID 418)
[INFO] 2019-01-19 13:19:20,669 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 18.0 (TID 419)
[INFO] 2019-01-19 13:19:20,671 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:19:20,671 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:20,671 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:19:20,672 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:20,686 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 18.0 (TID 418). 2734 bytes result sent to driver
[INFO] 2019-01-19 13:19:20,686 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 18.0 (TID 418) in 18 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:19:20,693 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 18.0 (TID 419). 2813 bytes result sent to driver
[INFO] 2019-01-19 13:19:20,693 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 18.0 (TID 419) in 24 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 18.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 18 (count at DecoupJson.scala:75) finished in 0.026 s
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 19)
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:20,694 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 19 (MapPartitionsRDD[84] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:19:20,695 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:19:20,696 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:19:20,697 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_28_piece0 in memory on 192.168.99.1:57658 (size: 3.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:19:20,697 org.apache.spark.SparkContext logInfo - Created broadcast 28 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:20,697 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[84] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:19:20,698 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 19.0 with 1 tasks
[INFO] 2019-01-19 13:19:20,698 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 19.0 (TID 420, localhost, executor driver, partition 0, ANY, 5900 bytes)
[INFO] 2019-01-19 13:19:20,698 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 19.0 (TID 420)
[INFO] 2019-01-19 13:19:20,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:20,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:20,701 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 19.0 (TID 420). 1873 bytes result sent to driver
[INFO] 2019-01-19 13:19:20,701 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 19.0 (TID 420) in 3 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:20,702 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 19.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:20,702 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 19 (count at DecoupJson.scala:75) finished in 0.004 s
[INFO] 2019-01-19 13:19:20,702 org.apache.spark.scheduler.DAGScheduler logInfo - Job 6 finished: count at DecoupJson.scala:75, took 0.099605 s
[INFO] 2019-01-19 13:19:20,730 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:20,731 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:19:20,732 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:19:20,732 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:19:20,733 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:20,734 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:19:20,734 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:19:20,735 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:19:20,762 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.019679 ms
[INFO] 2019-01-19 13:19:20,773 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 8.613024 ms
[INFO] 2019-01-19 13:19:20,803 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.160769 ms
[INFO] 2019-01-19 13:19:20,810 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29 stored as values in memory (estimated size 292.7 KB, free 1987.5 MB)
[INFO] 2019-01-19 13:19:20,829 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.5 MB)
[INFO] 2019-01-19 13:19:20,829 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_29_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:19:20,830 org.apache.spark.SparkContext logInfo - Created broadcast 29 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 13:19:20,831 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:20,853 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.782345 ms
[INFO] 2019-01-19 13:19:20,858 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30 stored as values in memory (estimated size 292.7 KB, free 1987.2 MB)
[INFO] 2019-01-19 13:19:20,874 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.2 MB)
[INFO] 2019-01-19 13:19:20,875 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_30_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:19:20,876 org.apache.spark.SparkContext logInfo - Created broadcast 30 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 13:19:20,877 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:20,904 org.apache.spark.SparkContext logInfo - Starting job: collect at DecoupJson.scala:95
[INFO] 2019-01-19 13:19:20,905 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 93 (rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:19:20,905 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 7 (collect at DecoupJson.scala:95) with 1 output partitions
[INFO] 2019-01-19 13:19:20,905 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 21 (collect at DecoupJson.scala:95)
[INFO] 2019-01-19 13:19:20,906 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 20)
[INFO] 2019-01-19 13:19:20,906 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 20)
[INFO] 2019-01-19 13:19:20,906 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 20 (MapPartitionsRDD[93] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 13:19:20,908 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31 stored as values in memory (estimated size 123.7 KB, free 1987.0 MB)
[INFO] 2019-01-19 13:19:20,909 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1987.0 MB)
[INFO] 2019-01-19 13:19:20,910 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_31_piece0 in memory on 192.168.99.1:57658 (size: 32.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:19:20,910 org.apache.spark.SparkContext logInfo - Created broadcast 31 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:20,911 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[93] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:19:20,911 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 20.0 with 2 tasks
[INFO] 2019-01-19 13:19:20,912 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 20.0 (TID 421, localhost, executor driver, partition 0, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 13:19:20,912 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 20.0 (TID 422, localhost, executor driver, partition 1, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 13:19:20,912 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 20.0 (TID 421)
[INFO] 2019-01-19 13:19:20,912 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 20.0 (TID 422)
[INFO] 2019-01-19 13:19:20,920 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:20,920 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:20,927 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:19:20,950 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:19:21,029 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 20.0 (TID 421). 2545 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,030 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 20.0 (TID 421) in 119 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:19:21,034 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 20.0 (TID 422). 2545 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 20.0 (TID 422) in 123 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 20.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 20 (rdd at DecoupJson.scala:95) finished in 0.124 s
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 21)
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:21,035 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 21 (MapPartitionsRDD[97] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 13:19:21,038 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_32 stored as values in memory (estimated size 65.9 KB, free 1986.9 MB)
[INFO] 2019-01-19 13:19:21,044 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_32_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1986.9 MB)
[INFO] 2019-01-19 13:19:21,046 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_32_piece0 in memory on 192.168.99.1:57658 (size: 21.2 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:19:21,046 org.apache.spark.SparkContext logInfo - Created broadcast 32 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:21,047 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[97] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:19:21,047 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 21.0 with 1 tasks
[INFO] 2019-01-19 13:19:21,048 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 21.0 (TID 423, localhost, executor driver, partition 0, ANY, 5871 bytes)
[INFO] 2019-01-19 13:19:21,048 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 21.0 (TID 423)
[INFO] 2019-01-19 13:19:21,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:19:21,052 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:19:21,067 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.174786 ms
[INFO] 2019-01-19 13:19:21,072 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 21.0 (TID 423). 7272 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,073 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 21.0 (TID 423) in 26 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:21,073 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 21.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:21,073 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 21 (collect at DecoupJson.scala:95) finished in 0.026 s
[INFO] 2019-01-19 13:19:21,074 org.apache.spark.scheduler.DAGScheduler logInfo - Job 7 finished: collect at DecoupJson.scala:95, took 0.169383 s
[INFO] 2019-01-19 13:19:21,100 myLogger setOutputDataTable - outputPath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train22
[INFO] 2019-01-19 13:19:21,172 org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat logInfo - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,196 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:21,197 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:19:21,198 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:19:21,198 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:19:21,199 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:19:21,200 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:19:21,201 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:19:21,201 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:19:21,222 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO] 2019-01-19 13:19:21,223 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO] 2019-01-19 13:19:21,223 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO] 2019-01-19 13:19:21,224 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO] 2019-01-19 13:19:21,224 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO] 2019-01-19 13:19:21,226 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:19:21,227 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,227 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:19:21,229 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,249 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_33 stored as values in memory (estimated size 292.7 KB, free 1986.6 MB)
[INFO] 2019-01-19 13:19:21,261 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_33_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1986.6 MB)
[INFO] 2019-01-19 13:19:21,262 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_33_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:19:21,263 org.apache.spark.SparkContext logInfo - Created broadcast 33 from save at DecoupJson.scala:166
[INFO] 2019-01-19 13:19:21,263 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:21,286 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_34 stored as values in memory (estimated size 292.7 KB, free 1986.3 MB)
[INFO] 2019-01-19 13:19:21,297 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_34_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1986.3 MB)
[INFO] 2019-01-19 13:19:21,298 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_34_piece0 in memory on 192.168.99.1:57658 (size: 25.4 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:19:21,298 org.apache.spark.SparkContext logInfo - Created broadcast 34 from save at DecoupJson.scala:166
[INFO] 2019-01-19 13:19:21,299 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:19:21,334 org.apache.spark.SparkContext logInfo - Starting job: save at DecoupJson.scala:166
[INFO] 2019-01-19 13:19:21,335 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 106 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:19:21,335 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 101 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:19:21,335 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 8 (save at DecoupJson.scala:166) with 2 output partitions
[INFO] 2019-01-19 13:19:21,335 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 24 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:19:21,335 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 22, ShuffleMapStage 23)
[INFO] 2019-01-19 13:19:21,335 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 22, ShuffleMapStage 23)
[INFO] 2019-01-19 13:19:21,336 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 22 (MapPartitionsRDD[106] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:19:21,337 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_35 stored as values in memory (estimated size 39.9 KB, free 1986.3 MB)
[INFO] 2019-01-19 13:19:21,339 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_35_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1986.2 MB)
[INFO] 2019-01-19 13:19:21,339 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_35_piece0 in memory on 192.168.99.1:57658 (size: 12.5 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:19:21,339 org.apache.spark.SparkContext logInfo - Created broadcast 35 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:21,339 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[106] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:19:21,339 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 22.0 with 1 tasks
[INFO] 2019-01-19 13:19:21,340 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 23 (MapPartitionsRDD[101] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:19:21,341 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 22.0 (TID 424, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 13:19:21,341 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 22.0 (TID 424)
[INFO] 2019-01-19 13:19:21,343 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_36 stored as values in memory (estimated size 39.9 KB, free 1986.2 MB)
[INFO] 2019-01-19 13:19:21,344 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1986.2 MB)
[INFO] 2019-01-19 13:19:21,344 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_36_piece0 in memory on 192.168.99.1:57658 (size: 12.5 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:19:21,345 org.apache.spark.SparkContext logInfo - Created broadcast 36 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:21,345 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:21,345 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[101] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:19:21,345 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 23.0 with 1 tasks
[INFO] 2019-01-19 13:19:21,346 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 23.0 (TID 425, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 13:19:21,347 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 23.0 (TID 425)
[INFO] 2019-01-19 13:19:21,350 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:19:21,354 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:19:21,357 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:19:21,466 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 22.0 (TID 424). 2099 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,467 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 22.0 (TID 424) in 127 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:21,467 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 22.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:21,468 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 22 (save at DecoupJson.scala:166) finished in 0.128 s
[INFO] 2019-01-19 13:19:21,468 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:21,468 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 23)
[INFO] 2019-01-19 13:19:21,468 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 24)
[INFO] 2019-01-19 13:19:21,468 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:21,473 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 23.0 (TID 425). 2009 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 23.0 (TID 425) in 130 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:19:21,476 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 23.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:21,477 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 23 (save at DecoupJson.scala:166) finished in 0.130 s
[INFO] 2019-01-19 13:19:21,477 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:19:21,477 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:19:21,477 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 24)
[INFO] 2019-01-19 13:19:21,477 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:19:21,477 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 24 (UnionRDD[109] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:19:21,494 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_37 stored as values in memory (estimated size 140.7 KB, free 1986.1 MB)
[INFO] 2019-01-19 13:19:21,496 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_37_piece0 stored as bytes in memory (estimated size 41.7 KB, free 1986.0 MB)
[INFO] 2019-01-19 13:19:21,496 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_37_piece0 in memory on 192.168.99.1:57658 (size: 41.7 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:19:21,497 org.apache.spark.SparkContext logInfo - Created broadcast 37 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:19:21,498 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ResultStage 24 (UnionRDD[109] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:19:21,498 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 24.0 with 2 tasks
[INFO] 2019-01-19 13:19:21,499 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 24.0 (TID 426, localhost, executor driver, partition 0, ANY, 6017 bytes)
[INFO] 2019-01-19 13:19:21,499 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 24.0 (TID 427, localhost, executor driver, partition 1, ANY, 6017 bytes)
[INFO] 2019-01-19 13:19:21,499 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 24.0 (TID 426)
[INFO] 2019-01-19 13:19:21,500 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 24.0 (TID 427)
[INFO] 2019-01-19 13:19:21,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:19:21,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:21,516 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:19:21,516 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:19:21,516 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:19:21,517 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,518 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:19:21,518 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:19:21,521 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,521 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:19:21,522 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,525 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:19:21,528 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:19:21,519 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:19:21,543 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:19:21,547 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 13:19:21,551 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 13:19:21,552 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 13:19:21,552 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 13:19:21,567 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 13:19:21,580 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 13:19:21,581 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 13:19:21,581 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 13:19:21,581 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 13:19:21,582 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 13:19:21,582 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 13:19:21,582 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 13:19:21,582 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 13:19:21,582 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 13:19:21,582 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 13:19:21,586 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 13:19:21,605 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 13:19:21,605 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 13:19:21,703 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 30,263
[INFO] 2019-01-19 13:19:21,707 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 32,866
[INFO] 2019-01-19 13:19:21,771 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 174B for [crm_cust_no] BINARY: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 57 entries, 1,653B raw, 57B comp}
[INFO] 2019-01-19 13:19:21,771 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [stat_mth] INT32: 111 values, 65B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:19:21,772 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [ast_curr_bal] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 52 entries, 416B raw, 52B comp}
[INFO] 2019-01-19 13:19:21,772 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [std_cred_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 688B raw, 86B comp}
[INFO] 2019-01-19 13:19:21,773 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:19:21,773 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [std_cred_bill_amt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 688B raw, 86B comp}
[INFO] 2019-01-19 13:19:21,773 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 97B for [ln_curr_bal] DOUBLE: 111 values, 53B raw, 55B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 128B raw, 16B comp}
[INFO] 2019-01-19 13:19:21,774 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 108B for [l3m_ln_davg_bal] DOUBLE: 111 values, 62B raw, 65B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 152B raw, 19B comp}
[INFO] 2019-01-19 13:19:21,774 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 124B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 79B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 184B raw, 23B comp}
[INFO] 2019-01-19 13:19:21,775 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 63 entries, 798B raw, 63B comp}
[INFO] 2019-01-19 13:19:21,776 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 64B for [std_cred_auto_repay_flag] INT32: 111 values, 28B raw, 30B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:19:21,776 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 146B for [std_cred_1st_biz_days] INT32: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 332B raw, 83B comp}
[INFO] 2019-01-19 13:19:21,776 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_lst_biz_days] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 64B raw, 16B comp}
[INFO] 2019-01-19 13:19:21,777 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 63B for [std_cred_1stbiz_op_days] BINARY: 111 values, 31B raw, 33B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 31B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,777 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 30B raw, 32B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,780 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l3m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 79 entries, 632B raw, 79B comp}
[INFO] 2019-01-19 13:19:21,781 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l6m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 82 entries, 656B raw, 82B comp}
[INFO] 2019-01-19 13:19:21,781 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l12m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 664B raw, 83B comp}
[INFO] 2019-01-19 13:19:21,781 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [l3m_ln_ovd_days_bm] INT32: 111 values, 32B raw, 34B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,782 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 71B for [l12m_ln_ovd_days_bm] INT32: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:19:21,782 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 65B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 29B raw, 31B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 13:19:21,782 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,782 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 71B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,783 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,784 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [nty] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 13:19:21,784 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 35B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,801 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 58B raw, 10B comp}
[INFO] 2019-01-19 13:19:21,802 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [yg_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,802 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,802 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [house_stt] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 13:19:21,800 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 1,520B for [crm_cust_no] BINARY: 111 values, 3,226B raw, 1,442B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:19:21,803 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 102B for [stat_mth] INT32: 111 values, 65B raw, 66B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:19:21,803 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 81B for [work_years] INT32: 111 values, 45B raw, 47B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,803 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [ast_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 96 entries, 768B raw, 96B comp}
[INFO] 2019-01-19 13:19:21,803 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 768B for [std_cred_curr_bal] DOUBLE: 111 values, 895B raw, 724B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:19:21,804 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:19:21,804 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 751B for [std_cred_bill_amt] DOUBLE: 111 values, 895B raw, 707B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:19:21,804 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [ln_curr_bal] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 13:19:21,804 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_ln_davg_bal] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 30 entries, 240B raw, 30B comp}
[INFO] 2019-01-19 13:19:21,805 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 43 entries, 344B raw, 43B comp}
[INFO] 2019-01-19 13:19:21,805 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 66B for [unit_kind] BINARY: 111 values, 29B raw, 31B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 16B raw, 2B comp}
[INFO] 2019-01-19 13:19:21,805 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [title] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 13:19:21,805 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 75B for [occp] BINARY: 111 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 59B raw, 7B comp}
[INFO] 2019-01-19 13:19:21,806 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,806 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 78B for [idy] BINARY: 111 values, 46B raw, 48B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 42B raw, 7B comp}
[INFO] 2019-01-19 13:19:21,806 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 136B raw, 17B comp}
[INFO] 2019-01-19 13:19:21,807 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [cp_y_income] BINARY: 111 values, 53B raw, 55B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 86B raw, 11B comp}
[INFO] 2019-01-19 13:19:21,807 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 115B for [zx_max_lns] INT32: 111 values, 79B raw, 79B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 13:19:21,805 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 147B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 89 entries, 1,151B raw, 89B comp}
[INFO] 2019-01-19 13:19:21,807 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 60B for [std_cred_auto_repay_flag] INT32: 111 values, 24B raw, 26B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:19:21,807 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 489B for [std_cred_1st_biz_days] INT32: 111 values, 451B raw, 453B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:19:21,808 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [std_cred_lst_biz_days] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 13:19:21,808 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 13:19:21,808 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 91B for [std_cred_1stbiz_op_days] BINARY: 111 values, 59B raw, 59B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 103B raw, 16B comp}
[INFO] 2019-01-19 13:19:21,808 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 76B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 32B raw, 34B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,809 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_std_cred_znamt] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 13:19:21,809 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 137B for [l6m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 93B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 38 entries, 304B raw, 38B comp}
[INFO] 2019-01-19 13:19:21,809 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l12m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 54 entries, 432B raw, 54B comp}
[INFO] 2019-01-19 13:19:21,809 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l3m_ln_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,810 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,810 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,810 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,810 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,811 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,811 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [nty] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 13:19:21,811 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 30B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,811 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 59B raw, 10B comp}
[INFO] 2019-01-19 13:19:21,811 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [yg_flag] BINARY: 111 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 11B raw, 2B comp}
[INFO] 2019-01-19 13:19:21,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:19:21,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [house_stt] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 16B raw, 3B comp}
[INFO] 2019-01-19 13:19:21,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [work_years] INT32: 111 values, 62B raw, 62B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 13:19:21,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 103B for [zx_max_ovd_lns] INT32: 111 values, 64B raw, 67B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:19:21,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 72B for [unit_kind] BINARY: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 32B raw, 4B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [title] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 116B for [zx_ln_max_ovd_amt] INT32: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 30 entries, 120B raw, 30B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 90B for [occp] BINARY: 111 values, 56B raw, 58B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 163B raw, 19B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 116B for [zx_ln_tot_ovd_mths] INT32: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 76B raw, 19B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 113B for [idy] BINARY: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 135B raw, 23B comp}
[INFO] 2019-01-19 13:19:21,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 27 entries, 216B raw, 27B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 99B for [zx_max_creds] INT32: 111 values, 61B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 111B for [cp_y_income] BINARY: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 160B raw, 19B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 86B for [zx_max_cred_banks] INT32: 111 values, 50B raw, 52B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 15 entries, 60B raw, 15B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:19:21,815 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ovd_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:19:21,815 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 129B for [zx_ln_max_ovd_amt] INT32: 111 values, 90B raw, 93B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 42 entries, 168B raw, 42B comp}
[INFO] 2019-01-19 13:19:21,815 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [zx_ln_tot_ovd_mths] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 92B raw, 23B comp}
[INFO] 2019-01-19 13:19:21,815 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,814 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:19:21,815 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_creds] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:19:21,815 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [zx_cred_max_ovd_amt] INT64: 111 values, 53B raw, 54B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 14 entries, 112B raw, 14B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_cred_banks] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 93B for [zx_cred_tot_ovd_mths] INT32: 111 values, 57B raw, 59B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 48B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 99B for [zx_cred_max_ovd_amt] INT64: 111 values, 58B raw, 57B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 12 entries, 96B raw, 12B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [zx_cred_tot_ovd_mths] INT32: 111 values, 48B raw, 50B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [zx_cred_max_ovd_duration] INT32: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 13:19:21,816 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_cred_max_ovd_duration] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:19:21,832 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119131921_0024_m_000001_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119131921_0024_m_000001
[INFO] 2019-01-19 13:19:21,833 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119131921_0024_m_000001_0: Committed
[INFO] 2019-01-19 13:19:21,835 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 24.0 (TID 427). 2379 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,836 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 24.0 (TID 427) in 337 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:19:21,838 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119131921_0024_m_000000_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119131921_0024_m_000000
[INFO] 2019-01-19 13:19:21,838 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119131921_0024_m_000000_0: Committed
[INFO] 2019-01-19 13:19:21,839 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 24.0 (TID 426). 2202 bytes result sent to driver
[INFO] 2019-01-19 13:19:21,839 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 24.0 (TID 426) in 341 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:19:21,840 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 24.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:19:21,840 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 24 (save at DecoupJson.scala:166) finished in 0.342 s
[INFO] 2019-01-19 13:19:21,840 org.apache.spark.scheduler.DAGScheduler logInfo - Job 8 finished: save at DecoupJson.scala:166, took 0.506430 s
[WARN] 2019-01-19 13:19:21,859 org.apache.parquet.hadoop.ParquetOutputFormat warn - Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level
[INFO] 2019-01-19 13:19:21,862 org.apache.spark.sql.execution.datasources.FileFormatWriter logInfo - Job null committed.
[INFO] 2019-01-19 13:19:21,884 myLogger setOutputDataTable - summaryFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\summary
[INFO] 2019-01-19 13:19:21,886 myLogger main - LayerSample end
[INFO] 2019-01-19 13:19:21,889 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 13:19:21,904 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 13:19:21,937 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[ERROR] 2019-01-19 13:19:22,709 org.apache.spark.storage.DiskBlockManager logError - Exception while deleting local spark dir: C:\Users\dell\AppData\Local\Temp\blockmgr-5960ed9e-261b-4fe6-98f5-e89d92986d99
java.io.IOException: Failed to delete: C:\Users\dell\AppData\Local\Temp\blockmgr-5960ed9e-261b-4fe6-98f5-e89d92986d99
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:169)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:165)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:165)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:160)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1361)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:89)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
[INFO] 2019-01-19 13:19:22,713 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 13:19:22,714 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 13:19:22,714 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 13:19:22,717 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 13:19:22,722 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 13:19:22,723 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 13:19:22,724 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-6f699ab8-7e98-48ea-b6de-9b060f2d78ca
[INFO] 2019-01-19 13:26:13,298 myLogger main - LayerSample start
[INFO] 2019-01-19 13:26:14,005 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 13:26:14,506 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 13:26:14,508 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 13:26:14,508 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 13:26:14,593 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 13:26:14,594 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 13:26:14,594 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 13:26:14,595 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 13:26:14,597 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 13:26:15,531 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 57804.
[INFO] 2019-01-19 13:26:15,563 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 13:26:15,599 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 13:26:15,605 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 13:26:15,606 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 13:26:15,626 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-51fefe21-3304-447d-9c65-19f40f086753
[INFO] 2019-01-19 13:26:15,660 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 13:26:15,717 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 13:26:16,016 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 13:26:16,019 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 13:26:16,173 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 13:26:16,239 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57817.
[INFO] 2019-01-19 13:26:16,241 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:57817
[INFO] 2019-01-19 13:26:16,243 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 13:26:16,246 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 57817, None)
[INFO] 2019-01-19 13:26:16,251 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:57817 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 57817, None)
[INFO] 2019-01-19 13:26:16,256 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 57817, None)
[INFO] 2019-01-19 13:26:16,257 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 57817, None)
[INFO] 2019-01-19 13:26:16,650 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 13:26:17,079 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 13:26:17,901 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 13:26:17,932 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 13:26:17,933 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:26:17,933 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:26:17,936 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:26:17,947 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 13:26:18,147 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:26:18,229 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:26:18,233 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:57817 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:26:18,237 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:18,243 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:26:18,246 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 13:26:18,326 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 13:26:18,343 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 13:26:18,483 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 13:26:18,658 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 13:26:18,672 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 389 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:18,674 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:18,678 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.416 s
[INFO] 2019-01-19 13:26:18,685 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.785114 s
[INFO] 2019-01-19 13:26:19,169 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:57817 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:26:31,174 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:31,179 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 13:26:31,182 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:26:31,183 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 13:26:31,251 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 13:26:31,623 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 291.425623 ms
[INFO] 2019-01-19 13:26:31,628 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 13:26:31,675 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 37.354836 ms
[INFO] 2019-01-19 13:26:31,715 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 278.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:26:31,729 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:26:31,730 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:26:31,732 org.apache.spark.SparkContext logInfo - Created broadcast 1 from rdd at LayerSample.scala:49
[INFO] 2019-01-19 13:26:31,749 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:31,947 org.apache.spark.SparkContext logInfo - Starting job: collect at LayerSample.scala:49
[INFO] 2019-01-19 13:26:31,952 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 6 (rdd at LayerSample.scala:49)
[INFO] 2019-01-19 13:26:31,954 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at LayerSample.scala:49) with 200 output partitions
[INFO] 2019-01-19 13:26:31,954 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 2 (collect at LayerSample.scala:49)
[INFO] 2019-01-19 13:26:31,954 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 1)
[INFO] 2019-01-19 13:26:31,955 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 1)
[INFO] 2019-01-19 13:26:31,956 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at rdd at LayerSample.scala:49), which has no missing parents
[INFO] 2019-01-19 13:26:31,970 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2 stored as values in memory (estimated size 17.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:26:31,973 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:26:31,975 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_2_piece0 in memory on 192.168.99.1:57817 (size: 8.0 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:26:31,976 org.apache.spark.SparkContext logInfo - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:31,978 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at rdd at LayerSample.scala:49)
[INFO] 2019-01-19 13:26:31,979 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2019-01-19 13:26:31,987 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6622 bytes)
[INFO] 2019-01-19 13:26:31,988 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2019-01-19 13:26:32,027 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.098664 ms
[INFO] 2019-01-19 13:26:32,044 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.593212 ms
[INFO] 2019-01-19 13:26:32,054 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 6.996627 ms
[INFO] 2019-01-19 13:26:32,071 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:32,184 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 13:26:32,684 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 2527 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,688 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 709 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:32,688 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:32,689 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 1 (rdd at LayerSample.scala:49) finished in 0.710 s
[INFO] 2019-01-19 13:26:32,690 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:26:32,691 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:26:32,692 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 2)
[INFO] 2019-01-19 13:26:32,693 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:26:32,699 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 2 (MapPartitionsRDD[11] at map at LayerSample.scala:49), which has no missing parents
[INFO] 2019-01-19 13:26:32,716 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3 stored as values in memory (estimated size 19.5 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:26:32,719 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:26:32,720 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_3_piece0 in memory on 192.168.99.1:57817 (size: 9.4 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:26:32,720 org.apache.spark.SparkContext logInfo - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:32,721 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at map at LayerSample.scala:49)
[INFO] 2019-01-19 13:26:32,722 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 2.0 with 200 tasks
[INFO] 2019-01-19 13:26:32,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,730 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,730 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 2.0 (TID 2)
[INFO] 2019-01-19 13:26:32,746 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 2.0 (TID 3)
[INFO] 2019-01-19 13:26:32,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,759 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,762 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 14 ms
[INFO] 2019-01-19 13:26:32,762 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 8 ms
[INFO] 2019-01-19 13:26:32,790 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.263976 ms
[INFO] 2019-01-19 13:26:32,805 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 2.0 (TID 3). 2826 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,805 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 2.0 (TID 2). 2826 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,806 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,807 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 2.0 (TID 4)
[INFO] 2019-01-19 13:26:32,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,809 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 2.0 (TID 5)
[INFO] 2019-01-19 13:26:32,815 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,815 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,815 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,815 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:32,819 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 2.0 (TID 5). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,822 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 2.0 (TID 4). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,823 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 2.0 (TID 6)
[INFO] 2019-01-19 13:26:32,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 2.0 (TID 5) in 15 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 13:26:32,826 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,827 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:32,827 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,830 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 2.0 (TID 4) in 24 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 13:26:32,831 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 2.0 (TID 6). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,831 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 2.0 (TID 7)
[INFO] 2019-01-19 13:26:32,832 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,833 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 2.0 (TID 6) in 13 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 13:26:32,835 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,835 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,835 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 2.0 (TID 8)
[INFO] 2019-01-19 13:26:32,841 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,841 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,843 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 2.0 (TID 3) in 114 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 13:26:32,846 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 2.0 (TID 8). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,848 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 2.0 (TID 2) in 121 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 13:26:32,846 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 2.0 (TID 7). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,850 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 2.0 (TID 9)
[INFO] 2019-01-19 13:26:32,851 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,852 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 2.0 (TID 7) in 27 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 13:26:32,854 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,855 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:32,855 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 2.0 (TID 10)
[INFO] 2019-01-19 13:26:32,855 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 2.0 (TID 8) in 23 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 13:26:32,861 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,862 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:32,865 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 2.0 (TID 10). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,866 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,867 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 2.0 (TID 10) in 17 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 13:26:32,867 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 2.0 (TID 11)
[INFO] 2019-01-19 13:26:32,870 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 2.0 (TID 9). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,871 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,871 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 2.0 (TID 12)
[INFO] 2019-01-19 13:26:32,871 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 2.0 (TID 9) in 22 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 13:26:32,875 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,875 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,878 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 2.0 (TID 12). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,880 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,880 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 2.0 (TID 12) in 10 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 13:26:32,880 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 2.0 (TID 13)
[INFO] 2019-01-19 13:26:32,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,898 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 2.0 (TID 13). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,899 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,900 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 2.0 (TID 13) in 21 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 13:26:32,900 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 2.0 (TID 14)
[INFO] 2019-01-19 13:26:32,904 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,904 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,919 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 2.0 (TID 11). 2809 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,920 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 2.0 (TID 14). 2809 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,934 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,935 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 48
[INFO] 2019-01-19 13:26:32,936 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,936 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 2.0 (TID 11) in 71 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 13:26:32,937 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 2.0 (TID 14) in 39 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 13:26:32,937 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 2.0 (TID 15)
[INFO] 2019-01-19 13:26:32,938 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 2.0 (TID 16)
[INFO] 2019-01-19 13:26:32,942 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,942 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,944 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,945 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:32,948 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 2.0 (TID 16). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,945 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 2.0 (TID 15). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,950 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,951 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,954 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 2.0 (TID 16) in 19 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 13:26:32,954 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 2.0 (TID 15) in 28 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 13:26:32,955 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 2.0 (TID 17)
[INFO] 2019-01-19 13:26:32,956 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 2.0 (TID 18)
[INFO] 2019-01-19 13:26:32,958 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_2_piece0 on 192.168.99.1:57817 in memory (size: 8.0 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:26:32,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,963 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 2.0 (TID 18). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,965 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,966 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,966 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,969 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 2.0 (TID 17). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,969 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 2.0 (TID 18) in 18 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 13:26:32,969 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 2.0 (TID 19)
[INFO] 2019-01-19 13:26:32,972 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,975 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,975 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,980 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 2.0 (TID 19). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,984 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:32,985 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 2.0 (TID 17) in 35 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 13:26:32,986 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 2.0 (TID 19) in 22 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 13:26:32,987 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 2.0 (TID 20)
[INFO] 2019-01-19 13:26:32,990 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:32,990 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:32,996 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 2.0 (TID 20). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:32,999 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,003 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 2.0 (TID 21)
[INFO] 2019-01-19 13:26:33,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 2.0 (TID 20) in 35 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 13:26:33,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,007 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 2.0 (TID 22)
[INFO] 2019-01-19 13:26:33,010 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 2.0 (TID 21). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,011 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,014 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 2.0 (TID 22). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,017 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,019 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,021 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 2.0 (TID 21) in 39 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 13:26:33,022 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 2.0 (TID 22) in 23 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 13:26:33,027 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 2.0 (TID 23)
[INFO] 2019-01-19 13:26:33,030 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,030 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,031 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 2.0 (TID 24)
[INFO] 2019-01-19 13:26:33,034 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,034 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,036 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 2.0 (TID 23). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,039 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,039 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 2.0 (TID 23) in 23 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 13:26:33,040 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 2.0 (TID 25)
[INFO] 2019-01-19 13:26:33,046 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,046 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,049 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 2.0 (TID 25). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,051 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,052 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 2.0 (TID 26)
[INFO] 2019-01-19 13:26:33,053 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 2.0 (TID 25) in 16 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 13:26:33,056 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,056 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,088 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 2.0 (TID 24). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,090 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,090 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 2.0 (TID 24) in 71 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 13:26:33,097 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 2.0 (TID 26). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,098 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,099 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 2.0 (TID 26) in 49 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 13:26:33,129 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 2.0 (TID 28)
[INFO] 2019-01-19 13:26:33,145 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,145 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,152 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 2.0 (TID 28). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,154 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,157 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 2.0 (TID 28) in 60 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 13:26:33,157 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 2.0 (TID 29)
[INFO] 2019-01-19 13:26:33,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,164 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 2.0 (TID 29). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,165 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,165 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 2.0 (TID 29) in 12 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 13:26:33,166 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 2.0 (TID 30)
[INFO] 2019-01-19 13:26:33,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,173 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 2.0 (TID 30). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,175 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,176 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 2.0 (TID 30) in 12 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 13:26:33,179 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 2.0 (TID 31)
[INFO] 2019-01-19 13:26:33,182 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,182 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,187 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 2.0 (TID 31). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,189 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,189 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 2.0 (TID 32)
[INFO] 2019-01-19 13:26:33,189 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 2.0 (TID 31) in 15 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 13:26:33,192 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,192 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,194 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 2.0 (TID 32). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,195 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 2.0 (TID 27)
[INFO] 2019-01-19 13:26:33,197 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,198 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 2.0 (TID 32) in 10 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 13:26:33,199 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 2.0 (TID 33)
[INFO] 2019-01-19 13:26:33,201 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,202 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,205 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 2.0 (TID 33). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,207 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,208 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 2.0 (TID 27). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,209 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 2.0 (TID 34)
[INFO] 2019-01-19 13:26:33,208 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 2.0 (TID 33) in 11 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 13:26:33,210 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,211 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 2.0 (TID 27) in 122 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 13:26:33,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,212 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 2.0 (TID 35)
[INFO] 2019-01-19 13:26:33,214 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 2.0 (TID 34). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,217 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,217 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,218 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,218 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 2.0 (TID 34) in 12 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 13:26:33,219 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 2.0 (TID 36)
[INFO] 2019-01-19 13:26:33,220 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 2.0 (TID 35). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,222 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,223 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 2.0 (TID 35) in 13 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 13:26:33,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,223 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 2.0 (TID 37)
[INFO] 2019-01-19 13:26:33,225 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 2.0 (TID 36). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,227 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,227 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,228 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,228 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 2.0 (TID 36) in 12 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 13:26:33,229 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 2.0 (TID 37). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,230 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 2.0 (TID 38)
[INFO] 2019-01-19 13:26:33,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,234 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,234 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 2.0 (TID 37) in 13 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 13:26:33,234 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 2.0 (TID 39)
[INFO] 2019-01-19 13:26:33,236 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 2.0 (TID 38). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,237 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,238 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 2.0 (TID 38) in 12 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 13:26:33,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,239 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 2.0 (TID 40)
[INFO] 2019-01-19 13:26:33,242 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,242 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,243 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 2.0 (TID 39). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,244 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,245 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 2.0 (TID 39) in 13 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 13:26:33,245 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 2.0 (TID 40). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,246 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,246 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 2.0 (TID 41)
[INFO] 2019-01-19 13:26:33,247 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 2.0 (TID 40) in 10 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 13:26:33,247 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 2.0 (TID 42)
[INFO] 2019-01-19 13:26:33,249 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,249 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,249 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,250 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,251 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 2.0 (TID 41). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,252 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,253 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 2.0 (TID 43)
[INFO] 2019-01-19 13:26:33,254 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 2.0 (TID 42). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,253 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 2.0 (TID 41) in 9 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 13:26:33,257 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,257 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 2.0 (TID 42) in 12 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 13:26:33,258 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 2.0 (TID 44)
[INFO] 2019-01-19 13:26:33,261 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,261 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,264 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 2.0 (TID 44). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,265 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 2.0 (TID 45, localhost, executor driver, partition 44, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,267 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 2.0 (TID 44) in 11 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 13:26:33,268 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 2.0 (TID 45)
[INFO] 2019-01-19 13:26:33,271 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,272 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,275 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 2.0 (TID 45). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,275 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 2.0 (TID 46, localhost, executor driver, partition 45, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,276 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 2.0 (TID 45) in 12 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 13:26:33,276 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 2.0 (TID 46)
[INFO] 2019-01-19 13:26:33,278 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,278 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,278 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,278 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,281 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 2.0 (TID 46). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,281 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 2.0 (TID 43). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,282 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 2.0 (TID 47, localhost, executor driver, partition 46, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,282 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 2.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,283 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 2.0 (TID 47)
[INFO] 2019-01-19 13:26:33,283 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 2.0 (TID 43) in 31 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 13:26:33,284 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 2.0 (TID 46) in 9 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 13:26:33,284 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 2.0 (TID 48)
[INFO] 2019-01-19 13:26:33,285 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,286 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,288 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 2.0 (TID 47). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,290 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 2.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,291 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 2.0 (TID 48). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,291 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 2.0 (TID 49)
[INFO] 2019-01-19 13:26:33,291 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 2.0 (TID 47) in 10 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 13:26:33,294 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,294 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,297 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 2.0 (TID 49). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,298 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 2.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,299 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 2.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,300 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 2.0 (TID 49) in 11 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 13:26:33,301 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 2.0 (TID 48) in 19 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 13:26:33,301 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 2.0 (TID 50)
[INFO] 2019-01-19 13:26:33,301 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 2.0 (TID 51)
[INFO] 2019-01-19 13:26:33,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,305 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,308 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,308 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,308 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 2.0 (TID 50). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,310 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 2.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,311 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 2.0 (TID 51). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,311 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 2.0 (TID 52)
[INFO] 2019-01-19 13:26:33,311 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 2.0 (TID 50) in 12 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 13:26:33,313 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 2.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,314 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 2.0 (TID 51) in 15 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 13:26:33,314 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,315 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:26:33,318 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 2.0 (TID 52). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,318 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 2.0 (TID 53)
[INFO] 2019-01-19 13:26:33,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,327 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 2.0 (TID 53). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,327 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 2.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,328 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 2.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,329 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 2.0 (TID 54)
[INFO] 2019-01-19 13:26:33,340 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,340 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,342 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 2.0 (TID 53) in 30 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 13:26:33,343 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 2.0 (TID 52) in 34 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 13:26:33,344 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 2.0 (TID 55)
[INFO] 2019-01-19 13:26:33,344 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 2.0 (TID 54). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,346 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 2.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,348 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 2.0 (TID 54) in 21 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 13:26:33,348 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 2.0 (TID 56)
[INFO] 2019-01-19 13:26:33,349 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 2.0 (TID 55). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,350 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 2.0 (TID 57, localhost, executor driver, partition 56, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,350 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 2.0 (TID 55) in 22 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 13:26:33,350 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 2.0 (TID 57)
[INFO] 2019-01-19 13:26:33,354 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,354 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,355 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,357 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 2.0 (TID 56). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,358 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 2.0 (TID 58, localhost, executor driver, partition 57, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,359 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 2.0 (TID 56) in 13 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 13:26:33,359 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 2.0 (TID 58)
[INFO] 2019-01-19 13:26:33,359 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 2.0 (TID 57). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,361 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 2.0 (TID 59, localhost, executor driver, partition 58, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,362 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 2.0 (TID 59)
[INFO] 2019-01-19 13:26:33,365 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,365 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,366 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 2.0 (TID 58). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,367 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 2.0 (TID 59). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 2.0 (TID 57) in 13 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 13:26:33,368 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 2.0 (TID 60, localhost, executor driver, partition 59, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,369 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 2.0 (TID 60)
[INFO] 2019-01-19 13:26:33,370 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 2.0 (TID 61, localhost, executor driver, partition 60, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,371 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 2.0 (TID 58) in 13 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 13:26:33,371 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 2.0 (TID 61)
[INFO] 2019-01-19 13:26:33,372 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 2.0 (TID 59) in 11 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 13:26:33,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:26:33,374 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,375 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,377 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 2.0 (TID 61). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,378 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 2.0 (TID 62, localhost, executor driver, partition 61, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,379 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 2.0 (TID 61) in 11 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 13:26:33,379 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 2.0 (TID 62)
[INFO] 2019-01-19 13:26:33,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,384 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 2.0 (TID 62). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,385 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 2.0 (TID 63, localhost, executor driver, partition 62, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,385 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 2.0 (TID 62) in 7 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 13:26:33,386 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 2.0 (TID 63)
[INFO] 2019-01-19 13:26:33,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,392 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 2.0 (TID 63). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,393 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 2.0 (TID 64, localhost, executor driver, partition 63, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,393 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 2.0 (TID 64)
[INFO] 2019-01-19 13:26:33,393 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 2.0 (TID 63) in 8 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 13:26:33,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,415 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 2.0 (TID 64). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,415 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 2.0 (TID 65, localhost, executor driver, partition 64, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,416 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 2.0 (TID 65)
[INFO] 2019-01-19 13:26:33,417 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 2.0 (TID 64) in 24 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 13:26:33,419 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 2.0 (TID 60). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,420 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 2.0 (TID 66, localhost, executor driver, partition 65, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,420 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 2.0 (TID 66)
[INFO] 2019-01-19 13:26:33,420 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 2.0 (TID 60) in 52 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 13:26:33,423 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,423 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,425 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 2.0 (TID 66). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,426 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 2.0 (TID 67, localhost, executor driver, partition 66, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,426 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 2.0 (TID 67)
[INFO] 2019-01-19 13:26:33,426 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 2.0 (TID 66) in 7 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 13:26:33,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,432 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 2.0 (TID 67). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,433 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 2.0 (TID 68, localhost, executor driver, partition 67, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,434 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 2.0 (TID 68)
[INFO] 2019-01-19 13:26:33,434 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 2.0 (TID 67) in 9 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 13:26:33,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,439 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 2.0 (TID 68). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,440 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 2.0 (TID 69, localhost, executor driver, partition 68, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,440 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 2.0 (TID 69)
[INFO] 2019-01-19 13:26:33,440 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 2.0 (TID 68) in 8 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 13:26:33,443 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,443 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,443 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,445 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 2.0 (TID 69). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,445 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 2.0 (TID 70, localhost, executor driver, partition 69, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,446 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 2.0 (TID 69) in 7 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 13:26:33,446 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 2.0 (TID 70)
[INFO] 2019-01-19 13:26:33,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,450 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 2.0 (TID 65). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,450 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 2.0 (TID 70). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,451 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 2.0 (TID 71, localhost, executor driver, partition 70, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,451 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 2.0 (TID 71)
[INFO] 2019-01-19 13:26:33,452 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 2.0 (TID 72, localhost, executor driver, partition 71, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,453 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 2.0 (TID 65) in 38 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 13:26:33,453 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 2.0 (TID 72)
[INFO] 2019-01-19 13:26:33,454 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 2.0 (TID 70) in 9 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 13:26:33,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,458 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 2.0 (TID 72). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,459 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 2.0 (TID 73, localhost, executor driver, partition 72, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,460 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 2.0 (TID 72) in 8 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 13:26:33,460 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 2.0 (TID 73)
[INFO] 2019-01-19 13:26:33,462 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,462 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,464 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 2.0 (TID 73). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,465 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 2.0 (TID 74, localhost, executor driver, partition 73, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,466 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 2.0 (TID 73) in 7 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 13:26:33,466 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 2.0 (TID 74)
[INFO] 2019-01-19 13:26:33,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,469 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,472 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 2.0 (TID 74). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,473 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 2.0 (TID 75, localhost, executor driver, partition 74, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,474 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 2.0 (TID 74) in 9 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 13:26:33,474 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 2.0 (TID 75)
[INFO] 2019-01-19 13:26:33,477 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,477 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,479 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 2.0 (TID 75). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,480 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 2.0 (TID 76, localhost, executor driver, partition 75, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,480 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 2.0 (TID 76)
[INFO] 2019-01-19 13:26:33,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,480 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 2.0 (TID 75) in 7 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 13:26:33,485 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 2.0 (TID 76). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,485 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,487 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 2.0 (TID 77, localhost, executor driver, partition 76, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,489 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 2.0 (TID 76) in 9 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 13:26:33,491 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 2.0 (TID 77)
[INFO] 2019-01-19 13:26:33,494 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,494 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,496 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 2.0 (TID 77). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,500 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 2.0 (TID 78, localhost, executor driver, partition 77, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,501 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 2.0 (TID 77) in 15 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 13:26:33,501 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 2.0 (TID 78)
[INFO] 2019-01-19 13:26:33,509 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 2.0 (TID 71). 2823 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,510 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 2.0 (TID 79, localhost, executor driver, partition 78, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,510 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 2.0 (TID 79)
[INFO] 2019-01-19 13:26:33,510 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 2.0 (TID 71) in 60 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 13:26:33,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,513 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,516 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 2.0 (TID 79). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,518 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 2.0 (TID 78). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,519 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 2.0 (TID 80, localhost, executor driver, partition 79, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,519 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 2.0 (TID 81, localhost, executor driver, partition 80, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,520 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 2.0 (TID 80)
[INFO] 2019-01-19 13:26:33,520 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 2.0 (TID 78) in 21 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 13:26:33,521 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 2.0 (TID 79) in 12 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 13:26:33,521 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 2.0 (TID 81)
[INFO] 2019-01-19 13:26:33,522 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,524 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,525 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 2.0 (TID 80). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,526 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 2.0 (TID 81). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,527 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 2.0 (TID 82, localhost, executor driver, partition 81, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,527 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 2.0 (TID 82)
[INFO] 2019-01-19 13:26:33,527 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 2.0 (TID 83, localhost, executor driver, partition 82, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,528 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 2.0 (TID 80) in 11 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 13:26:33,529 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 2.0 (TID 81) in 10 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 13:26:33,529 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 2.0 (TID 83)
[INFO] 2019-01-19 13:26:33,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,534 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 2.0 (TID 82). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,536 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 2.0 (TID 84, localhost, executor driver, partition 83, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,536 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 2.0 (TID 82) in 10 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 13:26:33,537 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 2.0 (TID 84)
[INFO] 2019-01-19 13:26:33,540 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,540 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,546 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 2.0 (TID 84). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,553 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 2.0 (TID 85, localhost, executor driver, partition 84, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,554 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 2.0 (TID 85)
[INFO] 2019-01-19 13:26:33,554 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 2.0 (TID 84) in 19 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 13:26:33,556 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,556 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,559 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 2.0 (TID 85). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,560 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 2.0 (TID 86, localhost, executor driver, partition 85, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,560 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 2.0 (TID 85) in 7 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 13:26:33,561 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 2.0 (TID 86)
[INFO] 2019-01-19 13:26:33,563 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,563 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,565 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 2.0 (TID 86). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,565 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 2.0 (TID 87, localhost, executor driver, partition 86, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,566 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 2.0 (TID 86) in 7 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 13:26:33,567 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 2.0 (TID 87)
[INFO] 2019-01-19 13:26:33,568 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,568 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,572 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 2.0 (TID 87). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,573 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 2.0 (TID 88, localhost, executor driver, partition 87, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,573 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 2.0 (TID 87) in 8 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 13:26:33,573 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 2.0 (TID 88)
[INFO] 2019-01-19 13:26:33,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,578 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 2.0 (TID 83). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,579 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 2.0 (TID 89, localhost, executor driver, partition 88, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,579 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 2.0 (TID 83) in 52 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 13:26:33,579 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 2.0 (TID 89)
[INFO] 2019-01-19 13:26:33,582 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,582 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,584 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 2.0 (TID 89). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,585 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 2.0 (TID 90, localhost, executor driver, partition 89, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,585 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 2.0 (TID 90)
[INFO] 2019-01-19 13:26:33,585 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 2.0 (TID 89) in 7 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 13:26:33,587 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 2.0 (TID 88). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,587 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,588 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,589 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 2.0 (TID 91, localhost, executor driver, partition 90, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,589 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 2.0 (TID 90). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,590 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 2.0 (TID 88) in 18 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 13:26:33,590 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 2.0 (TID 91)
[INFO] 2019-01-19 13:26:33,591 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 2.0 (TID 92, localhost, executor driver, partition 91, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,592 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 2.0 (TID 90) in 6 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 13:26:33,592 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 2.0 (TID 92)
[INFO] 2019-01-19 13:26:33,593 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,593 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,597 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 2.0 (TID 92). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,597 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 2.0 (TID 91). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,597 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 2.0 (TID 93, localhost, executor driver, partition 92, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,598 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 2.0 (TID 93)
[INFO] 2019-01-19 13:26:33,598 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 2.0 (TID 94, localhost, executor driver, partition 93, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,599 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 2.0 (TID 91) in 12 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 13:26:33,600 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 2.0 (TID 92) in 9 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 13:26:33,600 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 2.0 (TID 94)
[INFO] 2019-01-19 13:26:33,600 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,601 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,603 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,603 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,605 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 2.0 (TID 94). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,607 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 2.0 (TID 93). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,607 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 2.0 (TID 95, localhost, executor driver, partition 94, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,608 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 2.0 (TID 96, localhost, executor driver, partition 95, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,608 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 2.0 (TID 94) in 10 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 13:26:33,609 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 2.0 (TID 93) in 12 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 13:26:33,610 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 2.0 (TID 95)
[INFO] 2019-01-19 13:26:33,611 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 2.0 (TID 96)
[INFO] 2019-01-19 13:26:33,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,614 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 2.0 (TID 95). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,616 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 2.0 (TID 96). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,617 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 2.0 (TID 97, localhost, executor driver, partition 96, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,617 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 2.0 (TID 98, localhost, executor driver, partition 97, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,618 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 2.0 (TID 97)
[INFO] 2019-01-19 13:26:33,618 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 2.0 (TID 98)
[INFO] 2019-01-19 13:26:33,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,622 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 2.0 (TID 97). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,622 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,623 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,618 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 2.0 (TID 95) in 12 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 13:26:33,624 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 2.0 (TID 96) in 16 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 13:26:33,625 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 2.0 (TID 98). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,625 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 2.0 (TID 99, localhost, executor driver, partition 98, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,626 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 2.0 (TID 99)
[INFO] 2019-01-19 13:26:33,626 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 2.0 (TID 100, localhost, executor driver, partition 99, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,627 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 2.0 (TID 97) in 11 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 13:26:33,627 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 2.0 (TID 100)
[INFO] 2019-01-19 13:26:33,628 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,628 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,629 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,630 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,630 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 2.0 (TID 99). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,630 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 2.0 (TID 98) in 13 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 13:26:33,632 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 2.0 (TID 100). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,632 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 2.0 (TID 101, localhost, executor driver, partition 100, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,633 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 2.0 (TID 101)
[INFO] 2019-01-19 13:26:33,633 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 2.0 (TID 102, localhost, executor driver, partition 101, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,633 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 2.0 (TID 100) in 7 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 13:26:33,634 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 2.0 (TID 99) in 9 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 13:26:33,634 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 2.0 (TID 102)
[INFO] 2019-01-19 13:26:33,635 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,635 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,637 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,637 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,637 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 2.0 (TID 101). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,638 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 2.0 (TID 103, localhost, executor driver, partition 102, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,639 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 2.0 (TID 101) in 7 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 13:26:33,639 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 2.0 (TID 102). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,639 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 2.0 (TID 103)
[INFO] 2019-01-19 13:26:33,640 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 2.0 (TID 104, localhost, executor driver, partition 103, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,641 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 2.0 (TID 102) in 8 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 13:26:33,642 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,642 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,642 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 2.0 (TID 104)
[INFO] 2019-01-19 13:26:33,644 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 2.0 (TID 103). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,645 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 2.0 (TID 105, localhost, executor driver, partition 104, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,645 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 2.0 (TID 103) in 7 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 13:26:33,646 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,646 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,646 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 2.0 (TID 105)
[INFO] 2019-01-19 13:26:33,649 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 2.0 (TID 104). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,650 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 2.0 (TID 106, localhost, executor driver, partition 105, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,650 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 2.0 (TID 104) in 10 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 13:26:33,651 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 2.0 (TID 106)
[INFO] 2019-01-19 13:26:33,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,661 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 2.0 (TID 105). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,662 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 2.0 (TID 107, localhost, executor driver, partition 106, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,663 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 2.0 (TID 105) in 19 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 13:26:33,663 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 2.0 (TID 107)
[INFO] 2019-01-19 13:26:33,666 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,666 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,668 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 2.0 (TID 107). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,668 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 2.0 (TID 108, localhost, executor driver, partition 107, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,669 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 2.0 (TID 107) in 7 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 13:26:33,669 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 2.0 (TID 108)
[INFO] 2019-01-19 13:26:33,671 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 2.0 (TID 106). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,672 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 2.0 (TID 109, localhost, executor driver, partition 108, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,673 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 2.0 (TID 106) in 23 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 13:26:33,673 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,673 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,674 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 2.0 (TID 109)
[INFO] 2019-01-19 13:26:33,675 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 2.0 (TID 108). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,676 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 2.0 (TID 110, localhost, executor driver, partition 109, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,676 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,677 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,677 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 2.0 (TID 108) in 9 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 13:26:33,677 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 2.0 (TID 110)
[INFO] 2019-01-19 13:26:33,678 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 2.0 (TID 109). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,680 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 2.0 (TID 111, localhost, executor driver, partition 110, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,680 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 2.0 (TID 109) in 8 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 13:26:33,681 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,681 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,681 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 2.0 (TID 111)
[INFO] 2019-01-19 13:26:33,683 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 2.0 (TID 110). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 2.0 (TID 112, localhost, executor driver, partition 111, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,684 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 2.0 (TID 110) in 9 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 13:26:33,685 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 2.0 (TID 112)
[INFO] 2019-01-19 13:26:33,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,687 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 2.0 (TID 111). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,689 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 2.0 (TID 113, localhost, executor driver, partition 112, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,690 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,690 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,691 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 2.0 (TID 113)
[INFO] 2019-01-19 13:26:33,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,696 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 2.0 (TID 113). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,690 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 2.0 (TID 111) in 10 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 13:26:33,692 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 2.0 (TID 112). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,697 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 2.0 (TID 114, localhost, executor driver, partition 113, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,698 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 2.0 (TID 115, localhost, executor driver, partition 114, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,698 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 2.0 (TID 114)
[INFO] 2019-01-19 13:26:33,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 2.0 (TID 112) in 15 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 13:26:33,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 2.0 (TID 113) in 11 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 13:26:33,700 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 2.0 (TID 115)
[INFO] 2019-01-19 13:26:33,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,703 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,703 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,704 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 2.0 (TID 114). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,706 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 2.0 (TID 115). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,706 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 2.0 (TID 116, localhost, executor driver, partition 115, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,707 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 2.0 (TID 117, localhost, executor driver, partition 116, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,707 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 2.0 (TID 116)
[INFO] 2019-01-19 13:26:33,707 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 2.0 (TID 117)
[INFO] 2019-01-19 13:26:33,707 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 2.0 (TID 114) in 10 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 13:26:33,710 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,710 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,711 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 2.0 (TID 115) in 13 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 13:26:33,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,714 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 2.0 (TID 117). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,715 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 2.0 (TID 116). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,715 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 2.0 (TID 118, localhost, executor driver, partition 117, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,716 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 2.0 (TID 119, localhost, executor driver, partition 118, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,716 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 2.0 (TID 118)
[INFO] 2019-01-19 13:26:33,718 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 2.0 (TID 119)
[INFO] 2019-01-19 13:26:33,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,721 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,721 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,723 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 2.0 (TID 119). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,717 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 2.0 (TID 116) in 10 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 13:26:33,723 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 2.0 (TID 118). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,724 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 2.0 (TID 117) in 18 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 13:26:33,724 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 2.0 (TID 119) in 8 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 13:26:33,725 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 2.0 (TID 120, localhost, executor driver, partition 119, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,725 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 2.0 (TID 120)
[INFO] 2019-01-19 13:26:33,727 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 2.0 (TID 121, localhost, executor driver, partition 120, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,728 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 2.0 (TID 118) in 13 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 13:26:33,730 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 2.0 (TID 121)
[INFO] 2019-01-19 13:26:33,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,733 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 2.0 (TID 120). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,734 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,734 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 2.0 (TID 122, localhost, executor driver, partition 121, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,735 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 2.0 (TID 120) in 10 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 13:26:33,735 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 2.0 (TID 122)
[INFO] 2019-01-19 13:26:33,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 13:26:33,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,738 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,740 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 2.0 (TID 122). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,741 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 2.0 (TID 121). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,741 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 2.0 (TID 123, localhost, executor driver, partition 122, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,741 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 2.0 (TID 122) in 7 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 13:26:33,741 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 2.0 (TID 123)
[INFO] 2019-01-19 13:26:33,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,745 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,747 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 2.0 (TID 123). 2744 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,751 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 2.0 (TID 123) in 11 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 13:26:33,753 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 2.0 (TID 124, localhost, executor driver, partition 123, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,753 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 2.0 (TID 124)
[INFO] 2019-01-19 13:26:33,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,763 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 2.0 (TID 124). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,764 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 2.0 (TID 125, localhost, executor driver, partition 124, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,765 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 2.0 (TID 124) in 13 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 13:26:33,765 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 2.0 (TID 125)
[INFO] 2019-01-19 13:26:33,768 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,768 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,770 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 2.0 (TID 125). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,771 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 2.0 (TID 126, localhost, executor driver, partition 125, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,772 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 2.0 (TID 125) in 8 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 13:26:33,772 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 2.0 (TID 126)
[INFO] 2019-01-19 13:26:33,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,778 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 2.0 (TID 126). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,778 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 2.0 (TID 127, localhost, executor driver, partition 126, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,779 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 2.0 (TID 126) in 8 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 13:26:33,779 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 2.0 (TID 127)
[INFO] 2019-01-19 13:26:33,782 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 2.0 (TID 128, localhost, executor driver, partition 127, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,783 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 2.0 (TID 121) in 55 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 13:26:33,783 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 2.0 (TID 128)
[INFO] 2019-01-19 13:26:33,786 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,786 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,788 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 2.0 (TID 128). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,790 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 2.0 (TID 129, localhost, executor driver, partition 128, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,790 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 2.0 (TID 129)
[INFO] 2019-01-19 13:26:33,792 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 2.0 (TID 128) in 10 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 13:26:33,793 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,793 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,795 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 2.0 (TID 129). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,796 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 2.0 (TID 130, localhost, executor driver, partition 129, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,796 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 2.0 (TID 129) in 7 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 13:26:33,797 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 2.0 (TID 130)
[INFO] 2019-01-19 13:26:33,799 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,799 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,801 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 2.0 (TID 130). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,802 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 2.0 (TID 131, localhost, executor driver, partition 130, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,802 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 2.0 (TID 131)
[INFO] 2019-01-19 13:26:33,802 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 2.0 (TID 130) in 6 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 13:26:33,805 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,805 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,807 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 2.0 (TID 131). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 2.0 (TID 132, localhost, executor driver, partition 131, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,808 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 2.0 (TID 132)
[INFO] 2019-01-19 13:26:33,808 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 2.0 (TID 131) in 7 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 13:26:33,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,814 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 2.0 (TID 132). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,815 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 2.0 (TID 133, localhost, executor driver, partition 132, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,815 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 2.0 (TID 133)
[INFO] 2019-01-19 13:26:33,815 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 2.0 (TID 132) in 7 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 13:26:33,823 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,823 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,826 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 2.0 (TID 127). 2834 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,827 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 2.0 (TID 134, localhost, executor driver, partition 133, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,827 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 2.0 (TID 134)
[INFO] 2019-01-19 13:26:33,827 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 2.0 (TID 127) in 49 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 13:26:33,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,832 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 2.0 (TID 134). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,833 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 2.0 (TID 135, localhost, executor driver, partition 134, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,833 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 2.0 (TID 135)
[INFO] 2019-01-19 13:26:33,833 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 2.0 (TID 134) in 7 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 13:26:33,835 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,836 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,837 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,837 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,837 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 2.0 (TID 135). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,838 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 2.0 (TID 136, localhost, executor driver, partition 135, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,839 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 2.0 (TID 136)
[INFO] 2019-01-19 13:26:33,839 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 2.0 (TID 135) in 7 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 13:26:33,841 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,841 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,843 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 2.0 (TID 136). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,844 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 2.0 (TID 137, localhost, executor driver, partition 136, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,844 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 2.0 (TID 133). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,844 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 2.0 (TID 136) in 6 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 13:26:33,844 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 2.0 (TID 137)
[INFO] 2019-01-19 13:26:33,844 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 2.0 (TID 138, localhost, executor driver, partition 137, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,845 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 2.0 (TID 133) in 31 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 13:26:33,846 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 2.0 (TID 138)
[INFO] 2019-01-19 13:26:33,846 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,848 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,848 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,848 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 2.0 (TID 137). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,849 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 2.0 (TID 139, localhost, executor driver, partition 138, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,850 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 2.0 (TID 137) in 7 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 13:26:33,850 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 2.0 (TID 138). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,850 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 2.0 (TID 139)
[INFO] 2019-01-19 13:26:33,851 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 2.0 (TID 140, localhost, executor driver, partition 139, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,851 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 2.0 (TID 138) in 7 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 13:26:33,853 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,853 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,853 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 2.0 (TID 140)
[INFO] 2019-01-19 13:26:33,855 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 2.0 (TID 139). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,856 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,856 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,856 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 2.0 (TID 141, localhost, executor driver, partition 140, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,857 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 2.0 (TID 139) in 8 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 13:26:33,857 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 2.0 (TID 141)
[INFO] 2019-01-19 13:26:33,858 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 2.0 (TID 140). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,859 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 2.0 (TID 142, localhost, executor driver, partition 141, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,859 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 2.0 (TID 140) in 8 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 13:26:33,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,860 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 2.0 (TID 142)
[INFO] 2019-01-19 13:26:33,862 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 2.0 (TID 141). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,863 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,863 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,863 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 2.0 (TID 143, localhost, executor driver, partition 142, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,864 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 2.0 (TID 141) in 8 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 13:26:33,864 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 2.0 (TID 143)
[INFO] 2019-01-19 13:26:33,865 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 2.0 (TID 142). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,867 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 2.0 (TID 144, localhost, executor driver, partition 143, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,868 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 2.0 (TID 143). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,868 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 2.0 (TID 144)
[INFO] 2019-01-19 13:26:33,868 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 2.0 (TID 142) in 9 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 13:26:33,871 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 2.0 (TID 145, localhost, executor driver, partition 144, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,871 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,872 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 2.0 (TID 145)
[INFO] 2019-01-19 13:26:33,874 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 2.0 (TID 144). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,872 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 2.0 (TID 143) in 9 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 13:26:33,875 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 2.0 (TID 146, localhost, executor driver, partition 145, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,875 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 2.0 (TID 146)
[INFO] 2019-01-19 13:26:33,875 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 2.0 (TID 144) in 9 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 13:26:33,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,879 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 2.0 (TID 146). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,880 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 2.0 (TID 147, localhost, executor driver, partition 146, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,880 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 2.0 (TID 147)
[INFO] 2019-01-19 13:26:33,880 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 2.0 (TID 146) in 6 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 13:26:33,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,885 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 2.0 (TID 147). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,886 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 2.0 (TID 148, localhost, executor driver, partition 147, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,886 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 2.0 (TID 148)
[INFO] 2019-01-19 13:26:33,886 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 2.0 (TID 147) in 7 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 13:26:33,888 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,888 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,890 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,890 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,891 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 2.0 (TID 145). 2826 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,891 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 2.0 (TID 149, localhost, executor driver, partition 148, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,891 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 2.0 (TID 149)
[INFO] 2019-01-19 13:26:33,891 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 2.0 (TID 145) in 21 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 13:26:33,893 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 2.0 (TID 148). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,894 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 2.0 (TID 150, localhost, executor driver, partition 149, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,894 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,894 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,894 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 2.0 (TID 150)
[INFO] 2019-01-19 13:26:33,894 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 2.0 (TID 148) in 9 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 13:26:33,896 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 2.0 (TID 149). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,897 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 2.0 (TID 151, localhost, executor driver, partition 150, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,897 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 2.0 (TID 149) in 6 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 13:26:33,897 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,897 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,899 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 2.0 (TID 151)
[INFO] 2019-01-19 13:26:33,899 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 2.0 (TID 150). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,900 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 2.0 (TID 152, localhost, executor driver, partition 151, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,901 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 2.0 (TID 150) in 8 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 13:26:33,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,901 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 2.0 (TID 152)
[INFO] 2019-01-19 13:26:33,903 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 2.0 (TID 151). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,904 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 2.0 (TID 153, localhost, executor driver, partition 152, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,905 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 2.0 (TID 151) in 9 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 13:26:33,905 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,906 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,906 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 2.0 (TID 153)
[INFO] 2019-01-19 13:26:33,907 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 2.0 (TID 152). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,908 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 2.0 (TID 154, localhost, executor driver, partition 153, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,909 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 2.0 (TID 152) in 9 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 13:26:33,909 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,909 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,909 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 2.0 (TID 154)
[INFO] 2019-01-19 13:26:33,910 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 2.0 (TID 153). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,911 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,911 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,911 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 2.0 (TID 155, localhost, executor driver, partition 154, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,912 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 2.0 (TID 153) in 8 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 13:26:33,912 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 2.0 (TID 155)
[INFO] 2019-01-19 13:26:33,913 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 2.0 (TID 154). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,914 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 2.0 (TID 156, localhost, executor driver, partition 155, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,914 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,915 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,915 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 2.0 (TID 156)
[INFO] 2019-01-19 13:26:33,916 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 2.0 (TID 155). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,915 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 2.0 (TID 154) in 7 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 13:26:33,917 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 2.0 (TID 157, localhost, executor driver, partition 156, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,918 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,918 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 2.0 (TID 157)
[INFO] 2019-01-19 13:26:33,919 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 2.0 (TID 156). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,918 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 2.0 (TID 155) in 6 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 13:26:33,920 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 2.0 (TID 158, localhost, executor driver, partition 157, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,922 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,922 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,922 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 2.0 (TID 158)
[INFO] 2019-01-19 13:26:33,923 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 2.0 (TID 157). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,922 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 2.0 (TID 156) in 8 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 13:26:33,924 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,925 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,926 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 2.0 (TID 159, localhost, executor driver, partition 158, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,926 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 2.0 (TID 158). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,927 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 2.0 (TID 159)
[INFO] 2019-01-19 13:26:33,927 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 2.0 (TID 157) in 10 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 13:26:33,928 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 2.0 (TID 160, localhost, executor driver, partition 159, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,929 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 2.0 (TID 158) in 9 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 13:26:33,929 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 2.0 (TID 160)
[INFO] 2019-01-19 13:26:33,931 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,931 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,929 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,932 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 13:26:33,933 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 2.0 (TID 160). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,934 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 2.0 (TID 159). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,934 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 2.0 (TID 161, localhost, executor driver, partition 160, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,934 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 2.0 (TID 160) in 6 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 13:26:33,934 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 2.0 (TID 161)
[INFO] 2019-01-19 13:26:33,935 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 2.0 (TID 159) in 11 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 13:26:33,935 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 2.0 (TID 162, localhost, executor driver, partition 161, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,936 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 2.0 (TID 162)
[INFO] 2019-01-19 13:26:33,937 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,937 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,939 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,939 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,941 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 2.0 (TID 162). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,941 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 2.0 (TID 161). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,942 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 2.0 (TID 163, localhost, executor driver, partition 162, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,942 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 2.0 (TID 163)
[INFO] 2019-01-19 13:26:33,943 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 2.0 (TID 164, localhost, executor driver, partition 163, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,943 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 2.0 (TID 161) in 10 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 13:26:33,944 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 2.0 (TID 162) in 9 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 13:26:33,944 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 2.0 (TID 164)
[INFO] 2019-01-19 13:26:33,945 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,945 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,946 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,946 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 2.0 (TID 163). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,948 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 2.0 (TID 165, localhost, executor driver, partition 164, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,948 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 2.0 (TID 165)
[INFO] 2019-01-19 13:26:33,948 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 2.0 (TID 163) in 6 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 13:26:33,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:26:33,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,951 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,952 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 2.0 (TID 165). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,953 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 2.0 (TID 166, localhost, executor driver, partition 165, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,954 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 2.0 (TID 165) in 7 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 13:26:33,955 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 2.0 (TID 166)
[INFO] 2019-01-19 13:26:33,958 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,958 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,960 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 2.0 (TID 166). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,962 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 2.0 (TID 167, localhost, executor driver, partition 166, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,962 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 2.0 (TID 166) in 9 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 13:26:33,967 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 2.0 (TID 167)
[INFO] 2019-01-19 13:26:33,969 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 2.0 (TID 164). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,969 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,970 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 2.0 (TID 168, localhost, executor driver, partition 167, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,970 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 2.0 (TID 164) in 28 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 13:26:33,970 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 2.0 (TID 168)
[INFO] 2019-01-19 13:26:33,972 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 2.0 (TID 167). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,972 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 2.0 (TID 169, localhost, executor driver, partition 168, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,973 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 2.0 (TID 167) in 12 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 13:26:33,973 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 2.0 (TID 169)
[INFO] 2019-01-19 13:26:33,974 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,974 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,975 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,976 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,976 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 2.0 (TID 168). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,977 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 2.0 (TID 169). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,978 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 2.0 (TID 170, localhost, executor driver, partition 169, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,978 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 2.0 (TID 170)
[INFO] 2019-01-19 13:26:33,978 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 2.0 (TID 171, localhost, executor driver, partition 170, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,979 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 2.0 (TID 169) in 7 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 13:26:33,979 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 2.0 (TID 168) in 10 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 13:26:33,980 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 2.0 (TID 171)
[INFO] 2019-01-19 13:26:33,980 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,983 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 2.0 (TID 170). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,984 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 2.0 (TID 172, localhost, executor driver, partition 171, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,985 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 2.0 (TID 171). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,985 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 2.0 (TID 172)
[INFO] 2019-01-19 13:26:33,985 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 2.0 (TID 170) in 8 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 13:26:33,986 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 2.0 (TID 173, localhost, executor driver, partition 172, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,987 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 2.0 (TID 171) in 9 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 13:26:33,987 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,988 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:33,988 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 2.0 (TID 173)
[INFO] 2019-01-19 13:26:33,989 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 2.0 (TID 172). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,990 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,990 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,990 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 2.0 (TID 174, localhost, executor driver, partition 173, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,991 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 2.0 (TID 172) in 8 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 13:26:33,992 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 2.0 (TID 174)
[INFO] 2019-01-19 13:26:33,992 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 2.0 (TID 173). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,993 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 2.0 (TID 175, localhost, executor driver, partition 174, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,994 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 2.0 (TID 173) in 8 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 13:26:33,994 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 2.0 (TID 175)
[INFO] 2019-01-19 13:26:33,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:33,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:33,996 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 2.0 (TID 174). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:33,997 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 2.0 (TID 176, localhost, executor driver, partition 175, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:33,998 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 2.0 (TID 174) in 8 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 13:26:33,998 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 2.0 (TID 176)
[INFO] 2019-01-19 13:26:34,001 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,001 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,003 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 2.0 (TID 176). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,005 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 2.0 (TID 177, localhost, executor driver, partition 176, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,005 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 2.0 (TID 176) in 8 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 13:26:34,006 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 2.0 (TID 177)
[INFO] 2019-01-19 13:26:34,008 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,009 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,010 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 2.0 (TID 177). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,011 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 2.0 (TID 178, localhost, executor driver, partition 177, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,011 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 2.0 (TID 178)
[INFO] 2019-01-19 13:26:34,011 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 2.0 (TID 177) in 7 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 13:26:34,014 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,014 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,016 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 2.0 (TID 178). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,016 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 2.0 (TID 179, localhost, executor driver, partition 178, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,017 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 2.0 (TID 178) in 6 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 13:26:34,018 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 2.0 (TID 179)
[INFO] 2019-01-19 13:26:34,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,020 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,021 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,023 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 2.0 (TID 175). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,023 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 2.0 (TID 180, localhost, executor driver, partition 179, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,024 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 2.0 (TID 180)
[INFO] 2019-01-19 13:26:34,024 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 2.0 (TID 175) in 30 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 13:26:34,026 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 2.0 (TID 179). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,026 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 2.0 (TID 181, localhost, executor driver, partition 180, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,027 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 2.0 (TID 179) in 11 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 13:26:34,027 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 2.0 (TID 181)
[INFO] 2019-01-19 13:26:34,028 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 2.0 (TID 180). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,029 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 2.0 (TID 182, localhost, executor driver, partition 181, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,029 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 2.0 (TID 180) in 6 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 13:26:34,029 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,030 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,030 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 2.0 (TID 182)
[INFO] 2019-01-19 13:26:34,031 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 2.0 (TID 181). 2736 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,034 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 2.0 (TID 183, localhost, executor driver, partition 182, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,035 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 2.0 (TID 181) in 9 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 13:26:34,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,036 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 2.0 (TID 183)
[INFO] 2019-01-19 13:26:34,037 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 2.0 (TID 182). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,039 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,039 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,040 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 2.0 (TID 184, localhost, executor driver, partition 183, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,040 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 2.0 (TID 182) in 12 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 13:26:34,041 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 2.0 (TID 184)
[INFO] 2019-01-19 13:26:34,043 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 2.0 (TID 183). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,043 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,043 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,044 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 2.0 (TID 185, localhost, executor driver, partition 184, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,044 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 2.0 (TID 183) in 10 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 13:26:34,045 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 2.0 (TID 185)
[INFO] 2019-01-19 13:26:34,045 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 2.0 (TID 184). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,046 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 2.0 (TID 186, localhost, executor driver, partition 185, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,047 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 2.0 (TID 184) in 8 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 13:26:34,047 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 2.0 (TID 186)
[INFO] 2019-01-19 13:26:34,047 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,047 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,049 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 2.0 (TID 185). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,049 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,050 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,050 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 2.0 (TID 187, localhost, executor driver, partition 186, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,050 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 2.0 (TID 185) in 6 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 13:26:34,051 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 2.0 (TID 187)
[INFO] 2019-01-19 13:26:34,051 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 2.0 (TID 186). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,052 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 2.0 (TID 188, localhost, executor driver, partition 187, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,053 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 2.0 (TID 186) in 6 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 13:26:34,053 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 2.0 (TID 188)
[INFO] 2019-01-19 13:26:34,053 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,053 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,056 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 2.0 (TID 187). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,057 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,058 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,059 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 2.0 (TID 188). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,060 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 2.0 (TID 189, localhost, executor driver, partition 188, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,061 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 2.0 (TID 190, localhost, executor driver, partition 189, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,061 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 2.0 (TID 189)
[INFO] 2019-01-19 13:26:34,062 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 2.0 (TID 190)
[INFO] 2019-01-19 13:26:34,061 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 2.0 (TID 188) in 9 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 13:26:34,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,064 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 2.0 (TID 187) in 14 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 13:26:34,064 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,065 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,066 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 2.0 (TID 190). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,067 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 2.0 (TID 189). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,067 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 2.0 (TID 191, localhost, executor driver, partition 190, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,068 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 2.0 (TID 192, localhost, executor driver, partition 192, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,069 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 2.0 (TID 190) in 7 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 13:26:34,069 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 2.0 (TID 189) in 9 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 13:26:34,069 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 2.0 (TID 191)
[INFO] 2019-01-19 13:26:34,073 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,073 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,074 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 2.0 (TID 192)
[INFO] 2019-01-19 13:26:34,076 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,077 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,078 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 2.0 (TID 192). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,079 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 2.0 (TID 193, localhost, executor driver, partition 193, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,081 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 2.0 (TID 192) in 13 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 13:26:34,082 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 2.0 (TID 193)
[INFO] 2019-01-19 13:26:34,084 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,085 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,087 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 2.0 (TID 193). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,088 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 2.0 (TID 194, localhost, executor driver, partition 194, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,088 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 2.0 (TID 194)
[INFO] 2019-01-19 13:26:34,088 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 2.0 (TID 193) in 9 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 13:26:34,091 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 2.0 (TID 191). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,092 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 2.0 (TID 195, localhost, executor driver, partition 195, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,093 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 2.0 (TID 191) in 26 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 13:26:34,093 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 2.0 (TID 195)
[INFO] 2019-01-19 13:26:34,095 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,095 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,095 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,096 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,097 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 2.0 (TID 195). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,098 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 2.0 (TID 196, localhost, executor driver, partition 196, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,098 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 2.0 (TID 195) in 6 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 13:26:34,099 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 2.0 (TID 196)
[INFO] 2019-01-19 13:26:34,098 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 2.0 (TID 194). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,099 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 2.0 (TID 197, localhost, executor driver, partition 197, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,100 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 2.0 (TID 194) in 13 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 13:26:34,100 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 2.0 (TID 197)
[INFO] 2019-01-19 13:26:34,101 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,101 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,103 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:26:34,102 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 2.0 (TID 196). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,103 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 2.0 (TID 198, localhost, executor driver, partition 198, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,104 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 2.0 (TID 196) in 7 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 13:26:34,104 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 2.0 (TID 197). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,105 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 2.0 (TID 198)
[INFO] 2019-01-19 13:26:34,105 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 2.0 (TID 199, localhost, executor driver, partition 199, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:26:34,106 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 2.0 (TID 197) in 7 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 13:26:34,107 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 2.0 (TID 199)
[INFO] 2019-01-19 13:26:34,107 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,107 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,111 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 2.0 (TID 198). 2657 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,111 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 2.0 (TID 199). 2747 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,112 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 2.0 (TID 200, localhost, executor driver, partition 43, ANY, 5870 bytes)
[INFO] 2019-01-19 13:26:34,112 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 2.0 (TID 200)
[INFO] 2019-01-19 13:26:34,112 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 2.0 (TID 201, localhost, executor driver, partition 191, ANY, 5870 bytes)
[INFO] 2019-01-19 13:26:34,113 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 2.0 (TID 199) in 8 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 13:26:34,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 2.0 (TID 198) in 11 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 13:26:34,114 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 2.0 (TID 201)
[INFO] 2019-01-19 13:26:34,115 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,115 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,116 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:34,116 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:34,144 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 2.0 (TID 201). 2740 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,144 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 2.0 (TID 200). 2740 bytes result sent to driver
[INFO] 2019-01-19 13:26:34,144 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 2.0 (TID 201) in 32 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 13:26:34,145 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 2.0 (TID 200) in 34 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 13:26:34,145 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:34,145 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 2 (collect at LayerSample.scala:49) finished in 1.418 s
[INFO] 2019-01-19 13:26:34,146 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at LayerSample.scala:49, took 2.197152 s
[INFO] 2019-01-19 13:26:34,347 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag==1
[INFO] 2019-01-19 13:26:35,185 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:35,192 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:26:35,193 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:26:35,197 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[WARN] 2019-01-19 13:26:35,249 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2019-01-19 13:26:35,350 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.868711 ms
[INFO] 2019-01-19 13:26:35,387 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.717904 ms
[INFO] 2019-01-19 13:26:35,417 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4 stored as values in memory (estimated size 278.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:26:35,433 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:26:35,436 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_4_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:35,438 org.apache.spark.SparkContext logInfo - Created broadcast 4 from count at LayerSample.scala:54
[INFO] 2019-01-19 13:26:35,439 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:35,471 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:54
[INFO] 2019-01-19 13:26:35,472 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 14 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:35,472 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 2 (count at LayerSample.scala:54) with 1 output partitions
[INFO] 2019-01-19 13:26:35,472 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 4 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:35,472 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 3)
[INFO] 2019-01-19 13:26:35,473 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 3)
[INFO] 2019-01-19 13:26:35,473 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 3 (MapPartitionsRDD[14] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:26:35,489 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5 stored as values in memory (estimated size 13.5 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:26:35,490 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:26:35,492 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_5_piece0 in memory on 192.168.99.1:57817 (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:35,493 org.apache.spark.SparkContext logInfo - Created broadcast 5 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:35,493 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[14] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:35,493 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 3.0 with 1 tasks
[INFO] 2019-01-19 13:26:35,495 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 13:26:35,495 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 3.0 (TID 202)
[INFO] 2019-01-19 13:26:35,499 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:35,633 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:26:35,706 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 3.0 (TID 202). 2032 bytes result sent to driver
[INFO] 2019-01-19 13:26:35,712 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 3.0 (TID 202) in 218 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:35,712 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:35,713 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 3 (count at LayerSample.scala:54) finished in 0.219 s
[INFO] 2019-01-19 13:26:35,713 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:26:35,713 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:26:35,713 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 4)
[INFO] 2019-01-19 13:26:35,713 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:26:35,714 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 4 (MapPartitionsRDD[17] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:26:35,715 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6 stored as values in memory (estimated size 7.0 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:26:35,719 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:26:35,722 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_6_piece0 in memory on 192.168.99.1:57817 (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:35,723 org.apache.spark.SparkContext logInfo - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:35,723 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:35,724 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 4.0 with 1 tasks
[INFO] 2019-01-19 13:26:35,725 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 13:26:35,725 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 4.0 (TID 203)
[INFO] 2019-01-19 13:26:35,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:35,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:35,784 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 4.0 (TID 203). 2039 bytes result sent to driver
[INFO] 2019-01-19 13:26:35,785 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 4.0 (TID 203) in 61 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:35,785 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:35,786 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 4 (count at LayerSample.scala:54) finished in 0.062 s
[INFO] 2019-01-19 13:26:35,854 org.apache.spark.scheduler.DAGScheduler logInfo - Job 2 finished: count at LayerSample.scala:54, took 0.382378 s
[INFO] 2019-01-19 13:26:35,967 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 106.860587 ms
[INFO] 2019-01-19 13:26:37,667 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:37,671 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:26:37,672 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:26:37,672 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:26:37,868 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 151.805152 ms
[INFO] 2019-01-19 13:26:37,885 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7 stored as values in memory (estimated size 292.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:26:37,897 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:26:37,898 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_7_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:37,899 org.apache.spark.SparkContext logInfo - Created broadcast 7 from show at package.scala:17
[INFO] 2019-01-19 13:26:37,900 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:37,915 org.apache.spark.SparkContext logInfo - Starting job: show at package.scala:17
[INFO] 2019-01-19 13:26:37,916 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 3 (show at package.scala:17) with 1 output partitions
[INFO] 2019-01-19 13:26:37,916 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 5 (show at package.scala:17)
[INFO] 2019-01-19 13:26:37,916 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:26:37,916 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:26:37,917 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 5 (MapPartitionsRDD[20] at show at package.scala:17), which has no missing parents
[INFO] 2019-01-19 13:26:37,918 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8 stored as values in memory (estimated size 34.6 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:26:37,919 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:26:37,922 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_8_piece0 in memory on 192.168.99.1:57817 (size: 10.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:37,922 org.apache.spark.SparkContext logInfo - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:37,923 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at show at package.scala:17)
[INFO] 2019-01-19 13:26:37,923 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 5.0 with 1 tasks
[INFO] 2019-01-19 13:26:37,925 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 6563 bytes)
[INFO] 2019-01-19 13:26:37,925 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 5.0 (TID 204)
[INFO] 2019-01-19 13:26:37,967 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:37,982 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:26:38,072 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 5.0 (TID 204). 4469 bytes result sent to driver
[INFO] 2019-01-19 13:26:38,072 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 5.0 (TID 204) in 148 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:38,073 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:38,073 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 5 (show at package.scala:17) finished in 0.149 s
[INFO] 2019-01-19 13:26:38,074 org.apache.spark.scheduler.DAGScheduler logInfo - Job 3 finished: show at package.scala:17, took 0.157780 s
[INFO] 2019-01-19 13:26:38,148 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 66.554346 ms
[INFO] 2019-01-19 13:26:38,365 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:38,366 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:26:38,367 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:26:38,367 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:26:38,416 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 28.302452 ms
[INFO] 2019-01-19 13:26:38,427 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9 stored as values in memory (estimated size 292.7 KB, free 1990.7 MB)
[INFO] 2019-01-19 13:26:38,446 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1990.7 MB)
[INFO] 2019-01-19 13:26:38,449 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_9_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:38,450 org.apache.spark.SparkContext logInfo - Created broadcast 9 from show at package.scala:17
[INFO] 2019-01-19 13:26:38,453 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:38,462 org.apache.spark.SparkContext logInfo - Starting job: show at package.scala:17
[INFO] 2019-01-19 13:26:38,463 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 4 (show at package.scala:17) with 1 output partitions
[INFO] 2019-01-19 13:26:38,463 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 6 (show at package.scala:17)
[INFO] 2019-01-19 13:26:38,463 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:26:38,463 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:26:38,463 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 6 (MapPartitionsRDD[23] at show at package.scala:17), which has no missing parents
[INFO] 2019-01-19 13:26:38,465 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10 stored as values in memory (estimated size 33.4 KB, free 1990.7 MB)
[INFO] 2019-01-19 13:26:38,466 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1990.6 MB)
[INFO] 2019-01-19 13:26:38,467 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_10_piece0 in memory on 192.168.99.1:57817 (size: 9.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:26:38,467 org.apache.spark.SparkContext logInfo - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:38,468 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at show at package.scala:17)
[INFO] 2019-01-19 13:26:38,468 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 6.0 with 1 tasks
[INFO] 2019-01-19 13:26:38,468 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 6563 bytes)
[INFO] 2019-01-19 13:26:38,469 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 6.0 (TID 205)
[INFO] 2019-01-19 13:26:38,473 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:38,480 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:26:38,511 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 6.0 (TID 205). 4510 bytes result sent to driver
[INFO] 2019-01-19 13:26:38,511 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 6.0 (TID 205) in 43 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:38,511 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:38,512 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 6 (show at package.scala:17) finished in 0.044 s
[INFO] 2019-01-19 13:26:38,512 org.apache.spark.scheduler.DAGScheduler logInfo - Job 4 finished: show at package.scala:17, took 0.049692 s
[INFO] 2019-01-19 13:26:42,061 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag==0
[INFO] 2019-01-19 13:26:42,121 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:42,124 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:26:42,125 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:26:42,125 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:26:42,307 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 143.963303 ms
[INFO] 2019-01-19 13:26:42,316 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11 stored as values in memory (estimated size 278.7 KB, free 1990.4 MB)
[INFO] 2019-01-19 13:26:42,349 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1990.3 MB)
[INFO] 2019-01-19 13:26:42,356 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_11_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:42,364 org.apache.spark.SparkContext logInfo - Created broadcast 11 from count at LayerSample.scala:54
[INFO] 2019-01-19 13:26:42,365 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:42,397 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:54
[INFO] 2019-01-19 13:26:42,399 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 26 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:42,400 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 5 (count at LayerSample.scala:54) with 1 output partitions
[INFO] 2019-01-19 13:26:42,400 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 8 (count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:42,400 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 7)
[INFO] 2019-01-19 13:26:42,400 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 7)
[INFO] 2019-01-19 13:26:42,401 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 7 (MapPartitionsRDD[26] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:26:42,405 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12 stored as values in memory (estimated size 13.5 KB, free 1990.3 MB)
[INFO] 2019-01-19 13:26:42,407 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.3 KB, free 1990.3 MB)
[INFO] 2019-01-19 13:26:42,408 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_12_piece0 in memory on 192.168.99.1:57817 (size: 6.3 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:42,409 org.apache.spark.SparkContext logInfo - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:42,409 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[26] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:42,409 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 7.0 with 1 tasks
[INFO] 2019-01-19 13:26:42,410 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 13:26:42,411 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 7.0 (TID 206)
[INFO] 2019-01-19 13:26:42,415 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:42,430 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:26:42,492 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 7.0 (TID 206). 2032 bytes result sent to driver
[INFO] 2019-01-19 13:26:42,495 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 7.0 (TID 206) in 85 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:42,495 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:42,497 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 7 (count at LayerSample.scala:54) finished in 0.086 s
[INFO] 2019-01-19 13:26:42,497 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:26:42,497 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:26:42,497 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 8)
[INFO] 2019-01-19 13:26:42,497 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:26:42,498 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 8 (MapPartitionsRDD[29] at count at LayerSample.scala:54), which has no missing parents
[INFO] 2019-01-19 13:26:42,507 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 1990.3 MB)
[INFO] 2019-01-19 13:26:42,508 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1990.3 MB)
[INFO] 2019-01-19 13:26:42,520 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_13_piece0 in memory on 192.168.99.1:57817 (size: 3.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:42,521 org.apache.spark.SparkContext logInfo - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:42,521 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at count at LayerSample.scala:54)
[INFO] 2019-01-19 13:26:42,521 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 8.0 with 1 tasks
[INFO] 2019-01-19 13:26:42,526 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 8.0 (TID 207, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 13:26:42,528 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 8.0 (TID 207)
[INFO] 2019-01-19 13:26:42,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:42,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:42,532 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 8.0 (TID 207). 1952 bytes result sent to driver
[INFO] 2019-01-19 13:26:42,533 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 8.0 (TID 207) in 9 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:42,533 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:42,534 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 8 (count at LayerSample.scala:54) finished in 0.011 s
[INFO] 2019-01-19 13:26:42,540 org.apache.spark.scheduler.DAGScheduler logInfo - Job 5 finished: count at LayerSample.scala:54, took 0.136687 s
[INFO] 2019-01-19 13:26:52,026 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:52,027 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:26:52,028 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:26:52,028 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:26:52,029 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:26:52,030 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:26:52,031 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:26:52,031 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:26:52,070 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.374985 ms
[INFO] 2019-01-19 13:26:52,076 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.510655 ms
[INFO] 2019-01-19 13:26:52,091 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.414478 ms
[INFO] 2019-01-19 13:26:52,103 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.597552 ms
[INFO] 2019-01-19 13:26:52,108 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14 stored as values in memory (estimated size 278.7 KB, free 1990.0 MB)
[INFO] 2019-01-19 13:26:52,122 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1990.0 MB)
[INFO] 2019-01-19 13:26:52,123 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_14_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:52,124 org.apache.spark.SparkContext logInfo - Created broadcast 14 from count at LayerSample.scala:60
[INFO] 2019-01-19 13:26:52,124 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:52,148 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.53234 ms
[INFO] 2019-01-19 13:26:52,152 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15 stored as values in memory (estimated size 278.7 KB, free 1989.8 MB)
[INFO] 2019-01-19 13:26:52,172 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:26:52,173 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_15_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:52,173 org.apache.spark.SparkContext logInfo - Created broadcast 15 from count at LayerSample.scala:60
[INFO] 2019-01-19 13:26:52,174 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:26:52,218 org.apache.spark.SparkContext logInfo - Starting job: count at LayerSample.scala:60
[INFO] 2019-01-19 13:26:52,221 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 34 (count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,221 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 39 (count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,221 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 44 (count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,222 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 6 (count at LayerSample.scala:60) with 1 output partitions
[INFO] 2019-01-19 13:26:52,222 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 12 (count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,222 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 11)
[INFO] 2019-01-19 13:26:52,222 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 11)
[INFO] 2019-01-19 13:26:52,223 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 9 (MapPartitionsRDD[34] at count at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:26:52,247 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16 stored as values in memory (estimated size 12.2 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:26:52,253 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:26:52,256 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_16_piece0 in memory on 192.168.99.1:57817 (size: 5.9 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:52,257 org.apache.spark.SparkContext logInfo - Created broadcast 16 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:52,258 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[34] at count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,258 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 9.0 with 1 tasks
[INFO] 2019-01-19 13:26:52,259 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 10 (MapPartitionsRDD[39] at count at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:26:52,261 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17 stored as values in memory (estimated size 12.2 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:26:52,261 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 9.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:26:52,261 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 9.0 (TID 208)
[INFO] 2019-01-19 13:26:52,262 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:26:52,264 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_17_piece0 in memory on 192.168.99.1:57817 (size: 5.9 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:52,265 org.apache.spark.SparkContext logInfo - Created broadcast 17 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:52,265 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[39] at count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,265 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:52,265 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 10.0 with 1 tasks
[INFO] 2019-01-19 13:26:52,267 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 10.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:26:52,268 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 10.0 (TID 209)
[INFO] 2019-01-19 13:26:52,273 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:26:52,278 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:26:52,287 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:26:52,290 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 13:26:52,328 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 10.0 (TID 209). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:26:52,330 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 10.0 (TID 209) in 64 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:52,331 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:52,331 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 10 (count at LayerSample.scala:60) finished in 0.064 s
[INFO] 2019-01-19 13:26:52,331 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:26:52,331 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 9)
[INFO] 2019-01-19 13:26:52,331 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 12, ShuffleMapStage 11)
[INFO] 2019-01-19 13:26:52,331 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:26:52,337 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 9.0 (TID 208). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 9.0 (TID 208) in 78 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 9 (count at LayerSample.scala:60) finished in 0.080 s
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 12, ShuffleMapStage 11)
[INFO] 2019-01-19 13:26:52,338 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:26:52,339 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 11 (MapPartitionsRDD[44] at count at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:26:52,350 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18 stored as values in memory (estimated size 39.9 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:26:52,352 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:26:52,352 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_18_piece0 in memory on 192.168.99.1:57817 (size: 13.6 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:52,353 org.apache.spark.SparkContext logInfo - Created broadcast 18 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:52,353 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[44] at count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,353 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 11.0 with 2 tasks
[INFO] 2019-01-19 13:26:52,357 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 11.0 (TID 210, localhost, executor driver, partition 0, ANY, 5998 bytes)
[INFO] 2019-01-19 13:26:52,357 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 11.0 (TID 211, localhost, executor driver, partition 1, ANY, 5998 bytes)
[INFO] 2019-01-19 13:26:52,358 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 11.0 (TID 210)
[INFO] 2019-01-19 13:26:52,361 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:52,361 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:52,362 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 11.0 (TID 211)
[INFO] 2019-01-19 13:26:52,367 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:26:52,368 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:52,382 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 11.0 (TID 210). 2723 bytes result sent to driver
[INFO] 2019-01-19 13:26:52,383 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 11.0 (TID 210) in 30 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:26:52,386 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 11.0 (TID 211). 2644 bytes result sent to driver
[INFO] 2019-01-19 13:26:52,386 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 11.0 (TID 211) in 29 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:26:52,387 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:52,387 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 11 (count at LayerSample.scala:60) finished in 0.034 s
[INFO] 2019-01-19 13:26:52,387 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:26:52,387 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:26:52,387 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 12)
[INFO] 2019-01-19 13:26:52,387 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:26:52,388 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 12 (MapPartitionsRDD[47] at count at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:26:52,389 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:26:52,390 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:26:52,391 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_19_piece0 in memory on 192.168.99.1:57817 (size: 3.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:26:52,391 org.apache.spark.SparkContext logInfo - Created broadcast 19 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:26:52,391 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at count at LayerSample.scala:60)
[INFO] 2019-01-19 13:26:52,392 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 12.0 with 1 tasks
[INFO] 2019-01-19 13:26:52,393 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 12.0 (TID 212, localhost, executor driver, partition 0, ANY, 5900 bytes)
[INFO] 2019-01-19 13:26:52,393 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 12.0 (TID 212)
[INFO] 2019-01-19 13:26:52,395 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:26:52,395 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:26:52,398 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 12.0 (TID 212). 1873 bytes result sent to driver
[INFO] 2019-01-19 13:26:52,398 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 12.0 (TID 212) in 6 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:26:52,398 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:26:52,398 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 12 (count at LayerSample.scala:60) finished in 0.006 s
[INFO] 2019-01-19 13:26:52,399 org.apache.spark.scheduler.DAGScheduler logInfo - Job 6 finished: count at LayerSample.scala:60, took 0.181013 s
[WARN] 2019-01-19 13:27:29,521 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored message: HeartbeatResponse(false)
[WARN] 2019-01-19 13:27:29,523 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@6bb912b6,BlockManagerId(driver, 192.168.99.1, 57817, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[INFO] 2019-01-19 13:27:30,874 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:27:30,879 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 13:27:30,880 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:27:30,880 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 13:27:36,205 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5507
[INFO] 2019-01-19 13:27:36,205 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4934
[INFO] 2019-01-19 13:27:36,205 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4935
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4936
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4937
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4938
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4939
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4940
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4941
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4942
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4943
[INFO] 2019-01-19 13:27:36,206 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4944
[INFO] 2019-01-19 13:27:36,207 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4945
[INFO] 2019-01-19 13:27:36,207 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4946
[INFO] 2019-01-19 13:27:36,207 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4947
[INFO] 2019-01-19 13:27:36,207 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4948
[INFO] 2019-01-19 13:27:36,275 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_4_piece0 on 192.168.99.1:57817 in memory (size: 23.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,279 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:27:36,286 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 13:27:36,286 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:27:36,286 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 13:27:36,292 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 13:27:36,295 org.apache.spark.sql.execution.aggregate.HashAggregateExec logInfo - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
[INFO] 2019-01-19 13:27:36,406 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20 stored as values in memory (estimated size 278.7 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:27:36,510 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:27:36,511 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_20_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,512 org.apache.spark.SparkContext logInfo - Created broadcast 20 from show at LayerSample.scala:60
[INFO] 2019-01-19 13:27:36,513 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:27:36,591 org.apache.spark.SparkContext logInfo - Starting job: show at LayerSample.scala:60
[INFO] 2019-01-19 13:27:36,593 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 50 (show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,593 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 7 (show at LayerSample.scala:60) with 1 output partitions
[INFO] 2019-01-19 13:27:36,593 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 14 (show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,594 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 13)
[INFO] 2019-01-19 13:27:36,594 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 13)
[INFO] 2019-01-19 13:27:36,595 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 13 (MapPartitionsRDD[50] at show at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:27:36,596 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21 stored as values in memory (estimated size 17.5 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:27:36,597 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:27:36,598 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_21_piece0 in memory on 192.168.99.1:57817 (size: 8.1 KB, free: 1991.7 MB)
[INFO] 2019-01-19 13:27:36,599 org.apache.spark.SparkContext logInfo - Created broadcast 21 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:36,600 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[50] at show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,600 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 13.0 with 1 tasks
[INFO] 2019-01-19 13:27:36,602 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 13.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:27:36,603 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 13.0 (TID 213)
[INFO] 2019-01-19 13:27:36,629 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:27:36,717 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 1
[INFO] 2019-01-19 13:27:36,751 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_5_piece0 on 192.168.99.1:57817 in memory (size: 6.3 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,765 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_17_piece0 on 192.168.99.1:57817 in memory (size: 5.9 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,767 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_18_piece0 on 192.168.99.1:57817 in memory (size: 13.6 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,768 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_19_piece0 on 192.168.99.1:57817 in memory (size: 3.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,770 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_6_piece0 on 192.168.99.1:57817 in memory (size: 3.7 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,771 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5045
[INFO] 2019-01-19 13:27:36,771 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5046
[INFO] 2019-01-19 13:27:36,771 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5047
[INFO] 2019-01-19 13:27:36,771 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5048
[INFO] 2019-01-19 13:27:36,771 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5049
[INFO] 2019-01-19 13:27:36,773 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_7_piece0 on 192.168.99.1:57817 in memory (size: 25.4 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,774 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_8_piece0 on 192.168.99.1:57817 in memory (size: 10.4 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,776 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5098
[INFO] 2019-01-19 13:27:36,776 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5099
[INFO] 2019-01-19 13:27:36,776 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5100
[INFO] 2019-01-19 13:27:36,776 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5101
[INFO] 2019-01-19 13:27:36,777 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_9_piece0 on 192.168.99.1:57817 in memory (size: 25.4 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:36,779 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_10_piece0 on 192.168.99.1:57817 in memory (size: 9.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,780 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5150
[INFO] 2019-01-19 13:27:36,780 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5151
[INFO] 2019-01-19 13:27:36,780 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5152
[INFO] 2019-01-19 13:27:36,780 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5153
[INFO] 2019-01-19 13:27:36,780 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5154
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5155
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5156
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5157
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5158
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5159
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5160
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5161
[INFO] 2019-01-19 13:27:36,781 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5162
[INFO] 2019-01-19 13:27:36,782 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5163
[INFO] 2019-01-19 13:27:36,782 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5164
[INFO] 2019-01-19 13:27:36,783 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_11_piece0 on 192.168.99.1:57817 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,785 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 2
[INFO] 2019-01-19 13:27:36,788 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_12_piece0 on 192.168.99.1:57817 in memory (size: 6.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,790 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_13_piece0 on 192.168.99.1:57817 in memory (size: 3.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,790 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5261
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5262
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5263
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5264
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5265
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5266
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5267
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5268
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5269
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5270
[INFO] 2019-01-19 13:27:36,791 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5271
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5272
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5273
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5274
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5275
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5276
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5277
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5278
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5279
[INFO] 2019-01-19 13:27:36,792 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5280
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5281
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5282
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5283
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5284
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5285
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5286
[INFO] 2019-01-19 13:27:36,793 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5287
[INFO] 2019-01-19 13:27:36,794 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5288
[INFO] 2019-01-19 13:27:36,794 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5289
[INFO] 2019-01-19 13:27:36,794 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5290
[INFO] 2019-01-19 13:27:36,795 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_14_piece0 on 192.168.99.1:57817 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,795 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 3
[INFO] 2019-01-19 13:27:36,797 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_15_piece0 on 192.168.99.1:57817 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,801 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 4
[INFO] 2019-01-19 13:27:36,802 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 5
[INFO] 2019-01-19 13:27:36,803 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_16_piece0 on 192.168.99.1:57817 in memory (size: 5.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,920 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 13.0 (TID 213). 2440 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,920 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 13.0 (TID 213) in 319 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 13 (show at LayerSample.scala:60) finished in 0.321 s
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 14)
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:27:36,921 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 14 (MapPartitionsRDD[53] at show at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:27:36,922 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22 stored as values in memory (estimated size 18.2 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:36,923 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:36,924 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_22_piece0 in memory on 192.168.99.1:57817 (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,925 org.apache.spark.SparkContext logInfo - Created broadcast 22 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:36,925 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[53] at show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,925 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 14.0 with 1 tasks
[INFO] 2019-01-19 13:27:36,926 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 14.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,926 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 14.0 (TID 214)
[INFO] 2019-01-19 13:27:36,927 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,928 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:36,929 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 14.0 (TID 214). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,929 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 14.0 (TID 214) in 4 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:27:36,929 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:36,929 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 14 (show at LayerSample.scala:60) finished in 0.004 s
[INFO] 2019-01-19 13:27:36,930 org.apache.spark.scheduler.DAGScheduler logInfo - Job 7 finished: show at LayerSample.scala:60, took 0.337541 s
[INFO] 2019-01-19 13:27:36,937 org.apache.spark.SparkContext logInfo - Starting job: show at LayerSample.scala:60
[INFO] 2019-01-19 13:27:36,941 org.apache.spark.MapOutputTrackerMaster logInfo - Size of output statuses for shuffle 6 is 158 bytes
[INFO] 2019-01-19 13:27:36,943 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 8 (show at LayerSample.scala:60) with 4 output partitions
[INFO] 2019-01-19 13:27:36,943 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 16 (show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,943 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 15)
[INFO] 2019-01-19 13:27:36,943 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:27:36,943 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 16 (MapPartitionsRDD[53] at show at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:27:36,944 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23 stored as values in memory (estimated size 18.2 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:36,945 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:36,946 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_23_piece0 in memory on 192.168.99.1:57817 (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,946 org.apache.spark.SparkContext logInfo - Created broadcast 23 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:36,946 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[53] at show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,947 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 16.0 with 4 tasks
[INFO] 2019-01-19 13:27:36,947 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 16.0 (TID 215, localhost, executor driver, partition 1, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,948 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 16.0 (TID 216, localhost, executor driver, partition 2, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,948 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 16.0 (TID 215)
[INFO] 2019-01-19 13:27:36,948 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 16.0 (TID 216)
[INFO] 2019-01-19 13:27:36,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,951 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:36,951 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 16.0 (TID 215). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,952 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 16.0 (TID 217, localhost, executor driver, partition 3, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,952 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 16.0 (TID 216). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,952 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 16.0 (TID 217)
[INFO] 2019-01-19 13:27:36,952 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 16.0 (TID 215) in 5 ms on localhost (executor driver) (1/4)
[INFO] 2019-01-19 13:27:36,953 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 16.0 (TID 218, localhost, executor driver, partition 4, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,954 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,954 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,955 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 16.0 (TID 216) in 8 ms on localhost (executor driver) (2/4)
[INFO] 2019-01-19 13:27:36,955 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 16.0 (TID 218)
[INFO] 2019-01-19 13:27:36,955 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 16.0 (TID 217). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,956 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 16.0 (TID 217) in 5 ms on localhost (executor driver) (3/4)
[INFO] 2019-01-19 13:27:36,957 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,957 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,958 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 16.0 (TID 218). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,959 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 16.0 (TID 218) in 6 ms on localhost (executor driver) (4/4)
[INFO] 2019-01-19 13:27:36,959 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 16.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:36,959 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 16 (show at LayerSample.scala:60) finished in 0.012 s
[INFO] 2019-01-19 13:27:36,960 org.apache.spark.scheduler.DAGScheduler logInfo - Job 8 finished: show at LayerSample.scala:60, took 0.022509 s
[INFO] 2019-01-19 13:27:36,963 org.apache.spark.SparkContext logInfo - Starting job: show at LayerSample.scala:60
[INFO] 2019-01-19 13:27:36,964 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 9 (show at LayerSample.scala:60) with 20 output partitions
[INFO] 2019-01-19 13:27:36,964 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 18 (show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,964 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 17)
[INFO] 2019-01-19 13:27:36,964 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:27:36,964 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 18 (MapPartitionsRDD[53] at show at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:27:36,966 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24 stored as values in memory (estimated size 18.2 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:36,968 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:36,968 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_24_piece0 in memory on 192.168.99.1:57817 (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:36,969 org.apache.spark.SparkContext logInfo - Created broadcast 24 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:36,969 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 20 missing tasks from ResultStage 18 (MapPartitionsRDD[53] at show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:36,969 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 18.0 with 20 tasks
[INFO] 2019-01-19 13:27:36,970 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 18.0 (TID 219, localhost, executor driver, partition 5, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,971 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 18.0 (TID 220, localhost, executor driver, partition 6, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,971 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 18.0 (TID 219)
[INFO] 2019-01-19 13:27:36,971 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 18.0 (TID 220)
[INFO] 2019-01-19 13:27:36,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,974 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 18.0 (TID 219). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,974 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 18.0 (TID 220). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,975 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 18.0 (TID 221, localhost, executor driver, partition 7, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,975 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 18.0 (TID 221)
[INFO] 2019-01-19 13:27:36,976 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 18.0 (TID 222, localhost, executor driver, partition 8, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,976 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 18.0 (TID 220) in 6 ms on localhost (executor driver) (1/20)
[INFO] 2019-01-19 13:27:36,977 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 18.0 (TID 219) in 8 ms on localhost (executor driver) (2/20)
[INFO] 2019-01-19 13:27:36,977 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 18.0 (TID 222)
[INFO] 2019-01-19 13:27:36,977 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:36,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,980 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:36,981 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 18.0 (TID 222). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,982 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 18.0 (TID 221). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,983 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 18.0 (TID 223, localhost, executor driver, partition 9, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,983 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 18.0 (TID 224, localhost, executor driver, partition 10, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,984 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 18.0 (TID 222) in 9 ms on localhost (executor driver) (3/20)
[INFO] 2019-01-19 13:27:36,984 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 18.0 (TID 221) in 9 ms on localhost (executor driver) (4/20)
[INFO] 2019-01-19 13:27:36,984 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 18.0 (TID 223)
[INFO] 2019-01-19 13:27:36,984 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 18.0 (TID 224)
[INFO] 2019-01-19 13:27:36,986 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,986 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,987 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,987 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,987 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 18.0 (TID 223). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,988 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 18.0 (TID 225, localhost, executor driver, partition 11, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,989 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 18.0 (TID 223) in 6 ms on localhost (executor driver) (5/20)
[INFO] 2019-01-19 13:27:36,989 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 18.0 (TID 225)
[INFO] 2019-01-19 13:27:36,989 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 18.0 (TID 224). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,990 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 18.0 (TID 226, localhost, executor driver, partition 12, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,990 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 18.0 (TID 224) in 7 ms on localhost (executor driver) (6/20)
[INFO] 2019-01-19 13:27:36,991 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 18.0 (TID 226)
[INFO] 2019-01-19 13:27:36,991 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,991 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,992 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 18.0 (TID 225). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,993 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,993 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:36,993 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 18.0 (TID 227, localhost, executor driver, partition 13, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,994 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 18.0 (TID 226). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,994 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 18.0 (TID 227)
[INFO] 2019-01-19 13:27:36,994 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 18.0 (TID 225) in 6 ms on localhost (executor driver) (7/20)
[INFO] 2019-01-19 13:27:36,995 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 18.0 (TID 228, localhost, executor driver, partition 14, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,996 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 18.0 (TID 226) in 6 ms on localhost (executor driver) (8/20)
[INFO] 2019-01-19 13:27:36,996 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 18.0 (TID 228)
[INFO] 2019-01-19 13:27:36,996 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,996 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,997 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 18.0 (TID 227). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,998 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 18.0 (TID 229, localhost, executor driver, partition 15, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:36,998 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:36,998 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:36,998 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 18.0 (TID 229)
[INFO] 2019-01-19 13:27:36,999 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 18.0 (TID 228). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:36,998 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 18.0 (TID 227) in 5 ms on localhost (executor driver) (9/20)
[INFO] 2019-01-19 13:27:37,000 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,000 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,000 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 18.0 (TID 230, localhost, executor driver, partition 16, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,001 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 18.0 (TID 228) in 6 ms on localhost (executor driver) (10/20)
[INFO] 2019-01-19 13:27:37,002 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 18.0 (TID 229). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,002 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 18.0 (TID 230)
[INFO] 2019-01-19 13:27:37,002 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 18.0 (TID 231, localhost, executor driver, partition 17, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,003 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 18.0 (TID 229) in 5 ms on localhost (executor driver) (11/20)
[INFO] 2019-01-19 13:27:37,003 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 18.0 (TID 231)
[INFO] 2019-01-19 13:27:37,004 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,004 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,005 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 18.0 (TID 230). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,005 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,005 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,006 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 18.0 (TID 232, localhost, executor driver, partition 18, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,006 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 18.0 (TID 231). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,006 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 18.0 (TID 232)
[INFO] 2019-01-19 13:27:37,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 18.0 (TID 230) in 6 ms on localhost (executor driver) (12/20)
[INFO] 2019-01-19 13:27:37,007 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 18.0 (TID 233, localhost, executor driver, partition 19, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,008 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 18.0 (TID 231) in 6 ms on localhost (executor driver) (13/20)
[INFO] 2019-01-19 13:27:37,008 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 18.0 (TID 233)
[INFO] 2019-01-19 13:27:37,008 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,009 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,010 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 18.0 (TID 232). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,011 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 18.0 (TID 234, localhost, executor driver, partition 20, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,011 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 18.0 (TID 233). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,011 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 18.0 (TID 234)
[INFO] 2019-01-19 13:27:37,011 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 18.0 (TID 232) in 6 ms on localhost (executor driver) (14/20)
[INFO] 2019-01-19 13:27:37,013 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 18.0 (TID 235, localhost, executor driver, partition 21, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,013 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,013 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,013 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 18.0 (TID 235)
[INFO] 2019-01-19 13:27:37,015 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 18.0 (TID 234). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,013 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 18.0 (TID 233) in 6 ms on localhost (executor driver) (15/20)
[INFO] 2019-01-19 13:27:37,016 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 18.0 (TID 236, localhost, executor driver, partition 22, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,016 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 18.0 (TID 236)
[INFO] 2019-01-19 13:27:37,017 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,015 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,026 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 11 ms
[INFO] 2019-01-19 13:27:37,027 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 18.0 (TID 235). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,016 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 18.0 (TID 234) in 6 ms on localhost (executor driver) (16/20)
[INFO] 2019-01-19 13:27:37,028 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 18.0 (TID 237, localhost, executor driver, partition 23, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,030 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 18.0 (TID 237)
[INFO] 2019-01-19 13:27:37,030 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 18.0 (TID 235) in 18 ms on localhost (executor driver) (17/20)
[INFO] 2019-01-19 13:27:37,031 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,031 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,033 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 18.0 (TID 237). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,033 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 18.0 (TID 238, localhost, executor driver, partition 24, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,034 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 18.0 (TID 237) in 6 ms on localhost (executor driver) (18/20)
[INFO] 2019-01-19 13:27:37,036 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 18.0 (TID 238)
[INFO] 2019-01-19 13:27:37,038 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,039 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,040 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 18.0 (TID 238). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,041 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 18.0 (TID 238) in 8 ms on localhost (executor driver) (19/20)
[INFO] 2019-01-19 13:27:37,042 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 25 ms
[INFO] 2019-01-19 13:27:37,043 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 18.0 (TID 236). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,046 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 18.0 (TID 236) in 31 ms on localhost (executor driver) (20/20)
[INFO] 2019-01-19 13:27:37,046 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 18.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:37,047 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 18 (show at LayerSample.scala:60) finished in 0.078 s
[INFO] 2019-01-19 13:27:37,048 org.apache.spark.scheduler.DAGScheduler logInfo - Job 9 finished: show at LayerSample.scala:60, took 0.084787 s
[INFO] 2019-01-19 13:27:37,053 org.apache.spark.SparkContext logInfo - Starting job: show at LayerSample.scala:60
[INFO] 2019-01-19 13:27:37,055 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 10 (show at LayerSample.scala:60) with 100 output partitions
[INFO] 2019-01-19 13:27:37,055 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 20 (show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:37,055 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 19)
[INFO] 2019-01-19 13:27:37,055 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:27:37,055 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 20 (MapPartitionsRDD[53] at show at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:27:37,059 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25 stored as values in memory (estimated size 18.2 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:37,061 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1991.3 MB)
[INFO] 2019-01-19 13:27:37,063 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_25_piece0 in memory on 192.168.99.1:57817 (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:37,064 org.apache.spark.SparkContext logInfo - Created broadcast 25 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:37,064 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 100 missing tasks from ResultStage 20 (MapPartitionsRDD[53] at show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:37,068 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 20.0 with 100 tasks
[INFO] 2019-01-19 13:27:37,070 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 20.0 (TID 239, localhost, executor driver, partition 25, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,071 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 20.0 (TID 240, localhost, executor driver, partition 26, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,071 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 20.0 (TID 239)
[INFO] 2019-01-19 13:27:37,071 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 20.0 (TID 240)
[INFO] 2019-01-19 13:27:37,073 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,073 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,074 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 20.0 (TID 239). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,074 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,075 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,075 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 20.0 (TID 241, localhost, executor driver, partition 27, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,075 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 20.0 (TID 239) in 6 ms on localhost (executor driver) (1/100)
[INFO] 2019-01-19 13:27:37,076 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 20.0 (TID 241)
[INFO] 2019-01-19 13:27:37,076 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 20.0 (TID 240). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,077 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 20.0 (TID 242, localhost, executor driver, partition 28, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,077 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,077 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,078 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 20.0 (TID 242)
[INFO] 2019-01-19 13:27:37,079 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 20.0 (TID 241). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,077 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 20.0 (TID 240) in 7 ms on localhost (executor driver) (2/100)
[INFO] 2019-01-19 13:27:37,080 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 20.0 (TID 243, localhost, executor driver, partition 29, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,081 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 20.0 (TID 243)
[INFO] 2019-01-19 13:27:37,081 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 20.0 (TID 242). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,080 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 20.0 (TID 241) in 6 ms on localhost (executor driver) (3/100)
[INFO] 2019-01-19 13:27:37,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,083 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 20.0 (TID 244, localhost, executor driver, partition 30, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,084 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 20.0 (TID 242) in 8 ms on localhost (executor driver) (4/100)
[INFO] 2019-01-19 13:27:37,084 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 20.0 (TID 244)
[INFO] 2019-01-19 13:27:37,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,084 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 20.0 (TID 243). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,087 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 20.0 (TID 245, localhost, executor driver, partition 31, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,087 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 20.0 (TID 244). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,087 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 20.0 (TID 245)
[INFO] 2019-01-19 13:27:37,087 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 20.0 (TID 243) in 8 ms on localhost (executor driver) (5/100)
[INFO] 2019-01-19 13:27:37,088 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 20.0 (TID 246, localhost, executor driver, partition 32, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,088 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 20.0 (TID 244) in 6 ms on localhost (executor driver) (6/100)
[INFO] 2019-01-19 13:27:37,089 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,089 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,089 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 20.0 (TID 246)
[INFO] 2019-01-19 13:27:37,090 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 20.0 (TID 245). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,091 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 20.0 (TID 247, localhost, executor driver, partition 33, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,091 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 20.0 (TID 245) in 4 ms on localhost (executor driver) (7/100)
[INFO] 2019-01-19 13:27:37,091 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 20.0 (TID 247)
[INFO] 2019-01-19 13:27:37,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,095 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 20.0 (TID 247). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,095 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 20.0 (TID 248, localhost, executor driver, partition 34, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,096 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 20.0 (TID 246). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,097 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 20.0 (TID 249, localhost, executor driver, partition 35, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,097 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 20.0 (TID 247) in 7 ms on localhost (executor driver) (8/100)
[INFO] 2019-01-19 13:27:37,098 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 20.0 (TID 246) in 10 ms on localhost (executor driver) (9/100)
[INFO] 2019-01-19 13:27:37,098 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 20.0 (TID 248)
[INFO] 2019-01-19 13:27:37,099 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 20.0 (TID 249)
[INFO] 2019-01-19 13:27:37,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,100 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,101 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 20.0 (TID 248). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,101 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,101 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,102 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 20.0 (TID 249). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,103 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 20.0 (TID 250, localhost, executor driver, partition 36, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,103 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 20.0 (TID 251, localhost, executor driver, partition 37, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,104 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 20.0 (TID 248) in 9 ms on localhost (executor driver) (10/100)
[INFO] 2019-01-19 13:27:37,104 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 20.0 (TID 249) in 7 ms on localhost (executor driver) (11/100)
[INFO] 2019-01-19 13:27:37,104 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 20.0 (TID 250)
[INFO] 2019-01-19 13:27:37,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,107 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 20.0 (TID 251)
[INFO] 2019-01-19 13:27:37,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,109 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 20.0 (TID 250). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,111 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 20.0 (TID 252, localhost, executor driver, partition 38, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,112 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 20.0 (TID 250) in 10 ms on localhost (executor driver) (12/100)
[INFO] 2019-01-19 13:27:37,112 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 20.0 (TID 252)
[INFO] 2019-01-19 13:27:37,114 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,115 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,116 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 20.0 (TID 252). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,117 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 20.0 (TID 253, localhost, executor driver, partition 39, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,117 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 20.0 (TID 252) in 7 ms on localhost (executor driver) (13/100)
[INFO] 2019-01-19 13:27:37,118 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 20.0 (TID 253)
[INFO] 2019-01-19 13:27:37,121 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,121 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,123 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 20.0 (TID 253). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,125 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 20.0 (TID 254, localhost, executor driver, partition 40, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,125 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 20.0 (TID 253) in 8 ms on localhost (executor driver) (14/100)
[INFO] 2019-01-19 13:27:37,126 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 20.0 (TID 254)
[INFO] 2019-01-19 13:27:37,128 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,128 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,130 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 20.0 (TID 254). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,140 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 20.0 (TID 255, localhost, executor driver, partition 41, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,145 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 20.0 (TID 254) in 20 ms on localhost (executor driver) (15/100)
[INFO] 2019-01-19 13:27:37,148 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 20.0 (TID 255)
[INFO] 2019-01-19 13:27:37,150 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,150 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,152 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 20.0 (TID 255). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,153 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 20.0 (TID 256, localhost, executor driver, partition 42, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,154 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 20.0 (TID 255) in 24 ms on localhost (executor driver) (16/100)
[INFO] 2019-01-19 13:27:37,154 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 20.0 (TID 256)
[INFO] 2019-01-19 13:27:37,181 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 20.0 (TID 251). 2855 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,182 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 20.0 (TID 257, localhost, executor driver, partition 44, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,182 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 20.0 (TID 251) in 79 ms on localhost (executor driver) (17/100)
[INFO] 2019-01-19 13:27:37,184 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 20.0 (TID 257)
[INFO] 2019-01-19 13:27:37,187 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,187 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,188 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 20.0 (TID 257). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,189 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 20.0 (TID 258, localhost, executor driver, partition 45, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,189 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 20.0 (TID 257) in 7 ms on localhost (executor driver) (18/100)
[INFO] 2019-01-19 13:27:37,190 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 20.0 (TID 258)
[INFO] 2019-01-19 13:27:37,191 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,192 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,193 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 20.0 (TID 258). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,194 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 20.0 (TID 259, localhost, executor driver, partition 46, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,194 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 20.0 (TID 259)
[INFO] 2019-01-19 13:27:37,194 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 20.0 (TID 258) in 6 ms on localhost (executor driver) (19/100)
[INFO] 2019-01-19 13:27:37,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,197 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 20.0 (TID 259). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,197 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 20.0 (TID 260, localhost, executor driver, partition 47, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,198 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 20.0 (TID 259) in 5 ms on localhost (executor driver) (20/100)
[INFO] 2019-01-19 13:27:37,198 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 20.0 (TID 260)
[INFO] 2019-01-19 13:27:37,199 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,199 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,200 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,200 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,201 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 20.0 (TID 260). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,201 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 20.0 (TID 261, localhost, executor driver, partition 48, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,201 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 20.0 (TID 256). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,202 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 20.0 (TID 260) in 5 ms on localhost (executor driver) (21/100)
[INFO] 2019-01-19 13:27:37,202 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 20.0 (TID 262, localhost, executor driver, partition 49, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,202 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 20.0 (TID 261)
[INFO] 2019-01-19 13:27:37,203 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 20.0 (TID 256) in 50 ms on localhost (executor driver) (22/100)
[INFO] 2019-01-19 13:27:37,204 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 20.0 (TID 262)
[INFO] 2019-01-19 13:27:37,205 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,205 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,207 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 20.0 (TID 262). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,207 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 20.0 (TID 263, localhost, executor driver, partition 50, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,208 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 20.0 (TID 262) in 6 ms on localhost (executor driver) (23/100)
[INFO] 2019-01-19 13:27:37,209 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 20.0 (TID 263)
[INFO] 2019-01-19 13:27:37,210 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 20.0 (TID 261). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,211 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,213 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 20.0 (TID 263). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,214 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 20.0 (TID 264, localhost, executor driver, partition 51, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,214 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 20.0 (TID 265, localhost, executor driver, partition 52, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,215 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 20.0 (TID 264)
[INFO] 2019-01-19 13:27:37,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,222 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 20.0 (TID 264). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,215 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 20.0 (TID 265)
[INFO] 2019-01-19 13:27:37,215 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 20.0 (TID 261) in 14 ms on localhost (executor driver) (24/100)
[INFO] 2019-01-19 13:27:37,223 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 20.0 (TID 266, localhost, executor driver, partition 53, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,224 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 20.0 (TID 263) in 17 ms on localhost (executor driver) (25/100)
[INFO] 2019-01-19 13:27:37,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,226 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 20.0 (TID 264) in 12 ms on localhost (executor driver) (26/100)
[INFO] 2019-01-19 13:27:37,227 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 20.0 (TID 266)
[INFO] 2019-01-19 13:27:37,227 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 20.0 (TID 265). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,229 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,229 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,230 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 20.0 (TID 266). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,231 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 20.0 (TID 267, localhost, executor driver, partition 54, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,231 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 20.0 (TID 268, localhost, executor driver, partition 55, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,232 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 20.0 (TID 265) in 18 ms on localhost (executor driver) (27/100)
[INFO] 2019-01-19 13:27:37,232 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 20.0 (TID 266) in 9 ms on localhost (executor driver) (28/100)
[INFO] 2019-01-19 13:27:37,233 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 20.0 (TID 267)
[INFO] 2019-01-19 13:27:37,233 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 20.0 (TID 268)
[INFO] 2019-01-19 13:27:37,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,234 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,235 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,235 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,238 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 20.0 (TID 268). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,238 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 20.0 (TID 269, localhost, executor driver, partition 56, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,236 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 20.0 (TID 267). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,239 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 20.0 (TID 270, localhost, executor driver, partition 57, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,239 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 20.0 (TID 268) in 8 ms on localhost (executor driver) (29/100)
[INFO] 2019-01-19 13:27:37,240 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 20.0 (TID 269)
[INFO] 2019-01-19 13:27:37,240 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 20.0 (TID 270)
[INFO] 2019-01-19 13:27:37,241 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,241 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,242 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 20.0 (TID 269). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,244 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,245 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 20.0 (TID 270). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,240 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 20.0 (TID 267) in 11 ms on localhost (executor driver) (30/100)
[INFO] 2019-01-19 13:27:37,246 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 20.0 (TID 271, localhost, executor driver, partition 58, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,247 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 20.0 (TID 272, localhost, executor driver, partition 59, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,247 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 20.0 (TID 269) in 9 ms on localhost (executor driver) (31/100)
[INFO] 2019-01-19 13:27:37,247 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 20.0 (TID 270) in 8 ms on localhost (executor driver) (32/100)
[INFO] 2019-01-19 13:27:37,247 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 20.0 (TID 271)
[INFO] 2019-01-19 13:27:37,248 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 20.0 (TID 272)
[INFO] 2019-01-19 13:27:37,250 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,250 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,251 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 20.0 (TID 271). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,252 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,252 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,253 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 20.0 (TID 272). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,253 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 20.0 (TID 273, localhost, executor driver, partition 60, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,254 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 20.0 (TID 274, localhost, executor driver, partition 61, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,254 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 20.0 (TID 273)
[INFO] 2019-01-19 13:27:37,255 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 20.0 (TID 274)
[INFO] 2019-01-19 13:27:37,254 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 20.0 (TID 271) in 8 ms on localhost (executor driver) (33/100)
[INFO] 2019-01-19 13:27:37,256 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 20.0 (TID 272) in 10 ms on localhost (executor driver) (34/100)
[INFO] 2019-01-19 13:27:37,257 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,257 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,257 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,257 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,258 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 20.0 (TID 273). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,258 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 20.0 (TID 274). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,258 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 20.0 (TID 275, localhost, executor driver, partition 62, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,259 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 20.0 (TID 275)
[INFO] 2019-01-19 13:27:37,259 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 20.0 (TID 276, localhost, executor driver, partition 63, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,259 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 20.0 (TID 274) in 5 ms on localhost (executor driver) (35/100)
[INFO] 2019-01-19 13:27:37,260 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,261 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,261 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 20.0 (TID 276)
[INFO] 2019-01-19 13:27:37,262 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 20.0 (TID 275). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,263 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,263 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,261 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 20.0 (TID 273) in 8 ms on localhost (executor driver) (36/100)
[INFO] 2019-01-19 13:27:37,264 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 20.0 (TID 277, localhost, executor driver, partition 64, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,264 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 20.0 (TID 276). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,264 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 20.0 (TID 275) in 6 ms on localhost (executor driver) (37/100)
[INFO] 2019-01-19 13:27:37,265 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 20.0 (TID 277)
[INFO] 2019-01-19 13:27:37,265 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 20.0 (TID 278, localhost, executor driver, partition 65, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,265 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 20.0 (TID 278)
[INFO] 2019-01-19 13:27:37,265 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 20.0 (TID 276) in 6 ms on localhost (executor driver) (38/100)
[INFO] 2019-01-19 13:27:37,267 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,267 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,267 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,267 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,268 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 20.0 (TID 278). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,269 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 20.0 (TID 279, localhost, executor driver, partition 66, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,269 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 20.0 (TID 279)
[INFO] 2019-01-19 13:27:37,269 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 20.0 (TID 278) in 4 ms on localhost (executor driver) (39/100)
[INFO] 2019-01-19 13:27:37,271 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,271 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,272 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 20.0 (TID 277). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,272 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 20.0 (TID 279). 2599 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,272 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 20.0 (TID 280, localhost, executor driver, partition 67, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,273 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 20.0 (TID 280)
[INFO] 2019-01-19 13:27:37,273 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 20.0 (TID 281, localhost, executor driver, partition 68, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,274 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 20.0 (TID 279) in 5 ms on localhost (executor driver) (40/100)
[INFO] 2019-01-19 13:27:37,274 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 20.0 (TID 277) in 10 ms on localhost (executor driver) (41/100)
[INFO] 2019-01-19 13:27:37,274 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,274 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,274 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 20.0 (TID 281)
[INFO] 2019-01-19 13:27:37,275 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 20.0 (TID 280). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,276 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,277 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,276 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 20.0 (TID 282, localhost, executor driver, partition 69, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,278 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 20.0 (TID 281). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,278 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 20.0 (TID 282)
[INFO] 2019-01-19 13:27:37,281 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,282 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:27:37,278 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 20.0 (TID 280) in 6 ms on localhost (executor driver) (42/100)
[INFO] 2019-01-19 13:27:37,284 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 20.0 (TID 282). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,285 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 20.0 (TID 283, localhost, executor driver, partition 70, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,286 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 20.0 (TID 284, localhost, executor driver, partition 71, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,286 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 20.0 (TID 283)
[INFO] 2019-01-19 13:27:37,287 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,288 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 20.0 (TID 282) in 12 ms on localhost (executor driver) (43/100)
[INFO] 2019-01-19 13:27:37,289 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 20.0 (TID 284)
[INFO] 2019-01-19 13:27:37,289 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 20.0 (TID 281) in 16 ms on localhost (executor driver) (44/100)
[INFO] 2019-01-19 13:27:37,289 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 20.0 (TID 283). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,290 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 20.0 (TID 285, localhost, executor driver, partition 72, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,290 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,291 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 20.0 (TID 283) in 8 ms on localhost (executor driver) (45/100)
[INFO] 2019-01-19 13:27:37,291 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 20.0 (TID 285)
[INFO] 2019-01-19 13:27:37,291 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,294 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,294 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,296 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 20.0 (TID 285). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,296 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 20.0 (TID 286, localhost, executor driver, partition 73, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,297 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 20.0 (TID 285) in 7 ms on localhost (executor driver) (46/100)
[INFO] 2019-01-19 13:27:37,297 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 20.0 (TID 286)
[INFO] 2019-01-19 13:27:37,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,301 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 20.0 (TID 286). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,301 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 20.0 (TID 287, localhost, executor driver, partition 74, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,302 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 20.0 (TID 287)
[INFO] 2019-01-19 13:27:37,302 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 20.0 (TID 286) in 6 ms on localhost (executor driver) (47/100)
[INFO] 2019-01-19 13:27:37,302 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 20.0 (TID 284). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,303 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 20.0 (TID 288, localhost, executor driver, partition 75, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,303 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,303 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,303 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 20.0 (TID 284) in 18 ms on localhost (executor driver) (48/100)
[INFO] 2019-01-19 13:27:37,304 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 20.0 (TID 288)
[INFO] 2019-01-19 13:27:37,305 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 20.0 (TID 287). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,305 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 20.0 (TID 289, localhost, executor driver, partition 76, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,305 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 20.0 (TID 289)
[INFO] 2019-01-19 13:27:37,305 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 20.0 (TID 287) in 4 ms on localhost (executor driver) (49/100)
[INFO] 2019-01-19 13:27:37,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,308 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,310 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 20.0 (TID 288). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,311 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 20.0 (TID 289). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,312 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 20.0 (TID 290, localhost, executor driver, partition 77, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,312 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 20.0 (TID 290)
[INFO] 2019-01-19 13:27:37,312 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 20.0 (TID 291, localhost, executor driver, partition 78, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 20.0 (TID 288) in 17 ms on localhost (executor driver) (50/100)
[INFO] 2019-01-19 13:27:37,317 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:27:37,323 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 20.0 (TID 290). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,324 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 20.0 (TID 289) in 19 ms on localhost (executor driver) (51/100)
[INFO] 2019-01-19 13:27:37,325 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 20.0 (TID 292, localhost, executor driver, partition 79, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,324 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 20.0 (TID 291)
[INFO] 2019-01-19 13:27:37,329 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,329 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,331 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 20.0 (TID 291). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,331 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 20.0 (TID 290) in 20 ms on localhost (executor driver) (52/100)
[INFO] 2019-01-19 13:27:37,332 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 20.0 (TID 292)
[INFO] 2019-01-19 13:27:37,333 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 20.0 (TID 293, localhost, executor driver, partition 80, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,334 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 20.0 (TID 291) in 22 ms on localhost (executor driver) (53/100)
[INFO] 2019-01-19 13:27:37,334 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 20.0 (TID 293)
[INFO] 2019-01-19 13:27:37,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,335 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,349 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,350 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:27:37,356 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 20.0 (TID 293). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,361 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 20.0 (TID 294, localhost, executor driver, partition 81, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,362 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 20.0 (TID 292). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,363 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 20.0 (TID 293) in 31 ms on localhost (executor driver) (54/100)
[INFO] 2019-01-19 13:27:37,363 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 20.0 (TID 294)
[INFO] 2019-01-19 13:27:37,367 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,368 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,368 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 20.0 (TID 295, localhost, executor driver, partition 82, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,370 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 20.0 (TID 294). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,370 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 20.0 (TID 292) in 46 ms on localhost (executor driver) (55/100)
[INFO] 2019-01-19 13:27:37,370 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 20.0 (TID 295)
[INFO] 2019-01-19 13:27:37,371 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 20.0 (TID 296, localhost, executor driver, partition 83, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,371 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 20.0 (TID 294) in 11 ms on localhost (executor driver) (56/100)
[INFO] 2019-01-19 13:27:37,372 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 20.0 (TID 296)
[INFO] 2019-01-19 13:27:37,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,373 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,374 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 20.0 (TID 296). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,375 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 20.0 (TID 297, localhost, executor driver, partition 84, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,375 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 20.0 (TID 297)
[INFO] 2019-01-19 13:27:37,375 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 20.0 (TID 296) in 4 ms on localhost (executor driver) (57/100)
[INFO] 2019-01-19 13:27:37,377 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 20.0 (TID 295). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,377 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,378 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,378 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 20.0 (TID 298, localhost, executor driver, partition 85, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,378 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 20.0 (TID 295) in 14 ms on localhost (executor driver) (58/100)
[INFO] 2019-01-19 13:27:37,379 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 20.0 (TID 297). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,378 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 20.0 (TID 298)
[INFO] 2019-01-19 13:27:37,380 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 20.0 (TID 299, localhost, executor driver, partition 86, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,380 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 20.0 (TID 299)
[INFO] 2019-01-19 13:27:37,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,383 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,383 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 20.0 (TID 298). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,381 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 20.0 (TID 297) in 7 ms on localhost (executor driver) (59/100)
[INFO] 2019-01-19 13:27:37,384 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 20.0 (TID 299). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,384 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 20.0 (TID 300, localhost, executor driver, partition 87, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,385 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 20.0 (TID 300)
[INFO] 2019-01-19 13:27:37,385 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 20.0 (TID 301, localhost, executor driver, partition 88, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,385 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 20.0 (TID 298) in 8 ms on localhost (executor driver) (60/100)
[INFO] 2019-01-19 13:27:37,386 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 20.0 (TID 301)
[INFO] 2019-01-19 13:27:37,386 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 20.0 (TID 299) in 6 ms on localhost (executor driver) (61/100)
[INFO] 2019-01-19 13:27:37,386 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,387 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,388 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 20.0 (TID 300). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,389 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,389 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 20.0 (TID 302, localhost, executor driver, partition 89, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,389 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 20.0 (TID 300) in 5 ms on localhost (executor driver) (62/100)
[INFO] 2019-01-19 13:27:37,389 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 20.0 (TID 302)
[INFO] 2019-01-19 13:27:37,391 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 20.0 (TID 301). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,391 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 20.0 (TID 303, localhost, executor driver, partition 90, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,392 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 20.0 (TID 301) in 8 ms on localhost (executor driver) (63/100)
[INFO] 2019-01-19 13:27:37,392 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,393 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 20.0 (TID 303)
[INFO] 2019-01-19 13:27:37,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,398 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 20.0 (TID 303). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,399 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 20.0 (TID 302). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,400 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 20.0 (TID 304, localhost, executor driver, partition 91, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,400 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 20.0 (TID 304)
[INFO] 2019-01-19 13:27:37,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 20.0 (TID 305, localhost, executor driver, partition 92, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,404 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 20.0 (TID 303) in 13 ms on localhost (executor driver) (64/100)
[INFO] 2019-01-19 13:27:37,404 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 20.0 (TID 302) in 16 ms on localhost (executor driver) (65/100)
[INFO] 2019-01-19 13:27:37,405 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 20.0 (TID 305)
[INFO] 2019-01-19 13:27:37,408 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,408 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,410 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 20.0 (TID 305). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,411 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 20.0 (TID 306, localhost, executor driver, partition 93, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,412 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 20.0 (TID 306)
[INFO] 2019-01-19 13:27:37,412 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 20.0 (TID 305) in 12 ms on localhost (executor driver) (66/100)
[INFO] 2019-01-19 13:27:37,415 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,415 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,417 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 20.0 (TID 306). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,418 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 20.0 (TID 307, localhost, executor driver, partition 94, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,418 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 20.0 (TID 306) in 7 ms on localhost (executor driver) (67/100)
[INFO] 2019-01-19 13:27:37,418 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 20.0 (TID 307)
[INFO] 2019-01-19 13:27:37,420 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 20.0 (TID 304). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,421 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,421 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,424 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 20.0 (TID 307). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,424 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 20.0 (TID 308, localhost, executor driver, partition 95, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,425 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 20.0 (TID 304) in 26 ms on localhost (executor driver) (68/100)
[INFO] 2019-01-19 13:27:37,425 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 20.0 (TID 308)
[INFO] 2019-01-19 13:27:37,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,430 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 20.0 (TID 309, localhost, executor driver, partition 96, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,431 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 20.0 (TID 308). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,431 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 20.0 (TID 307) in 13 ms on localhost (executor driver) (69/100)
[INFO] 2019-01-19 13:27:37,432 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 20.0 (TID 310, localhost, executor driver, partition 97, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,433 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 20.0 (TID 309)
[INFO] 2019-01-19 13:27:37,434 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 20.0 (TID 308) in 11 ms on localhost (executor driver) (70/100)
[INFO] 2019-01-19 13:27:37,436 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 20.0 (TID 310)
[INFO] 2019-01-19 13:27:37,435 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:27:37,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,440 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,440 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 20.0 (TID 309). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,441 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 20.0 (TID 310). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,442 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 20.0 (TID 311, localhost, executor driver, partition 98, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,444 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 20.0 (TID 312, localhost, executor driver, partition 99, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,445 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 20.0 (TID 310) in 12 ms on localhost (executor driver) (71/100)
[INFO] 2019-01-19 13:27:37,445 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 20.0 (TID 309) in 17 ms on localhost (executor driver) (72/100)
[INFO] 2019-01-19 13:27:37,445 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 20.0 (TID 312)
[INFO] 2019-01-19 13:27:37,444 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 20.0 (TID 311)
[INFO] 2019-01-19 13:27:37,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,451 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 20.0 (TID 311). 2773 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,451 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 20.0 (TID 312). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,452 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 20.0 (TID 313, localhost, executor driver, partition 100, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,453 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 20.0 (TID 314, localhost, executor driver, partition 101, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,453 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 20.0 (TID 311) in 11 ms on localhost (executor driver) (73/100)
[INFO] 2019-01-19 13:27:37,454 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 20.0 (TID 313)
[INFO] 2019-01-19 13:27:37,454 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 20.0 (TID 312) in 11 ms on localhost (executor driver) (74/100)
[INFO] 2019-01-19 13:27:37,454 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 20.0 (TID 314)
[INFO] 2019-01-19 13:27:37,457 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,458 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,458 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,461 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 20.0 (TID 313). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,462 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 20.0 (TID 314). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,463 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 20.0 (TID 315, localhost, executor driver, partition 102, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,466 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 20.0 (TID 316, localhost, executor driver, partition 103, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,468 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 20.0 (TID 313) in 16 ms on localhost (executor driver) (75/100)
[INFO] 2019-01-19 13:27:37,468 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 20.0 (TID 314) in 15 ms on localhost (executor driver) (76/100)
[INFO] 2019-01-19 13:27:37,469 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 20.0 (TID 315)
[INFO] 2019-01-19 13:27:37,470 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 20.0 (TID 316)
[INFO] 2019-01-19 13:27:37,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,474 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 20.0 (TID 315). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,475 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 20.0 (TID 317, localhost, executor driver, partition 104, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,476 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:27:37,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 20.0 (TID 315) in 14 ms on localhost (executor driver) (77/100)
[INFO] 2019-01-19 13:27:37,478 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 20.0 (TID 316). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,478 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 20.0 (TID 317)
[INFO] 2019-01-19 13:27:37,481 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 20.0 (TID 318, localhost, executor driver, partition 105, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,482 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,482 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 20.0 (TID 316) in 18 ms on localhost (executor driver) (78/100)
[INFO] 2019-01-19 13:27:37,483 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 20.0 (TID 317). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,484 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 20.0 (TID 318)
[INFO] 2019-01-19 13:27:37,485 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 20.0 (TID 319, localhost, executor driver, partition 106, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,487 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,488 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,488 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 20.0 (TID 317) in 13 ms on localhost (executor driver) (79/100)
[INFO] 2019-01-19 13:27:37,489 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 20.0 (TID 318). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,490 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 20.0 (TID 319)
[INFO] 2019-01-19 13:27:37,500 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,506 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 6 ms
[INFO] 2019-01-19 13:27:37,510 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 20.0 (TID 319). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,511 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 20.0 (TID 320, localhost, executor driver, partition 107, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,512 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 20.0 (TID 321, localhost, executor driver, partition 108, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,514 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 20.0 (TID 318) in 33 ms on localhost (executor driver) (80/100)
[INFO] 2019-01-19 13:27:37,516 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 20.0 (TID 320)
[INFO] 2019-01-19 13:27:37,519 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,520 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,516 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 20.0 (TID 321)
[INFO] 2019-01-19 13:27:37,516 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 20.0 (TID 319) in 31 ms on localhost (executor driver) (81/100)
[INFO] 2019-01-19 13:27:37,522 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,524 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 20.0 (TID 320). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,524 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 20.0 (TID 321). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,525 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 20.0 (TID 322, localhost, executor driver, partition 109, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,526 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 20.0 (TID 322)
[INFO] 2019-01-19 13:27:37,526 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 20.0 (TID 323, localhost, executor driver, partition 110, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,527 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 20.0 (TID 321) in 15 ms on localhost (executor driver) (82/100)
[INFO] 2019-01-19 13:27:37,528 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 20.0 (TID 320) in 17 ms on localhost (executor driver) (83/100)
[INFO] 2019-01-19 13:27:37,528 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 20.0 (TID 323)
[INFO] 2019-01-19 13:27:37,528 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,531 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 13:27:37,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,551 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 21 ms
[INFO] 2019-01-19 13:27:37,553 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 20.0 (TID 323). 2773 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,555 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 20.0 (TID 324, localhost, executor driver, partition 111, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,557 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 20.0 (TID 323) in 31 ms on localhost (executor driver) (84/100)
[INFO] 2019-01-19 13:27:37,559 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 20.0 (TID 324)
[INFO] 2019-01-19 13:27:37,564 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,564 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,566 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 20.0 (TID 324). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,567 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 20.0 (TID 325, localhost, executor driver, partition 112, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,567 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 20.0 (TID 324) in 14 ms on localhost (executor driver) (85/100)
[INFO] 2019-01-19 13:27:37,569 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 20.0 (TID 325)
[INFO] 2019-01-19 13:27:37,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,579 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 20.0 (TID 325). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,582 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 20.0 (TID 326, localhost, executor driver, partition 113, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,583 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 20.0 (TID 326)
[INFO] 2019-01-19 13:27:37,583 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 20.0 (TID 325) in 17 ms on localhost (executor driver) (86/100)
[INFO] 2019-01-19 13:27:37,585 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,585 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,586 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 20.0 (TID 326). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,587 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 20.0 (TID 327, localhost, executor driver, partition 114, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,587 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 20.0 (TID 327)
[INFO] 2019-01-19 13:27:37,587 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 20.0 (TID 326) in 5 ms on localhost (executor driver) (87/100)
[INFO] 2019-01-19 13:27:37,589 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,590 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,591 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 20.0 (TID 327). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,593 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 20.0 (TID 328, localhost, executor driver, partition 115, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,593 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 20.0 (TID 327) in 7 ms on localhost (executor driver) (88/100)
[INFO] 2019-01-19 13:27:37,593 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 20.0 (TID 328)
[INFO] 2019-01-19 13:27:37,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,596 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 20.0 (TID 328). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,597 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 20.0 (TID 329, localhost, executor driver, partition 116, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,597 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 20.0 (TID 329)
[INFO] 2019-01-19 13:27:37,598 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 20.0 (TID 328) in 7 ms on localhost (executor driver) (89/100)
[INFO] 2019-01-19 13:27:37,599 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,600 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,601 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 20.0 (TID 329). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,602 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 20.0 (TID 330, localhost, executor driver, partition 117, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,602 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 20.0 (TID 329) in 5 ms on localhost (executor driver) (90/100)
[INFO] 2019-01-19 13:27:37,603 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 20.0 (TID 330)
[INFO] 2019-01-19 13:27:37,605 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,605 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,607 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 20.0 (TID 330). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 20.0 (TID 331, localhost, executor driver, partition 118, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,609 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 20.0 (TID 330) in 8 ms on localhost (executor driver) (91/100)
[INFO] 2019-01-19 13:27:37,609 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 20.0 (TID 331)
[INFO] 2019-01-19 13:27:37,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,613 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 20.0 (TID 331). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,614 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 20.0 (TID 332, localhost, executor driver, partition 119, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,614 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 20.0 (TID 331) in 6 ms on localhost (executor driver) (92/100)
[INFO] 2019-01-19 13:27:37,614 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 20.0 (TID 332)
[INFO] 2019-01-19 13:27:37,616 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,616 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,617 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 20.0 (TID 332). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,618 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 20.0 (TID 333, localhost, executor driver, partition 120, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,618 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 20.0 (TID 333)
[INFO] 2019-01-19 13:27:37,618 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 20.0 (TID 332) in 5 ms on localhost (executor driver) (93/100)
[INFO] 2019-01-19 13:27:37,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,621 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 20.0 (TID 333). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,622 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 20.0 (TID 334, localhost, executor driver, partition 121, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,622 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 20.0 (TID 334)
[INFO] 2019-01-19 13:27:37,622 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 20.0 (TID 333) in 4 ms on localhost (executor driver) (94/100)
[INFO] 2019-01-19 13:27:37,625 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,625 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,626 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 20.0 (TID 334). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,627 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 20.0 (TID 335, localhost, executor driver, partition 122, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,627 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 20.0 (TID 335)
[INFO] 2019-01-19 13:27:37,627 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 20.0 (TID 334) in 5 ms on localhost (executor driver) (95/100)
[INFO] 2019-01-19 13:27:37,629 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,629 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,630 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 20.0 (TID 335). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,631 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 20.0 (TID 336, localhost, executor driver, partition 123, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,631 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 20.0 (TID 335) in 4 ms on localhost (executor driver) (96/100)
[INFO] 2019-01-19 13:27:37,631 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 20.0 (TID 336)
[INFO] 2019-01-19 13:27:37,633 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,634 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,635 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 20.0 (TID 336). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,635 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 20.0 (TID 337, localhost, executor driver, partition 124, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,636 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 20.0 (TID 337)
[INFO] 2019-01-19 13:27:37,636 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 20.0 (TID 336) in 6 ms on localhost (executor driver) (97/100)
[INFO] 2019-01-19 13:27:37,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,640 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,640 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 20.0 (TID 322). 2852 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,641 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 20.0 (TID 338, localhost, executor driver, partition 43, ANY, 5800 bytes)
[INFO] 2019-01-19 13:27:37,641 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 20.0 (TID 322) in 117 ms on localhost (executor driver) (98/100)
[INFO] 2019-01-19 13:27:37,641 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 20.0 (TID 337). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,641 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 20.0 (TID 338)
[INFO] 2019-01-19 13:27:37,642 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 20.0 (TID 337) in 7 ms on localhost (executor driver) (99/100)
[INFO] 2019-01-19 13:27:37,643 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,643 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,647 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 20.0 (TID 338). 2703 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,648 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 20.0 (TID 338) in 8 ms on localhost (executor driver) (100/100)
[INFO] 2019-01-19 13:27:37,648 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 20.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:37,649 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 20 (show at LayerSample.scala:60) finished in 0.580 s
[INFO] 2019-01-19 13:27:37,653 org.apache.spark.scheduler.DAGScheduler logInfo - Job 10 finished: show at LayerSample.scala:60, took 0.600937 s
[INFO] 2019-01-19 13:27:37,714 org.apache.spark.SparkContext logInfo - Starting job: show at LayerSample.scala:60
[INFO] 2019-01-19 13:27:37,715 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 11 (show at LayerSample.scala:60) with 75 output partitions
[INFO] 2019-01-19 13:27:37,715 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 22 (show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:37,715 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 21)
[INFO] 2019-01-19 13:27:37,715 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:27:37,715 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 22 (MapPartitionsRDD[53] at show at LayerSample.scala:60), which has no missing parents
[INFO] 2019-01-19 13:27:37,718 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26 stored as values in memory (estimated size 18.2 KB, free 1991.2 MB)
[INFO] 2019-01-19 13:27:37,721 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1991.2 MB)
[INFO] 2019-01-19 13:27:37,722 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_26_piece0 in memory on 192.168.99.1:57817 (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:37,723 org.apache.spark.SparkContext logInfo - Created broadcast 26 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:37,726 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 75 missing tasks from ResultStage 22 (MapPartitionsRDD[53] at show at LayerSample.scala:60)
[INFO] 2019-01-19 13:27:37,727 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 22.0 with 75 tasks
[INFO] 2019-01-19 13:27:37,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 22.0 (TID 339, localhost, executor driver, partition 125, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 22.0 (TID 340, localhost, executor driver, partition 126, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,730 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 22.0 (TID 339)
[INFO] 2019-01-19 13:27:37,730 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 22.0 (TID 340)
[INFO] 2019-01-19 13:27:37,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,732 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,732 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,733 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 22.0 (TID 340). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,735 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 22.0 (TID 339). 2852 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,735 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 22.0 (TID 341, localhost, executor driver, partition 127, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,737 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 22.0 (TID 342, localhost, executor driver, partition 128, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,738 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 22.0 (TID 340) in 9 ms on localhost (executor driver) (1/75)
[INFO] 2019-01-19 13:27:37,738 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 22.0 (TID 339) in 10 ms on localhost (executor driver) (2/75)
[INFO] 2019-01-19 13:27:37,739 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 22.0 (TID 341)
[INFO] 2019-01-19 13:27:37,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,744 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 22.0 (TID 342)
[INFO] 2019-01-19 13:27:37,749 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,749 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,745 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 22.0 (TID 341). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,750 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 22.0 (TID 343, localhost, executor driver, partition 129, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,751 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 22.0 (TID 342). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,751 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 22.0 (TID 341) in 16 ms on localhost (executor driver) (3/75)
[INFO] 2019-01-19 13:27:37,751 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 22.0 (TID 343)
[INFO] 2019-01-19 13:27:37,751 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 22.0 (TID 344, localhost, executor driver, partition 130, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,752 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 22.0 (TID 344)
[INFO] 2019-01-19 13:27:37,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,752 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 22.0 (TID 342) in 16 ms on localhost (executor driver) (4/75)
[INFO] 2019-01-19 13:27:37,753 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,754 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 22.0 (TID 343). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,755 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 22.0 (TID 345, localhost, executor driver, partition 131, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,755 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 22.0 (TID 344). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,755 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 22.0 (TID 345)
[INFO] 2019-01-19 13:27:37,755 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 22.0 (TID 343) in 5 ms on localhost (executor driver) (5/75)
[INFO] 2019-01-19 13:27:37,756 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 22.0 (TID 346, localhost, executor driver, partition 132, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,757 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 22.0 (TID 344) in 6 ms on localhost (executor driver) (6/75)
[INFO] 2019-01-19 13:27:37,757 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 22.0 (TID 346)
[INFO] 2019-01-19 13:27:37,757 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,757 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,758 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 22.0 (TID 345). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,759 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,759 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,759 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 22.0 (TID 347, localhost, executor driver, partition 133, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,759 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 22.0 (TID 345) in 4 ms on localhost (executor driver) (7/75)
[INFO] 2019-01-19 13:27:37,759 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 22.0 (TID 347)
[INFO] 2019-01-19 13:27:37,760 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 22.0 (TID 346). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,760 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 22.0 (TID 348, localhost, executor driver, partition 134, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,761 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 22.0 (TID 346) in 5 ms on localhost (executor driver) (8/75)
[INFO] 2019-01-19 13:27:37,761 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 22.0 (TID 348)
[INFO] 2019-01-19 13:27:37,761 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,761 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,762 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 22.0 (TID 347). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,763 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,763 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,763 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 22.0 (TID 349, localhost, executor driver, partition 135, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,763 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 22.0 (TID 349)
[INFO] 2019-01-19 13:27:37,763 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 22.0 (TID 347) in 4 ms on localhost (executor driver) (9/75)
[INFO] 2019-01-19 13:27:37,764 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 22.0 (TID 348). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,765 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 22.0 (TID 350, localhost, executor driver, partition 136, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,765 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 22.0 (TID 350)
[INFO] 2019-01-19 13:27:37,765 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,765 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,765 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 22.0 (TID 348) in 5 ms on localhost (executor driver) (10/75)
[INFO] 2019-01-19 13:27:37,766 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 22.0 (TID 349). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,767 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 22.0 (TID 351, localhost, executor driver, partition 137, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,767 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 22.0 (TID 351)
[INFO] 2019-01-19 13:27:37,767 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 22.0 (TID 349) in 4 ms on localhost (executor driver) (11/75)
[INFO] 2019-01-19 13:27:37,768 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 22.0 (TID 350). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,768 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 22.0 (TID 352, localhost, executor driver, partition 138, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,768 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,769 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,768 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 22.0 (TID 352)
[INFO] 2019-01-19 13:27:37,768 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 22.0 (TID 350) in 4 ms on localhost (executor driver) (12/75)
[INFO] 2019-01-19 13:27:37,770 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 22.0 (TID 351). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,770 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 22.0 (TID 353, localhost, executor driver, partition 139, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,770 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 22.0 (TID 351) in 4 ms on localhost (executor driver) (13/75)
[INFO] 2019-01-19 13:27:37,770 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 22.0 (TID 353)
[INFO] 2019-01-19 13:27:37,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,771 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 22.0 (TID 352). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,771 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,772 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 22.0 (TID 354, localhost, executor driver, partition 140, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,772 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 22.0 (TID 354)
[INFO] 2019-01-19 13:27:37,773 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 22.0 (TID 353). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,772 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 22.0 (TID 352) in 4 ms on localhost (executor driver) (14/75)
[INFO] 2019-01-19 13:27:37,774 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,774 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,776 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 22.0 (TID 355, localhost, executor driver, partition 141, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,777 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 22.0 (TID 353) in 7 ms on localhost (executor driver) (15/75)
[INFO] 2019-01-19 13:27:37,777 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 22.0 (TID 355)
[INFO] 2019-01-19 13:27:37,777 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 22.0 (TID 354). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,778 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 22.0 (TID 356, localhost, executor driver, partition 142, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,778 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 22.0 (TID 356)
[INFO] 2019-01-19 13:27:37,778 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 22.0 (TID 354) in 7 ms on localhost (executor driver) (16/75)
[INFO] 2019-01-19 13:27:37,779 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,779 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,779 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,779 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 22.0 (TID 355). 2607 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,780 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,780 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 22.0 (TID 357, localhost, executor driver, partition 143, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,781 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 22.0 (TID 356). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,781 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 22.0 (TID 355) in 7 ms on localhost (executor driver) (17/75)
[INFO] 2019-01-19 13:27:37,782 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 22.0 (TID 357)
[INFO] 2019-01-19 13:27:37,783 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,783 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,788 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 22.0 (TID 358, localhost, executor driver, partition 144, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,788 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 22.0 (TID 356) in 10 ms on localhost (executor driver) (18/75)
[INFO] 2019-01-19 13:27:37,789 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 22.0 (TID 357). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,789 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 22.0 (TID 358)
[INFO] 2019-01-19 13:27:37,789 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 22.0 (TID 359, localhost, executor driver, partition 145, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,790 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 22.0 (TID 359)
[INFO] 2019-01-19 13:27:37,790 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 22.0 (TID 357) in 10 ms on localhost (executor driver) (19/75)
[INFO] 2019-01-19 13:27:37,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,791 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 22.0 (TID 358). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,792 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 22.0 (TID 360, localhost, executor driver, partition 146, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,792 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 22.0 (TID 359). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,792 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 22.0 (TID 360)
[INFO] 2019-01-19 13:27:37,792 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 22.0 (TID 358) in 9 ms on localhost (executor driver) (20/75)
[INFO] 2019-01-19 13:27:37,793 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 22.0 (TID 361, localhost, executor driver, partition 147, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,793 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 22.0 (TID 361)
[INFO] 2019-01-19 13:27:37,793 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 22.0 (TID 359) in 4 ms on localhost (executor driver) (21/75)
[INFO] 2019-01-19 13:27:37,794 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,794 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,795 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,795 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,795 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 22.0 (TID 360). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,795 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 22.0 (TID 361). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,796 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 22.0 (TID 362, localhost, executor driver, partition 148, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,796 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 22.0 (TID 360) in 4 ms on localhost (executor driver) (22/75)
[INFO] 2019-01-19 13:27:37,797 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 22.0 (TID 362)
[INFO] 2019-01-19 13:27:37,797 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 22.0 (TID 363, localhost, executor driver, partition 149, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,798 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 22.0 (TID 363)
[INFO] 2019-01-19 13:27:37,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 22.0 (TID 361) in 5 ms on localhost (executor driver) (23/75)
[INFO] 2019-01-19 13:27:37,798 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,798 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,799 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,799 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,799 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 22.0 (TID 362). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,800 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 22.0 (TID 364, localhost, executor driver, partition 150, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,802 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 22.0 (TID 362) in 6 ms on localhost (executor driver) (24/75)
[INFO] 2019-01-19 13:27:37,802 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 22.0 (TID 364)
[INFO] 2019-01-19 13:27:37,803 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 22.0 (TID 363). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,803 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,804 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,804 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 22.0 (TID 365, localhost, executor driver, partition 151, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,806 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 22.0 (TID 363) in 9 ms on localhost (executor driver) (25/75)
[INFO] 2019-01-19 13:27:37,806 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 22.0 (TID 365)
[INFO] 2019-01-19 13:27:37,806 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 22.0 (TID 364). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,807 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,809 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:27:37,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 22.0 (TID 366, localhost, executor driver, partition 152, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,810 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 22.0 (TID 365). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,811 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 22.0 (TID 366)
[INFO] 2019-01-19 13:27:37,811 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 22.0 (TID 364) in 11 ms on localhost (executor driver) (26/75)
[INFO] 2019-01-19 13:27:37,812 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 22.0 (TID 367, localhost, executor driver, partition 153, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,813 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,813 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,814 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 22.0 (TID 365) in 11 ms on localhost (executor driver) (27/75)
[INFO] 2019-01-19 13:27:37,814 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 22.0 (TID 367)
[INFO] 2019-01-19 13:27:37,814 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 22.0 (TID 366). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,815 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 22.0 (TID 368, localhost, executor driver, partition 154, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,815 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 22.0 (TID 368)
[INFO] 2019-01-19 13:27:37,815 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 22.0 (TID 366) in 7 ms on localhost (executor driver) (28/75)
[INFO] 2019-01-19 13:27:37,816 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,816 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,817 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 22.0 (TID 367). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,818 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 22.0 (TID 368). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,818 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 22.0 (TID 369, localhost, executor driver, partition 155, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,819 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 22.0 (TID 370, localhost, executor driver, partition 156, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,819 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 22.0 (TID 367) in 8 ms on localhost (executor driver) (29/75)
[INFO] 2019-01-19 13:27:37,819 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 22.0 (TID 369)
[INFO] 2019-01-19 13:27:37,820 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 22.0 (TID 368) in 5 ms on localhost (executor driver) (30/75)
[INFO] 2019-01-19 13:27:37,820 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 22.0 (TID 370)
[INFO] 2019-01-19 13:27:37,821 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,821 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,821 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,821 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,822 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 22.0 (TID 370). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,822 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 22.0 (TID 369). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,823 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 22.0 (TID 371, localhost, executor driver, partition 157, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,823 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 22.0 (TID 371)
[INFO] 2019-01-19 13:27:37,823 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 22.0 (TID 372, localhost, executor driver, partition 158, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,823 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 22.0 (TID 372)
[INFO] 2019-01-19 13:27:37,824 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 22.0 (TID 369) in 5 ms on localhost (executor driver) (31/75)
[INFO] 2019-01-19 13:27:37,824 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 22.0 (TID 370) in 6 ms on localhost (executor driver) (32/75)
[INFO] 2019-01-19 13:27:37,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,825 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,826 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 22.0 (TID 371). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,826 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 22.0 (TID 372). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,827 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 22.0 (TID 373, localhost, executor driver, partition 159, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,827 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 22.0 (TID 373)
[INFO] 2019-01-19 13:27:37,827 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 22.0 (TID 371) in 4 ms on localhost (executor driver) (33/75)
[INFO] 2019-01-19 13:27:37,827 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 22.0 (TID 374, localhost, executor driver, partition 160, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,828 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 22.0 (TID 372) in 4 ms on localhost (executor driver) (34/75)
[INFO] 2019-01-19 13:27:37,828 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 22.0 (TID 374)
[INFO] 2019-01-19 13:27:37,828 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,830 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 22.0 (TID 373). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,830 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 22.0 (TID 375, localhost, executor driver, partition 161, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,830 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 22.0 (TID 375)
[INFO] 2019-01-19 13:27:37,836 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,838 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:27:37,831 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 22.0 (TID 374). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,830 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 22.0 (TID 373) in 4 ms on localhost (executor driver) (35/75)
[INFO] 2019-01-19 13:27:37,842 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 22.0 (TID 375). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,844 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 22.0 (TID 376, localhost, executor driver, partition 162, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,845 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 22.0 (TID 377, localhost, executor driver, partition 163, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,845 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 22.0 (TID 374) in 18 ms on localhost (executor driver) (36/75)
[INFO] 2019-01-19 13:27:37,846 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 22.0 (TID 375) in 16 ms on localhost (executor driver) (37/75)
[INFO] 2019-01-19 13:27:37,846 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 22.0 (TID 376)
[INFO] 2019-01-19 13:27:37,846 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 22.0 (TID 377)
[INFO] 2019-01-19 13:27:37,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,848 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,849 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 22.0 (TID 376). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,850 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,850 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,852 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 22.0 (TID 377). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,855 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 22.0 (TID 378, localhost, executor driver, partition 164, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,857 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 22.0 (TID 379, localhost, executor driver, partition 165, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,858 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 22.0 (TID 378)
[INFO] 2019-01-19 13:27:37,861 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 22.0 (TID 379)
[INFO] 2019-01-19 13:27:37,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,858 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 22.0 (TID 376) in 15 ms on localhost (executor driver) (38/75)
[INFO] 2019-01-19 13:27:37,868 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 22.0 (TID 377) in 24 ms on localhost (executor driver) (39/75)
[INFO] 2019-01-19 13:27:37,866 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 22.0 (TID 379). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,868 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 22.0 (TID 378). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,869 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 22.0 (TID 380, localhost, executor driver, partition 166, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,870 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 22.0 (TID 380)
[INFO] 2019-01-19 13:27:37,870 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 22.0 (TID 381, localhost, executor driver, partition 167, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,872 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 22.0 (TID 378) in 17 ms on localhost (executor driver) (40/75)
[INFO] 2019-01-19 13:27:37,872 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 22.0 (TID 381)
[INFO] 2019-01-19 13:27:37,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,873 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,874 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 22.0 (TID 380). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,874 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 22.0 (TID 379) in 18 ms on localhost (executor driver) (41/75)
[INFO] 2019-01-19 13:27:37,876 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,879 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 22.0 (TID 381). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,880 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 22.0 (TID 382, localhost, executor driver, partition 168, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,880 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 22.0 (TID 383, localhost, executor driver, partition 169, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,884 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 22.0 (TID 380) in 15 ms on localhost (executor driver) (42/75)
[INFO] 2019-01-19 13:27:37,885 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 22.0 (TID 381) in 15 ms on localhost (executor driver) (43/75)
[INFO] 2019-01-19 13:27:37,886 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 22.0 (TID 382)
[INFO] 2019-01-19 13:27:37,888 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 22.0 (TID 383)
[INFO] 2019-01-19 13:27:37,892 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,893 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,896 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 22.0 (TID 382). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,898 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 22.0 (TID 384, localhost, executor driver, partition 170, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,898 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 22.0 (TID 384)
[INFO] 2019-01-19 13:27:37,898 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 22.0 (TID 382) in 20 ms on localhost (executor driver) (44/75)
[INFO] 2019-01-19 13:27:37,900 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,903 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 22.0 (TID 384). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,903 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 22.0 (TID 383). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,903 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 22.0 (TID 385, localhost, executor driver, partition 171, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,904 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 22.0 (TID 385)
[INFO] 2019-01-19 13:27:37,904 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 22.0 (TID 386, localhost, executor driver, partition 172, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,904 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 22.0 (TID 384) in 7 ms on localhost (executor driver) (45/75)
[INFO] 2019-01-19 13:27:37,910 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 22.0 (TID 386)
[INFO] 2019-01-19 13:27:37,911 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,911 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,912 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 22.0 (TID 385). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,914 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,914 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,914 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 22.0 (TID 383) in 34 ms on localhost (executor driver) (46/75)
[INFO] 2019-01-19 13:27:37,917 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 22.0 (TID 386). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,917 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 22.0 (TID 387, localhost, executor driver, partition 173, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,917 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 22.0 (TID 387)
[INFO] 2019-01-19 13:27:37,917 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 22.0 (TID 388, localhost, executor driver, partition 174, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,917 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 22.0 (TID 386) in 13 ms on localhost (executor driver) (47/75)
[INFO] 2019-01-19 13:27:37,918 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 22.0 (TID 385) in 15 ms on localhost (executor driver) (48/75)
[INFO] 2019-01-19 13:27:37,919 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 22.0 (TID 388)
[INFO] 2019-01-19 13:27:37,919 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,919 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,921 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 22.0 (TID 387). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,923 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 22.0 (TID 389, localhost, executor driver, partition 175, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,923 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,924 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,924 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 22.0 (TID 389)
[INFO] 2019-01-19 13:27:37,925 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 22.0 (TID 388). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,926 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,926 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,924 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 22.0 (TID 387) in 7 ms on localhost (executor driver) (49/75)
[INFO] 2019-01-19 13:27:37,927 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 22.0 (TID 390, localhost, executor driver, partition 176, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,928 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 22.0 (TID 389). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,928 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 22.0 (TID 390)
[INFO] 2019-01-19 13:27:37,928 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 22.0 (TID 388) in 11 ms on localhost (executor driver) (50/75)
[INFO] 2019-01-19 13:27:37,929 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 22.0 (TID 391, localhost, executor driver, partition 177, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,929 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 22.0 (TID 389) in 6 ms on localhost (executor driver) (51/75)
[INFO] 2019-01-19 13:27:37,930 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 22.0 (TID 391)
[INFO] 2019-01-19 13:27:37,929 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,930 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,931 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,931 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,931 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 22.0 (TID 390). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,932 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 22.0 (TID 391). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,932 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 22.0 (TID 392, localhost, executor driver, partition 178, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,933 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 22.0 (TID 393, localhost, executor driver, partition 179, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,933 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 22.0 (TID 390) in 6 ms on localhost (executor driver) (52/75)
[INFO] 2019-01-19 13:27:37,934 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 22.0 (TID 392)
[INFO] 2019-01-19 13:27:37,934 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 22.0 (TID 391) in 5 ms on localhost (executor driver) (53/75)
[INFO] 2019-01-19 13:27:37,934 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 22.0 (TID 393)
[INFO] 2019-01-19 13:27:37,936 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,936 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,939 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,939 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,941 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 22.0 (TID 393). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,941 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 22.0 (TID 392). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,942 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 22.0 (TID 394, localhost, executor driver, partition 180, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,942 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 22.0 (TID 394)
[INFO] 2019-01-19 13:27:37,942 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 22.0 (TID 395, localhost, executor driver, partition 181, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,943 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 22.0 (TID 392) in 12 ms on localhost (executor driver) (54/75)
[INFO] 2019-01-19 13:27:37,943 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 22.0 (TID 393) in 10 ms on localhost (executor driver) (55/75)
[INFO] 2019-01-19 13:27:37,944 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 22.0 (TID 395)
[INFO] 2019-01-19 13:27:37,945 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,945 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,946 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 22.0 (TID 394). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,947 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 22.0 (TID 396, localhost, executor driver, partition 182, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,948 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 22.0 (TID 394) in 7 ms on localhost (executor driver) (56/75)
[INFO] 2019-01-19 13:27:37,948 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 22.0 (TID 396)
[INFO] 2019-01-19 13:27:37,948 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,948 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,949 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 22.0 (TID 395). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,950 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 22.0 (TID 397, localhost, executor driver, partition 183, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,950 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 22.0 (TID 397)
[INFO] 2019-01-19 13:27:37,950 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 22.0 (TID 395) in 8 ms on localhost (executor driver) (57/75)
[INFO] 2019-01-19 13:27:37,951 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 22.0 (TID 396). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,951 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 22.0 (TID 398, localhost, executor driver, partition 184, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,951 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 22.0 (TID 398)
[INFO] 2019-01-19 13:27:37,951 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 22.0 (TID 396) in 4 ms on localhost (executor driver) (58/75)
[INFO] 2019-01-19 13:27:37,952 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,952 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,953 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,953 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,953 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 22.0 (TID 397). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,954 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 22.0 (TID 399, localhost, executor driver, partition 185, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,954 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 22.0 (TID 397) in 4 ms on localhost (executor driver) (59/75)
[INFO] 2019-01-19 13:27:37,954 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 22.0 (TID 399)
[INFO] 2019-01-19 13:27:37,954 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 22.0 (TID 398). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,955 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 22.0 (TID 400, localhost, executor driver, partition 186, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,955 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 22.0 (TID 398) in 4 ms on localhost (executor driver) (60/75)
[INFO] 2019-01-19 13:27:37,955 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 22.0 (TID 400)
[INFO] 2019-01-19 13:27:37,956 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,956 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,957 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,957 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,958 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 22.0 (TID 399). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,958 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 22.0 (TID 401, localhost, executor driver, partition 187, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,958 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 22.0 (TID 400). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,959 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 22.0 (TID 399) in 6 ms on localhost (executor driver) (61/75)
[INFO] 2019-01-19 13:27:37,958 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 22.0 (TID 401)
[INFO] 2019-01-19 13:27:37,959 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 22.0 (TID 402, localhost, executor driver, partition 188, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,960 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 22.0 (TID 400) in 6 ms on localhost (executor driver) (62/75)
[INFO] 2019-01-19 13:27:37,960 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 22.0 (TID 402)
[INFO] 2019-01-19 13:27:37,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,961 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 22.0 (TID 401). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,961 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,962 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,962 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 22.0 (TID 403, localhost, executor driver, partition 189, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,962 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 22.0 (TID 401) in 4 ms on localhost (executor driver) (63/75)
[INFO] 2019-01-19 13:27:37,963 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 22.0 (TID 403)
[INFO] 2019-01-19 13:27:37,963 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 22.0 (TID 402). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,963 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 22.0 (TID 404, localhost, executor driver, partition 190, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,964 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 22.0 (TID 404)
[INFO] 2019-01-19 13:27:37,964 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 22.0 (TID 402) in 5 ms on localhost (executor driver) (64/75)
[INFO] 2019-01-19 13:27:37,964 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,964 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,965 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,965 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 22.0 (TID 403). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,965 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,966 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 22.0 (TID 405, localhost, executor driver, partition 192, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,966 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 22.0 (TID 405)
[INFO] 2019-01-19 13:27:37,966 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 22.0 (TID 403) in 4 ms on localhost (executor driver) (65/75)
[INFO] 2019-01-19 13:27:37,967 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 22.0 (TID 404). 2765 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,967 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 22.0 (TID 406, localhost, executor driver, partition 193, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,968 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 22.0 (TID 404) in 5 ms on localhost (executor driver) (66/75)
[INFO] 2019-01-19 13:27:37,968 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 22.0 (TID 406)
[INFO] 2019-01-19 13:27:37,969 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 22.0 (TID 405). 2776 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 22.0 (TID 407, localhost, executor driver, partition 194, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,969 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,969 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,969 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 22.0 (TID 407)
[INFO] 2019-01-19 13:27:37,969 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 22.0 (TID 405) in 4 ms on localhost (executor driver) (67/75)
[INFO] 2019-01-19 13:27:37,971 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 22.0 (TID 406). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,971 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 22.0 (TID 408, localhost, executor driver, partition 195, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,971 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 22.0 (TID 408)
[INFO] 2019-01-19 13:27:37,971 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,971 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 22.0 (TID 406) in 4 ms on localhost (executor driver) (68/75)
[INFO] 2019-01-19 13:27:37,971 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,972 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 22.0 (TID 407). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,973 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 22.0 (TID 409, localhost, executor driver, partition 196, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,973 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 22.0 (TID 409)
[INFO] 2019-01-19 13:27:37,973 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 22.0 (TID 407) in 4 ms on localhost (executor driver) (69/75)
[INFO] 2019-01-19 13:27:37,973 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 22.0 (TID 408). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,974 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 22.0 (TID 410, localhost, executor driver, partition 197, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,974 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 22.0 (TID 410)
[INFO] 2019-01-19 13:27:37,974 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 22.0 (TID 408) in 3 ms on localhost (executor driver) (70/75)
[INFO] 2019-01-19 13:27:37,974 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,974 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,975 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 22.0 (TID 409). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,976 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,976 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,976 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 22.0 (TID 411, localhost, executor driver, partition 198, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,976 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 22.0 (TID 411)
[INFO] 2019-01-19 13:27:37,976 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 22.0 (TID 409) in 3 ms on localhost (executor driver) (71/75)
[INFO] 2019-01-19 13:27:37,977 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 22.0 (TID 410). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,977 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 22.0 (TID 412, localhost, executor driver, partition 199, PROCESS_LOCAL, 5800 bytes)
[INFO] 2019-01-19 13:27:37,977 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 22.0 (TID 412)
[INFO] 2019-01-19 13:27:37,977 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,977 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 22.0 (TID 410) in 3 ms on localhost (executor driver) (72/75)
[INFO] 2019-01-19 13:27:37,978 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 22.0 (TID 411). 2599 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,979 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 22.0 (TID 413, localhost, executor driver, partition 191, ANY, 5800 bytes)
[INFO] 2019-01-19 13:27:37,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:37,979 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 22.0 (TID 411) in 3 ms on localhost (executor driver) (73/75)
[INFO] 2019-01-19 13:27:37,979 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 22.0 (TID 413)
[INFO] 2019-01-19 13:27:37,980 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 22.0 (TID 412). 2686 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,980 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 22.0 (TID 412) in 3 ms on localhost (executor driver) (74/75)
[INFO] 2019-01-19 13:27:37,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:37,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:37,982 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 22.0 (TID 413). 2696 bytes result sent to driver
[INFO] 2019-01-19 13:27:37,983 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 22.0 (TID 413) in 4 ms on localhost (executor driver) (75/75)
[INFO] 2019-01-19 13:27:37,983 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 22.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:37,983 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 22 (show at LayerSample.scala:60) finished in 0.255 s
[INFO] 2019-01-19 13:27:37,983 org.apache.spark.scheduler.DAGScheduler logInfo - Job 11 finished: show at LayerSample.scala:60, took 0.269226 s
[INFO] 2019-01-19 13:27:53,833 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_26_piece0 on 192.168.99.1:57817 in memory (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5509
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5510
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5511
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5512
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5513
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5514
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5515
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5516
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5517
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5518
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5519
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5520
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5521
[INFO] 2019-01-19 13:27:53,835 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5522
[INFO] 2019-01-19 13:27:53,837 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_20_piece0 on 192.168.99.1:57817 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:53,839 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 6
[INFO] 2019-01-19 13:27:53,841 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_21_piece0 on 192.168.99.1:57817 in memory (size: 8.1 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:53,844 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_22_piece0 on 192.168.99.1:57817 in memory (size: 8.9 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:53,847 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_23_piece0 on 192.168.99.1:57817 in memory (size: 8.9 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:27:53,848 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_24_piece0 on 192.168.99.1:57817 in memory (size: 8.9 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:27:53,849 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_25_piece0 on 192.168.99.1:57817 in memory (size: 8.9 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:27:54,618 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:27:54,619 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:27:54,619 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:27:54,619 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:27:54,620 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:27:54,621 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:27:54,621 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:27:54,621 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:27:54,855 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.04037 ms
[INFO] 2019-01-19 13:27:54,908 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 37.278672 ms
[INFO] 2019-01-19 13:27:54,919 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27 stored as values in memory (estimated size 292.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:27:54,931 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:27:54,931 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_27_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:54,933 org.apache.spark.SparkContext logInfo - Created broadcast 27 from head at DecoupJson.scala:139
[INFO] 2019-01-19 13:27:54,933 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:27:54,983 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.489957 ms
[INFO] 2019-01-19 13:27:54,992 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28 stored as values in memory (estimated size 292.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:27:55,006 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:27:55,007 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_28_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:55,008 org.apache.spark.SparkContext logInfo - Created broadcast 28 from head at DecoupJson.scala:139
[INFO] 2019-01-19 13:27:55,009 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:27:55,082 org.apache.spark.SparkContext logInfo - Starting job: head at DecoupJson.scala:139
[INFO] 2019-01-19 13:27:55,082 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 57 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,082 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 62 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,083 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 69 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,083 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 74 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,083 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 12 (head at DecoupJson.scala:139) with 1 output partitions
[INFO] 2019-01-19 13:27:55,083 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 27 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,083 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 26)
[INFO] 2019-01-19 13:27:55,083 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 26)
[INFO] 2019-01-19 13:27:55,085 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 23 (MapPartitionsRDD[57] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:27:55,086 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29 stored as values in memory (estimated size 39.9 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:27:55,088 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:27:55,089 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_29_piece0 in memory on 192.168.99.1:57817 (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:55,090 org.apache.spark.SparkContext logInfo - Created broadcast 29 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:55,091 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[57] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,091 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 23.0 with 1 tasks
[INFO] 2019-01-19 13:27:55,091 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 24 (MapPartitionsRDD[62] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:27:55,092 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 23.0 (TID 414, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:27:55,093 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30 stored as values in memory (estimated size 39.9 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:27:55,093 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 23.0 (TID 414)
[INFO] 2019-01-19 13:27:55,094 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:27:55,095 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_30_piece0 in memory on 192.168.99.1:57817 (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:55,096 org.apache.spark.SparkContext logInfo - Created broadcast 30 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:55,096 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[62] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,096 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 24.0 with 1 tasks
[INFO] 2019-01-19 13:27:55,102 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:27:55,116 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:27:55,129 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 24.0 (TID 415, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:27:55,130 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 24.0 (TID 415)
[INFO] 2019-01-19 13:27:55,142 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:27:55,150 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:27:55,279 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 23.0 (TID 414). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:27:55,280 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 23.0 (TID 414) in 189 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:27:55,280 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 23.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:55,281 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 23 (head at DecoupJson.scala:139) finished in 0.189 s
[INFO] 2019-01-19 13:27:55,281 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:27:55,281 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 24)
[INFO] 2019-01-19 13:27:55,281 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 27, ShuffleMapStage 25, ShuffleMapStage 26)
[INFO] 2019-01-19 13:27:55,281 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:27:55,299 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 24.0 (TID 415). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:27:55,299 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 24.0 (TID 415) in 173 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:27:55,299 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 24.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:27:55,299 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 24 (head at DecoupJson.scala:139) finished in 0.203 s
[INFO] 2019-01-19 13:27:55,299 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:27:55,300 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:27:55,300 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 27, ShuffleMapStage 25, ShuffleMapStage 26)
[INFO] 2019-01-19 13:27:55,300 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:27:55,300 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 25 (MapPartitionsRDD[69] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:27:55,396 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31 stored as values in memory (estimated size 301.7 KB, free 1990.7 MB)
[INFO] 2019-01-19 13:27:55,398 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31_piece0 stored as bytes in memory (estimated size 67.9 KB, free 1990.6 MB)
[INFO] 2019-01-19 13:27:55,399 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_31_piece0 in memory on 192.168.99.1:57817 (size: 67.9 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:55,399 org.apache.spark.SparkContext logInfo - Created broadcast 31 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:27:55,399 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[69] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:27:55,401 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 25.0 with 2 tasks
[INFO] 2019-01-19 13:27:55,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 25.0 (TID 416, localhost, executor driver, partition 0, ANY, 5898 bytes)
[INFO] 2019-01-19 13:27:55,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 25.0 (TID 417, localhost, executor driver, partition 1, ANY, 5898 bytes)
[INFO] 2019-01-19 13:27:55,403 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 25.0 (TID 416)
[INFO] 2019-01-19 13:27:55,403 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 25.0 (TID 417)
[INFO] 2019-01-19 13:27:55,432 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:55,433 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:27:55,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:27:55,449 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:27:55,514 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 72.693056 ms
[INFO] 2019-01-19 13:27:55,563 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 38.83477 ms
[INFO] 2019-01-19 13:27:55,606 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 36.159465 ms
[INFO] 2019-01-19 13:27:55,629 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10491
[INFO] 2019-01-19 13:27:55,629 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10492
[INFO] 2019-01-19 13:27:55,629 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10493
[INFO] 2019-01-19 13:27:55,629 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10494
[INFO] 2019-01-19 13:27:55,632 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_29_piece0 on 192.168.99.1:57817 in memory (size: 12.5 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:27:55,635 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_30_piece0 on 192.168.99.1:57817 in memory (size: 12.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:55,657 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.075742 ms
[INFO] 2019-01-19 13:27:55,682 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.886916 ms
[INFO] 2019-01-19 13:27:55,706 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.93095 ms
[INFO] 2019-01-19 13:27:55,738 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 27.276689 ms
[INFO] 2019-01-19 13:27:55,772 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.274265 ms
[INFO] 2019-01-19 13:27:55,807 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.89346 ms
[INFO] 2019-01-19 13:27:55,830 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.317044 ms
[INFO] 2019-01-19 13:27:55,850 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.487976 ms
[INFO] 2019-01-19 13:27:55,872 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.432262 ms
[INFO] 2019-01-19 13:27:55,893 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.671733 ms
[INFO] 2019-01-19 13:27:55,914 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.932647 ms
[INFO] 2019-01-19 13:27:55,939 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.584349 ms
[INFO] 2019-01-19 13:27:55,961 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.760592 ms
[INFO] 2019-01-19 13:27:55,982 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.549728 ms
[INFO] 2019-01-19 13:27:56,012 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.669087 ms
[INFO] 2019-01-19 13:27:56,038 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.322002 ms
[INFO] 2019-01-19 13:27:56,054 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.944219 ms
[INFO] 2019-01-19 13:27:56,072 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.495689 ms
[INFO] 2019-01-19 13:27:56,089 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.853596 ms
[INFO] 2019-01-19 13:27:56,106 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.822918 ms
[INFO] 2019-01-19 13:27:56,122 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.202291 ms
[INFO] 2019-01-19 13:27:56,142 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.544768 ms
[INFO] 2019-01-19 13:27:56,163 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.23235 ms
[INFO] 2019-01-19 13:27:56,196 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 25.405704 ms
[INFO] 2019-01-19 13:27:56,222 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.878807 ms
[INFO] 2019-01-19 13:27:56,248 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.57593 ms
[INFO] 2019-01-19 13:27:56,271 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.546928 ms
[INFO] 2019-01-19 13:27:56,289 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.16002 ms
[INFO] 2019-01-19 13:27:56,309 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.760218 ms
[INFO] 2019-01-19 13:27:56,337 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.072063 ms
[INFO] 2019-01-19 13:27:56,355 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.783447 ms
[INFO] 2019-01-19 13:27:56,378 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.092779 ms
[INFO] 2019-01-19 13:27:56,396 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.357816 ms
[INFO] 2019-01-19 13:27:56,416 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.922752 ms
[INFO] 2019-01-19 13:27:56,441 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.953164 ms
[INFO] 2019-01-19 13:27:56,469 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.735313 ms
[INFO] 2019-01-19 13:27:56,491 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.509881 ms
[INFO] 2019-01-19 13:27:56,510 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.93223 ms
[INFO] 2019-01-19 13:27:56,529 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.850091 ms
[INFO] 2019-01-19 13:27:56,553 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.063842 ms
[INFO] 2019-01-19 13:27:56,573 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.334565 ms
[INFO] 2019-01-19 13:27:56,603 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 23.885924 ms
[INFO] 2019-01-19 13:27:56,631 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.099213 ms
[INFO] 2019-01-19 13:27:56,680 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 38.853812 ms
[INFO] 2019-01-19 13:27:56,736 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.228272 ms
[INFO] 2019-01-19 13:27:56,758 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.374499 ms
[INFO] 2019-01-19 13:27:56,778 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.790168 ms
[INFO] 2019-01-19 13:27:56,793 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.241783 ms
[INFO] 2019-01-19 13:27:56,857 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 47.818746 ms
[INFO] 2019-01-19 13:27:56,879 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.844231 ms
[INFO] 2019-01-19 13:27:57,372 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 37.944765 ms
[INFO] 2019-01-19 13:27:57,706 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 166.380576 ms
[INFO] 2019-01-19 13:27:57,758 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.264329 ms
[INFO] 2019-01-19 13:27:57,855 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 45.816235 ms
[INFO] 2019-01-19 13:27:57,894 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.669308 ms
[INFO] 2019-01-19 13:27:57,918 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.985958 ms
[INFO] 2019-01-19 13:27:59,031 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5508
[INFO] 2019-01-19 13:27:59,034 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_3_piece0 on 192.168.99.1:57817 in memory (size: 9.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:59,035 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 0
[INFO] 2019-01-19 13:27:59,038 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_1_piece0 on 192.168.99.1:57817 in memory (size: 23.7 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:27:59,038 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 61
[INFO] 2019-01-19 13:27:59,038 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 60
[INFO] 2019-01-19 13:27:59,038 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 59
[INFO] 2019-01-19 13:27:59,038 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 58
[INFO] 2019-01-19 13:27:59,038 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 57
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 56
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 55
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 54
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 53
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 52
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 51
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 50
[INFO] 2019-01-19 13:27:59,039 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 49
[INFO] 2019-01-19 13:28:00,448 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 25.0 (TID 416). 3967 bytes result sent to driver
[INFO] 2019-01-19 13:28:00,450 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 25.0 (TID 416) in 5049 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:28:00,500 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 25.0 (TID 417). 4054 bytes result sent to driver
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 25.0 (TID 417) in 5099 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 25.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 25 (head at DecoupJson.scala:139) finished in 5.100 s
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 27, ShuffleMapStage 26)
[INFO] 2019-01-19 13:28:00,501 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:00,502 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 26 (MapPartitionsRDD[74] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:28:00,597 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_32 stored as values in memory (estimated size 531.2 KB, free 1990.5 MB)
[INFO] 2019-01-19 13:28:00,599 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_32_piece0 stored as bytes in memory (estimated size 134.0 KB, free 1990.4 MB)
[INFO] 2019-01-19 13:28:00,600 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_32_piece0 in memory on 192.168.99.1:57817 (size: 134.0 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:28:00,601 org.apache.spark.SparkContext logInfo - Created broadcast 32 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:00,602 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[74] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:28:00,602 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 26.0 with 200 tasks
[INFO] 2019-01-19 13:28:00,603 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 26.0 (TID 418, localhost, executor driver, partition 0, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:00,603 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 26.0 (TID 419, localhost, executor driver, partition 1, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:00,604 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 26.0 (TID 419)
[INFO] 2019-01-19 13:28:00,604 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 26.0 (TID 418)
[INFO] 2019-01-19 13:28:00,625 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:00,626 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:00,632 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:00,633 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:00,959 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 119.247671 ms
[INFO] 2019-01-19 13:28:01,129 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 88.523797 ms
[INFO] 2019-01-19 13:28:01,356 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 166.477194 ms
[INFO] 2019-01-19 13:28:01,432 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 54.983571 ms
[INFO] 2019-01-19 13:28:01,514 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 55.37956 ms
[INFO] 2019-01-19 13:28:02,106 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 270.667413 ms
[INFO] 2019-01-19 13:28:02,403 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 119.382017 ms
[INFO] 2019-01-19 13:28:02,492 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 61.167416 ms
[INFO] 2019-01-19 13:28:02,534 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 26.0 (TID 419). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:02,535 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 26.0 (TID 420, localhost, executor driver, partition 2, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:02,535 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 26.0 (TID 420)
[INFO] 2019-01-19 13:28:02,535 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 26.0 (TID 419) in 1932 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 13:28:02,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:02,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:02,554 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 26.0 (TID 418). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:02,555 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 26.0 (TID 421, localhost, executor driver, partition 3, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:02,555 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 26.0 (TID 418) in 1953 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 13:28:02,555 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 26.0 (TID 421)
[INFO] 2019-01-19 13:28:02,574 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:02,574 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:03,156 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 26.0 (TID 421). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:03,157 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 26.0 (TID 422, localhost, executor driver, partition 4, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:03,157 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 26.0 (TID 421) in 603 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 13:28:03,158 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 26.0 (TID 422)
[INFO] 2019-01-19 13:28:03,162 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 26.0 (TID 420). 4343 bytes result sent to driver
[INFO] 2019-01-19 13:28:03,162 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 26.0 (TID 423, localhost, executor driver, partition 5, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:03,163 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 26.0 (TID 420) in 629 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 13:28:03,163 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 26.0 (TID 423)
[INFO] 2019-01-19 13:28:03,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:03,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:03,202 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:03,202 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:03,713 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 26.0 (TID 422). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:03,713 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 26.0 (TID 424, localhost, executor driver, partition 6, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:03,713 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 26.0 (TID 424)
[INFO] 2019-01-19 13:28:03,713 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 26.0 (TID 422) in 557 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 13:28:03,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:03,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:03,760 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 26.0 (TID 423). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:03,761 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 26.0 (TID 425, localhost, executor driver, partition 7, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:03,761 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 26.0 (TID 425)
[INFO] 2019-01-19 13:28:03,761 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 26.0 (TID 423) in 599 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 13:28:03,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:03,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:04,364 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 26.0 (TID 424). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:04,365 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 26.0 (TID 426, localhost, executor driver, partition 8, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:04,365 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 26.0 (TID 426)
[INFO] 2019-01-19 13:28:04,365 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 26.0 (TID 424) in 652 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 13:28:04,383 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:04,383 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:04,425 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 26.0 (TID 425). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:04,426 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 26.0 (TID 427, localhost, executor driver, partition 9, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:04,426 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 26.0 (TID 427)
[INFO] 2019-01-19 13:28:04,426 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 26.0 (TID 425) in 666 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 13:28:04,455 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:04,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:05,099 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 26.0 (TID 426). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:05,100 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 26.0 (TID 428, localhost, executor driver, partition 10, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:05,101 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 26.0 (TID 428)
[INFO] 2019-01-19 13:28:05,101 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 26.0 (TID 426) in 736 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 13:28:05,116 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:05,116 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:05,167 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 26.0 (TID 427). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:05,167 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 26.0 (TID 429, localhost, executor driver, partition 11, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:05,167 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 26.0 (TID 429)
[INFO] 2019-01-19 13:28:05,168 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 26.0 (TID 427) in 741 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 13:28:05,183 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:05,183 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:05,720 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 26.0 (TID 428). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:05,721 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 26.0 (TID 430, localhost, executor driver, partition 12, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:05,721 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 26.0 (TID 430)
[INFO] 2019-01-19 13:28:05,721 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 26.0 (TID 428) in 621 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 13:28:05,750 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:05,750 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:05,779 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 26.0 (TID 429). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:05,779 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 26.0 (TID 431, localhost, executor driver, partition 13, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:05,779 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 26.0 (TID 431)
[INFO] 2019-01-19 13:28:05,779 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 26.0 (TID 429) in 612 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 13:28:05,796 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:05,796 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:06,226 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 26.0 (TID 430). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:06,226 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 26.0 (TID 432, localhost, executor driver, partition 14, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:06,227 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 26.0 (TID 432)
[INFO] 2019-01-19 13:28:06,227 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 26.0 (TID 430) in 507 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 13:28:06,241 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:06,242 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:06,286 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 26.0 (TID 431). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:06,287 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 26.0 (TID 433, localhost, executor driver, partition 15, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:06,287 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 26.0 (TID 433)
[INFO] 2019-01-19 13:28:06,287 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 26.0 (TID 431) in 508 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 13:28:06,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:06,305 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:06,783 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 26.0 (TID 432). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:06,784 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 26.0 (TID 434, localhost, executor driver, partition 16, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:06,784 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 26.0 (TID 434)
[INFO] 2019-01-19 13:28:06,784 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 26.0 (TID 432) in 558 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 13:28:06,800 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:06,800 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:06,835 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 26.0 (TID 433). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:06,835 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 26.0 (TID 435, localhost, executor driver, partition 17, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:06,836 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 26.0 (TID 433) in 549 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 13:28:06,836 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 26.0 (TID 435)
[INFO] 2019-01-19 13:28:06,852 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:06,852 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:07,278 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 26.0 (TID 434). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:07,279 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 26.0 (TID 436, localhost, executor driver, partition 18, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:07,279 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 26.0 (TID 434) in 496 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 13:28:07,279 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 26.0 (TID 436)
[INFO] 2019-01-19 13:28:07,294 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:07,294 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:07,343 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 26.0 (TID 435). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:07,344 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 26.0 (TID 437, localhost, executor driver, partition 19, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:07,344 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 26.0 (TID 437)
[INFO] 2019-01-19 13:28:07,344 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 26.0 (TID 435) in 509 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 13:28:07,360 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:07,360 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:07,807 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 26.0 (TID 436). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:07,807 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 26.0 (TID 438, localhost, executor driver, partition 20, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:07,808 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 26.0 (TID 436) in 529 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 13:28:07,808 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 26.0 (TID 438)
[INFO] 2019-01-19 13:28:07,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:07,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:07,869 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 26.0 (TID 437). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:07,869 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 26.0 (TID 439, localhost, executor driver, partition 21, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:07,869 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 26.0 (TID 439)
[INFO] 2019-01-19 13:28:07,869 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 26.0 (TID 437) in 525 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 13:28:07,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:07,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:08,355 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 26.0 (TID 438). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:08,356 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 26.0 (TID 440, localhost, executor driver, partition 22, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:08,356 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 26.0 (TID 440)
[INFO] 2019-01-19 13:28:08,356 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 26.0 (TID 438) in 549 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 13:28:08,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:08,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:08,429 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 26.0 (TID 439). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:08,429 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 26.0 (TID 441, localhost, executor driver, partition 23, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:08,429 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 26.0 (TID 441)
[INFO] 2019-01-19 13:28:08,430 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 26.0 (TID 439) in 561 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 13:28:08,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:08,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:08,834 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 26.0 (TID 440). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:08,834 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 26.0 (TID 442, localhost, executor driver, partition 24, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:08,834 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 26.0 (TID 442)
[INFO] 2019-01-19 13:28:08,834 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 26.0 (TID 440) in 478 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 13:28:08,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:08,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:08,906 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 26.0 (TID 441). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:08,907 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 26.0 (TID 443, localhost, executor driver, partition 25, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:08,907 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 26.0 (TID 443)
[INFO] 2019-01-19 13:28:08,907 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 26.0 (TID 441) in 478 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 13:28:08,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:08,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:09,369 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 26.0 (TID 442). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:09,369 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 26.0 (TID 444, localhost, executor driver, partition 26, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:09,370 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 26.0 (TID 442) in 536 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 13:28:09,370 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 26.0 (TID 444)
[INFO] 2019-01-19 13:28:09,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:09,385 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:09,449 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 26.0 (TID 443). 4253 bytes result sent to driver
[INFO] 2019-01-19 13:28:09,449 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 26.0 (TID 445, localhost, executor driver, partition 27, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:09,450 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 26.0 (TID 445)
[INFO] 2019-01-19 13:28:09,450 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 26.0 (TID 443) in 543 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 13:28:09,464 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:09,464 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:09,829 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 26.0 (TID 444). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:09,829 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 26.0 (TID 446, localhost, executor driver, partition 28, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:09,829 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 26.0 (TID 446)
[INFO] 2019-01-19 13:28:09,829 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 26.0 (TID 444) in 460 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 13:28:09,844 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:09,844 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:09,885 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 26.0 (TID 445). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:09,885 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 26.0 (TID 447, localhost, executor driver, partition 29, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:09,886 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 26.0 (TID 447)
[INFO] 2019-01-19 13:28:09,886 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 26.0 (TID 445) in 437 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 13:28:09,899 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:09,899 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:10,260 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 26.0 (TID 446). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:10,261 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 26.0 (TID 448, localhost, executor driver, partition 30, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:10,261 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 26.0 (TID 448)
[INFO] 2019-01-19 13:28:10,261 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 26.0 (TID 446) in 432 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 13:28:10,276 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:10,276 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:10,332 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 26.0 (TID 447). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:10,332 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 26.0 (TID 449, localhost, executor driver, partition 31, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:10,332 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 26.0 (TID 449)
[INFO] 2019-01-19 13:28:10,332 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 26.0 (TID 447) in 447 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 13:28:10,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:10,348 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:10,677 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 26.0 (TID 448). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:10,677 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 26.0 (TID 450, localhost, executor driver, partition 32, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:10,677 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 26.0 (TID 450)
[INFO] 2019-01-19 13:28:10,678 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 26.0 (TID 448) in 418 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 13:28:10,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:10,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:10,723 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 26.0 (TID 449). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:10,724 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 26.0 (TID 451, localhost, executor driver, partition 33, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:10,724 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 26.0 (TID 449) in 392 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 13:28:10,724 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 26.0 (TID 451)
[INFO] 2019-01-19 13:28:10,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:10,737 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:11,076 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 26.0 (TID 450). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:11,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 26.0 (TID 452, localhost, executor driver, partition 34, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:11,076 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 26.0 (TID 452)
[INFO] 2019-01-19 13:28:11,076 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 26.0 (TID 450) in 399 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 13:28:11,090 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:11,091 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:11,122 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 26.0 (TID 451). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:11,122 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 26.0 (TID 453, localhost, executor driver, partition 35, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:11,123 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 26.0 (TID 453)
[INFO] 2019-01-19 13:28:11,123 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 26.0 (TID 451) in 400 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 13:28:11,139 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:11,139 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:11,445 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 26.0 (TID 452). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:11,446 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 26.0 (TID 454, localhost, executor driver, partition 36, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:11,446 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 26.0 (TID 454)
[INFO] 2019-01-19 13:28:11,446 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 26.0 (TID 452) in 370 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 13:28:11,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:11,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:11,496 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 26.0 (TID 453). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:11,496 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 26.0 (TID 455, localhost, executor driver, partition 37, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:11,496 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 26.0 (TID 455)
[INFO] 2019-01-19 13:28:11,496 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 26.0 (TID 453) in 374 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 13:28:11,509 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:11,509 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:11,830 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 26.0 (TID 454). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:11,830 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 26.0 (TID 456, localhost, executor driver, partition 38, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:11,830 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 26.0 (TID 456)
[INFO] 2019-01-19 13:28:11,830 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 26.0 (TID 454) in 385 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 13:28:11,842 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:11,842 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:11,905 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 26.0 (TID 455). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:11,906 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 26.0 (TID 457, localhost, executor driver, partition 39, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:11,906 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 26.0 (TID 457)
[INFO] 2019-01-19 13:28:11,906 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 26.0 (TID 455) in 410 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 13:28:11,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:11,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:12,249 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 26.0 (TID 456). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:12,250 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 26.0 (TID 458, localhost, executor driver, partition 40, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:12,250 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 26.0 (TID 458)
[INFO] 2019-01-19 13:28:12,250 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 26.0 (TID 456) in 420 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 13:28:12,262 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:12,262 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:12,308 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 26.0 (TID 457). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:12,308 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 26.0 (TID 459, localhost, executor driver, partition 41, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:12,308 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 26.0 (TID 459)
[INFO] 2019-01-19 13:28:12,308 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 26.0 (TID 457) in 402 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 13:28:12,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:12,323 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:12,672 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 26.0 (TID 458). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:12,672 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 26.0 (TID 460, localhost, executor driver, partition 42, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:12,673 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 26.0 (TID 458) in 424 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 13:28:12,673 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 26.0 (TID 460)
[INFO] 2019-01-19 13:28:12,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:12,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:12,723 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 26.0 (TID 459). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:12,724 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 26.0 (TID 461, localhost, executor driver, partition 43, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:12,724 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 26.0 (TID 461)
[INFO] 2019-01-19 13:28:12,724 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 26.0 (TID 459) in 416 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 13:28:12,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:12,736 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:13,066 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 26.0 (TID 460). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:13,066 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 26.0 (TID 462, localhost, executor driver, partition 44, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:13,066 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 26.0 (TID 462)
[INFO] 2019-01-19 13:28:13,066 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 26.0 (TID 460) in 394 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 13:28:13,078 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:13,079 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:13,098 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 26.0 (TID 461). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:13,099 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 26.0 (TID 463, localhost, executor driver, partition 45, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:13,099 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 26.0 (TID 463)
[INFO] 2019-01-19 13:28:13,099 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 26.0 (TID 461) in 376 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 13:28:13,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:13,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:13,454 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 26.0 (TID 462). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:13,455 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 26.0 (TID 464, localhost, executor driver, partition 46, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:13,455 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 26.0 (TID 464)
[INFO] 2019-01-19 13:28:13,455 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 26.0 (TID 462) in 389 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 13:28:13,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:13,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:13,495 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 26.0 (TID 463). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:13,495 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 26.0 (TID 465, localhost, executor driver, partition 47, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:13,496 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 26.0 (TID 465)
[INFO] 2019-01-19 13:28:13,496 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 26.0 (TID 463) in 398 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 13:28:13,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:13,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:13,819 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 26.0 (TID 464). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:13,819 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 26.0 (TID 466, localhost, executor driver, partition 48, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:13,819 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 26.0 (TID 466)
[INFO] 2019-01-19 13:28:13,819 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 26.0 (TID 464) in 365 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 13:28:13,831 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:13,831 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:13,871 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 26.0 (TID 465). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:13,875 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 26.0 (TID 467, localhost, executor driver, partition 49, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:13,876 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 26.0 (TID 465) in 381 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 13:28:13,877 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 26.0 (TID 467)
[INFO] 2019-01-19 13:28:13,889 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:13,889 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:14,202 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 26.0 (TID 466). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:14,202 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 26.0 (TID 468, localhost, executor driver, partition 50, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:14,202 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 26.0 (TID 468)
[INFO] 2019-01-19 13:28:14,202 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 26.0 (TID 466) in 383 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 13:28:14,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:14,213 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:14,255 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 26.0 (TID 467). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:14,255 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 26.0 (TID 469, localhost, executor driver, partition 51, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:14,255 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 26.0 (TID 469)
[INFO] 2019-01-19 13:28:14,255 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 26.0 (TID 467) in 380 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 13:28:14,268 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:14,268 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:14,565 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 26.0 (TID 468). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:14,565 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 26.0 (TID 470, localhost, executor driver, partition 52, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:14,566 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 26.0 (TID 470)
[INFO] 2019-01-19 13:28:14,566 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 26.0 (TID 468) in 364 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 13:28:14,579 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:14,579 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:14,621 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 26.0 (TID 469). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:14,624 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 26.0 (TID 471, localhost, executor driver, partition 53, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:14,624 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 26.0 (TID 469) in 369 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 13:28:14,624 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 26.0 (TID 471)
[INFO] 2019-01-19 13:28:14,637 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:14,637 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:14,945 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 26.0 (TID 470). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:14,945 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 26.0 (TID 472, localhost, executor driver, partition 54, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:14,946 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 26.0 (TID 472)
[INFO] 2019-01-19 13:28:14,946 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 26.0 (TID 470) in 381 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 13:28:14,959 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:14,965 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 6 ms
[INFO] 2019-01-19 13:28:15,006 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 26.0 (TID 471). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:15,006 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 26.0 (TID 473, localhost, executor driver, partition 55, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:15,006 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 26.0 (TID 473)
[INFO] 2019-01-19 13:28:15,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 26.0 (TID 471) in 383 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 13:28:15,017 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:15,017 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:15,339 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 26.0 (TID 472). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:15,339 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 26.0 (TID 474, localhost, executor driver, partition 56, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:15,339 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 26.0 (TID 474)
[INFO] 2019-01-19 13:28:15,340 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 26.0 (TID 472) in 395 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 13:28:15,352 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:15,352 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:15,390 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 26.0 (TID 473). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:15,391 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 26.0 (TID 475, localhost, executor driver, partition 57, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:15,391 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 26.0 (TID 473) in 385 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 13:28:15,391 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 26.0 (TID 475)
[INFO] 2019-01-19 13:28:15,405 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:15,405 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:15,697 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 26.0 (TID 474). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:15,697 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 26.0 (TID 476, localhost, executor driver, partition 58, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:15,697 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 26.0 (TID 476)
[INFO] 2019-01-19 13:28:15,697 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 26.0 (TID 474) in 358 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 13:28:15,707 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:15,707 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:15,760 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 26.0 (TID 475). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:15,760 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 26.0 (TID 477, localhost, executor driver, partition 59, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:15,761 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 26.0 (TID 475) in 371 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 13:28:15,761 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 26.0 (TID 477)
[INFO] 2019-01-19 13:28:15,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:15,775 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:16,108 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 26.0 (TID 476). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:16,109 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 26.0 (TID 478, localhost, executor driver, partition 60, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:16,110 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 26.0 (TID 478)
[INFO] 2019-01-19 13:28:16,110 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 26.0 (TID 476) in 413 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 13:28:16,120 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:16,121 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:16,160 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 26.0 (TID 477). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:16,160 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 26.0 (TID 479, localhost, executor driver, partition 61, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:16,161 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 26.0 (TID 479)
[INFO] 2019-01-19 13:28:16,161 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 26.0 (TID 477) in 401 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 13:28:16,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:16,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:16,568 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 26.0 (TID 478). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:16,569 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 26.0 (TID 480, localhost, executor driver, partition 62, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:16,569 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 26.0 (TID 480)
[INFO] 2019-01-19 13:28:16,569 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 26.0 (TID 478) in 460 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 13:28:16,581 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:16,582 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:16,585 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 26.0 (TID 479). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:16,586 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 26.0 (TID 481, localhost, executor driver, partition 63, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:16,586 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 26.0 (TID 481)
[INFO] 2019-01-19 13:28:16,586 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 26.0 (TID 479) in 426 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 13:28:16,598 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:16,598 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:16,929 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 26.0 (TID 480). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:16,930 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 26.0 (TID 482, localhost, executor driver, partition 64, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:16,930 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 26.0 (TID 482)
[INFO] 2019-01-19 13:28:16,930 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 26.0 (TID 480) in 362 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 13:28:16,942 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:16,943 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:16,970 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 26.0 (TID 481). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:16,970 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 26.0 (TID 483, localhost, executor driver, partition 65, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:16,970 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 26.0 (TID 483)
[INFO] 2019-01-19 13:28:16,970 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 26.0 (TID 481) in 385 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 13:28:16,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:16,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:17,318 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 26.0 (TID 482). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:17,318 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 26.0 (TID 484, localhost, executor driver, partition 66, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:17,319 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 26.0 (TID 484)
[INFO] 2019-01-19 13:28:17,319 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 26.0 (TID 482) in 389 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 13:28:17,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:17,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:17,365 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 26.0 (TID 483). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:17,365 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 26.0 (TID 485, localhost, executor driver, partition 67, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:17,365 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 26.0 (TID 485)
[INFO] 2019-01-19 13:28:17,365 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 26.0 (TID 483) in 395 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 13:28:17,375 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:17,375 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:17,676 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 26.0 (TID 484). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:17,676 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 26.0 (TID 486, localhost, executor driver, partition 68, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:17,677 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 26.0 (TID 486)
[INFO] 2019-01-19 13:28:17,677 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 26.0 (TID 484) in 359 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 13:28:17,690 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:17,690 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:17,698 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 26.0 (TID 485). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:17,699 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 26.0 (TID 487, localhost, executor driver, partition 69, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:17,699 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 26.0 (TID 487)
[INFO] 2019-01-19 13:28:17,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 26.0 (TID 485) in 334 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 13:28:17,712 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:17,712 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:18,082 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 26.0 (TID 486). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:18,083 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 26.0 (TID 488, localhost, executor driver, partition 70, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:18,083 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 26.0 (TID 488)
[INFO] 2019-01-19 13:28:18,083 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 26.0 (TID 486) in 407 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 13:28:18,086 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 26.0 (TID 487). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:18,087 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 26.0 (TID 489, localhost, executor driver, partition 71, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:18,088 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 26.0 (TID 487) in 390 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 13:28:18,088 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 26.0 (TID 489)
[INFO] 2019-01-19 13:28:18,096 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:18,096 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:18,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:18,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:18,474 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 26.0 (TID 489). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:18,474 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 26.0 (TID 490, localhost, executor driver, partition 72, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:18,475 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 26.0 (TID 489) in 388 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 13:28:18,475 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 26.0 (TID 490)
[INFO] 2019-01-19 13:28:18,479 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 26.0 (TID 488). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:18,480 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 26.0 (TID 491, localhost, executor driver, partition 73, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:18,480 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 26.0 (TID 491)
[INFO] 2019-01-19 13:28:18,480 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 26.0 (TID 488) in 398 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 13:28:18,485 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:18,485 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:18,493 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:18,493 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:18,854 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 26.0 (TID 490). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:18,855 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 26.0 (TID 492, localhost, executor driver, partition 74, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:18,856 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 26.0 (TID 490) in 382 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 13:28:18,856 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 26.0 (TID 492)
[INFO] 2019-01-19 13:28:18,861 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 26.0 (TID 491). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:18,861 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 26.0 (TID 493, localhost, executor driver, partition 75, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:18,862 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 26.0 (TID 491) in 383 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 13:28:18,862 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 26.0 (TID 493)
[INFO] 2019-01-19 13:28:18,869 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:18,870 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:18,876 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:18,876 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:19,226 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 26.0 (TID 493). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:19,226 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 26.0 (TID 494, localhost, executor driver, partition 76, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:19,226 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 26.0 (TID 494)
[INFO] 2019-01-19 13:28:19,226 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 26.0 (TID 493) in 365 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 13:28:19,231 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 26.0 (TID 492). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:19,231 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 26.0 (TID 495, localhost, executor driver, partition 77, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:19,232 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 26.0 (TID 492) in 378 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 13:28:19,232 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 26.0 (TID 495)
[INFO] 2019-01-19 13:28:19,241 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:19,242 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:19,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:19,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:19,601 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 26.0 (TID 495). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:19,601 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 26.0 (TID 496, localhost, executor driver, partition 78, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:19,602 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 26.0 (TID 496)
[INFO] 2019-01-19 13:28:19,602 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 26.0 (TID 495) in 371 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 13:28:19,605 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 26.0 (TID 494). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:19,605 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 26.0 (TID 497, localhost, executor driver, partition 79, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:19,606 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 26.0 (TID 497)
[INFO] 2019-01-19 13:28:19,606 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 26.0 (TID 494) in 380 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 13:28:19,615 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:19,616 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:19,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:19,618 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:19,950 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 26.0 (TID 497). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:19,951 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 26.0 (TID 498, localhost, executor driver, partition 80, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:19,951 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 26.0 (TID 498)
[INFO] 2019-01-19 13:28:19,951 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 26.0 (TID 497) in 346 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 13:28:19,965 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 26.0 (TID 496). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:19,965 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 26.0 (TID 499, localhost, executor driver, partition 81, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:19,966 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 26.0 (TID 499)
[INFO] 2019-01-19 13:28:19,966 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 26.0 (TID 496) in 365 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 13:28:19,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:19,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:19,977 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:19,977 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:20,366 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 26.0 (TID 499). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:20,367 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 26.0 (TID 500, localhost, executor driver, partition 82, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:20,367 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 26.0 (TID 499) in 402 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 13:28:20,367 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 26.0 (TID 500)
[INFO] 2019-01-19 13:28:20,372 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 26.0 (TID 498). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:20,372 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 26.0 (TID 501, localhost, executor driver, partition 83, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:20,372 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 26.0 (TID 501)
[INFO] 2019-01-19 13:28:20,372 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 26.0 (TID 498) in 421 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 13:28:20,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:20,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:20,385 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:20,385 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:20,705 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 26.0 (TID 500). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:20,706 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 26.0 (TID 502, localhost, executor driver, partition 84, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:20,706 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 26.0 (TID 502)
[INFO] 2019-01-19 13:28:20,706 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 26.0 (TID 500) in 340 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 13:28:20,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:20,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:20,731 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 26.0 (TID 501). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:20,732 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 26.0 (TID 503, localhost, executor driver, partition 85, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:20,732 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 26.0 (TID 503)
[INFO] 2019-01-19 13:28:20,732 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 26.0 (TID 501) in 360 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 13:28:20,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:20,744 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:21,067 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 26.0 (TID 502). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:21,068 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 26.0 (TID 504, localhost, executor driver, partition 86, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:21,068 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 26.0 (TID 504)
[INFO] 2019-01-19 13:28:21,068 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 26.0 (TID 502) in 362 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 13:28:21,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:21,080 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:21,115 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 26.0 (TID 503). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:21,115 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 26.0 (TID 505, localhost, executor driver, partition 87, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:21,116 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 26.0 (TID 505)
[INFO] 2019-01-19 13:28:21,116 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 26.0 (TID 503) in 384 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 13:28:21,127 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:21,127 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:21,416 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 26.0 (TID 504). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:21,417 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 26.0 (TID 506, localhost, executor driver, partition 88, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:21,417 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 26.0 (TID 506)
[INFO] 2019-01-19 13:28:21,417 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 26.0 (TID 504) in 350 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 13:28:21,428 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:21,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:21,473 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 26.0 (TID 505). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:21,474 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 26.0 (TID 507, localhost, executor driver, partition 89, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:21,474 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 26.0 (TID 507)
[INFO] 2019-01-19 13:28:21,474 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 26.0 (TID 505) in 359 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 13:28:21,484 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:21,484 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:21,809 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 26.0 (TID 506). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:21,809 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 26.0 (TID 508, localhost, executor driver, partition 90, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:21,810 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 26.0 (TID 508)
[INFO] 2019-01-19 13:28:21,810 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 26.0 (TID 506) in 394 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 13:28:21,822 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:21,822 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:21,879 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 26.0 (TID 507). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:21,879 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 26.0 (TID 509, localhost, executor driver, partition 91, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:21,879 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 26.0 (TID 509)
[INFO] 2019-01-19 13:28:21,879 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 26.0 (TID 507) in 406 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 13:28:21,894 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:21,894 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:22,164 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 26.0 (TID 508). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:22,165 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 26.0 (TID 510, localhost, executor driver, partition 92, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:22,165 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 26.0 (TID 510)
[INFO] 2019-01-19 13:28:22,165 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 26.0 (TID 508) in 356 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 13:28:22,176 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:22,177 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:22,243 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 26.0 (TID 509). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:22,244 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 26.0 (TID 511, localhost, executor driver, partition 93, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:22,244 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 26.0 (TID 511)
[INFO] 2019-01-19 13:28:22,244 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 26.0 (TID 509) in 365 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 13:28:22,254 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:22,254 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:22,532 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 26.0 (TID 510). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:22,532 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 26.0 (TID 512, localhost, executor driver, partition 94, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:22,533 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 26.0 (TID 512)
[INFO] 2019-01-19 13:28:22,533 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 26.0 (TID 510) in 368 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 13:28:22,545 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:22,545 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:22,626 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 26.0 (TID 511). 4270 bytes result sent to driver
[INFO] 2019-01-19 13:28:22,626 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 26.0 (TID 513, localhost, executor driver, partition 95, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:22,627 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 26.0 (TID 513)
[INFO] 2019-01-19 13:28:22,627 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 26.0 (TID 511) in 384 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 13:28:22,641 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:22,641 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:22,905 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 26.0 (TID 512). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:22,905 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 26.0 (TID 514, localhost, executor driver, partition 96, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:22,906 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 26.0 (TID 512) in 374 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 13:28:22,906 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 26.0 (TID 514)
[INFO] 2019-01-19 13:28:22,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:22,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:22,985 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 26.0 (TID 513). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:22,985 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 26.0 (TID 515, localhost, executor driver, partition 97, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:22,986 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 26.0 (TID 515)
[INFO] 2019-01-19 13:28:22,986 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 26.0 (TID 513) in 360 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 13:28:22,997 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:22,997 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:23,268 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 26.0 (TID 514). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:23,269 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 26.0 (TID 516, localhost, executor driver, partition 98, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:23,269 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 26.0 (TID 516)
[INFO] 2019-01-19 13:28:23,269 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 26.0 (TID 514) in 364 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 13:28:23,282 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:23,282 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:23,346 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 26.0 (TID 515). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:23,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 26.0 (TID 517, localhost, executor driver, partition 99, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:23,347 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 26.0 (TID 517)
[INFO] 2019-01-19 13:28:23,347 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 26.0 (TID 515) in 362 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 13:28:23,359 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:23,359 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:23,633 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 26.0 (TID 516). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:23,634 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 26.0 (TID 518, localhost, executor driver, partition 100, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:23,634 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 26.0 (TID 518)
[INFO] 2019-01-19 13:28:23,634 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 26.0 (TID 516) in 365 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 13:28:23,646 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:23,646 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:23,685 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 26.0 (TID 517). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:23,685 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 26.0 (TID 519, localhost, executor driver, partition 101, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:23,685 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 26.0 (TID 519)
[INFO] 2019-01-19 13:28:23,686 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 26.0 (TID 517) in 340 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 13:28:23,696 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:23,696 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:23,995 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 26.0 (TID 518). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:23,995 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 26.0 (TID 520, localhost, executor driver, partition 102, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:23,995 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 26.0 (TID 520)
[INFO] 2019-01-19 13:28:23,995 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 26.0 (TID 518) in 361 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 13:28:24,006 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:24,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:24,027 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 26.0 (TID 519). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:24,027 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 26.0 (TID 521, localhost, executor driver, partition 103, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:24,027 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 26.0 (TID 521)
[INFO] 2019-01-19 13:28:24,027 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 26.0 (TID 519) in 342 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 13:28:24,039 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:24,039 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:24,409 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 26.0 (TID 520). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:24,409 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 26.0 (TID 522, localhost, executor driver, partition 104, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:24,410 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 26.0 (TID 520) in 415 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 13:28:24,410 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 26.0 (TID 522)
[INFO] 2019-01-19 13:28:24,425 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:24,426 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:24,435 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 26.0 (TID 521). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:24,435 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 26.0 (TID 523, localhost, executor driver, partition 105, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:24,435 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 26.0 (TID 523)
[INFO] 2019-01-19 13:28:24,436 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 26.0 (TID 521) in 408 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 13:28:24,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:24,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:24,806 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 26.0 (TID 522). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:24,806 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 26.0 (TID 524, localhost, executor driver, partition 106, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:24,806 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 26.0 (TID 524)
[INFO] 2019-01-19 13:28:24,806 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 26.0 (TID 522) in 397 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 13:28:24,819 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 26.0 (TID 523). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:24,820 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 26.0 (TID 525, localhost, executor driver, partition 107, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:24,820 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:24,820 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:24,820 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 26.0 (TID 525)
[INFO] 2019-01-19 13:28:24,820 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 26.0 (TID 523) in 385 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 13:28:24,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:24,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:25,152 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 26.0 (TID 525). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:25,153 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 26.0 (TID 526, localhost, executor driver, partition 108, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:25,153 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 26.0 (TID 526)
[INFO] 2019-01-19 13:28:25,153 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 26.0 (TID 525) in 334 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 13:28:25,160 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 26.0 (TID 524). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:25,161 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 26.0 (TID 527, localhost, executor driver, partition 109, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:25,161 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 26.0 (TID 524) in 355 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 13:28:25,162 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 26.0 (TID 527)
[INFO] 2019-01-19 13:28:25,168 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:25,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:25,175 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:25,175 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:25,512 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 26.0 (TID 527). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:25,513 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 26.0 (TID 528, localhost, executor driver, partition 110, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:25,513 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 26.0 (TID 528)
[INFO] 2019-01-19 13:28:25,513 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 26.0 (TID 527) in 352 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 13:28:25,521 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 26.0 (TID 526). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:25,522 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 26.0 (TID 529, localhost, executor driver, partition 111, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:25,522 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 26.0 (TID 529)
[INFO] 2019-01-19 13:28:25,522 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 26.0 (TID 526) in 370 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 13:28:25,526 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:25,526 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:25,533 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:25,534 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:25,863 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 26.0 (TID 528). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:25,863 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 26.0 (TID 530, localhost, executor driver, partition 112, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:25,863 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 26.0 (TID 530)
[INFO] 2019-01-19 13:28:25,864 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 26.0 (TID 528) in 351 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 13:28:25,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:25,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:25,910 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 26.0 (TID 529). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:25,911 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 26.0 (TID 531, localhost, executor driver, partition 113, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:25,911 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 26.0 (TID 531)
[INFO] 2019-01-19 13:28:25,911 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 26.0 (TID 529) in 389 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 13:28:25,924 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:25,924 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:26,240 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 26.0 (TID 530). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:26,241 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 26.0 (TID 532, localhost, executor driver, partition 114, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:26,241 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 26.0 (TID 532)
[INFO] 2019-01-19 13:28:26,241 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 26.0 (TID 530) in 378 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 13:28:26,254 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:26,254 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:26,268 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 26.0 (TID 531). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:26,270 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 26.0 (TID 533, localhost, executor driver, partition 115, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:26,271 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 26.0 (TID 531) in 360 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 13:28:26,272 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 26.0 (TID 533)
[INFO] 2019-01-19 13:28:26,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:26,288 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:26,704 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 26.0 (TID 532). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:26,704 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 26.0 (TID 534, localhost, executor driver, partition 116, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:26,705 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 26.0 (TID 534)
[INFO] 2019-01-19 13:28:26,705 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 26.0 (TID 532) in 464 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 13:28:26,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:26,719 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:26,732 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 26.0 (TID 533). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:26,732 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 26.0 (TID 535, localhost, executor driver, partition 117, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:26,733 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 26.0 (TID 535)
[INFO] 2019-01-19 13:28:26,733 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 26.0 (TID 533) in 463 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 13:28:26,750 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:26,750 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:27,206 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 26.0 (TID 534). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:27,206 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 26.0 (TID 536, localhost, executor driver, partition 118, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:27,207 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 26.0 (TID 534) in 503 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 13:28:27,207 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 26.0 (TID 536)
[INFO] 2019-01-19 13:28:27,222 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:27,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:27,249 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 26.0 (TID 535). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:27,249 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 26.0 (TID 537, localhost, executor driver, partition 119, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:27,250 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 26.0 (TID 535) in 518 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 13:28:27,250 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 26.0 (TID 537)
[INFO] 2019-01-19 13:28:27,265 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:27,265 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:27,640 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 26.0 (TID 536). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:27,641 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 26.0 (TID 538, localhost, executor driver, partition 120, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:27,641 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 26.0 (TID 538)
[INFO] 2019-01-19 13:28:27,641 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 26.0 (TID 536) in 435 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 13:28:27,647 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 26.0 (TID 537). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:27,648 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 26.0 (TID 539, localhost, executor driver, partition 121, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:27,648 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 26.0 (TID 537) in 399 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 13:28:27,648 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 26.0 (TID 539)
[INFO] 2019-01-19 13:28:27,654 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:27,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:27,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:27,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:27,994 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 26.0 (TID 538). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:27,994 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 26.0 (TID 540, localhost, executor driver, partition 122, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:27,994 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 26.0 (TID 540)
[INFO] 2019-01-19 13:28:27,994 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 26.0 (TID 538) in 353 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 13:28:27,998 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 26.0 (TID 539). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:27,999 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 26.0 (TID 541, localhost, executor driver, partition 123, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:27,999 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 26.0 (TID 539) in 351 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 13:28:27,999 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 26.0 (TID 541)
[INFO] 2019-01-19 13:28:28,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:28,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:28,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:28,012 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:28,357 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 26.0 (TID 540). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:28,357 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 26.0 (TID 542, localhost, executor driver, partition 124, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:28,358 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 26.0 (TID 542)
[INFO] 2019-01-19 13:28:28,358 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 26.0 (TID 540) in 364 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 13:28:28,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:28,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:28,374 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 26.0 (TID 541). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:28,375 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 26.0 (TID 543, localhost, executor driver, partition 125, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:28,375 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 26.0 (TID 543)
[INFO] 2019-01-19 13:28:28,375 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 26.0 (TID 541) in 377 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 13:28:28,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:28,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:28,733 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 26.0 (TID 543). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:28,734 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 26.0 (TID 544, localhost, executor driver, partition 126, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:28,734 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 26.0 (TID 544)
[INFO] 2019-01-19 13:28:28,734 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 26.0 (TID 543) in 359 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 13:28:28,738 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 26.0 (TID 542). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:28,739 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 26.0 (TID 545, localhost, executor driver, partition 127, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:28,739 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 26.0 (TID 542) in 382 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 13:28:28,739 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 26.0 (TID 545)
[INFO] 2019-01-19 13:28:28,748 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:28,748 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:28,757 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:28,757 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:29,133 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 26.0 (TID 544). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:29,134 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 26.0 (TID 546, localhost, executor driver, partition 128, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:29,134 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 26.0 (TID 544) in 400 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 13:28:29,135 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 26.0 (TID 546)
[INFO] 2019-01-19 13:28:29,140 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 26.0 (TID 545). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:29,140 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 26.0 (TID 547, localhost, executor driver, partition 129, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:29,141 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 26.0 (TID 545) in 403 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 13:28:29,141 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 26.0 (TID 547)
[INFO] 2019-01-19 13:28:29,149 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:29,149 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:29,156 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:29,156 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:29,538 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 26.0 (TID 546). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:29,538 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 26.0 (TID 548, localhost, executor driver, partition 130, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:29,539 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 26.0 (TID 548)
[INFO] 2019-01-19 13:28:29,539 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 26.0 (TID 546) in 405 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 13:28:29,555 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:29,555 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:29,562 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 26.0 (TID 547). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:29,562 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 26.0 (TID 549, localhost, executor driver, partition 131, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:29,563 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 26.0 (TID 547) in 423 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 13:28:29,563 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 26.0 (TID 549)
[INFO] 2019-01-19 13:28:29,576 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:29,576 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:29,942 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 26.0 (TID 548). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:29,942 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 26.0 (TID 550, localhost, executor driver, partition 132, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:29,942 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 26.0 (TID 550)
[INFO] 2019-01-19 13:28:29,942 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 26.0 (TID 548) in 404 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 13:28:29,954 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:29,954 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:29,980 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 26.0 (TID 549). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:29,980 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 26.0 (TID 551, localhost, executor driver, partition 133, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:29,981 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 26.0 (TID 551)
[INFO] 2019-01-19 13:28:29,981 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 26.0 (TID 549) in 419 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 13:28:29,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:29,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:30,306 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 26.0 (TID 550). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:30,307 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 26.0 (TID 552, localhost, executor driver, partition 134, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:30,307 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 26.0 (TID 552)
[INFO] 2019-01-19 13:28:30,307 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 26.0 (TID 550) in 365 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 13:28:30,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:30,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:30,363 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 26.0 (TID 551). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:30,364 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 26.0 (TID 553, localhost, executor driver, partition 135, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:30,364 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 26.0 (TID 553)
[INFO] 2019-01-19 13:28:30,364 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 26.0 (TID 551) in 384 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 13:28:30,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:30,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:30,714 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 26.0 (TID 552). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:30,715 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 26.0 (TID 554, localhost, executor driver, partition 136, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:30,715 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 26.0 (TID 554)
[INFO] 2019-01-19 13:28:30,715 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 26.0 (TID 552) in 408 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 13:28:30,727 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:30,727 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:30,752 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 26.0 (TID 553). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:30,753 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 26.0 (TID 555, localhost, executor driver, partition 137, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:30,753 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 26.0 (TID 555)
[INFO] 2019-01-19 13:28:30,753 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 26.0 (TID 553) in 390 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 13:28:30,766 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:30,766 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:31,094 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 26.0 (TID 554). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:31,094 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 26.0 (TID 556, localhost, executor driver, partition 138, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:31,095 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 26.0 (TID 556)
[INFO] 2019-01-19 13:28:31,095 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 26.0 (TID 554) in 381 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 13:28:31,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:31,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:31,157 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 26.0 (TID 555). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:31,157 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 26.0 (TID 557, localhost, executor driver, partition 139, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:31,157 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 26.0 (TID 557)
[INFO] 2019-01-19 13:28:31,157 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 26.0 (TID 555) in 404 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 13:28:31,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:31,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:31,496 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 26.0 (TID 556). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:31,497 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 26.0 (TID 558, localhost, executor driver, partition 140, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:31,497 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 26.0 (TID 558)
[INFO] 2019-01-19 13:28:31,497 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 26.0 (TID 556) in 403 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 13:28:31,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:31,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:31,591 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 26.0 (TID 557). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:31,592 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 26.0 (TID 559, localhost, executor driver, partition 141, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:31,592 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 26.0 (TID 559)
[INFO] 2019-01-19 13:28:31,592 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 26.0 (TID 557) in 435 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 13:28:31,607 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:31,607 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:32,002 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 26.0 (TID 558). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:32,003 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 26.0 (TID 560, localhost, executor driver, partition 142, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:32,003 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 26.0 (TID 560)
[INFO] 2019-01-19 13:28:32,003 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 26.0 (TID 558) in 506 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 13:28:32,016 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:32,016 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:32,058 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 26.0 (TID 559). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:32,059 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 26.0 (TID 561, localhost, executor driver, partition 143, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:32,059 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 26.0 (TID 561)
[INFO] 2019-01-19 13:28:32,059 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 26.0 (TID 559) in 468 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 13:28:32,071 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:32,071 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:32,483 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 26.0 (TID 560). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:32,484 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 26.0 (TID 562, localhost, executor driver, partition 144, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:32,484 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 26.0 (TID 560) in 481 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 13:28:32,484 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 26.0 (TID 562)
[INFO] 2019-01-19 13:28:32,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:32,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:32,547 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 26.0 (TID 561). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:32,548 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 26.0 (TID 563, localhost, executor driver, partition 145, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:32,548 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 26.0 (TID 563)
[INFO] 2019-01-19 13:28:32,548 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 26.0 (TID 561) in 489 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 13:28:32,561 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:32,561 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:32,872 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 26.0 (TID 562). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:32,872 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 26.0 (TID 564, localhost, executor driver, partition 146, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:32,873 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 26.0 (TID 564)
[INFO] 2019-01-19 13:28:32,873 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 26.0 (TID 562) in 390 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 13:28:32,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:32,885 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:32,937 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 26.0 (TID 563). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:32,938 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 26.0 (TID 565, localhost, executor driver, partition 147, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:32,938 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 26.0 (TID 565)
[INFO] 2019-01-19 13:28:32,938 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 26.0 (TID 563) in 390 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 13:28:32,952 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:32,952 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:33,244 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 26.0 (TID 564). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:33,245 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 26.0 (TID 566, localhost, executor driver, partition 148, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:33,245 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 26.0 (TID 566)
[INFO] 2019-01-19 13:28:33,245 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 26.0 (TID 564) in 373 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 13:28:33,256 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:33,256 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:33,333 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 26.0 (TID 565). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:33,334 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 26.0 (TID 567, localhost, executor driver, partition 149, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:33,334 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 26.0 (TID 567)
[INFO] 2019-01-19 13:28:33,334 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 26.0 (TID 565) in 396 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 13:28:33,346 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:33,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:33,659 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 26.0 (TID 566). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:33,660 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 26.0 (TID 568, localhost, executor driver, partition 150, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:33,660 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 26.0 (TID 568)
[INFO] 2019-01-19 13:28:33,660 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 26.0 (TID 566) in 415 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 13:28:33,675 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:33,676 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:33,755 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 26.0 (TID 567). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:33,755 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 26.0 (TID 569, localhost, executor driver, partition 151, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:33,755 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 26.0 (TID 569)
[INFO] 2019-01-19 13:28:33,755 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 26.0 (TID 567) in 422 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 13:28:33,769 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:33,769 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:34,061 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 26.0 (TID 568). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:34,062 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 26.0 (TID 570, localhost, executor driver, partition 152, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:34,062 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 26.0 (TID 570)
[INFO] 2019-01-19 13:28:34,062 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 26.0 (TID 568) in 403 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 13:28:34,076 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:34,076 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:34,166 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 26.0 (TID 569). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:34,166 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 26.0 (TID 571, localhost, executor driver, partition 153, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:34,167 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 26.0 (TID 571)
[INFO] 2019-01-19 13:28:34,167 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 26.0 (TID 569) in 412 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 13:28:34,182 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:34,182 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:34,473 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 26.0 (TID 570). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:34,473 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 26.0 (TID 572, localhost, executor driver, partition 154, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:34,474 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 26.0 (TID 572)
[INFO] 2019-01-19 13:28:34,474 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 26.0 (TID 570) in 413 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 13:28:34,487 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:34,487 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:34,554 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 26.0 (TID 571). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:34,554 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 26.0 (TID 573, localhost, executor driver, partition 155, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:34,554 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 26.0 (TID 573)
[INFO] 2019-01-19 13:28:34,554 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 26.0 (TID 571) in 388 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 13:28:34,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:34,567 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:34,847 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 26.0 (TID 572). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:34,848 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 26.0 (TID 574, localhost, executor driver, partition 156, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:34,848 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 26.0 (TID 574)
[INFO] 2019-01-19 13:28:34,848 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 26.0 (TID 572) in 375 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 13:28:34,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:34,861 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:34,933 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 26.0 (TID 573). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:34,933 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 26.0 (TID 575, localhost, executor driver, partition 157, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:34,933 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 26.0 (TID 575)
[INFO] 2019-01-19 13:28:34,933 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 26.0 (TID 573) in 379 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 13:28:34,946 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:34,947 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:35,224 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 26.0 (TID 574). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:35,224 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 26.0 (TID 576, localhost, executor driver, partition 158, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:35,225 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 26.0 (TID 574) in 378 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 13:28:35,225 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 26.0 (TID 576)
[INFO] 2019-01-19 13:28:35,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:35,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:35,294 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 26.0 (TID 575). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:35,294 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 26.0 (TID 577, localhost, executor driver, partition 159, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:35,295 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 26.0 (TID 577)
[INFO] 2019-01-19 13:28:35,295 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 26.0 (TID 575) in 362 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 13:28:35,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:35,307 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:35,636 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 26.0 (TID 576). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:35,637 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 26.0 (TID 578, localhost, executor driver, partition 160, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:35,637 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 26.0 (TID 578)
[INFO] 2019-01-19 13:28:35,637 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 26.0 (TID 576) in 413 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 13:28:35,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:35,648 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:35,675 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 26.0 (TID 577). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:35,675 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 26.0 (TID 579, localhost, executor driver, partition 161, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:35,676 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 26.0 (TID 579)
[INFO] 2019-01-19 13:28:35,676 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 26.0 (TID 577) in 382 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 13:28:35,689 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:35,689 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:36,078 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 26.0 (TID 578). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:36,079 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 26.0 (TID 580, localhost, executor driver, partition 162, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:36,079 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 26.0 (TID 580)
[INFO] 2019-01-19 13:28:36,079 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 26.0 (TID 578) in 443 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 13:28:36,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:36,093 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:36,137 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 26.0 (TID 579). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:36,137 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 26.0 (TID 581, localhost, executor driver, partition 163, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:36,137 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 26.0 (TID 581)
[INFO] 2019-01-19 13:28:36,138 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 26.0 (TID 579) in 463 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 13:28:36,148 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:36,148 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:36,511 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 26.0 (TID 580). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:36,511 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 26.0 (TID 582, localhost, executor driver, partition 164, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:36,511 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 26.0 (TID 582)
[INFO] 2019-01-19 13:28:36,511 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 26.0 (TID 580) in 433 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 13:28:36,524 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:36,524 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:36,578 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 26.0 (TID 581). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:36,579 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 26.0 (TID 583, localhost, executor driver, partition 165, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:36,579 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 26.0 (TID 583)
[INFO] 2019-01-19 13:28:36,579 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 26.0 (TID 581) in 442 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 13:28:36,593 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:36,593 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:36,918 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 26.0 (TID 582). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:36,919 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 26.0 (TID 584, localhost, executor driver, partition 166, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:36,919 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 26.0 (TID 584)
[INFO] 2019-01-19 13:28:36,919 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 26.0 (TID 582) in 408 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 13:28:36,933 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:36,933 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:37,012 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 26.0 (TID 583). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:37,013 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 26.0 (TID 585, localhost, executor driver, partition 167, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:37,013 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 26.0 (TID 585)
[INFO] 2019-01-19 13:28:37,013 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 26.0 (TID 583) in 435 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 13:28:37,029 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:37,029 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:37,322 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 26.0 (TID 584). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:37,323 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 26.0 (TID 586, localhost, executor driver, partition 168, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:37,323 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 26.0 (TID 586)
[INFO] 2019-01-19 13:28:37,323 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 26.0 (TID 584) in 405 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 13:28:37,336 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:37,336 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:37,390 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 26.0 (TID 585). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:37,391 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 26.0 (TID 587, localhost, executor driver, partition 169, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:37,391 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 26.0 (TID 587)
[INFO] 2019-01-19 13:28:37,391 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 26.0 (TID 585) in 378 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 13:28:37,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:37,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:37,698 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 26.0 (TID 586). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:37,698 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 26.0 (TID 588, localhost, executor driver, partition 170, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:37,698 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 26.0 (TID 588)
[INFO] 2019-01-19 13:28:37,698 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 26.0 (TID 586) in 376 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 13:28:37,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:37,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:37,767 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 26.0 (TID 587). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:37,767 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 26.0 (TID 589, localhost, executor driver, partition 171, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:37,768 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 26.0 (TID 589)
[INFO] 2019-01-19 13:28:37,768 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 26.0 (TID 587) in 378 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 13:28:37,780 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:37,780 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:38,091 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 26.0 (TID 588). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:38,092 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 26.0 (TID 590, localhost, executor driver, partition 172, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:38,092 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 26.0 (TID 590)
[INFO] 2019-01-19 13:28:38,092 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 26.0 (TID 588) in 394 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 13:28:38,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:38,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:38,157 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 26.0 (TID 589). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:38,158 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 26.0 (TID 591, localhost, executor driver, partition 173, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:38,158 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 26.0 (TID 591)
[INFO] 2019-01-19 13:28:38,158 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 26.0 (TID 589) in 391 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 13:28:38,171 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:38,171 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:38,485 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 26.0 (TID 590). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:38,486 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 26.0 (TID 592, localhost, executor driver, partition 174, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:38,486 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 26.0 (TID 592)
[INFO] 2019-01-19 13:28:38,486 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 26.0 (TID 590) in 395 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 13:28:38,500 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:38,500 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:38,558 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 26.0 (TID 591). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:38,559 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 26.0 (TID 593, localhost, executor driver, partition 175, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:38,559 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 26.0 (TID 593)
[INFO] 2019-01-19 13:28:38,559 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 26.0 (TID 591) in 402 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 13:28:38,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:38,570 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:38,867 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 26.0 (TID 592). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:38,868 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 26.0 (TID 594, localhost, executor driver, partition 176, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:38,868 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 26.0 (TID 594)
[INFO] 2019-01-19 13:28:38,868 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 26.0 (TID 592) in 382 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 13:28:38,881 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:38,881 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:38,929 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 26.0 (TID 593). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:38,930 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 26.0 (TID 595, localhost, executor driver, partition 177, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:38,930 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 26.0 (TID 595)
[INFO] 2019-01-19 13:28:38,930 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 26.0 (TID 593) in 371 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 13:28:38,944 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:38,944 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:39,257 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 26.0 (TID 594). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:39,257 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 26.0 (TID 596, localhost, executor driver, partition 178, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:39,258 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 26.0 (TID 596)
[INFO] 2019-01-19 13:28:39,258 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 26.0 (TID 594) in 390 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 13:28:39,276 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:39,276 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:39,315 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 26.0 (TID 595). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:39,315 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 26.0 (TID 597, localhost, executor driver, partition 179, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:39,315 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 26.0 (TID 597)
[INFO] 2019-01-19 13:28:39,315 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 26.0 (TID 595) in 386 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 13:28:39,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:39,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:39,648 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 26.0 (TID 596). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:39,648 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 26.0 (TID 598, localhost, executor driver, partition 180, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:39,649 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 26.0 (TID 598)
[INFO] 2019-01-19 13:28:39,649 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 26.0 (TID 596) in 392 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 13:28:39,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:39,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:39,680 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 26.0 (TID 597). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:39,680 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 26.0 (TID 599, localhost, executor driver, partition 181, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:39,680 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 26.0 (TID 599)
[INFO] 2019-01-19 13:28:39,680 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 26.0 (TID 597) in 365 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 13:28:39,692 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:39,692 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:40,019 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 26.0 (TID 598). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:40,019 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 26.0 (TID 600, localhost, executor driver, partition 182, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:40,020 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 26.0 (TID 600)
[INFO] 2019-01-19 13:28:40,020 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 26.0 (TID 598) in 372 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 13:28:40,034 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:40,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:40,054 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 26.0 (TID 599). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:40,055 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 26.0 (TID 601, localhost, executor driver, partition 183, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:40,055 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 26.0 (TID 599) in 375 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 13:28:40,055 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 26.0 (TID 601)
[INFO] 2019-01-19 13:28:40,070 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:40,070 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:40,401 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 26.0 (TID 600). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:40,402 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 26.0 (TID 602, localhost, executor driver, partition 184, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:40,402 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 26.0 (TID 602)
[INFO] 2019-01-19 13:28:40,402 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 26.0 (TID 600) in 383 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 13:28:40,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:40,415 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:40,434 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 26.0 (TID 601). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:40,435 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 26.0 (TID 603, localhost, executor driver, partition 185, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:40,435 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 26.0 (TID 603)
[INFO] 2019-01-19 13:28:40,435 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 26.0 (TID 601) in 381 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 13:28:40,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:40,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:40,788 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 26.0 (TID 602). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:40,788 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 26.0 (TID 604, localhost, executor driver, partition 186, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:40,789 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 26.0 (TID 604)
[INFO] 2019-01-19 13:28:40,789 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 26.0 (TID 602) in 387 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 13:28:40,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:40,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:40,823 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 26.0 (TID 603). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:40,823 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 26.0 (TID 605, localhost, executor driver, partition 187, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:40,823 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 26.0 (TID 605)
[INFO] 2019-01-19 13:28:40,823 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 26.0 (TID 603) in 389 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 13:28:40,836 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:40,836 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:41,159 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 26.0 (TID 604). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:41,160 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 26.0 (TID 606, localhost, executor driver, partition 188, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:41,160 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 26.0 (TID 606)
[INFO] 2019-01-19 13:28:41,160 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 26.0 (TID 604) in 372 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 13:28:41,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:41,173 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:41,189 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 26.0 (TID 605). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:41,189 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 26.0 (TID 607, localhost, executor driver, partition 189, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:41,189 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 26.0 (TID 607)
[INFO] 2019-01-19 13:28:41,189 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 26.0 (TID 605) in 366 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 13:28:41,203 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:41,203 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:41,609 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 26.0 (TID 606). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:41,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 26.0 (TID 608, localhost, executor driver, partition 190, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:41,609 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 26.0 (TID 608)
[INFO] 2019-01-19 13:28:41,609 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 26.0 (TID 606) in 450 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 13:28:41,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:41,620 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:41,666 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 26.0 (TID 607). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:41,666 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 26.0 (TID 609, localhost, executor driver, partition 191, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:41,667 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 26.0 (TID 609)
[INFO] 2019-01-19 13:28:41,667 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 26.0 (TID 607) in 478 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 13:28:41,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:41,680 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:41,985 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 26.0 (TID 608). 4166 bytes result sent to driver
[INFO] 2019-01-19 13:28:41,985 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 26.0 (TID 610, localhost, executor driver, partition 192, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:41,985 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 26.0 (TID 610)
[INFO] 2019-01-19 13:28:41,985 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 26.0 (TID 608) in 376 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 13:28:41,998 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:41,999 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:42,182 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 26.0 (TID 609). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:42,183 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 26.0 (TID 611, localhost, executor driver, partition 193, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:42,183 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 26.0 (TID 611)
[INFO] 2019-01-19 13:28:42,183 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 26.0 (TID 609) in 517 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 13:28:42,209 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:42,209 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:42,436 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 26.0 (TID 610). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:42,437 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 26.0 (TID 612, localhost, executor driver, partition 194, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:42,437 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 26.0 (TID 610) in 452 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 13:28:42,437 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 26.0 (TID 612)
[INFO] 2019-01-19 13:28:42,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:42,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:42,607 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 26.0 (TID 611). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:42,608 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 26.0 (TID 613, localhost, executor driver, partition 195, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:42,608 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 26.0 (TID 613)
[INFO] 2019-01-19 13:28:42,608 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 26.0 (TID 611) in 425 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 13:28:42,622 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:42,622 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:42,835 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 26.0 (TID 612). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:42,836 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 26.0 (TID 614, localhost, executor driver, partition 196, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:42,836 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 26.0 (TID 614)
[INFO] 2019-01-19 13:28:42,836 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 26.0 (TID 612) in 400 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 13:28:42,852 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:42,852 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:43,030 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 26.0 (TID 613). 4093 bytes result sent to driver
[INFO] 2019-01-19 13:28:43,030 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 26.0 (TID 615, localhost, executor driver, partition 197, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:43,031 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 26.0 (TID 615)
[INFO] 2019-01-19 13:28:43,031 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 26.0 (TID 613) in 424 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 13:28:43,048 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:43,048 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:43,370 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 26.0 (TID 614). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:43,371 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 26.0 (TID 616, localhost, executor driver, partition 198, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:43,371 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 26.0 (TID 616)
[INFO] 2019-01-19 13:28:43,371 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 26.0 (TID 614) in 535 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 13:28:43,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:43,388 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:43,549 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 26.0 (TID 615). 4256 bytes result sent to driver
[INFO] 2019-01-19 13:28:43,549 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 26.0 (TID 617, localhost, executor driver, partition 199, ANY, 5789 bytes)
[INFO] 2019-01-19 13:28:43,549 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 26.0 (TID 617)
[INFO] 2019-01-19 13:28:43,549 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 26.0 (TID 615) in 519 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 13:28:43,563 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:43,563 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:43,747 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 26.0 (TID 616). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:43,748 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 26.0 (TID 616) in 377 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 13:28:43,903 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 26.0 (TID 617). 4183 bytes result sent to driver
[INFO] 2019-01-19 13:28:43,903 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 26.0 (TID 617) in 354 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 13:28:43,903 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 26.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:43,904 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 26 (head at DecoupJson.scala:139) finished in 43.301 s
[INFO] 2019-01-19 13:28:43,904 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:43,904 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:43,904 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 27)
[INFO] 2019-01-19 13:28:43,904 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:43,904 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 27 (MapPartitionsRDD[77] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:28:43,938 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_33 stored as values in memory (estimated size 672.0 KB, free 1989.7 MB)
[INFO] 2019-01-19 13:28:43,941 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_33_piece0 stored as bytes in memory (estimated size 159.1 KB, free 1989.6 MB)
[INFO] 2019-01-19 13:28:43,942 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_33_piece0 in memory on 192.168.99.1:57817 (size: 159.1 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:28:43,942 org.apache.spark.SparkContext logInfo - Created broadcast 33 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:43,943 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[77] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:28:43,943 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 27.0 with 1 tasks
[INFO] 2019-01-19 13:28:43,944 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 27.0 (TID 618, localhost, executor driver, partition 0, ANY, 5800 bytes)
[INFO] 2019-01-19 13:28:43,944 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 27.0 (TID 618)
[INFO] 2019-01-19 13:28:43,959 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 200 non-empty blocks out of 200 blocks
[INFO] 2019-01-19 13:28:43,959 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:44,280 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 174.594437 ms
[INFO] 2019-01-19 13:28:44,416 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 51.843517 ms
[INFO] 2019-01-19 13:28:44,526 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 64.891405 ms
[INFO] 2019-01-19 13:28:44,641 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 96.41325 ms
[INFO] 2019-01-19 13:28:44,814 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 27.0 (TID 618). 8317 bytes result sent to driver
[INFO] 2019-01-19 13:28:44,814 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 27.0 (TID 618) in 871 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:44,815 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 27.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:44,815 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 27 (head at DecoupJson.scala:139) finished in 0.872 s
[INFO] 2019-01-19 13:28:44,815 org.apache.spark.scheduler.DAGScheduler logInfo - Job 12 finished: head at DecoupJson.scala:139, took 49.733532 s
[INFO] 2019-01-19 13:28:44,890 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 57.224806 ms
[INFO] 2019-01-19 13:28:45,207 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:45,208 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:28:45,209 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:28:45,209 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:28:45,210 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:45,212 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:28:45,212 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:28:45,212 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:28:45,258 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.691898 ms
[INFO] 2019-01-19 13:28:45,311 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 36.760677 ms
[INFO] 2019-01-19 13:28:45,336 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_34 stored as values in memory (estimated size 292.7 KB, free 1989.3 MB)
[INFO] 2019-01-19 13:28:45,352 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_34_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1989.2 MB)
[INFO] 2019-01-19 13:28:45,353 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_34_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:28:45,354 org.apache.spark.SparkContext logInfo - Created broadcast 34 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 13:28:45,355 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:45,380 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_35 stored as values in memory (estimated size 292.7 KB, free 1989.0 MB)
[INFO] 2019-01-19 13:28:45,399 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_35_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:28:45,400 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_35_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:28:45,400 org.apache.spark.SparkContext logInfo - Created broadcast 35 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 13:28:45,401 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:45,551 org.apache.spark.SparkContext logInfo - Starting job: first at DecoupJson.scala:146
[INFO] 2019-01-19 13:28:45,552 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 86 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,552 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 81 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,552 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 91 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,553 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 13 (first at DecoupJson.scala:146) with 1 output partitions
[INFO] 2019-01-19 13:28:45,553 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 31 (first at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,553 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 30)
[INFO] 2019-01-19 13:28:45,553 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 30)
[INFO] 2019-01-19 13:28:45,553 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 28 (MapPartitionsRDD[86] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:28:45,555 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_36 stored as values in memory (estimated size 39.9 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:28:45,557 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:28:45,558 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_36_piece0 in memory on 192.168.99.1:57817 (size: 12.5 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:28:45,558 org.apache.spark.SparkContext logInfo - Created broadcast 36 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:45,559 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[86] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,559 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 28.0 with 1 tasks
[INFO] 2019-01-19 13:28:45,559 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 29 (MapPartitionsRDD[81] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:28:45,560 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_37 stored as values in memory (estimated size 39.9 KB, free 1988.8 MB)
[INFO] 2019-01-19 13:28:45,562 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1988.8 MB)
[INFO] 2019-01-19 13:28:45,563 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 28.0 (TID 619, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 13:28:45,564 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_37_piece0 in memory on 192.168.99.1:57817 (size: 12.5 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:28:45,565 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 28.0 (TID 619)
[INFO] 2019-01-19 13:28:45,567 org.apache.spark.SparkContext logInfo - Created broadcast 37 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:45,567 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:45,568 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[81] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,569 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 29.0 with 1 tasks
[INFO] 2019-01-19 13:28:45,570 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 29.0 (TID 620, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 13:28:45,570 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 29.0 (TID 620)
[INFO] 2019-01-19 13:28:45,573 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:45,581 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:28:45,587 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:28:45,667 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 29.0 (TID 620). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 29.0 (TID 620) in 100 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 29.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 29 (rdd at DecoupJson.scala:146) finished in 0.100 s
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 28)
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 30, ResultStage 31)
[INFO] 2019-01-19 13:28:45,669 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 28.0 (TID 619). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 28.0 (TID 619) in 115 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 28.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 28 (rdd at DecoupJson.scala:146) finished in 0.115 s
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:45,674 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 30, ResultStage 31)
[INFO] 2019-01-19 13:28:45,675 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:45,675 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 30 (MapPartitionsRDD[91] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:28:45,678 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_38 stored as values in memory (estimated size 139.7 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:28:45,679 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_38_piece0 stored as bytes in memory (estimated size 37.1 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:28:45,680 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_38_piece0 in memory on 192.168.99.1:57817 (size: 37.1 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:28:45,681 org.apache.spark.SparkContext logInfo - Created broadcast 38 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:45,681 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[91] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,681 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 30.0 with 2 tasks
[INFO] 2019-01-19 13:28:45,682 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 30.0 (TID 621, localhost, executor driver, partition 0, ANY, 5967 bytes)
[INFO] 2019-01-19 13:28:45,682 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 30.0 (TID 622, localhost, executor driver, partition 1, ANY, 5967 bytes)
[INFO] 2019-01-19 13:28:45,683 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 30.0 (TID 621)
[INFO] 2019-01-19 13:28:45,683 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 30.0 (TID 622)
[INFO] 2019-01-19 13:28:45,686 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:28:45,686 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:45,686 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:28:45,687 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:45,782 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 30.0 (TID 621). 2633 bytes result sent to driver
[INFO] 2019-01-19 13:28:45,782 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 30.0 (TID 621) in 101 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:28:45,797 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 30.0 (TID 622). 2633 bytes result sent to driver
[INFO] 2019-01-19 13:28:45,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 30.0 (TID 622) in 116 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:28:45,798 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 30.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:45,798 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 30 (rdd at DecoupJson.scala:146) finished in 0.117 s
[INFO] 2019-01-19 13:28:45,799 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:45,799 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:45,799 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 31)
[INFO] 2019-01-19 13:28:45,799 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:45,800 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 31 (MapPartitionsRDD[96] at map at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:28:45,804 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_39 stored as values in memory (estimated size 155.4 KB, free 1988.5 MB)
[INFO] 2019-01-19 13:28:45,806 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_39_piece0 stored as bytes in memory (estimated size 47.1 KB, free 1988.5 MB)
[INFO] 2019-01-19 13:28:45,807 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_39_piece0 in memory on 192.168.99.1:57817 (size: 47.1 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:45,808 org.apache.spark.SparkContext logInfo - Created broadcast 39 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:45,808 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[96] at map at DecoupJson.scala:146)
[INFO] 2019-01-19 13:28:45,808 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 31.0 with 1 tasks
[INFO] 2019-01-19 13:28:45,811 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 31.0 (TID 623, localhost, executor driver, partition 0, ANY, 5869 bytes)
[INFO] 2019-01-19 13:28:45,812 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 31.0 (TID 623)
[INFO] 2019-01-19 13:28:45,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:45,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:45,832 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 9.601408 ms
[INFO] 2019-01-19 13:28:45,841 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 31.0 (TID 623). 4043 bytes result sent to driver
[INFO] 2019-01-19 13:28:45,841 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 31.0 (TID 623) in 32 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:45,842 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 31 (first at DecoupJson.scala:146) finished in 0.033 s
[INFO] 2019-01-19 13:28:45,842 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 31.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:45,842 org.apache.spark.scheduler.DAGScheduler logInfo - Job 13 finished: first at DecoupJson.scala:146, took 0.291083 s
[INFO] 2019-01-19 13:28:45,946 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:45,947 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:28:45,947 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:28:45,947 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:28:45,948 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:45,948 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:28:45,949 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:28:45,949 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:28:45,970 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 6.417277 ms
[INFO] 2019-01-19 13:28:45,985 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 4.27125 ms
[INFO] 2019-01-19 13:28:45,989 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_40 stored as values in memory (estimated size 278.7 KB, free 1988.2 MB)
[INFO] 2019-01-19 13:28:46,010 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_40_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1988.2 MB)
[INFO] 2019-01-19 13:28:46,014 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_40_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:46,015 org.apache.spark.SparkContext logInfo - Created broadcast 40 from count at DecoupJson.scala:75
[INFO] 2019-01-19 13:28:46,016 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:46,030 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_41 stored as values in memory (estimated size 278.7 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:28:46,049 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_41_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:28:46,051 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_41_piece0 in memory on 192.168.99.1:57817 (size: 23.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:46,052 org.apache.spark.SparkContext logInfo - Created broadcast 41 from count at DecoupJson.scala:75
[INFO] 2019-01-19 13:28:46,052 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:46,092 org.apache.spark.SparkContext logInfo - Starting job: count at DecoupJson.scala:75
[INFO] 2019-01-19 13:28:46,093 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 106 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,093 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 101 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,094 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 111 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,094 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 14 (count at DecoupJson.scala:75) with 1 output partitions
[INFO] 2019-01-19 13:28:46,094 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 35 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,095 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 34)
[INFO] 2019-01-19 13:28:46,095 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 34)
[INFO] 2019-01-19 13:28:46,096 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 32 (MapPartitionsRDD[106] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:28:46,098 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_42 stored as values in memory (estimated size 12.2 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:28:46,099 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:28:46,100 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_42_piece0 in memory on 192.168.99.1:57817 (size: 5.9 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:46,100 org.apache.spark.SparkContext logInfo - Created broadcast 42 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:46,101 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[106] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,101 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 32.0 with 1 tasks
[INFO] 2019-01-19 13:28:46,101 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 33 (MapPartitionsRDD[101] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:28:46,102 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 32.0 (TID 624, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:28:46,102 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_43 stored as values in memory (estimated size 12.2 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:28:46,102 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 32.0 (TID 624)
[INFO] 2019-01-19 13:28:46,104 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:28:46,104 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_43_piece0 in memory on 192.168.99.1:57817 (size: 5.9 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:46,104 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:46,105 org.apache.spark.SparkContext logInfo - Created broadcast 43 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:46,105 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[101] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,105 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 33.0 with 1 tasks
[INFO] 2019-01-19 13:28:46,106 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 33.0 (TID 625, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:28:46,107 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 33.0 (TID 625)
[INFO] 2019-01-19 13:28:46,109 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:46,113 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:28:46,118 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:28:46,142 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 33.0 (TID 625). 2026 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,143 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 33.0 (TID 625) in 37 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:46,143 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 33.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:46,143 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 33 (count at DecoupJson.scala:75) finished in 0.038 s
[INFO] 2019-01-19 13:28:46,143 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:46,144 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 32)
[INFO] 2019-01-19 13:28:46,144 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 34, ResultStage 35)
[INFO] 2019-01-19 13:28:46,144 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:46,149 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 32.0 (TID 624). 1857 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,149 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 32.0 (TID 624) in 48 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:46,149 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 32.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:46,149 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 32 (count at DecoupJson.scala:75) finished in 0.048 s
[INFO] 2019-01-19 13:28:46,149 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:46,150 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:46,150 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 34, ResultStage 35)
[INFO] 2019-01-19 13:28:46,150 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:46,150 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 34 (MapPartitionsRDD[111] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:28:46,152 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_44 stored as values in memory (estimated size 39.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:28:46,154 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_44_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:28:46,155 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_44_piece0 in memory on 192.168.99.1:57817 (size: 13.6 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:46,155 org.apache.spark.SparkContext logInfo - Created broadcast 44 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:46,155 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[111] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,155 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 34.0 with 2 tasks
[INFO] 2019-01-19 13:28:46,156 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 34.0 (TID 626, localhost, executor driver, partition 0, ANY, 5998 bytes)
[INFO] 2019-01-19 13:28:46,156 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 34.0 (TID 627, localhost, executor driver, partition 1, ANY, 5998 bytes)
[INFO] 2019-01-19 13:28:46,157 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 34.0 (TID 627)
[INFO] 2019-01-19 13:28:46,157 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 34.0 (TID 626)
[INFO] 2019-01-19 13:28:46,159 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:28:46,159 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:46,159 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:28:46,160 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:28:46,178 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 34.0 (TID 626). 2723 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,178 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 34.0 (TID 626) in 22 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:28:46,184 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 34.0 (TID 627). 2723 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,184 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 34.0 (TID 627) in 28 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:28:46,184 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 34.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:46,184 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 34 (count at DecoupJson.scala:75) finished in 0.028 s
[INFO] 2019-01-19 13:28:46,185 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:46,185 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:46,185 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 35)
[INFO] 2019-01-19 13:28:46,185 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:46,185 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 35 (MapPartitionsRDD[114] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:28:46,186 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:28:46,191 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:28:46,193 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_45_piece0 in memory on 192.168.99.1:57817 (size: 3.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:28:46,194 org.apache.spark.SparkContext logInfo - Created broadcast 45 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:46,194 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[114] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:28:46,195 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 35.0 with 1 tasks
[INFO] 2019-01-19 13:28:46,196 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 35.0 (TID 628, localhost, executor driver, partition 0, ANY, 5900 bytes)
[INFO] 2019-01-19 13:28:46,196 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 35.0 (TID 628)
[INFO] 2019-01-19 13:28:46,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:46,198 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:46,201 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 35.0 (TID 628). 1873 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,201 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 35.0 (TID 628) in 6 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:46,202 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 35.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:46,203 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 35 (count at DecoupJson.scala:75) finished in 0.008 s
[INFO] 2019-01-19 13:28:46,203 org.apache.spark.scheduler.DAGScheduler logInfo - Job 14 finished: count at DecoupJson.scala:75, took 0.111395 s
[INFO] 2019-01-19 13:28:46,417 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:46,418 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:28:46,419 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:28:46,419 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:28:46,424 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:46,426 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:28:46,426 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:28:46,427 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:28:46,448 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.107767 ms
[INFO] 2019-01-19 13:28:46,461 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.042533 ms
[INFO] 2019-01-19 13:28:46,497 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.709484 ms
[INFO] 2019-01-19 13:28:46,502 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_46 stored as values in memory (estimated size 292.7 KB, free 1987.5 MB)
[INFO] 2019-01-19 13:28:46,522 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_46_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.5 MB)
[INFO] 2019-01-19 13:28:46,522 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_46_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:28:46,523 org.apache.spark.SparkContext logInfo - Created broadcast 46 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 13:28:46,524 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:46,550 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.784527 ms
[INFO] 2019-01-19 13:28:46,554 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_47 stored as values in memory (estimated size 292.7 KB, free 1987.2 MB)
[INFO] 2019-01-19 13:28:46,571 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_47_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.2 MB)
[INFO] 2019-01-19 13:28:46,572 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_47_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:28:46,572 org.apache.spark.SparkContext logInfo - Created broadcast 47 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 13:28:46,573 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:46,599 org.apache.spark.SparkContext logInfo - Starting job: collect at DecoupJson.scala:95
[INFO] 2019-01-19 13:28:46,599 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 123 (rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:28:46,600 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 15 (collect at DecoupJson.scala:95) with 1 output partitions
[INFO] 2019-01-19 13:28:46,600 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 37 (collect at DecoupJson.scala:95)
[INFO] 2019-01-19 13:28:46,600 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 36)
[INFO] 2019-01-19 13:28:46,600 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 36)
[INFO] 2019-01-19 13:28:46,600 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 36 (MapPartitionsRDD[123] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 13:28:46,602 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_48 stored as values in memory (estimated size 123.7 KB, free 1987.0 MB)
[INFO] 2019-01-19 13:28:46,604 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_48_piece0 stored as bytes in memory (estimated size 32.4 KB, free 1987.0 MB)
[INFO] 2019-01-19 13:28:46,605 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_48_piece0 in memory on 192.168.99.1:57817 (size: 32.4 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:28:46,605 org.apache.spark.SparkContext logInfo - Created broadcast 48 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:46,605 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[123] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:28:46,605 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 36.0 with 2 tasks
[INFO] 2019-01-19 13:28:46,606 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 36.0 (TID 629, localhost, executor driver, partition 0, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 13:28:46,607 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 36.0 (TID 630, localhost, executor driver, partition 1, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 13:28:46,607 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 36.0 (TID 629)
[INFO] 2019-01-19 13:28:46,607 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 36.0 (TID 630)
[INFO] 2019-01-19 13:28:46,615 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:46,615 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:46,626 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:28:46,631 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:28:46,729 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 36.0 (TID 629). 2635 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,729 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 36.0 (TID 629) in 124 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:28:46,734 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 36.0 (TID 630). 2635 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,734 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 36.0 (TID 630) in 128 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 36.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 36 (rdd at DecoupJson.scala:95) finished in 0.130 s
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 37)
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:46,735 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 37 (MapPartitionsRDD[127] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 13:28:46,737 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_49 stored as values in memory (estimated size 65.9 KB, free 1986.9 MB)
[INFO] 2019-01-19 13:28:46,739 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_49_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1986.9 MB)
[INFO] 2019-01-19 13:28:46,740 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_49_piece0 in memory on 192.168.99.1:57817 (size: 21.2 KB, free: 1991.3 MB)
[INFO] 2019-01-19 13:28:46,740 org.apache.spark.SparkContext logInfo - Created broadcast 49 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:46,740 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[127] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:28:46,740 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 37.0 with 1 tasks
[INFO] 2019-01-19 13:28:46,741 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 37.0 (TID 631, localhost, executor driver, partition 0, ANY, 5871 bytes)
[INFO] 2019-01-19 13:28:46,742 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 37.0 (TID 631)
[INFO] 2019-01-19 13:28:46,746 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:28:46,746 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:46,758 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.908142 ms
[INFO] 2019-01-19 13:28:46,768 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 37.0 (TID 631). 7272 bytes result sent to driver
[INFO] 2019-01-19 13:28:46,771 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 37.0 (TID 631) in 30 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:46,771 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 37 (collect at DecoupJson.scala:95) finished in 0.030 s
[INFO] 2019-01-19 13:28:46,771 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 37.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:46,771 org.apache.spark.scheduler.DAGScheduler logInfo - Job 15 finished: collect at DecoupJson.scala:95, took 0.172018 s
[INFO] 2019-01-19 13:28:46,856 myLogger setOutputDataTable - outputPath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train22
[INFO] 2019-01-19 13:28:46,950 org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat logInfo - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:46,971 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:46,973 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:28:46,973 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:28:46,973 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:28:46,974 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:28:46,975 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:28:46,975 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:28:46,975 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:28:46,988 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO] 2019-01-19 13:28:46,989 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO] 2019-01-19 13:28:46,989 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO] 2019-01-19 13:28:46,990 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO] 2019-01-19 13:28:46,990 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO] 2019-01-19 13:28:46,992 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:28:46,993 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:46,994 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:28:46,995 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:47,011 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_50 stored as values in memory (estimated size 292.7 KB, free 1986.6 MB)
[INFO] 2019-01-19 13:28:47,027 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_50_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1986.6 MB)
[INFO] 2019-01-19 13:28:47,029 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_50_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:28:47,029 org.apache.spark.SparkContext logInfo - Created broadcast 50 from save at DecoupJson.scala:166
[INFO] 2019-01-19 13:28:47,029 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:47,048 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_51 stored as values in memory (estimated size 292.7 KB, free 1986.3 MB)
[INFO] 2019-01-19 13:28:47,067 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_51_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1986.3 MB)
[INFO] 2019-01-19 13:28:47,068 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_51_piece0 in memory on 192.168.99.1:57817 (size: 25.4 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:28:47,068 org.apache.spark.SparkContext logInfo - Created broadcast 51 from save at DecoupJson.scala:166
[INFO] 2019-01-19 13:28:47,069 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:28:47,126 org.apache.spark.SparkContext logInfo - Starting job: save at DecoupJson.scala:166
[INFO] 2019-01-19 13:28:47,126 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 131 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:28:47,126 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 136 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:28:47,128 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 16 (save at DecoupJson.scala:166) with 2 output partitions
[INFO] 2019-01-19 13:28:47,128 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 40 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:28:47,129 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 38, ShuffleMapStage 39)
[INFO] 2019-01-19 13:28:47,129 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 38, ShuffleMapStage 39)
[INFO] 2019-01-19 13:28:47,129 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 38 (MapPartitionsRDD[131] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:28:47,130 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_52 stored as values in memory (estimated size 39.9 KB, free 1986.3 MB)
[INFO] 2019-01-19 13:28:47,132 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_52_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1986.2 MB)
[INFO] 2019-01-19 13:28:47,132 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_52_piece0 in memory on 192.168.99.1:57817 (size: 12.5 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:28:47,133 org.apache.spark.SparkContext logInfo - Created broadcast 52 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:47,133 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[131] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:28:47,133 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 38.0 with 1 tasks
[INFO] 2019-01-19 13:28:47,134 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 39 (MapPartitionsRDD[136] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:28:47,135 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_53 stored as values in memory (estimated size 39.9 KB, free 1986.2 MB)
[INFO] 2019-01-19 13:28:47,137 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 38.0 (TID 632, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 13:28:47,137 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 38.0 (TID 632)
[INFO] 2019-01-19 13:28:47,138 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_53_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1986.2 MB)
[INFO] 2019-01-19 13:28:47,139 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_53_piece0 in memory on 192.168.99.1:57817 (size: 12.5 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:28:47,139 org.apache.spark.SparkContext logInfo - Created broadcast 53 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:47,139 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[136] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:28:47,139 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 39.0 with 1 tasks
[INFO] 2019-01-19 13:28:47,140 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:47,140 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 39.0 (TID 633, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 13:28:47,141 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 39.0 (TID 633)
[INFO] 2019-01-19 13:28:47,143 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:28:47,151 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:28:47,152 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:28:47,239 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 38.0 (TID 632). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:28:47,239 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 38.0 (TID 632) in 103 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:47,240 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 38.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:47,240 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 38 (save at DecoupJson.scala:166) finished in 0.107 s
[INFO] 2019-01-19 13:28:47,240 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:47,240 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 39)
[INFO] 2019-01-19 13:28:47,240 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 40)
[INFO] 2019-01-19 13:28:47,240 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:47,249 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 39.0 (TID 633). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:28:47,249 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 39.0 (TID 633) in 109 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:28:47,249 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 39.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:47,250 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 39 (save at DecoupJson.scala:166) finished in 0.110 s
[INFO] 2019-01-19 13:28:47,250 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:28:47,250 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:28:47,250 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 40)
[INFO] 2019-01-19 13:28:47,250 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:28:47,250 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 40 (UnionRDD[139] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:28:47,267 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_54 stored as values in memory (estimated size 140.7 KB, free 1986.1 MB)
[INFO] 2019-01-19 13:28:47,269 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_54_piece0 stored as bytes in memory (estimated size 41.7 KB, free 1986.0 MB)
[INFO] 2019-01-19 13:28:47,270 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_54_piece0 in memory on 192.168.99.1:57817 (size: 41.7 KB, free: 1991.2 MB)
[INFO] 2019-01-19 13:28:47,270 org.apache.spark.SparkContext logInfo - Created broadcast 54 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:28:47,270 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ResultStage 40 (UnionRDD[139] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:28:47,271 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 40.0 with 2 tasks
[INFO] 2019-01-19 13:28:47,272 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 40.0 (TID 634, localhost, executor driver, partition 0, ANY, 6017 bytes)
[INFO] 2019-01-19 13:28:47,272 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 40.0 (TID 635, localhost, executor driver, partition 1, ANY, 6017 bytes)
[INFO] 2019-01-19 13:28:47,273 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 40.0 (TID 634)
[INFO] 2019-01-19 13:28:47,274 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 40.0 (TID 635)
[INFO] 2019-01-19 13:28:47,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:28:47,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:47,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:28:47,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:28:47,296 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:28:47,296 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:28:47,296 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:47,297 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:47,297 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:28:47,297 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:28:47,297 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:47,297 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:28:47,301 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:28:47,303 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:28:47,305 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:28:47,305 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:28:47,333 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 13:28:47,333 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 13:28:47,333 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 13:28:47,333 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 13:28:47,333 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 13:28:47,334 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 13:28:47,334 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 13:28:47,334 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 13:28:47,334 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 13:28:47,334 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 13:28:47,333 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 13:28:47,334 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 13:28:47,335 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 13:28:47,339 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 13:28:47,355 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 13:28:47,359 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 13:28:47,390 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 13:28:47,390 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 13:28:47,538 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 30,263
[INFO] 2019-01-19 13:28:47,583 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 32,866
[INFO] 2019-01-19 13:28:47,657 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 174B for [crm_cust_no] BINARY: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 57 entries, 1,653B raw, 57B comp}
[INFO] 2019-01-19 13:28:47,658 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [stat_mth] INT32: 111 values, 65B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:28:47,658 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [ast_curr_bal] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 52 entries, 416B raw, 52B comp}
[INFO] 2019-01-19 13:28:47,658 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [std_cred_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 688B raw, 86B comp}
[INFO] 2019-01-19 13:28:47,658 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:28:47,659 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [std_cred_bill_amt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 688B raw, 86B comp}
[INFO] 2019-01-19 13:28:47,659 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 97B for [ln_curr_bal] DOUBLE: 111 values, 53B raw, 55B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 128B raw, 16B comp}
[INFO] 2019-01-19 13:28:47,662 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 108B for [l3m_ln_davg_bal] DOUBLE: 111 values, 62B raw, 65B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 152B raw, 19B comp}
[INFO] 2019-01-19 13:28:47,663 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 124B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 79B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 184B raw, 23B comp}
[INFO] 2019-01-19 13:28:47,664 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 63 entries, 798B raw, 63B comp}
[INFO] 2019-01-19 13:28:47,665 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 64B for [std_cred_auto_repay_flag] INT32: 111 values, 28B raw, 30B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:28:47,665 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 146B for [std_cred_1st_biz_days] INT32: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 332B raw, 83B comp}
[INFO] 2019-01-19 13:28:47,666 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_lst_biz_days] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 64B raw, 16B comp}
[INFO] 2019-01-19 13:28:47,666 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 63B for [std_cred_1stbiz_op_days] BINARY: 111 values, 31B raw, 33B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 31B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,666 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 30B raw, 32B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,678 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l3m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 79 entries, 632B raw, 79B comp}
[INFO] 2019-01-19 13:28:47,680 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l6m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 82 entries, 656B raw, 82B comp}
[INFO] 2019-01-19 13:28:47,680 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [l12m_std_cred_znamt] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 664B raw, 83B comp}
[INFO] 2019-01-19 13:28:47,680 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [l3m_ln_ovd_days_bm] INT32: 111 values, 32B raw, 34B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,681 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 71B for [l12m_ln_ovd_days_bm] INT32: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:28:47,681 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 65B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 29B raw, 31B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 13:28:47,681 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,681 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 71B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,682 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,682 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [nty] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 13:28:47,683 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 35B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,683 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 58B raw, 10B comp}
[INFO] 2019-01-19 13:28:47,684 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [yg_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,797 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,798 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [house_stt] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 13:28:47,798 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 81B for [work_years] INT32: 111 values, 45B raw, 47B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,799 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 66B for [unit_kind] BINARY: 111 values, 29B raw, 31B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 16B raw, 2B comp}
[INFO] 2019-01-19 13:28:47,799 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [title] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 13:28:47,801 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 75B for [occp] BINARY: 111 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 59B raw, 7B comp}
[INFO] 2019-01-19 13:28:47,808 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,809 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 78B for [idy] BINARY: 111 values, 46B raw, 48B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 42B raw, 7B comp}
[INFO] 2019-01-19 13:28:47,809 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 136B raw, 17B comp}
[INFO] 2019-01-19 13:28:47,810 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [cp_y_income] BINARY: 111 values, 53B raw, 55B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 86B raw, 11B comp}
[INFO] 2019-01-19 13:28:47,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 115B for [zx_max_lns] INT32: 111 values, 79B raw, 79B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 13:28:47,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 13:28:47,812 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 103B for [zx_max_ovd_lns] INT32: 111 values, 64B raw, 67B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:28:47,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 116B for [zx_ln_max_ovd_amt] INT32: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 30 entries, 120B raw, 30B comp}
[INFO] 2019-01-19 13:28:47,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 116B for [zx_ln_tot_ovd_mths] INT32: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 76B raw, 19B comp}
[INFO] 2019-01-19 13:28:47,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:28:47,813 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 99B for [zx_max_creds] INT32: 111 values, 61B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:28:47,818 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 86B for [zx_max_cred_banks] INT32: 111 values, 50B raw, 52B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:28:47,818 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:28:47,819 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [zx_cred_max_ovd_amt] INT64: 111 values, 53B raw, 54B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 14 entries, 112B raw, 14B comp}
[INFO] 2019-01-19 13:28:47,819 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 93B for [zx_cred_tot_ovd_mths] INT32: 111 values, 57B raw, 59B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:28:47,819 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_cred_max_ovd_duration] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,856 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 1,520B for [crm_cust_no] BINARY: 111 values, 3,226B raw, 1,442B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:28:47,857 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 102B for [stat_mth] INT32: 111 values, 65B raw, 66B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:28:47,857 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [ast_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 96 entries, 768B raw, 96B comp}
[INFO] 2019-01-19 13:28:47,859 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 768B for [std_cred_curr_bal] DOUBLE: 111 values, 895B raw, 724B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:28:47,859 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:28:47,859 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 751B for [std_cred_bill_amt] DOUBLE: 111 values, 895B raw, 707B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:28:47,859 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [ln_curr_bal] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 13:28:47,860 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_ln_davg_bal] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 30 entries, 240B raw, 30B comp}
[INFO] 2019-01-19 13:28:47,861 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 43 entries, 344B raw, 43B comp}
[INFO] 2019-01-19 13:28:47,862 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 147B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 89 entries, 1,151B raw, 89B comp}
[INFO] 2019-01-19 13:28:47,862 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 60B for [std_cred_auto_repay_flag] INT32: 111 values, 24B raw, 26B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:28:47,862 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 489B for [std_cred_1st_biz_days] INT32: 111 values, 451B raw, 453B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:28:47,862 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [std_cred_lst_biz_days] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 13:28:47,863 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 91B for [std_cred_1stbiz_op_days] BINARY: 111 values, 59B raw, 59B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 103B raw, 16B comp}
[INFO] 2019-01-19 13:28:47,863 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 76B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 32B raw, 34B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,863 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [l3m_std_cred_znamt] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 13:28:47,863 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 137B for [l6m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 93B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 38 entries, 304B raw, 38B comp}
[INFO] 2019-01-19 13:28:47,864 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l12m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 54 entries, 432B raw, 54B comp}
[INFO] 2019-01-19 13:28:47,864 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l3m_ln_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,864 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,864 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,864 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,865 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,865 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,865 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [nty] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 13:28:47,865 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 30B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,866 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 59B raw, 10B comp}
[INFO] 2019-01-19 13:28:47,866 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [yg_flag] BINARY: 111 values, 15B raw, 17B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 11B raw, 2B comp}
[INFO] 2019-01-19 13:28:47,866 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:28:47,866 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [house_stt] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 16B raw, 3B comp}
[INFO] 2019-01-19 13:28:47,866 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [work_years] INT32: 111 values, 62B raw, 62B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 13:28:47,867 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 72B for [unit_kind] BINARY: 111 values, 35B raw, 37B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 32B raw, 4B comp}
[INFO] 2019-01-19 13:28:47,867 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [title] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,867 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 90B for [occp] BINARY: 111 values, 56B raw, 58B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 163B raw, 19B comp}
[INFO] 2019-01-19 13:28:47,867 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,867 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 113B for [idy] BINARY: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 135B raw, 23B comp}
[INFO] 2019-01-19 13:28:47,868 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 27 entries, 216B raw, 27B comp}
[INFO] 2019-01-19 13:28:47,868 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 111B for [cp_y_income] BINARY: 111 values, 77B raw, 80B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 160B raw, 19B comp}
[INFO] 2019-01-19 13:28:47,868 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 15 entries, 60B raw, 15B comp}
[INFO] 2019-01-19 13:28:47,869 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:28:47,869 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ovd_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:28:47,869 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 129B for [zx_ln_max_ovd_amt] INT32: 111 values, 90B raw, 93B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 42 entries, 168B raw, 42B comp}
[INFO] 2019-01-19 13:28:47,869 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [zx_ln_tot_ovd_mths] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 23 entries, 92B raw, 23B comp}
[INFO] 2019-01-19 13:28:47,889 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,890 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_creds] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:28:47,890 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_cred_banks] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:28:47,890 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 48B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 20B raw, 5B comp}
[INFO] 2019-01-19 13:28:47,890 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 99B for [zx_cred_max_ovd_amt] INT64: 111 values, 58B raw, 57B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 12 entries, 96B raw, 12B comp}
[INFO] 2019-01-19 13:28:47,890 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [zx_cred_tot_ovd_mths] INT32: 111 values, 48B raw, 50B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:28:47,891 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [zx_cred_max_ovd_duration] INT32: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 13:28:47,925 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119132847_0040_m_000000_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119132847_0040_m_000000
[INFO] 2019-01-19 13:28:47,926 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119132847_0040_m_000000_0: Committed
[INFO] 2019-01-19 13:28:47,929 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 40.0 (TID 634). 2379 bytes result sent to driver
[INFO] 2019-01-19 13:28:47,930 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 40.0 (TID 634) in 659 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:28:47,931 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119132847_0040_m_000001_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119132847_0040_m_000001
[INFO] 2019-01-19 13:28:47,932 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119132847_0040_m_000001_0: Committed
[INFO] 2019-01-19 13:28:47,932 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 40.0 (TID 635). 2202 bytes result sent to driver
[INFO] 2019-01-19 13:28:47,933 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 40.0 (TID 635) in 661 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:28:47,933 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 40.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:28:47,933 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 40 (save at DecoupJson.scala:166) finished in 0.662 s
[INFO] 2019-01-19 13:28:47,933 org.apache.spark.scheduler.DAGScheduler logInfo - Job 16 finished: save at DecoupJson.scala:166, took 0.807403 s
[WARN] 2019-01-19 13:28:47,959 org.apache.parquet.hadoop.ParquetOutputFormat warn - Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level
[INFO] 2019-01-19 13:28:47,966 org.apache.spark.sql.execution.datasources.FileFormatWriter logInfo - Job null committed.
[INFO] 2019-01-19 13:28:47,999 myLogger setOutputDataTable - summaryFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\summary
[INFO] 2019-01-19 13:28:48,035 myLogger main - LayerSample end
[INFO] 2019-01-19 13:28:48,049 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 13:28:48,076 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 13:28:48,108 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[ERROR] 2019-01-19 13:28:49,020 org.apache.spark.storage.DiskBlockManager logError - Exception while deleting local spark dir: C:\Users\dell\AppData\Local\Temp\blockmgr-51fefe21-3304-447d-9c65-19f40f086753
java.io.IOException: Failed to delete: C:\Users\dell\AppData\Local\Temp\blockmgr-51fefe21-3304-447d-9c65-19f40f086753
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:169)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:165)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:165)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:160)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1361)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:89)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
[INFO] 2019-01-19 13:28:49,023 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 13:28:49,025 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 13:28:49,026 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 13:28:49,032 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 13:28:49,040 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 13:28:49,040 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 13:28:49,043 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-8b27bccb-bcc1-4d6d-8856-dda3517e6bd6
[INFO] 2019-01-19 13:29:50,329 myLogger main - alignedSample start
[INFO] 2019-01-19 13:29:51,884 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 13:29:52,348 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 13:29:52,349 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 13:29:52,350 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 13:29:52,406 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 13:29:52,407 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 13:29:52,408 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 13:29:52,409 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 13:29:52,409 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 13:29:53,109 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 57890.
[INFO] 2019-01-19 13:29:53,126 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 13:29:53,144 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 13:29:53,148 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 13:29:53,148 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 13:29:53,164 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-b8d2347b-7f9c-4800-ad2d-e5bea8c31399
[INFO] 2019-01-19 13:29:53,182 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 13:29:53,222 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 13:29:53,433 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 13:29:53,436 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 13:29:53,538 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 13:29:53,567 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57904.
[INFO] 2019-01-19 13:29:53,568 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:57904
[INFO] 2019-01-19 13:29:53,570 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 13:29:53,571 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 57904, None)
[INFO] 2019-01-19 13:29:53,574 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:57904 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 57904, None)
[INFO] 2019-01-19 13:29:53,577 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 57904, None)
[INFO] 2019-01-19 13:29:53,578 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 57904, None)
[INFO] 2019-01-19 13:29:53,839 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 13:29:54,066 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 13:29:54,709 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 13:29:54,725 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 13:29:54,726 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:29:54,726 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:29:54,727 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:29:54,733 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 13:29:54,830 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:29:54,880 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:29:54,883 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:57904 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:29:54,886 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:29:54,890 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:29:54,891 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 13:29:54,948 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 13:29:54,957 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 13:29:55,226 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 13:29:55,438 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 13:29:55,447 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 528 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:29:55,448 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:29:55,451 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.549 s
[INFO] 2019-01-19 13:29:55,456 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.746393 s
[INFO] 2019-01-19 13:29:55,939 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:57904 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:29:57,128 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:29:57,133 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 13:29:57,135 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:29:57,136 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 13:29:57,324 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 48
[INFO] 2019-01-19 13:29:57,583 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 232.065722 ms
[INFO] 2019-01-19 13:29:57,688 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 82.480647 ms
[INFO] 2019-01-19 13:29:57,737 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 278.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:29:57,754 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:29:57,758 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on 192.168.99.1:57904 (size: 23.7 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:29:57,760 org.apache.spark.SparkContext logInfo - Created broadcast 1 from rdd at AlignedSample.scala:46
[INFO] 2019-01-19 13:29:57,775 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:29:57,920 org.apache.spark.SparkContext logInfo - Starting job: collect at AlignedSample.scala:46
[INFO] 2019-01-19 13:29:57,924 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 4 (rdd at AlignedSample.scala:46)
[INFO] 2019-01-19 13:29:57,925 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at AlignedSample.scala:46) with 200 output partitions
[INFO] 2019-01-19 13:29:57,925 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 2 (collect at AlignedSample.scala:46)
[INFO] 2019-01-19 13:29:57,925 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 1)
[INFO] 2019-01-19 13:29:57,926 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 1)
[INFO] 2019-01-19 13:29:57,927 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at rdd at AlignedSample.scala:46), which has no missing parents
[INFO] 2019-01-19 13:29:57,934 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2 stored as values in memory (estimated size 23.0 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:29:57,937 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:29:57,939 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_2_piece0 in memory on 192.168.99.1:57904 (size: 10.6 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:29:57,939 org.apache.spark.SparkContext logInfo - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:29:57,941 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at rdd at AlignedSample.scala:46)
[INFO] 2019-01-19 13:29:57,941 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2019-01-19 13:29:57,946 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6622 bytes)
[INFO] 2019-01-19 13:29:57,946 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2019-01-19 13:29:57,972 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.819592 ms
[INFO] 2019-01-19 13:29:57,987 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 6.17644 ms
[INFO] 2019-01-19 13:29:57,999 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 6.356627 ms
[INFO] 2019-01-19 13:29:58,010 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.412715 ms
[INFO] 2019-01-19 13:29:58,025 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.478258 ms
[INFO] 2019-01-19 13:29:58,030 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:29:58,115 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 13:29:58,522 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 2527 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,525 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 583 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:29:58,525 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:29:58,526 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 1 (rdd at AlignedSample.scala:46) finished in 0.584 s
[INFO] 2019-01-19 13:29:58,527 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:29:58,527 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:29:58,527 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 2)
[INFO] 2019-01-19 13:29:58,528 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:29:58,532 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 2 (MapPartitionsRDD[9] at map at AlignedSample.scala:46), which has no missing parents
[INFO] 2019-01-19 13:29:58,546 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3 stored as values in memory (estimated size 21.9 KB, free 1991.7 MB)
[INFO] 2019-01-19 13:29:58,547 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.5 KB, free 1991.6 MB)
[INFO] 2019-01-19 13:29:58,548 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_3_piece0 in memory on 192.168.99.1:57904 (size: 10.5 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:29:58,548 org.apache.spark.SparkContext logInfo - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:29:58,549 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at map at AlignedSample.scala:46)
[INFO] 2019-01-19 13:29:58,549 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 2.0 with 200 tasks
[INFO] 2019-01-19 13:29:58,554 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,555 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,555 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 2.0 (TID 2)
[INFO] 2019-01-19 13:29:58,556 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 2.0 (TID 3)
[INFO] 2019-01-19 13:29:58,578 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,578 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,580 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 5 ms
[INFO] 2019-01-19 13:29:58,580 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 8 ms
[INFO] 2019-01-19 13:29:58,595 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.317112 ms
[INFO] 2019-01-19 13:29:58,605 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 2.0 (TID 3). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,606 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 2.0 (TID 2). 2836 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,611 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,611 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 2.0 (TID 4)
[INFO] 2019-01-19 13:29:58,613 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 2.0 (TID 5)
[INFO] 2019-01-19 13:29:58,617 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 2.0 (TID 3) in 63 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 13:29:58,626 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,627 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,628 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,629 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 11 ms
[INFO] 2019-01-19 13:29:58,630 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 2.0 (TID 4). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,633 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,634 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 2.0 (TID 4) in 28 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 13:29:58,634 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 2.0 (TID 5). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,635 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 2.0 (TID 6)
[INFO] 2019-01-19 13:29:58,637 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,640 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,640 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,641 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 2.0 (TID 5) in 31 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 13:29:58,643 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 2.0 (TID 7)
[INFO] 2019-01-19 13:29:58,645 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 2.0 (TID 6). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,647 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,647 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 2.0 (TID 6) in 15 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 13:29:58,648 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 2.0 (TID 8)
[INFO] 2019-01-19 13:29:58,651 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,652 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,655 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 2.0 (TID 8). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,656 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,657 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,657 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,657 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 2.0 (TID 8) in 11 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 13:29:58,658 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 2.0 (TID 9)
[INFO] 2019-01-19 13:29:58,662 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 2.0 (TID 7). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,664 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,665 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 2.0 (TID 10)
[INFO] 2019-01-19 13:29:58,665 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 2.0 (TID 7) in 28 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 13:29:58,669 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,670 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,672 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 2.0 (TID 2) in 119 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 13:29:58,674 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 2.0 (TID 10). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,673 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,674 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,679 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,680 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 2.0 (TID 10) in 17 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 13:29:58,680 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 2.0 (TID 11)
[INFO] 2019-01-19 13:29:58,682 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 2.0 (TID 9). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,684 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,686 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 2.0 (TID 9) in 30 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 13:29:58,689 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 2.0 (TID 11). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,689 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 2.0 (TID 12)
[INFO] 2019-01-19 13:29:58,692 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,693 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,694 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,696 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 2.0 (TID 11) in 18 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 13:29:58,697 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 2.0 (TID 13)
[INFO] 2019-01-19 13:29:58,697 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 2.0 (TID 12). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,701 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,701 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,702 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 2.0 (TID 12) in 19 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 13:29:58,702 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 2.0 (TID 14)
[INFO] 2019-01-19 13:29:58,707 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 2.0 (TID 13). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,709 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,710 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 2.0 (TID 13) in 18 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 13:29:58,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,711 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,711 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 2.0 (TID 15)
[INFO] 2019-01-19 13:29:58,716 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 2.0 (TID 14). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,718 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,719 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 2.0 (TID 14) in 19 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 13:29:58,719 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 2.0 (TID 16)
[INFO] 2019-01-19 13:29:58,722 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,722 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,723 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,724 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,729 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 2.0 (TID 16). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,732 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,735 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 2.0 (TID 16) in 18 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 13:29:58,739 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 2.0 (TID 17)
[INFO] 2019-01-19 13:29:58,743 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,743 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,753 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 2.0 (TID 15). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,754 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,755 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 2.0 (TID 15) in 47 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 13:29:58,756 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 2.0 (TID 18)
[INFO] 2019-01-19 13:29:58,760 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,760 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,769 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 2.0 (TID 18). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,770 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 2.0 (TID 17). 2754 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,771 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,772 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,775 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 2.0 (TID 19)
[INFO] 2019-01-19 13:29:58,777 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 2.0 (TID 17) in 45 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 13:29:58,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,789 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 2.0 (TID 18) in 35 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 13:29:58,790 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 2.0 (TID 20)
[INFO] 2019-01-19 13:29:58,790 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 2.0 (TID 19). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,794 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,794 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,794 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,805 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 2.0 (TID 19) in 35 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 13:29:58,806 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 2.0 (TID 20). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,806 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 2.0 (TID 21)
[INFO] 2019-01-19 13:29:58,813 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,818 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,821 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 2.0 (TID 21). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,824 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,825 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 2.0 (TID 22)
[INFO] 2019-01-19 13:29:58,828 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 2.0 (TID 21) in 37 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 13:29:58,829 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 2.0 (TID 20) in 58 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 13:29:58,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,830 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,831 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 2.0 (TID 23)
[INFO] 2019-01-19 13:29:58,836 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,837 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,841 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 2.0 (TID 22). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,846 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,849 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 2.0 (TID 23). 2754 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,850 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 2.0 (TID 24)
[INFO] 2019-01-19 13:29:58,849 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 2.0 (TID 22) in 32 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 13:29:58,852 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,855 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 2.0 (TID 23) in 33 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 13:29:58,856 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,856 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,856 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 2.0 (TID 25)
[INFO] 2019-01-19 13:29:58,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,866 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,873 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 2.0 (TID 24). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,874 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,874 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 2.0 (TID 24) in 29 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 13:29:58,875 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 2.0 (TID 26)
[INFO] 2019-01-19 13:29:58,880 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,881 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:58,886 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 2.0 (TID 26). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,886 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 2.0 (TID 25). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,887 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,889 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,890 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 2.0 (TID 27)
[INFO] 2019-01-19 13:29:58,891 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 2.0 (TID 25) in 40 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 13:29:58,901 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,909 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 8 ms
[INFO] 2019-01-19 13:29:58,923 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 2.0 (TID 27). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:58,923 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 2.0 (TID 26) in 50 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 13:29:58,973 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 2.0 (TID 28)
[INFO] 2019-01-19 13:29:58,993 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:58,993 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:58,997 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 2.0 (TID 27) in 110 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 13:29:58,993 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:58,998 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 2.0 (TID 29)
[INFO] 2019-01-19 13:29:59,006 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,007 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 2.0 (TID 28). 2836 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,013 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,016 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 2.0 (TID 29). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,018 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 2.0 (TID 30)
[INFO] 2019-01-19 13:29:59,018 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 2.0 (TID 28) in 130 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 13:29:59,048 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,048 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:29:59,070 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 2.0 (TID 30). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,074 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,082 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,090 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 2.0 (TID 29) in 99 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 13:29:59,092 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 2.0 (TID 30) in 79 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 13:29:59,096 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 2.0 (TID 31)
[INFO] 2019-01-19 13:29:59,102 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 2.0 (TID 32)
[INFO] 2019-01-19 13:29:59,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,119 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 2.0 (TID 32). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,121 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 2.0 (TID 31). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,121 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,122 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,123 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 2.0 (TID 31) in 51 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 13:29:59,123 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 2.0 (TID 32) in 43 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 13:29:59,123 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 2.0 (TID 34)
[INFO] 2019-01-19 13:29:59,128 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,129 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,133 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 2.0 (TID 34). 2754 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,134 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,135 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 2.0 (TID 34) in 13 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 13:29:59,135 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 2.0 (TID 35)
[INFO] 2019-01-19 13:29:59,140 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,140 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,146 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 2.0 (TID 35). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,149 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,151 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 2.0 (TID 35) in 17 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 13:29:59,152 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 2.0 (TID 36)
[INFO] 2019-01-19 13:29:59,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,161 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 2.0 (TID 36). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,164 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,165 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 2.0 (TID 36) in 17 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 13:29:59,165 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 2.0 (TID 37)
[INFO] 2019-01-19 13:29:59,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,169 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,214 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 2.0 (TID 33)
[INFO] 2019-01-19 13:29:59,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,234 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 2.0 (TID 33). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,235 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,235 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 2.0 (TID 33) in 115 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 13:29:59,252 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 2.0 (TID 37). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,256 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 2.0 (TID 38)
[INFO] 2019-01-19 13:29:59,258 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,272 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,272 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,275 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 2.0 (TID 38). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,276 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 2.0 (TID 37) in 113 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 13:29:59,272 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 2.0 (TID 39)
[INFO] 2019-01-19 13:29:59,282 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,282 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,283 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,286 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 2.0 (TID 39). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,288 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,288 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 2.0 (TID 38) in 54 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 13:29:59,289 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 2.0 (TID 40)
[INFO] 2019-01-19 13:29:59,289 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 2.0 (TID 39) in 36 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 13:29:59,291 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,293 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 2.0 (TID 41)
[INFO] 2019-01-19 13:29:59,297 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,298 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,299 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 2.0 (TID 40). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,300 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,301 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 2.0 (TID 41). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,301 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,302 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 2.0 (TID 42)
[INFO] 2019-01-19 13:29:59,303 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 2.0 (TID 41) in 15 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 13:29:59,304 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,305 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,305 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 2.0 (TID 40) in 22 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 13:29:59,306 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 2.0 (TID 43)
[INFO] 2019-01-19 13:29:59,307 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 2.0 (TID 42). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,309 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,309 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,310 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,316 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 2.0 (TID 43). 2754 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,316 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 2.0 (TID 42) in 11 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 13:29:59,317 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 2.0 (TID 44)
[INFO] 2019-01-19 13:29:59,319 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,320 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,323 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 2.0 (TID 44). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,323 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 2.0 (TID 45, localhost, executor driver, partition 44, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,324 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 2.0 (TID 46, localhost, executor driver, partition 45, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,325 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 2.0 (TID 43) in 24 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 13:29:59,326 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 2.0 (TID 44) in 17 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 13:29:59,326 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 2.0 (TID 45)
[INFO] 2019-01-19 13:29:59,326 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 2.0 (TID 46)
[INFO] 2019-01-19 13:29:59,329 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,329 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,333 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 2.0 (TID 45). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,334 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 2.0 (TID 47, localhost, executor driver, partition 46, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,334 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 2.0 (TID 45) in 12 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 13:29:59,335 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 2.0 (TID 47)
[INFO] 2019-01-19 13:29:59,335 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 2.0 (TID 46). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,336 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 2.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,337 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 2.0 (TID 46) in 13 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 13:29:59,338 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 2.0 (TID 48)
[INFO] 2019-01-19 13:29:59,340 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,341 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,371 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,374 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 2.0 (TID 48). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,374 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 2.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,375 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 2.0 (TID 48) in 40 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 13:29:59,376 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 2.0 (TID 49)
[INFO] 2019-01-19 13:29:59,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,379 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,382 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 2.0 (TID 49). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,382 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 2.0 (TID 47). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,382 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 2.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,383 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 2.0 (TID 50)
[INFO] 2019-01-19 13:29:59,383 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 2.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,385 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 2.0 (TID 49) in 11 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 13:29:59,385 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,386 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,386 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 2.0 (TID 47) in 53 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 13:29:59,386 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 2.0 (TID 51)
[INFO] 2019-01-19 13:29:59,395 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,395 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,398 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 2.0 (TID 51). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,400 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 2.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,401 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 2.0 (TID 51) in 18 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 13:29:59,401 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 2.0 (TID 52)
[INFO] 2019-01-19 13:29:59,405 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,406 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,407 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 2.0 (TID 50). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,409 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 2.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,410 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 2.0 (TID 52). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,411 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 2.0 (TID 50) in 29 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 13:29:59,411 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 2.0 (TID 53)
[INFO] 2019-01-19 13:29:59,412 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 2.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,413 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 2.0 (TID 52) in 12 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 13:29:59,413 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 2.0 (TID 54)
[INFO] 2019-01-19 13:29:59,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,427 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 6 ms
[INFO] 2019-01-19 13:29:59,431 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 2.0 (TID 54). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,432 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 2.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,433 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 2.0 (TID 54) in 22 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 13:29:59,433 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 2.0 (TID 55)
[INFO] 2019-01-19 13:29:59,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,441 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 2.0 (TID 53). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,441 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 2.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,442 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 2.0 (TID 53) in 33 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 13:29:59,442 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 2.0 (TID 56)
[INFO] 2019-01-19 13:29:59,446 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 2.0 (TID 55). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,447 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,447 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 2.0 (TID 57, localhost, executor driver, partition 56, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,449 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 2.0 (TID 55) in 16 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 13:29:59,451 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 2.0 (TID 56). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,452 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 2.0 (TID 57)
[INFO] 2019-01-19 13:29:59,452 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 2.0 (TID 58, localhost, executor driver, partition 57, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,453 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 2.0 (TID 56) in 12 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 13:29:59,454 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,455 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,455 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 2.0 (TID 58)
[INFO] 2019-01-19 13:29:59,457 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 2.0 (TID 57). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,459 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 2.0 (TID 59, localhost, executor driver, partition 58, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,460 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,460 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,464 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 2.0 (TID 57) in 17 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 13:29:59,465 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 2.0 (TID 59)
[INFO] 2019-01-19 13:29:59,466 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 2.0 (TID 58). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,468 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 2.0 (TID 60, localhost, executor driver, partition 59, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,471 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 2.0 (TID 59). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,476 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 2.0 (TID 61, localhost, executor driver, partition 60, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,476 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 2.0 (TID 60)
[INFO] 2019-01-19 13:29:59,476 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 2.0 (TID 61)
[INFO] 2019-01-19 13:29:59,480 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,480 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 2.0 (TID 58) in 24 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 13:29:59,480 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,482 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:29:59,490 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 2.0 (TID 61). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,490 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 2.0 (TID 59) in 32 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 13:29:59,490 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 2.0 (TID 60). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,492 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 2.0 (TID 62, localhost, executor driver, partition 61, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,492 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 2.0 (TID 62)
[INFO] 2019-01-19 13:29:59,493 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 2.0 (TID 63, localhost, executor driver, partition 62, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,494 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 2.0 (TID 61) in 20 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 13:29:59,494 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 2.0 (TID 63)
[INFO] 2019-01-19 13:29:59,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,500 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 2.0 (TID 62). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,501 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 2.0 (TID 60) in 34 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 13:29:59,502 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 2.0 (TID 64, localhost, executor driver, partition 63, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,503 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 2.0 (TID 62) in 12 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 13:29:59,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,504 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 2.0 (TID 64)
[INFO] 2019-01-19 13:29:59,507 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 2.0 (TID 63). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,524 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 2.0 (TID 65, localhost, executor driver, partition 64, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,525 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 2.0 (TID 65)
[INFO] 2019-01-19 13:29:59,526 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 2.0 (TID 63) in 33 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 13:29:59,530 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 2.0 (TID 64). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,531 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 2.0 (TID 66, localhost, executor driver, partition 65, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,531 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 2.0 (TID 66)
[INFO] 2019-01-19 13:29:59,531 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 2.0 (TID 64) in 30 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 13:29:59,534 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,534 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,535 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,535 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:29:59,538 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 2.0 (TID 66). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,539 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 2.0 (TID 65). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,539 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 2.0 (TID 67, localhost, executor driver, partition 66, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,540 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 2.0 (TID 68, localhost, executor driver, partition 67, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,541 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 2.0 (TID 66) in 9 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 13:29:59,541 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 2.0 (TID 65) in 18 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 13:29:59,541 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 2.0 (TID 67)
[INFO] 2019-01-19 13:29:59,541 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 2.0 (TID 68)
[INFO] 2019-01-19 13:29:59,544 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,544 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,544 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,544 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,559 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 2.0 (TID 68). 2740 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,559 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 2.0 (TID 67). 2819 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,561 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 2.0 (TID 69, localhost, executor driver, partition 68, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,562 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 2.0 (TID 70, localhost, executor driver, partition 69, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,562 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 2.0 (TID 69)
[INFO] 2019-01-19 13:29:59,564 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 2.0 (TID 68) in 24 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 13:29:59,563 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 2.0 (TID 70)
[INFO] 2019-01-19 13:29:59,565 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,565 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,568 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 2.0 (TID 70). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,569 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 2.0 (TID 69). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,570 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 2.0 (TID 71, localhost, executor driver, partition 70, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,570 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 2.0 (TID 72, localhost, executor driver, partition 71, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,572 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 2.0 (TID 72)
[INFO] 2019-01-19 13:29:59,572 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 2.0 (TID 67) in 33 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 13:29:59,572 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 2.0 (TID 70) in 10 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 13:29:59,573 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 2.0 (TID 69) in 13 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 13:29:59,573 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 2.0 (TID 71)
[INFO] 2019-01-19 13:29:59,574 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,574 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,575 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,577 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 2.0 (TID 72). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,577 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 2.0 (TID 71). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,580 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 2.0 (TID 73, localhost, executor driver, partition 72, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,581 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 2.0 (TID 74, localhost, executor driver, partition 73, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,581 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_2_piece0 on 192.168.99.1:57904 in memory (size: 10.6 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:29:59,582 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 2.0 (TID 72) in 12 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 13:29:59,582 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 2.0 (TID 71) in 13 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 13:29:59,583 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 2.0 (TID 73)
[INFO] 2019-01-19 13:29:59,584 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 2.0 (TID 74)
[INFO] 2019-01-19 13:29:59,586 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,586 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,586 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,587 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:29:59,588 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 2.0 (TID 74). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,590 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 2.0 (TID 75, localhost, executor driver, partition 74, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,591 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 2.0 (TID 73). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,591 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 2.0 (TID 74) in 11 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 13:29:59,592 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 2.0 (TID 76, localhost, executor driver, partition 75, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,592 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 2.0 (TID 75)
[INFO] 2019-01-19 13:29:59,593 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 2.0 (TID 73) in 15 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 13:29:59,596 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,596 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,600 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 2.0 (TID 75). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,601 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 2.0 (TID 76)
[INFO] 2019-01-19 13:29:59,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,647 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 2.0 (TID 76). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,648 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 2.0 (TID 77, localhost, executor driver, partition 76, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,649 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 2.0 (TID 78, localhost, executor driver, partition 77, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,651 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 2.0 (TID 75) in 62 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 13:29:59,651 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 2.0 (TID 76) in 59 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 13:29:59,660 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 2.0 (TID 77)
[INFO] 2019-01-19 13:29:59,667 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 2.0 (TID 78)
[INFO] 2019-01-19 13:29:59,687 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,687 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,687 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,688 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,692 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 2.0 (TID 77). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,695 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 2.0 (TID 78). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,697 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 2.0 (TID 79, localhost, executor driver, partition 78, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,698 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 2.0 (TID 80, localhost, executor driver, partition 79, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 2.0 (TID 77) in 52 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 13:29:59,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 2.0 (TID 78) in 51 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 13:29:59,700 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 2.0 (TID 79)
[INFO] 2019-01-19 13:29:59,701 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 2.0 (TID 80)
[INFO] 2019-01-19 13:29:59,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,703 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,704 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,705 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,705 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 2.0 (TID 79). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,708 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 2.0 (TID 81, localhost, executor driver, partition 80, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,707 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 2.0 (TID 80). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,712 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 2.0 (TID 82, localhost, executor driver, partition 81, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,713 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 2.0 (TID 79) in 17 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 13:29:59,713 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 2.0 (TID 81)
[INFO] 2019-01-19 13:29:59,714 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 2.0 (TID 82)
[INFO] 2019-01-19 13:29:59,716 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,716 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,717 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,717 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,718 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 2.0 (TID 81). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,714 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 2.0 (TID 80) in 15 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 13:29:59,719 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 2.0 (TID 82). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,720 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 2.0 (TID 83, localhost, executor driver, partition 82, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,725 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 2.0 (TID 84, localhost, executor driver, partition 83, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,729 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 2.0 (TID 81) in 21 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 13:29:59,730 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 2.0 (TID 82) in 19 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 13:29:59,739 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 2.0 (TID 83)
[INFO] 2019-01-19 13:29:59,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,774 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 2.0 (TID 83). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,775 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 2.0 (TID 84)
[INFO] 2019-01-19 13:29:59,778 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 2.0 (TID 85, localhost, executor driver, partition 84, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,780 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,808 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 2.0 (TID 83) in 88 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 13:29:59,836 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 2.0 (TID 85)
[INFO] 2019-01-19 13:29:59,839 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 2.0 (TID 84). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,840 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,841 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,843 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 2.0 (TID 85). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 2.0 (TID 86, localhost, executor driver, partition 85, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,852 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 2.0 (TID 87, localhost, executor driver, partition 86, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,853 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 2.0 (TID 86)
[INFO] 2019-01-19 13:29:59,854 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 2.0 (TID 84) in 129 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 13:29:59,855 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 2.0 (TID 85) in 78 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 13:29:59,855 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 2.0 (TID 87)
[INFO] 2019-01-19 13:29:59,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,871 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 2.0 (TID 87). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,873 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 2.0 (TID 88, localhost, executor driver, partition 87, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,875 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 2.0 (TID 86). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,875 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 2.0 (TID 87) in 24 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 13:29:59,877 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 2.0 (TID 89, localhost, executor driver, partition 88, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,877 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 2.0 (TID 88)
[INFO] 2019-01-19 13:29:59,881 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 2.0 (TID 86) in 32 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 13:29:59,881 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,882 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:29:59,888 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 2.0 (TID 89)
[INFO] 2019-01-19 13:29:59,890 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,911 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 2.0 (TID 88). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,913 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 2.0 (TID 90, localhost, executor driver, partition 89, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,914 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 2.0 (TID 88) in 41 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 13:29:59,915 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 2.0 (TID 90)
[INFO] 2019-01-19 13:29:59,929 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,929 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:29:59,949 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 2.0 (TID 90). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:29:59,963 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 2.0 (TID 91, localhost, executor driver, partition 90, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:29:59,971 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 2.0 (TID 90) in 58 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 13:29:59,975 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 2.0 (TID 91)
[INFO] 2019-01-19 13:29:59,997 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:29:59,997 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,007 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 2.0 (TID 91). 2754 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,015 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 2.0 (TID 92, localhost, executor driver, partition 91, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,019 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 2.0 (TID 91) in 66 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 13:30:00,022 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 2.0 (TID 92)
[INFO] 2019-01-19 13:30:00,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:30:00,047 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 2.0 (TID 92). 2844 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,057 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 2.0 (TID 93, localhost, executor driver, partition 92, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,059 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 2.0 (TID 92) in 46 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 13:30:00,059 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 2.0 (TID 93)
[INFO] 2019-01-19 13:30:00,063 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,063 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,065 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 2.0 (TID 93). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,067 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 2.0 (TID 94, localhost, executor driver, partition 93, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,069 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 2.0 (TID 93) in 12 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 13:30:00,069 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 2.0 (TID 94)
[INFO] 2019-01-19 13:30:00,072 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,072 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,075 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 2.0 (TID 94). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,076 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 2.0 (TID 95, localhost, executor driver, partition 94, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,077 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 2.0 (TID 94) in 10 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 13:30:00,078 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 2.0 (TID 95)
[INFO] 2019-01-19 13:30:00,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 192 ms
[INFO] 2019-01-19 13:30:00,084 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 2.0 (TID 89). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,085 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 2.0 (TID 96, localhost, executor driver, partition 95, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,085 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 2.0 (TID 89) in 208 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 13:30:00,086 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 2.0 (TID 96)
[INFO] 2019-01-19 13:30:00,089 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,089 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,093 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 2.0 (TID 96). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,094 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 2.0 (TID 97, localhost, executor driver, partition 96, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,094 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 2.0 (TID 96) in 10 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 13:30:00,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,419 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 309 ms
[INFO] 2019-01-19 13:30:00,424 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 2.0 (TID 95). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,426 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 2.0 (TID 98, localhost, executor driver, partition 97, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,429 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 2.0 (TID 95) in 353 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 13:30:00,429 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 2.0 (TID 98)
[INFO] 2019-01-19 13:30:00,432 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,432 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,434 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 2.0 (TID 98). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,436 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 2.0 (TID 99, localhost, executor driver, partition 98, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,438 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 2.0 (TID 98) in 12 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 13:30:00,438 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 2.0 (TID 99)
[INFO] 2019-01-19 13:30:00,450 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,450 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,453 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 2.0 (TID 99). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,454 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 2.0 (TID 100, localhost, executor driver, partition 99, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,456 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 2.0 (TID 99) in 20 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 13:30:00,456 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 2.0 (TID 100)
[INFO] 2019-01-19 13:30:00,459 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,460 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,463 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 2.0 (TID 100). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,464 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 2.0 (TID 101, localhost, executor driver, partition 100, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,465 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 2.0 (TID 100) in 11 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 13:30:00,465 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 2.0 (TID 101)
[INFO] 2019-01-19 13:30:00,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,468 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,471 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 2.0 (TID 101). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,473 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 2.0 (TID 102, localhost, executor driver, partition 101, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,474 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 2.0 (TID 101) in 11 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 13:30:00,474 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 2.0 (TID 102)
[INFO] 2019-01-19 13:30:00,476 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,478 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:30:00,480 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 2.0 (TID 102). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,481 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 2.0 (TID 103, localhost, executor driver, partition 102, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,482 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 2.0 (TID 102) in 9 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 13:30:00,483 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 2.0 (TID 103)
[INFO] 2019-01-19 13:30:00,485 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,488 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 2.0 (TID 103). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,489 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 2.0 (TID 104, localhost, executor driver, partition 103, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,490 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 2.0 (TID 103) in 9 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 13:30:00,490 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 2.0 (TID 104)
[INFO] 2019-01-19 13:30:00,095 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 2.0 (TID 97)
[INFO] 2019-01-19 13:30:00,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,496 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,499 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 2.0 (TID 97). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,500 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 2.0 (TID 105, localhost, executor driver, partition 104, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,500 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 2.0 (TID 97) in 407 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 13:30:00,501 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 2.0 (TID 105)
[INFO] 2019-01-19 13:30:00,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,504 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,507 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 2.0 (TID 105). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,508 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 2.0 (TID 106, localhost, executor driver, partition 105, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,508 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 2.0 (TID 105) in 9 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 13:30:00,509 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 2.0 (TID 106)
[INFO] 2019-01-19 13:30:00,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,512 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,515 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 2.0 (TID 106). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,518 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 2.0 (TID 107, localhost, executor driver, partition 106, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,519 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 2.0 (TID 106) in 12 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 13:30:00,519 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 2.0 (TID 107)
[INFO] 2019-01-19 13:30:00,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,523 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,526 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 2.0 (TID 107). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,527 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 2.0 (TID 108, localhost, executor driver, partition 107, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,528 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 2.0 (TID 107) in 10 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 13:30:00,529 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 2.0 (TID 108)
[INFO] 2019-01-19 13:30:00,531 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,532 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,534 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 2.0 (TID 108). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,536 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 2.0 (TID 109, localhost, executor driver, partition 108, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,537 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 2.0 (TID 108) in 9 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 13:30:00,537 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 2.0 (TID 109)
[INFO] 2019-01-19 13:30:00,539 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,539 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,542 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 2.0 (TID 109). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,544 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 2.0 (TID 110, localhost, executor driver, partition 109, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,544 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 2.0 (TID 109) in 9 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 13:30:00,545 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 2.0 (TID 110)
[INFO] 2019-01-19 13:30:00,548 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,549 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,554 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 2.0 (TID 110). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,555 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 2.0 (TID 111, localhost, executor driver, partition 110, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,555 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 2.0 (TID 110) in 12 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 13:30:00,556 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 2.0 (TID 111)
[INFO] 2019-01-19 13:30:00,559 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,560 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,567 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,567 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,572 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 2.0 (TID 104). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,574 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 2.0 (TID 112, localhost, executor driver, partition 111, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,575 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 2.0 (TID 104) in 86 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 13:30:00,575 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 2.0 (TID 112)
[INFO] 2019-01-19 13:30:00,578 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,578 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,590 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 2.0 (TID 111). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,590 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 2.0 (TID 113, localhost, executor driver, partition 112, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,592 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 2.0 (TID 112). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,593 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 2.0 (TID 114, localhost, executor driver, partition 113, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,594 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 2.0 (TID 111) in 40 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 13:30:00,594 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 2.0 (TID 112) in 20 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 13:30:00,595 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 2.0 (TID 113)
[INFO] 2019-01-19 13:30:00,598 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,598 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,600 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 2.0 (TID 113). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,602 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 2.0 (TID 115, localhost, executor driver, partition 114, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,602 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 2.0 (TID 114)
[INFO] 2019-01-19 13:30:00,604 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,604 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,607 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 2.0 (TID 114). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,607 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 2.0 (TID 113) in 17 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 13:30:00,609 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 2.0 (TID 116, localhost, executor driver, partition 115, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,610 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 2.0 (TID 115)
[INFO] 2019-01-19 13:30:00,614 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,614 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,616 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 2.0 (TID 115). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,616 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 2.0 (TID 114) in 23 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 13:30:00,628 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 2.0 (TID 116)
[INFO] 2019-01-19 13:30:00,634 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,635 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,635 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 2.0 (TID 117, localhost, executor driver, partition 116, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,637 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 2.0 (TID 115) in 36 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 13:30:00,637 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 2.0 (TID 117)
[INFO] 2019-01-19 13:30:00,637 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 2.0 (TID 116). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,639 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 2.0 (TID 118, localhost, executor driver, partition 117, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,640 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 2.0 (TID 116) in 31 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 13:30:00,639 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,640 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,642 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 2.0 (TID 117). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,642 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 2.0 (TID 118)
[INFO] 2019-01-19 13:30:00,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,647 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 2.0 (TID 119, localhost, executor driver, partition 118, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,648 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 2.0 (TID 117) in 14 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 13:30:00,648 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 2.0 (TID 119)
[INFO] 2019-01-19 13:30:00,649 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 2.0 (TID 118). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,651 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,651 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,651 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 2.0 (TID 120, localhost, executor driver, partition 119, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,652 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 2.0 (TID 118) in 13 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 13:30:00,652 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 2.0 (TID 120)
[INFO] 2019-01-19 13:30:00,653 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 2.0 (TID 119). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,654 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 2.0 (TID 121, localhost, executor driver, partition 120, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,654 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,655 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 2.0 (TID 119) in 8 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 13:30:00,658 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 2.0 (TID 121)
[INFO] 2019-01-19 13:30:00,659 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 2.0 (TID 120). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,660 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 2.0 (TID 122, localhost, executor driver, partition 121, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,662 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,662 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,663 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 2.0 (TID 122)
[INFO] 2019-01-19 13:30:00,663 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 2.0 (TID 120) in 11 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 13:30:00,665 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 2.0 (TID 121). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,665 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,665 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,666 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 2.0 (TID 123, localhost, executor driver, partition 122, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,666 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 2.0 (TID 121) in 12 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 13:30:00,667 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 2.0 (TID 123)
[INFO] 2019-01-19 13:30:00,668 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 2.0 (TID 122). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,669 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 2.0 (TID 124, localhost, executor driver, partition 123, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,672 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 2.0 (TID 122) in 11 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 13:30:00,672 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,672 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,672 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 2.0 (TID 124)
[INFO] 2019-01-19 13:30:00,674 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 2.0 (TID 123). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,675 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,676 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 2.0 (TID 125, localhost, executor driver, partition 124, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,677 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 2 ms
[INFO] 2019-01-19 13:30:00,677 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 2.0 (TID 123) in 12 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 13:30:00,679 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 2.0 (TID 125)
[INFO] 2019-01-19 13:30:00,680 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 2.0 (TID 124). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,684 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 2.0 (TID 126, localhost, executor driver, partition 125, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,686 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 2.0 (TID 124) in 17 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 13:30:00,686 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 2.0 (TID 125). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,687 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 2.0 (TID 127, localhost, executor driver, partition 126, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,688 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 2.0 (TID 126)
[INFO] 2019-01-19 13:30:00,689 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 2.0 (TID 125) in 13 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 13:30:00,690 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 2.0 (TID 127)
[INFO] 2019-01-19 13:30:00,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,700 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,700 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,701 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 2.0 (TID 126). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,704 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 2.0 (TID 127). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,705 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 2.0 (TID 128, localhost, executor driver, partition 127, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,706 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 2.0 (TID 129, localhost, executor driver, partition 128, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,707 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 2.0 (TID 128)
[INFO] 2019-01-19 13:30:00,707 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 2.0 (TID 129)
[INFO] 2019-01-19 13:30:00,708 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 2.0 (TID 126) in 23 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 13:30:00,710 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,710 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,711 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 2.0 (TID 127) in 24 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 13:30:00,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,718 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 2.0 (TID 128). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,719 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 2.0 (TID 129). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,720 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 2.0 (TID 130, localhost, executor driver, partition 129, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,721 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 2.0 (TID 131, localhost, executor driver, partition 130, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,721 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 2.0 (TID 128) in 18 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 13:30:00,722 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 2.0 (TID 129) in 16 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 13:30:00,722 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 2.0 (TID 130)
[INFO] 2019-01-19 13:30:00,722 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 2.0 (TID 131)
[INFO] 2019-01-19 13:30:00,725 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,725 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,729 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 2.0 (TID 130). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,729 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,729 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,730 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 2.0 (TID 132, localhost, executor driver, partition 131, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,731 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 2.0 (TID 130) in 10 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 13:30:00,731 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 2.0 (TID 132)
[INFO] 2019-01-19 13:30:00,731 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 2.0 (TID 131). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,732 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 2.0 (TID 133, localhost, executor driver, partition 132, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,733 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 2.0 (TID 131) in 12 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 13:30:00,733 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,733 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,733 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 2.0 (TID 133)
[INFO] 2019-01-19 13:30:00,734 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 2.0 (TID 132). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,736 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 2.0 (TID 134, localhost, executor driver, partition 133, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,737 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 2.0 (TID 132) in 8 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 13:30:00,737 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 2.0 (TID 134)
[INFO] 2019-01-19 13:30:00,737 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 2.0 (TID 133). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,739 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,739 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,739 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 2.0 (TID 135, localhost, executor driver, partition 134, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,740 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 2.0 (TID 133) in 8 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 13:30:00,740 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 2.0 (TID 135)
[INFO] 2019-01-19 13:30:00,741 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 2.0 (TID 134). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,742 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,743 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,742 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 2.0 (TID 136, localhost, executor driver, partition 135, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,744 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 2.0 (TID 134) in 9 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 13:30:00,744 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 2.0 (TID 136)
[INFO] 2019-01-19 13:30:00,745 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 2.0 (TID 135). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,747 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,747 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,748 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 2.0 (TID 137, localhost, executor driver, partition 136, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,749 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 2.0 (TID 135) in 10 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 13:30:00,749 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 2.0 (TID 136). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,750 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 2.0 (TID 137)
[INFO] 2019-01-19 13:30:00,750 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 2.0 (TID 138, localhost, executor driver, partition 137, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,751 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 2.0 (TID 136) in 9 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 13:30:00,751 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 2.0 (TID 138)
[INFO] 2019-01-19 13:30:00,752 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,752 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,753 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 2.0 (TID 137). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,754 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,754 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 2.0 (TID 139, localhost, executor driver, partition 138, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,755 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 2.0 (TID 137) in 7 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 13:30:00,755 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 2.0 (TID 139)
[INFO] 2019-01-19 13:30:00,755 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 2.0 (TID 138). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,756 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 2.0 (TID 140, localhost, executor driver, partition 139, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,757 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,757 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,757 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 2.0 (TID 140)
[INFO] 2019-01-19 13:30:00,757 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 2.0 (TID 138) in 7 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 13:30:00,759 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,760 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,766 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 2.0 (TID 139). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,767 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 2.0 (TID 140). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,767 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 2.0 (TID 141, localhost, executor driver, partition 140, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,768 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 2.0 (TID 141)
[INFO] 2019-01-19 13:30:00,768 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 2.0 (TID 139) in 14 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 13:30:00,769 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 2.0 (TID 142, localhost, executor driver, partition 141, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,769 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 2.0 (TID 142)
[INFO] 2019-01-19 13:30:00,769 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 2.0 (TID 140) in 13 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 13:30:00,770 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,771 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,771 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,772 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 2.0 (TID 141). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,773 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 2.0 (TID 143, localhost, executor driver, partition 142, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,773 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 2.0 (TID 141) in 6 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 13:30:00,773 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 2.0 (TID 142). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,773 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 2.0 (TID 143)
[INFO] 2019-01-19 13:30:00,775 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 2.0 (TID 144, localhost, executor driver, partition 143, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,775 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 2.0 (TID 144)
[INFO] 2019-01-19 13:30:00,775 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 2.0 (TID 142) in 6 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 13:30:00,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,776 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,777 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,777 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 2.0 (TID 143). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,777 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,778 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 2.0 (TID 145, localhost, executor driver, partition 144, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,778 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 2.0 (TID 143) in 6 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 13:30:00,778 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 2.0 (TID 145)
[INFO] 2019-01-19 13:30:00,779 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 2.0 (TID 144). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,780 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 2.0 (TID 146, localhost, executor driver, partition 145, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,780 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 2.0 (TID 144) in 6 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 13:30:00,781 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 2.0 (TID 146)
[INFO] 2019-01-19 13:30:00,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,781 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,783 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 2.0 (TID 145). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,783 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,783 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,783 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 2.0 (TID 147, localhost, executor driver, partition 146, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,784 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 2.0 (TID 145) in 7 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 13:30:00,784 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 2.0 (TID 147)
[INFO] 2019-01-19 13:30:00,785 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 2.0 (TID 146). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,786 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,786 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,787 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 2.0 (TID 148, localhost, executor driver, partition 147, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,788 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 2.0 (TID 146) in 9 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 13:30:00,788 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 2.0 (TID 148)
[INFO] 2019-01-19 13:30:00,788 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 2.0 (TID 147). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,789 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 2.0 (TID 149, localhost, executor driver, partition 148, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,790 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 2.0 (TID 147) in 7 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 13:30:00,790 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 2.0 (TID 149)
[INFO] 2019-01-19 13:30:00,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,792 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,792 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,792 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 2.0 (TID 148). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,793 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 2.0 (TID 150, localhost, executor driver, partition 149, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,793 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 2.0 (TID 148) in 6 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 13:30:00,794 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 2.0 (TID 149). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,794 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 2.0 (TID 150)
[INFO] 2019-01-19 13:30:00,796 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,796 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,797 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 2.0 (TID 151, localhost, executor driver, partition 150, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 2.0 (TID 149) in 9 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 13:30:00,798 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 2.0 (TID 151)
[INFO] 2019-01-19 13:30:00,798 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 2.0 (TID 150). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,799 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 2.0 (TID 152, localhost, executor driver, partition 151, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,800 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 2.0 (TID 150) in 8 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 13:30:00,800 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 2.0 (TID 152)
[INFO] 2019-01-19 13:30:00,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,804 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 2.0 (TID 152). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,800 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,804 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:30:00,808 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 2.0 (TID 151). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 2.0 (TID 153, localhost, executor driver, partition 152, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,810 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 2.0 (TID 154, localhost, executor driver, partition 153, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,811 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 2.0 (TID 151) in 16 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 13:30:00,810 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 2.0 (TID 153)
[INFO] 2019-01-19 13:30:00,812 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 2.0 (TID 152) in 14 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 13:30:00,812 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 2.0 (TID 154)
[INFO] 2019-01-19 13:30:00,813 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,815 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 2.0 (TID 153). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,815 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 2.0 (TID 154). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,816 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 2.0 (TID 155, localhost, executor driver, partition 154, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,816 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 2.0 (TID 155)
[INFO] 2019-01-19 13:30:00,816 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 2.0 (TID 156, localhost, executor driver, partition 155, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,817 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 2.0 (TID 154) in 6 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 13:30:00,817 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 2.0 (TID 156)
[INFO] 2019-01-19 13:30:00,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,819 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,819 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,820 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 2.0 (TID 155). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,820 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 2.0 (TID 156). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,820 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 2.0 (TID 153) in 12 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 13:30:00,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 2.0 (TID 157, localhost, executor driver, partition 156, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,821 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 2.0 (TID 157)
[INFO] 2019-01-19 13:30:00,821 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 2.0 (TID 158, localhost, executor driver, partition 157, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 2.0 (TID 156) in 6 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 13:30:00,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 2.0 (TID 155) in 7 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 13:30:00,823 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 2.0 (TID 158)
[INFO] 2019-01-19 13:30:00,823 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,823 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,849 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 2.0 (TID 157). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,851 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 2.0 (TID 159, localhost, executor driver, partition 158, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,851 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 2.0 (TID 157) in 30 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 13:30:00,852 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 2.0 (TID 159)
[INFO] 2019-01-19 13:30:00,854 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,854 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,856 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 2.0 (TID 159). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,856 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 2.0 (TID 160, localhost, executor driver, partition 159, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,857 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 2.0 (TID 159) in 7 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 13:30:00,857 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 2.0 (TID 160)
[INFO] 2019-01-19 13:30:00,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,869 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 2.0 (TID 160). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,871 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 2.0 (TID 161, localhost, executor driver, partition 160, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,872 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 2.0 (TID 160) in 15 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 13:30:00,873 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 2.0 (TID 161)
[INFO] 2019-01-19 13:30:00,875 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,876 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,879 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 2.0 (TID 161). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,880 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 2.0 (TID 162, localhost, executor driver, partition 161, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,881 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 2.0 (TID 161) in 11 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 13:30:00,881 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 2.0 (TID 162)
[INFO] 2019-01-19 13:30:00,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,887 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 4 ms
[INFO] 2019-01-19 13:30:00,889 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 2.0 (TID 162). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,891 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 2.0 (TID 163, localhost, executor driver, partition 162, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,891 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 2.0 (TID 162) in 12 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 13:30:00,892 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 2.0 (TID 163)
[INFO] 2019-01-19 13:30:00,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,901 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 2.0 (TID 163). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,901 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 2.0 (TID 164, localhost, executor driver, partition 163, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,902 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 2.0 (TID 163) in 11 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 13:30:00,902 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 2.0 (TID 164)
[INFO] 2019-01-19 13:30:00,902 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,902 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 78 ms
[INFO] 2019-01-19 13:30:00,904 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,904 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,906 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 2.0 (TID 164). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,907 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 2.0 (TID 165, localhost, executor driver, partition 164, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,907 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 2.0 (TID 165)
[INFO] 2019-01-19 13:30:00,907 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 2.0 (TID 164) in 6 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 13:30:00,911 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,912 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,914 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 2.0 (TID 165). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,914 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 2.0 (TID 158). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,914 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 2.0 (TID 166, localhost, executor driver, partition 165, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,915 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 2.0 (TID 166)
[INFO] 2019-01-19 13:30:00,915 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 2.0 (TID 167, localhost, executor driver, partition 166, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,918 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 2.0 (TID 158) in 97 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 13:30:00,918 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 2.0 (TID 167)
[INFO] 2019-01-19 13:30:00,919 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 2.0 (TID 166). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,920 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 2.0 (TID 165) in 13 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 13:30:00,920 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,921 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,925 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 2.0 (TID 168, localhost, executor driver, partition 167, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,926 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 2.0 (TID 166) in 12 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 13:30:00,926 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 2.0 (TID 168)
[INFO] 2019-01-19 13:30:00,930 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,930 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,931 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 2.0 (TID 168). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,932 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 2.0 (TID 169, localhost, executor driver, partition 168, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,932 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 2.0 (TID 169)
[INFO] 2019-01-19 13:30:00,932 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 2.0 (TID 168) in 7 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 13:30:00,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,936 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 2.0 (TID 169). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,938 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 2.0 (TID 170, localhost, executor driver, partition 169, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,938 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 2.0 (TID 169) in 6 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 13:30:00,938 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 2.0 (TID 170)
[INFO] 2019-01-19 13:30:00,941 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,941 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,942 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 2.0 (TID 170). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,943 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 2.0 (TID 171, localhost, executor driver, partition 170, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,943 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 2.0 (TID 171)
[INFO] 2019-01-19 13:30:00,943 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 2.0 (TID 170) in 6 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 13:30:00,946 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,946 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,947 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 2.0 (TID 171). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,948 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 2.0 (TID 167). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,948 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 2.0 (TID 172, localhost, executor driver, partition 171, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,948 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 2.0 (TID 172)
[INFO] 2019-01-19 13:30:00,949 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 2.0 (TID 173, localhost, executor driver, partition 172, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,949 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 2.0 (TID 167) in 34 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 13:30:00,950 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 2.0 (TID 171) in 6 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 13:30:00,950 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 2.0 (TID 173)
[INFO] 2019-01-19 13:30:00,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,950 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,952 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 2.0 (TID 172). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,953 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,953 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 2.0 (TID 174, localhost, executor driver, partition 173, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,954 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,954 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 2.0 (TID 172) in 6 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 13:30:00,954 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 2.0 (TID 174)
[INFO] 2019-01-19 13:30:00,955 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 2.0 (TID 173). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,956 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,956 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,956 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 2.0 (TID 175, localhost, executor driver, partition 174, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,957 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 2.0 (TID 173) in 9 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 13:30:00,957 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 2.0 (TID 175)
[INFO] 2019-01-19 13:30:00,958 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 2.0 (TID 174). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,959 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 2.0 (TID 176, localhost, executor driver, partition 175, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,959 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 2.0 (TID 174) in 6 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 13:30:00,960 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 2.0 (TID 176)
[INFO] 2019-01-19 13:30:00,959 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,960 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,963 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,963 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,964 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 2.0 (TID 175). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,965 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 2.0 (TID 176). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,965 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 2.0 (TID 177, localhost, executor driver, partition 176, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,966 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 2.0 (TID 177)
[INFO] 2019-01-19 13:30:00,966 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 2.0 (TID 178, localhost, executor driver, partition 177, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,967 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 2.0 (TID 175) in 11 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 13:30:00,967 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 2.0 (TID 178)
[INFO] 2019-01-19 13:30:00,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,969 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,969 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,969 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 2.0 (TID 177). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,970 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 2.0 (TID 176) in 12 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 13:30:00,970 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 2.0 (TID 179, localhost, executor driver, partition 178, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,970 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 2.0 (TID 179)
[INFO] 2019-01-19 13:30:00,970 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 2.0 (TID 177) in 5 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 13:30:00,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:00,976 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 2.0 (TID 179). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,977 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 2.0 (TID 180, localhost, executor driver, partition 179, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,978 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 2.0 (TID 179) in 8 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 13:30:00,978 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 2.0 (TID 180)
[INFO] 2019-01-19 13:30:00,980 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 2.0 (TID 178). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,980 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 2.0 (TID 181, localhost, executor driver, partition 180, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,980 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,980 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,981 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 2.0 (TID 181)
[INFO] 2019-01-19 13:30:00,981 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 2.0 (TID 178) in 14 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 13:30:00,982 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 2.0 (TID 180). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,982 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 2.0 (TID 182, localhost, executor driver, partition 181, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,983 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 2.0 (TID 180) in 7 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 13:30:00,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,983 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 2.0 (TID 182)
[INFO] 2019-01-19 13:30:00,985 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 2.0 (TID 181). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,985 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 2.0 (TID 183, localhost, executor driver, partition 182, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,985 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 2.0 (TID 181) in 5 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 13:30:00,986 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,986 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,987 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 2.0 (TID 183)
[INFO] 2019-01-19 13:30:00,988 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 2.0 (TID 182). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,990 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,990 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,991 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 2.0 (TID 184, localhost, executor driver, partition 183, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,992 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 2.0 (TID 183). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,992 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 2.0 (TID 184)
[INFO] 2019-01-19 13:30:00,992 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 2.0 (TID 182) in 10 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 13:30:00,993 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 2.0 (TID 185, localhost, executor driver, partition 184, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,993 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 2.0 (TID 183) in 8 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 13:30:00,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,994 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,994 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 2.0 (TID 185)
[INFO] 2019-01-19 13:30:00,995 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 2.0 (TID 184). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,996 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 2.0 (TID 186, localhost, executor driver, partition 185, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:00,997 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 2.0 (TID 184) in 6 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 13:30:00,997 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 2.0 (TID 186)
[INFO] 2019-01-19 13:30:00,997 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:00,997 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:00,999 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 2.0 (TID 185). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:00,999 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 2.0 (TID 187, localhost, executor driver, partition 186, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,000 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 2.0 (TID 187)
[INFO] 2019-01-19 13:30:01,000 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 2.0 (TID 185) in 7 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 13:30:01,002 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,002 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,003 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,003 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,003 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 2.0 (TID 187). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,004 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 2.0 (TID 188, localhost, executor driver, partition 187, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,004 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 2.0 (TID 188)
[INFO] 2019-01-19 13:30:01,004 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 2.0 (TID 187) in 5 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 13:30:01,006 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 2.0 (TID 186). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,006 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,006 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,007 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 2.0 (TID 189, localhost, executor driver, partition 188, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,008 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 2.0 (TID 186) in 12 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 13:30:01,008 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 2.0 (TID 188). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,008 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 2.0 (TID 189)
[INFO] 2019-01-19 13:30:01,009 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 2.0 (TID 190, localhost, executor driver, partition 189, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,009 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 2.0 (TID 188) in 5 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 13:30:01,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,011 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:01,012 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 2.0 (TID 189). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,013 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 2.0 (TID 190)
[INFO] 2019-01-19 13:30:01,014 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,015 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:01,016 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 2.0 (TID 190). 2746 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,017 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 2.0 (TID 191, localhost, executor driver, partition 190, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,018 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 2.0 (TID 192, localhost, executor driver, partition 192, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,019 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 2.0 (TID 189) in 12 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 13:30:01,019 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 2.0 (TID 190) in 10 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 13:30:01,020 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 2.0 (TID 191)
[INFO] 2019-01-19 13:30:01,021 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 2.0 (TID 192)
[INFO] 2019-01-19 13:30:01,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,026 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 2.0 (TID 192). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,026 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 2.0 (TID 193, localhost, executor driver, partition 193, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,027 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 2.0 (TID 192) in 9 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 13:30:01,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,027 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 13:30:01,028 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 2.0 (TID 193)
[INFO] 2019-01-19 13:30:01,029 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 2.0 (TID 191). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,030 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 2.0 (TID 194, localhost, executor driver, partition 194, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,030 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 2.0 (TID 191) in 13 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 13:30:01,031 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 2.0 (TID 194)
[INFO] 2019-01-19 13:30:01,031 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,031 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,032 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:01,033 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 2.0 (TID 193). 2757 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,033 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 2.0 (TID 195, localhost, executor driver, partition 195, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,034 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 2.0 (TID 193) in 8 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 13:30:01,034 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 2.0 (TID 194). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,034 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 2.0 (TID 195)
[INFO] 2019-01-19 13:30:01,035 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 2.0 (TID 196, localhost, executor driver, partition 196, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,035 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 2.0 (TID 194) in 5 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 13:30:01,036 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 2.0 (TID 196)
[INFO] 2019-01-19 13:30:01,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,038 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,038 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,038 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 2.0 (TID 195). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,038 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 2.0 (TID 197, localhost, executor driver, partition 197, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,039 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 2.0 (TID 197)
[INFO] 2019-01-19 13:30:01,039 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 2.0 (TID 195) in 6 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 13:30:01,039 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 2.0 (TID 196). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,040 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 2.0 (TID 198, localhost, executor driver, partition 198, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,040 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 2.0 (TID 196) in 5 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 13:30:01,040 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 2.0 (TID 198)
[INFO] 2019-01-19 13:30:01,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,042 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 2.0 (TID 197). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,043 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,043 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,045 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 2.0 (TID 198). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,046 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 2.0 (TID 199, localhost, executor driver, partition 199, PROCESS_LOCAL, 5870 bytes)
[INFO] 2019-01-19 13:30:01,047 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 2.0 (TID 200, localhost, executor driver, partition 43, ANY, 5870 bytes)
[INFO] 2019-01-19 13:30:01,047 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 2.0 (TID 197) in 9 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 13:30:01,048 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 2.0 (TID 198) in 9 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 13:30:01,049 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 2.0 (TID 199)
[INFO] 2019-01-19 13:30:01,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 0 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,053 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 2.0 (TID 199). 2667 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,053 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 2.0 (TID 200)
[INFO] 2019-01-19 13:30:01,056 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 2.0 (TID 201, localhost, executor driver, partition 191, ANY, 5870 bytes)
[INFO] 2019-01-19 13:30:01,057 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,057 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:01,080 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 2.0 (TID 199) in 35 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 13:30:01,080 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 2.0 (TID 201)
[INFO] 2019-01-19 13:30:01,086 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:01,087 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:01,153 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 2.0 (TID 200). 3364 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,153 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 2.0 (TID 201). 3356 bytes result sent to driver
[INFO] 2019-01-19 13:30:01,153 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 2.0 (TID 200) in 107 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 13:30:01,154 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 2.0 (TID 201) in 98 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 13:30:01,154 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:01,154 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 2 (collect at AlignedSample.scala:46) finished in 2.602 s
[INFO] 2019-01-19 13:30:01,154 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at AlignedSample.scala:46, took 3.234488 s
[INFO] 2019-01-19 13:30:01,236 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag == 1
[INFO] 2019-01-19 13:30:01,476 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: samp_flag == 0
[INFO] 2019-01-19 13:30:03,395 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:03,397 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:30:03,397 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:03,399 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:30:03,403 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:03,403 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:30:03,404 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:03,404 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[WARN] 2019-01-19 13:30:03,472 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2019-01-19 13:30:03,681 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 43.860268 ms
[INFO] 2019-01-19 13:30:03,750 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 45.465028 ms
[INFO] 2019-01-19 13:30:03,781 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4 stored as values in memory (estimated size 292.7 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:30:03,790 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.4 MB)
[INFO] 2019-01-19 13:30:03,793 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_4_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:30:03,796 org.apache.spark.SparkContext logInfo - Created broadcast 4 from head at DecoupJson.scala:139
[INFO] 2019-01-19 13:30:03,797 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:03,865 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 34.896038 ms
[INFO] 2019-01-19 13:30:03,875 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5 stored as values in memory (estimated size 292.7 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:30:03,887 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.1 MB)
[INFO] 2019-01-19 13:30:03,889 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_5_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:30:03,890 org.apache.spark.SparkContext logInfo - Created broadcast 5 from head at DecoupJson.scala:139
[INFO] 2019-01-19 13:30:03,891 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:03,978 org.apache.spark.SparkContext logInfo - Starting job: head at DecoupJson.scala:139
[INFO] 2019-01-19 13:30:03,980 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 17 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:03,981 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 12 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:03,981 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 24 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:03,981 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 29 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:03,981 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 2 (head at DecoupJson.scala:139) with 1 output partitions
[INFO] 2019-01-19 13:30:03,982 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 7 (head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:03,982 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 6)
[INFO] 2019-01-19 13:30:03,982 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 6)
[INFO] 2019-01-19 13:30:03,983 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:30:03,985 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6 stored as values in memory (estimated size 39.6 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:30:03,987 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:30:03,990 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_6_piece0 in memory on 192.168.99.1:57904 (size: 12.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:30:03,990 org.apache.spark.SparkContext logInfo - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:03,991 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:03,991 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 3.0 with 1 tasks
[INFO] 2019-01-19 13:30:03,992 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:30:03,994 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7 stored as values in memory (estimated size 39.7 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:30:03,998 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1991.0 MB)
[INFO] 2019-01-19 13:30:03,999 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_7_piece0 in memory on 192.168.99.1:57904 (size: 12.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:30:04,000 org.apache.spark.SparkContext logInfo - Created broadcast 7 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:04,000 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:04,000 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 4.0 with 1 tasks
[INFO] 2019-01-19 13:30:04,000 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:30:04,001 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 3.0 (TID 202)
[INFO] 2019-01-19 13:30:04,004 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 13:30:04,005 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 4.0 (TID 203)
[INFO] 2019-01-19 13:30:04,013 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:04,013 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:04,043 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:30:04,062 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:30:04,102 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 13:30:04,246 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 3.0 (TID 202). 2009 bytes result sent to driver
[INFO] 2019-01-19 13:30:04,251 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 3.0 (TID 202) in 252 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:04,252 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:04,257 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 3 (head at DecoupJson.scala:139) finished in 0.266 s
[INFO] 2019-01-19 13:30:04,257 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:04,257 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 4)
[INFO] 2019-01-19 13:30:04,257 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, ResultStage 7)
[INFO] 2019-01-19 13:30:04,257 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:04,262 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 4.0 (TID 203). 2009 bytes result sent to driver
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 4.0 (TID 203) in 260 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 4 (head at DecoupJson.scala:139) finished in 0.262 s
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, ResultStage 7)
[INFO] 2019-01-19 13:30:04,263 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:04,264 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:30:04,306 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8 stored as values in memory (estimated size 276.8 KB, free 1990.7 MB)
[INFO] 2019-01-19 13:30:04,309 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8_piece0 stored as bytes in memory (estimated size 61.6 KB, free 1990.6 MB)
[INFO] 2019-01-19 13:30:04,310 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_8_piece0 in memory on 192.168.99.1:57904 (size: 61.6 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:30:04,310 org.apache.spark.SparkContext logInfo - Created broadcast 8 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:04,310 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:04,310 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 5.0 with 2 tasks
[INFO] 2019-01-19 13:30:04,312 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, ANY, 5898 bytes)
[INFO] 2019-01-19 13:30:04,313 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 5.0 (TID 205, localhost, executor driver, partition 1, ANY, 5898 bytes)
[INFO] 2019-01-19 13:30:04,313 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 5.0 (TID 205)
[INFO] 2019-01-19 13:30:04,313 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 5.0 (TID 204)
[INFO] 2019-01-19 13:30:04,339 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:04,340 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:04,357 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:04,357 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:04,426 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 74.017485 ms
[INFO] 2019-01-19 13:30:04,457 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 25.1088 ms
[INFO] 2019-01-19 13:30:04,483 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.011413 ms
[INFO] 2019-01-19 13:30:04,506 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.869947 ms
[INFO] 2019-01-19 13:30:04,542 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 28.249912 ms
[INFO] 2019-01-19 13:30:04,581 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 32.938308 ms
[INFO] 2019-01-19 13:30:04,606 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.548735 ms
[INFO] 2019-01-19 13:30:04,634 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.428867 ms
[INFO] 2019-01-19 13:30:04,657 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.490179 ms
[INFO] 2019-01-19 13:30:04,677 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.349418 ms
[INFO] 2019-01-19 13:30:04,694 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.890973 ms
[INFO] 2019-01-19 13:30:04,711 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.994664 ms
[INFO] 2019-01-19 13:30:04,731 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.552856 ms
[INFO] 2019-01-19 13:30:04,753 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.763435 ms
[INFO] 2019-01-19 13:30:04,778 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.840349 ms
[INFO] 2019-01-19 13:30:04,799 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.791291 ms
[INFO] 2019-01-19 13:30:04,821 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.232416 ms
[INFO] 2019-01-19 13:30:04,845 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.332559 ms
[INFO] 2019-01-19 13:30:04,865 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.187942 ms
[INFO] 2019-01-19 13:30:04,884 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.191446 ms
[INFO] 2019-01-19 13:30:04,903 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.353981 ms
[INFO] 2019-01-19 13:30:04,921 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.55213 ms
[INFO] 2019-01-19 13:30:04,937 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.354642 ms
[INFO] 2019-01-19 13:30:04,962 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.138663 ms
[INFO] 2019-01-19 13:30:04,982 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.303226 ms
[INFO] 2019-01-19 13:30:05,004 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.303623 ms
[INFO] 2019-01-19 13:30:05,030 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.513186 ms
[INFO] 2019-01-19 13:30:05,054 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.107633 ms
[INFO] 2019-01-19 13:30:05,076 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.569849 ms
[INFO] 2019-01-19 13:30:05,096 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.559205 ms
[INFO] 2019-01-19 13:30:05,116 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.191094 ms
[INFO] 2019-01-19 13:30:05,136 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.295821 ms
[INFO] 2019-01-19 13:30:05,161 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.556514 ms
[INFO] 2019-01-19 13:30:05,207 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 40.748423 ms
[INFO] 2019-01-19 13:30:05,227 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.563479 ms
[INFO] 2019-01-19 13:30:05,254 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.213462 ms
[INFO] 2019-01-19 13:30:05,274 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.864923 ms
[INFO] 2019-01-19 13:30:05,300 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.868228 ms
[INFO] 2019-01-19 13:30:05,337 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 31.021835 ms
[INFO] 2019-01-19 13:30:05,368 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.883059 ms
[INFO] 2019-01-19 13:30:05,404 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 32.384347 ms
[INFO] 2019-01-19 13:30:05,423 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.553562 ms
[INFO] 2019-01-19 13:30:05,445 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.153782 ms
[INFO] 2019-01-19 13:30:05,468 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.612536 ms
[INFO] 2019-01-19 13:30:05,490 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.067369 ms
[INFO] 2019-01-19 13:30:05,511 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.063843 ms
[INFO] 2019-01-19 13:30:05,533 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.285638 ms
[INFO] 2019-01-19 13:30:05,551 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.524317 ms
[INFO] 2019-01-19 13:30:05,571 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.440747 ms
[INFO] 2019-01-19 13:30:05,589 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.391689 ms
[INFO] 2019-01-19 13:30:05,606 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.520747 ms
[INFO] 2019-01-19 13:30:05,653 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 36.284644 ms
[INFO] 2019-01-19 13:30:05,677 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.551007 ms
[INFO] 2019-01-19 13:30:06,096 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 42.819342 ms
[INFO] 2019-01-19 13:30:06,422 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_7_piece0 on 192.168.99.1:57904 in memory (size: 12.3 KB, free: 1991.8 MB)
[INFO] 2019-01-19 13:30:06,426 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_6_piece0 on 192.168.99.1:57904 in memory (size: 12.3 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:30:06,430 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4937
[INFO] 2019-01-19 13:30:06,430 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4936
[INFO] 2019-01-19 13:30:06,431 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4935
[INFO] 2019-01-19 13:30:06,431 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4934
[INFO] 2019-01-19 13:30:06,434 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_3_piece0 on 192.168.99.1:57904 in memory (size: 10.5 KB, free: 1991.9 MB)
[INFO] 2019-01-19 13:30:06,561 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 147.457032 ms
[INFO] 2019-01-19 13:30:06,613 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.214544 ms
[INFO] 2019-01-19 13:30:06,764 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 80.302178 ms
[INFO] 2019-01-19 13:30:06,799 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.744768 ms
[INFO] 2019-01-19 13:30:06,818 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 12.205485 ms
[INFO] 2019-01-19 13:30:08,849 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 5.0 (TID 204). 3905 bytes result sent to driver
[INFO] 2019-01-19 13:30:08,851 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 5.0 (TID 204) in 4540 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:30:08,874 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 5.0 (TID 205). 3905 bytes result sent to driver
[INFO] 2019-01-19 13:30:08,874 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 5.0 (TID 205) in 4562 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:30:08,875 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:08,875 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 5 (head at DecoupJson.scala:139) finished in 4.565 s
[INFO] 2019-01-19 13:30:08,875 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:08,875 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:08,875 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 6, ResultStage 7)
[INFO] 2019-01-19 13:30:08,875 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:08,876 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 6 (MapPartitionsRDD[29] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:30:08,911 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9 stored as values in memory (estimated size 507.1 KB, free 1990.3 MB)
[INFO] 2019-01-19 13:30:08,914 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9_piece0 stored as bytes in memory (estimated size 126.8 KB, free 1990.1 MB)
[INFO] 2019-01-19 13:30:08,915 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_9_piece0 in memory on 192.168.99.1:57904 (size: 126.8 KB, free: 1991.7 MB)
[INFO] 2019-01-19 13:30:08,915 org.apache.spark.SparkContext logInfo - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:08,916 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[29] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:08,916 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 6.0 with 200 tasks
[INFO] 2019-01-19 13:30:08,918 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 6.0 (TID 206, localhost, executor driver, partition 0, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:08,919 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 6.0 (TID 207, localhost, executor driver, partition 1, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:08,919 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 6.0 (TID 206)
[INFO] 2019-01-19 13:30:08,920 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 6.0 (TID 207)
[INFO] 2019-01-19 13:30:08,948 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:08,948 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:08,949 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:08,949 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:09,267 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 130.210181 ms
[INFO] 2019-01-19 13:30:09,428 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 67.203515 ms
[INFO] 2019-01-19 13:30:09,580 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 102.888003 ms
[INFO] 2019-01-19 13:30:09,634 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 33.647421 ms
[INFO] 2019-01-19 13:30:09,711 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 54.249423 ms
[INFO] 2019-01-19 13:30:10,210 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 211.738762 ms
[INFO] 2019-01-19 13:30:10,368 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.043085 ms
[INFO] 2019-01-19 13:30:10,513 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 84.860459 ms
[INFO] 2019-01-19 13:30:10,588 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 53.375285 ms
[INFO] 2019-01-19 13:30:10,635 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 6.0 (TID 207). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:10,636 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 6.0 (TID 208, localhost, executor driver, partition 2, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:10,636 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 6.0 (TID 208)
[INFO] 2019-01-19 13:30:10,637 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 6.0 (TID 207) in 1719 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 13:30:10,642 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 6.0 (TID 206). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:10,643 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 6.0 (TID 209, localhost, executor driver, partition 3, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:10,643 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 6.0 (TID 206) in 1725 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 13:30:10,644 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 6.0 (TID 209)
[INFO] 2019-01-19 13:30:10,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:10,655 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:10,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:10,659 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:11,189 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 6.0 (TID 209). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:11,190 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 6.0 (TID 210, localhost, executor driver, partition 4, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:11,190 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 6.0 (TID 210)
[INFO] 2019-01-19 13:30:11,190 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 6.0 (TID 209) in 547 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 13:30:11,194 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 6.0 (TID 208). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:11,195 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 6.0 (TID 211, localhost, executor driver, partition 5, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:11,195 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 6.0 (TID 208) in 559 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 13:30:11,195 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 6.0 (TID 211)
[INFO] 2019-01-19 13:30:11,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:11,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:11,211 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:11,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:11,686 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 6.0 (TID 210). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:11,687 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 6.0 (TID 212, localhost, executor driver, partition 6, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:11,687 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 6.0 (TID 210) in 498 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 13:30:11,687 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 6.0 (TID 212)
[INFO] 2019-01-19 13:30:11,692 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 6.0 (TID 211). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:11,693 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 6.0 (TID 213, localhost, executor driver, partition 7, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:11,693 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 6.0 (TID 213)
[INFO] 2019-01-19 13:30:11,693 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 6.0 (TID 211) in 499 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 13:30:11,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:11,702 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:11,706 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:11,706 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:12,119 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 6.0 (TID 213). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:12,119 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 6.0 (TID 214, localhost, executor driver, partition 8, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:12,119 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 6.0 (TID 213) in 427 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 13:30:12,119 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 6.0 (TID 214)
[INFO] 2019-01-19 13:30:12,136 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:12,136 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:12,146 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 6.0 (TID 212). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:12,147 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 6.0 (TID 215, localhost, executor driver, partition 9, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:12,147 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 6.0 (TID 215)
[INFO] 2019-01-19 13:30:12,147 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 6.0 (TID 212) in 461 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 13:30:12,162 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:12,163 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:12,590 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 6.0 (TID 214). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:12,591 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 6.0 (TID 216, localhost, executor driver, partition 10, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:12,591 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 6.0 (TID 216)
[INFO] 2019-01-19 13:30:12,591 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 6.0 (TID 214) in 472 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 13:30:12,596 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 6.0 (TID 215). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:12,596 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 6.0 (TID 217, localhost, executor driver, partition 11, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:12,597 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 6.0 (TID 215) in 451 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 13:30:12,597 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 6.0 (TID 217)
[INFO] 2019-01-19 13:30:12,610 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:12,611 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 3 ms
[INFO] 2019-01-19 13:30:12,615 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:12,615 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:12,990 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 6.0 (TID 216). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:12,990 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 6.0 (TID 218, localhost, executor driver, partition 12, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:12,990 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 6.0 (TID 218)
[INFO] 2019-01-19 13:30:12,991 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 6.0 (TID 216) in 400 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 13:30:13,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:13,008 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:13,028 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 6.0 (TID 217). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:13,029 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 6.0 (TID 219, localhost, executor driver, partition 13, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:13,029 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 6.0 (TID 219)
[INFO] 2019-01-19 13:30:13,029 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 6.0 (TID 217) in 433 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 13:30:13,045 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:13,045 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:13,430 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 6.0 (TID 218). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:13,431 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 6.0 (TID 220, localhost, executor driver, partition 14, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:13,431 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 6.0 (TID 220)
[INFO] 2019-01-19 13:30:13,431 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 6.0 (TID 218) in 441 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 13:30:13,440 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 6.0 (TID 219). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:13,441 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 6.0 (TID 221, localhost, executor driver, partition 15, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:13,441 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 6.0 (TID 219) in 413 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 13:30:13,442 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 6.0 (TID 221)
[INFO] 2019-01-19 13:30:13,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:13,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:13,457 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:13,457 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:13,797 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 6.0 (TID 220). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:13,798 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 6.0 (TID 222, localhost, executor driver, partition 16, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:13,798 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 6.0 (TID 222)
[INFO] 2019-01-19 13:30:13,798 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 6.0 (TID 220) in 368 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 13:30:13,802 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 6.0 (TID 221). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:13,802 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 6.0 (TID 223, localhost, executor driver, partition 17, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:13,802 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 6.0 (TID 223)
[INFO] 2019-01-19 13:30:13,802 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 6.0 (TID 221) in 361 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 13:30:13,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:13,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:13,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:13,814 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:14,108 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 6.0 (TID 223). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:14,109 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 6.0 (TID 224, localhost, executor driver, partition 18, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:14,109 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 6.0 (TID 224)
[INFO] 2019-01-19 13:30:14,109 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 6.0 (TID 223) in 307 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 13:30:14,113 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 6.0 (TID 222). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:14,114 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 6.0 (TID 225, localhost, executor driver, partition 19, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:14,115 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 6.0 (TID 225)
[INFO] 2019-01-19 13:30:14,115 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 6.0 (TID 222) in 317 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 13:30:14,124 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:14,125 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:14,130 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:14,130 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:14,441 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 6.0 (TID 224). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:14,442 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 6.0 (TID 226, localhost, executor driver, partition 20, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:14,442 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 6.0 (TID 226)
[INFO] 2019-01-19 13:30:14,442 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 6.0 (TID 224) in 334 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 13:30:14,445 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 6.0 (TID 225). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:14,446 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 6.0 (TID 227, localhost, executor driver, partition 21, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:14,446 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 6.0 (TID 227)
[INFO] 2019-01-19 13:30:14,446 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 6.0 (TID 225) in 332 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 13:30:14,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:14,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:14,457 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:14,457 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:14,776 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 6.0 (TID 226). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:14,776 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 6.0 (TID 228, localhost, executor driver, partition 22, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:14,776 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 6.0 (TID 228)
[INFO] 2019-01-19 13:30:14,776 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 6.0 (TID 226) in 335 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 13:30:14,779 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 6.0 (TID 227). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:14,780 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 6.0 (TID 229, localhost, executor driver, partition 23, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:14,781 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 6.0 (TID 227) in 336 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 13:30:14,781 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 6.0 (TID 229)
[INFO] 2019-01-19 13:30:14,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:14,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:14,795 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:14,795 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:15,063 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 6.0 (TID 228). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,063 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 6.0 (TID 230, localhost, executor driver, partition 24, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,064 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 6.0 (TID 228) in 288 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 13:30:15,064 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 6.0 (TID 230)
[INFO] 2019-01-19 13:30:15,074 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 6.0 (TID 229). 4031 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,074 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 6.0 (TID 231, localhost, executor driver, partition 25, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,075 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 6.0 (TID 229) in 294 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 13:30:15,075 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 6.0 (TID 231)
[INFO] 2019-01-19 13:30:15,077 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,077 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:15,087 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,087 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:15,383 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 6.0 (TID 231). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,384 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 6.0 (TID 232, localhost, executor driver, partition 26, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,384 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 6.0 (TID 231) in 310 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 13:30:15,385 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 6.0 (TID 232)
[INFO] 2019-01-19 13:30:15,392 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 6.0 (TID 230). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,392 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 6.0 (TID 233, localhost, executor driver, partition 27, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,393 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 6.0 (TID 233)
[INFO] 2019-01-19 13:30:15,393 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 6.0 (TID 230) in 330 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 13:30:15,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:15,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,404 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:15,679 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 6.0 (TID 232). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,679 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 6.0 (TID 234, localhost, executor driver, partition 28, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,679 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 6.0 (TID 234)
[INFO] 2019-01-19 13:30:15,679 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 6.0 (TID 232) in 295 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 13:30:15,683 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 6.0 (TID 233). 4031 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 6.0 (TID 235, localhost, executor driver, partition 29, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,684 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 6.0 (TID 235)
[INFO] 2019-01-19 13:30:15,684 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 6.0 (TID 233) in 292 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 13:30:15,693 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,693 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:15,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,699 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:15,968 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 6.0 (TID 234). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,968 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 6.0 (TID 236, localhost, executor driver, partition 30, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,968 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 6.0 (TID 236)
[INFO] 2019-01-19 13:30:15,968 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 6.0 (TID 234) in 289 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 13:30:15,973 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 6.0 (TID 235). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:15,974 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 6.0 (TID 237, localhost, executor driver, partition 31, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:15,974 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 6.0 (TID 237)
[INFO] 2019-01-19 13:30:15,974 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 6.0 (TID 235) in 291 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 13:30:15,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:15,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:15,983 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:16,273 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 6.0 (TID 237). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:16,274 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 6.0 (TID 238, localhost, executor driver, partition 32, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:16,274 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 6.0 (TID 238)
[INFO] 2019-01-19 13:30:16,274 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 6.0 (TID 237) in 300 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 13:30:16,277 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 6.0 (TID 236). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:16,278 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 6.0 (TID 239, localhost, executor driver, partition 33, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:16,278 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 6.0 (TID 239)
[INFO] 2019-01-19 13:30:16,278 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 6.0 (TID 236) in 310 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 13:30:16,287 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:16,287 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:16,290 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:16,291 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:16,582 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 6.0 (TID 238). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:16,583 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 6.0 (TID 240, localhost, executor driver, partition 34, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:16,583 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 6.0 (TID 240)
[INFO] 2019-01-19 13:30:16,583 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 6.0 (TID 238) in 309 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 13:30:16,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:16,596 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:16,598 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 6.0 (TID 239). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:16,599 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 6.0 (TID 241, localhost, executor driver, partition 35, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:16,599 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 6.0 (TID 241)
[INFO] 2019-01-19 13:30:16,599 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 6.0 (TID 239) in 321 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 13:30:16,609 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:16,609 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:16,880 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 6.0 (TID 240). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:16,881 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 6.0 (TID 242, localhost, executor driver, partition 36, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:16,881 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 6.0 (TID 242)
[INFO] 2019-01-19 13:30:16,881 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 6.0 (TID 240) in 299 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 13:30:16,895 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:16,895 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:16,909 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 6.0 (TID 241). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:16,909 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 6.0 (TID 243, localhost, executor driver, partition 37, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:16,909 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 6.0 (TID 243)
[INFO] 2019-01-19 13:30:16,909 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 6.0 (TID 241) in 311 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 13:30:16,922 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:16,922 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:17,183 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 6.0 (TID 242). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:17,184 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 6.0 (TID 244, localhost, executor driver, partition 38, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:17,184 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 6.0 (TID 244)
[INFO] 2019-01-19 13:30:17,184 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 6.0 (TID 242) in 304 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 13:30:17,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:17,196 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:17,211 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 6.0 (TID 243). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:17,212 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 6.0 (TID 245, localhost, executor driver, partition 39, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:17,212 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 6.0 (TID 245)
[INFO] 2019-01-19 13:30:17,212 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 6.0 (TID 243) in 303 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 13:30:17,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:17,225 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:17,489 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 6.0 (TID 244). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:17,489 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 6.0 (TID 246, localhost, executor driver, partition 40, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:17,490 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 6.0 (TID 246)
[INFO] 2019-01-19 13:30:17,490 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 6.0 (TID 244) in 307 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 13:30:17,505 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:17,505 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:17,509 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 6.0 (TID 245). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:17,510 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 6.0 (TID 247, localhost, executor driver, partition 41, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:17,510 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 6.0 (TID 247)
[INFO] 2019-01-19 13:30:17,510 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 6.0 (TID 245) in 299 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 13:30:17,521 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:17,521 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:17,789 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 6.0 (TID 246). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:17,790 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 6.0 (TID 248, localhost, executor driver, partition 42, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:17,790 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 6.0 (TID 248)
[INFO] 2019-01-19 13:30:17,790 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 6.0 (TID 246) in 301 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 13:30:17,801 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:17,801 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:17,806 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 6.0 (TID 247). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:17,806 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 6.0 (TID 249, localhost, executor driver, partition 43, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:17,806 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 6.0 (TID 249)
[INFO] 2019-01-19 13:30:17,807 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 6.0 (TID 247) in 297 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 13:30:17,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:17,817 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:18,092 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 6.0 (TID 248). 4281 bytes result sent to driver
[INFO] 2019-01-19 13:30:18,092 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 6.0 (TID 250, localhost, executor driver, partition 44, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:18,093 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 6.0 (TID 250)
[INFO] 2019-01-19 13:30:18,093 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 6.0 (TID 248) in 303 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 13:30:18,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:18,106 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:18,113 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 6.0 (TID 249). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:18,113 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 6.0 (TID 251, localhost, executor driver, partition 45, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:18,114 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 6.0 (TID 251)
[INFO] 2019-01-19 13:30:18,114 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 6.0 (TID 249) in 308 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 13:30:18,129 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:18,130 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:18,400 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 6.0 (TID 250). 4031 bytes result sent to driver
[INFO] 2019-01-19 13:30:18,401 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 6.0 (TID 252, localhost, executor driver, partition 46, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:18,401 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 6.0 (TID 252)
[INFO] 2019-01-19 13:30:18,401 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 6.0 (TID 250) in 309 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 13:30:18,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:18,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:18,421 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 6.0 (TID 251). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:18,422 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 6.0 (TID 253, localhost, executor driver, partition 47, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:18,422 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 6.0 (TID 253)
[INFO] 2019-01-19 13:30:18,422 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 6.0 (TID 251) in 309 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 13:30:18,433 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:18,433 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:18,683 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 6.0 (TID 252). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:18,684 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 6.0 (TID 254, localhost, executor driver, partition 48, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:18,684 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 6.0 (TID 254)
[INFO] 2019-01-19 13:30:18,684 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 6.0 (TID 252) in 283 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 13:30:18,700 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:18,700 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:18,729 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 6.0 (TID 253). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:18,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 6.0 (TID 255, localhost, executor driver, partition 49, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:18,730 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 6.0 (TID 255)
[INFO] 2019-01-19 13:30:18,730 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 6.0 (TID 253) in 308 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 13:30:18,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:18,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:19,066 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 6.0 (TID 254). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:19,067 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 6.0 (TID 256, localhost, executor driver, partition 50, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:19,067 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 6.0 (TID 256)
[INFO] 2019-01-19 13:30:19,067 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 6.0 (TID 254) in 384 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 13:30:19,078 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:19,079 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:19,091 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 6.0 (TID 255). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:19,091 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 6.0 (TID 257, localhost, executor driver, partition 51, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:19,091 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 6.0 (TID 257)
[INFO] 2019-01-19 13:30:19,092 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 6.0 (TID 255) in 363 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 13:30:19,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:19,104 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:19,409 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 6.0 (TID 256). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:19,409 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 6.0 (TID 258, localhost, executor driver, partition 52, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:19,409 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 6.0 (TID 258)
[INFO] 2019-01-19 13:30:19,409 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 6.0 (TID 256) in 343 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 13:30:19,421 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 6.0 (TID 257). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:19,422 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 6.0 (TID 259, localhost, executor driver, partition 53, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:19,422 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:19,422 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:19,422 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 6.0 (TID 259)
[INFO] 2019-01-19 13:30:19,422 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 6.0 (TID 257) in 331 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 13:30:19,435 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:19,435 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:19,719 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 6.0 (TID 258). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:19,720 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 6.0 (TID 260, localhost, executor driver, partition 54, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:19,720 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 6.0 (TID 260)
[INFO] 2019-01-19 13:30:19,720 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 6.0 (TID 258) in 311 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 13:30:19,730 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 6.0 (TID 259). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:19,731 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 6.0 (TID 261, localhost, executor driver, partition 55, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:19,731 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 6.0 (TID 261)
[INFO] 2019-01-19 13:30:19,731 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 6.0 (TID 259) in 310 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 13:30:19,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:19,731 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:19,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:19,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:20,008 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 6.0 (TID 260). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,008 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 6.0 (TID 262, localhost, executor driver, partition 56, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,008 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 6.0 (TID 262)
[INFO] 2019-01-19 13:30:20,009 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 6.0 (TID 260) in 289 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 13:30:20,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,024 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 6.0 (TID 261). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,024 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:20,024 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 6.0 (TID 263, localhost, executor driver, partition 57, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,025 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 6.0 (TID 263)
[INFO] 2019-01-19 13:30:20,025 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 6.0 (TID 261) in 295 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 13:30:20,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,034 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:20,309 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 6.0 (TID 262). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,310 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 6.0 (TID 264, localhost, executor driver, partition 58, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,310 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 6.0 (TID 262) in 302 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 13:30:20,311 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 6.0 (TID 264)
[INFO] 2019-01-19 13:30:20,327 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,327 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:20,330 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 6.0 (TID 263). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,330 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 6.0 (TID 265, localhost, executor driver, partition 59, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,331 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 6.0 (TID 265)
[INFO] 2019-01-19 13:30:20,331 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 6.0 (TID 263) in 307 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 13:30:20,342 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,342 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:20,611 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 6.0 (TID 264). 4191 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,611 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 6.0 (TID 266, localhost, executor driver, partition 60, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,612 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 6.0 (TID 266)
[INFO] 2019-01-19 13:30:20,612 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 6.0 (TID 264) in 302 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 13:30:20,619 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 6.0 (TID 265). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,620 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 6.0 (TID 267, localhost, executor driver, partition 61, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,620 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 6.0 (TID 267)
[INFO] 2019-01-19 13:30:20,620 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 6.0 (TID 265) in 290 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 13:30:20,624 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,624 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:20,633 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,633 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:20,899 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 6.0 (TID 266). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,900 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 6.0 (TID 268, localhost, executor driver, partition 62, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,900 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 6.0 (TID 268)
[INFO] 2019-01-19 13:30:20,900 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 6.0 (TID 266) in 289 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 13:30:20,916 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:20,919 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 6.0 (TID 267). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:20,920 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 6.0 (TID 269, localhost, executor driver, partition 63, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:20,920 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 6.0 (TID 269)
[INFO] 2019-01-19 13:30:20,920 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 6.0 (TID 267) in 300 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 13:30:20,933 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:20,933 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:21,190 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 6.0 (TID 268). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:21,190 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 6.0 (TID 270, localhost, executor driver, partition 64, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:21,191 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 6.0 (TID 270)
[INFO] 2019-01-19 13:30:21,191 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 6.0 (TID 268) in 291 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 13:30:21,202 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:21,202 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:21,210 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 6.0 (TID 269). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:21,210 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 6.0 (TID 271, localhost, executor driver, partition 65, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:21,211 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 6.0 (TID 269) in 292 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 13:30:21,211 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 6.0 (TID 271)
[INFO] 2019-01-19 13:30:21,220 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:21,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:21,494 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 6.0 (TID 270). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:21,495 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 6.0 (TID 272, localhost, executor driver, partition 66, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:21,495 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 6.0 (TID 272)
[INFO] 2019-01-19 13:30:21,495 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 6.0 (TID 270) in 305 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 13:30:21,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:21,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:21,508 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 6.0 (TID 271). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:21,508 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 6.0 (TID 273, localhost, executor driver, partition 67, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:21,508 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 6.0 (TID 273)
[INFO] 2019-01-19 13:30:21,508 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 6.0 (TID 271) in 298 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 13:30:21,521 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:21,521 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:21,813 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 6.0 (TID 272). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:21,814 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 6.0 (TID 274, localhost, executor driver, partition 68, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:21,814 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 6.0 (TID 274)
[INFO] 2019-01-19 13:30:21,814 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 6.0 (TID 272) in 319 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 13:30:21,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:21,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:21,829 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 6.0 (TID 273). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:21,829 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 6.0 (TID 275, localhost, executor driver, partition 69, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:21,830 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 6.0 (TID 275)
[INFO] 2019-01-19 13:30:21,830 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 6.0 (TID 273) in 322 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 13:30:21,841 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:21,842 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:22,126 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 6.0 (TID 274). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:22,127 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 6.0 (TID 276, localhost, executor driver, partition 70, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:22,127 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 6.0 (TID 276)
[INFO] 2019-01-19 13:30:22,127 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 6.0 (TID 274) in 313 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 13:30:22,136 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 6.0 (TID 275). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:22,137 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 6.0 (TID 277, localhost, executor driver, partition 71, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:22,137 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 6.0 (TID 277)
[INFO] 2019-01-19 13:30:22,137 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 6.0 (TID 275) in 308 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 13:30:22,139 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:22,139 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:22,147 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:22,147 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:22,431 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 6.0 (TID 276). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:22,432 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 6.0 (TID 278, localhost, executor driver, partition 72, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:22,432 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 6.0 (TID 278)
[INFO] 2019-01-19 13:30:22,432 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 6.0 (TID 276) in 305 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 13:30:22,440 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 6.0 (TID 277). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:22,440 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 6.0 (TID 279, localhost, executor driver, partition 73, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:22,440 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 6.0 (TID 279)
[INFO] 2019-01-19 13:30:22,441 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 6.0 (TID 277) in 304 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 13:30:22,445 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:22,445 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:22,452 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:22,452 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:22,728 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 6.0 (TID 279). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:22,729 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 6.0 (TID 280, localhost, executor driver, partition 74, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:22,729 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 6.0 (TID 280)
[INFO] 2019-01-19 13:30:22,729 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 6.0 (TID 279) in 289 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 13:30:22,733 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 6.0 (TID 278). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:22,733 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 6.0 (TID 281, localhost, executor driver, partition 75, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:22,734 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 6.0 (TID 281)
[INFO] 2019-01-19 13:30:22,734 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 6.0 (TID 278) in 303 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 13:30:22,742 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:22,742 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:22,747 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:22,748 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:23,023 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 6.0 (TID 280). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,023 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 6.0 (TID 282, localhost, executor driver, partition 76, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,024 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 6.0 (TID 282)
[INFO] 2019-01-19 13:30:23,024 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 6.0 (TID 280) in 295 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 13:30:23,032 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 6.0 (TID 281). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,033 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 6.0 (TID 283, localhost, executor driver, partition 77, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,033 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 6.0 (TID 283)
[INFO] 2019-01-19 13:30:23,033 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 6.0 (TID 281) in 300 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 13:30:23,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,035 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:23,045 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,046 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:23,326 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 6.0 (TID 282). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,326 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 6.0 (TID 284, localhost, executor driver, partition 78, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,327 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 6.0 (TID 284)
[INFO] 2019-01-19 13:30:23,327 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 6.0 (TID 282) in 304 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 13:30:23,338 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,338 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:23,340 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 6.0 (TID 283). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,340 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 6.0 (TID 285, localhost, executor driver, partition 79, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,340 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 6.0 (TID 285)
[INFO] 2019-01-19 13:30:23,340 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 6.0 (TID 283) in 308 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 13:30:23,350 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,350 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:23,613 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 6.0 (TID 284). 4031 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,613 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 6.0 (TID 286, localhost, executor driver, partition 80, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,613 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 6.0 (TID 286)
[INFO] 2019-01-19 13:30:23,613 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 6.0 (TID 284) in 287 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 13:30:23,625 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 6.0 (TID 285). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,625 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 6.0 (TID 287, localhost, executor driver, partition 81, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,625 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,625 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 6.0 (TID 285) in 285 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 13:30:23,625 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 6.0 (TID 287)
[INFO] 2019-01-19 13:30:23,625 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:23,637 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,637 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:23,899 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 6.0 (TID 286). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,901 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 6.0 (TID 288, localhost, executor driver, partition 82, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,901 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 6.0 (TID 288)
[INFO] 2019-01-19 13:30:23,901 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 6.0 (TID 286) in 288 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 13:30:23,913 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,913 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:23,925 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 6.0 (TID 287). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:23,925 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 6.0 (TID 289, localhost, executor driver, partition 83, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:23,925 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 6.0 (TID 289)
[INFO] 2019-01-19 13:30:23,925 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 6.0 (TID 287) in 300 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 13:30:23,935 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:23,935 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:24,204 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 6.0 (TID 288). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:24,205 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 6.0 (TID 290, localhost, executor driver, partition 84, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:24,205 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 6.0 (TID 290)
[INFO] 2019-01-19 13:30:24,205 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 6.0 (TID 288) in 305 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 13:30:24,216 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 6.0 (TID 289). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:24,216 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 6.0 (TID 291, localhost, executor driver, partition 85, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:24,216 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 6.0 (TID 291)
[INFO] 2019-01-19 13:30:24,216 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 6.0 (TID 289) in 291 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 13:30:24,220 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:24,220 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:24,228 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:24,228 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:24,506 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 6.0 (TID 290). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:24,506 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 6.0 (TID 292, localhost, executor driver, partition 86, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:24,507 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 6.0 (TID 292)
[INFO] 2019-01-19 13:30:24,507 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 6.0 (TID 290) in 302 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 13:30:24,518 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 6.0 (TID 291). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:24,518 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 6.0 (TID 293, localhost, executor driver, partition 87, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:24,518 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 6.0 (TID 293)
[INFO] 2019-01-19 13:30:24,518 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 6.0 (TID 291) in 302 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 13:30:24,520 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:24,520 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:24,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:24,530 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:24,822 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 6.0 (TID 292). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:24,822 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 6.0 (TID 294, localhost, executor driver, partition 88, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:24,822 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 6.0 (TID 294)
[INFO] 2019-01-19 13:30:24,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 6.0 (TID 292) in 316 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 13:30:24,834 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:24,834 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:24,837 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 6.0 (TID 293). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:24,838 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 6.0 (TID 295, localhost, executor driver, partition 89, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:24,838 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 6.0 (TID 295)
[INFO] 2019-01-19 13:30:24,838 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 6.0 (TID 293) in 320 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 13:30:24,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:24,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:25,123 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 6.0 (TID 294). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:25,123 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 6.0 (TID 296, localhost, executor driver, partition 90, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:25,123 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 6.0 (TID 296)
[INFO] 2019-01-19 13:30:25,123 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 6.0 (TID 294) in 301 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 13:30:25,134 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:25,134 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:25,138 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 6.0 (TID 295). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:25,138 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 6.0 (TID 297, localhost, executor driver, partition 91, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:25,138 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 6.0 (TID 297)
[INFO] 2019-01-19 13:30:25,138 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 6.0 (TID 295) in 301 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 13:30:25,150 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:25,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:25,434 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 6.0 (TID 296). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:25,435 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 6.0 (TID 298, localhost, executor driver, partition 92, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:25,435 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 6.0 (TID 298)
[INFO] 2019-01-19 13:30:25,435 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 6.0 (TID 296) in 312 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 13:30:25,439 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 6.0 (TID 297). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:25,440 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 6.0 (TID 299, localhost, executor driver, partition 93, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:25,440 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 6.0 (TID 297) in 302 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 13:30:25,440 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 6.0 (TID 299)
[INFO] 2019-01-19 13:30:25,445 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:25,446 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:25,452 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:25,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:25,744 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 6.0 (TID 298). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:25,745 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 6.0 (TID 300, localhost, executor driver, partition 94, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:25,745 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 6.0 (TID 300)
[INFO] 2019-01-19 13:30:25,745 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 6.0 (TID 298) in 310 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 13:30:25,756 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 6.0 (TID 299). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:25,757 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 6.0 (TID 301, localhost, executor driver, partition 95, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:25,757 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 6.0 (TID 301)
[INFO] 2019-01-19 13:30:25,757 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 6.0 (TID 299) in 317 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 13:30:25,761 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:25,761 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:25,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:25,772 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:26,071 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 6.0 (TID 300). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:26,072 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 6.0 (TID 302, localhost, executor driver, partition 96, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:26,072 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 6.0 (TID 302)
[INFO] 2019-01-19 13:30:26,072 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 6.0 (TID 300) in 327 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 13:30:26,081 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 6.0 (TID 301). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:26,081 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 6.0 (TID 303, localhost, executor driver, partition 97, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:26,081 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 6.0 (TID 303)
[INFO] 2019-01-19 13:30:26,082 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 6.0 (TID 301) in 324 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 13:30:26,087 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:26,087 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:26,092 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:26,092 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:26,385 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 6.0 (TID 303). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:26,385 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 6.0 (TID 304, localhost, executor driver, partition 98, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:26,385 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 6.0 (TID 304)
[INFO] 2019-01-19 13:30:26,385 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 6.0 (TID 303) in 304 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 13:30:26,389 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 6.0 (TID 302). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:26,390 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 6.0 (TID 305, localhost, executor driver, partition 99, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:26,390 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 6.0 (TID 305)
[INFO] 2019-01-19 13:30:26,390 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 6.0 (TID 302) in 318 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 13:30:26,398 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:26,398 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:26,404 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:26,405 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:26,715 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 6.0 (TID 305). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:26,715 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 6.0 (TID 306, localhost, executor driver, partition 100, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:26,716 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 6.0 (TID 305) in 327 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 13:30:26,716 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 6.0 (TID 306)
[INFO] 2019-01-19 13:30:26,720 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 6.0 (TID 304). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:26,720 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 6.0 (TID 307, localhost, executor driver, partition 101, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:26,721 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 6.0 (TID 307)
[INFO] 2019-01-19 13:30:26,721 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 6.0 (TID 304) in 336 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 13:30:26,728 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:26,728 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:26,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:26,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:27,033 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 6.0 (TID 306). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:27,034 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 6.0 (TID 308, localhost, executor driver, partition 102, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:27,034 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 6.0 (TID 308)
[INFO] 2019-01-19 13:30:27,034 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 6.0 (TID 306) in 319 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 13:30:27,038 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 6.0 (TID 307). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:27,039 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 6.0 (TID 309, localhost, executor driver, partition 103, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:27,039 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 6.0 (TID 309)
[INFO] 2019-01-19 13:30:27,039 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 6.0 (TID 307) in 319 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 13:30:27,044 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:27,044 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:27,050 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:27,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:27,361 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 6.0 (TID 308). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:27,362 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 6.0 (TID 310, localhost, executor driver, partition 104, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:27,362 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 6.0 (TID 310)
[INFO] 2019-01-19 13:30:27,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 6.0 (TID 308) in 328 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 13:30:27,368 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 6.0 (TID 309). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:27,368 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 6.0 (TID 311, localhost, executor driver, partition 105, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:27,369 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 6.0 (TID 311)
[INFO] 2019-01-19 13:30:27,369 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 6.0 (TID 309) in 330 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 13:30:27,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:27,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:27,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:27,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:27,688 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 6.0 (TID 310). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:27,689 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 6.0 (TID 312, localhost, executor driver, partition 106, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:27,689 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 6.0 (TID 312)
[INFO] 2019-01-19 13:30:27,689 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 6.0 (TID 310) in 328 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 13:30:27,698 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 6.0 (TID 311). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:27,699 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 6.0 (TID 313, localhost, executor driver, partition 107, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:27,699 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 6.0 (TID 313)
[INFO] 2019-01-19 13:30:27,699 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 6.0 (TID 311) in 331 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 13:30:27,703 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:27,703 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:27,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:27,713 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:28,029 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 6.0 (TID 312). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,030 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 6.0 (TID 314, localhost, executor driver, partition 108, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,030 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 6.0 (TID 314)
[INFO] 2019-01-19 13:30:28,030 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 6.0 (TID 312) in 341 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 13:30:28,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:28,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:28,042 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 6.0 (TID 313). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,043 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 6.0 (TID 315, localhost, executor driver, partition 109, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,043 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 6.0 (TID 315)
[INFO] 2019-01-19 13:30:28,043 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 6.0 (TID 313) in 344 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 13:30:28,053 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:28,053 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:28,345 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 6.0 (TID 314). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,346 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 6.0 (TID 316, localhost, executor driver, partition 110, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,346 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 6.0 (TID 316)
[INFO] 2019-01-19 13:30:28,346 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 6.0 (TID 314) in 316 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 13:30:28,355 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:28,355 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:28,374 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 6.0 (TID 315). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,375 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 6.0 (TID 317, localhost, executor driver, partition 111, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,375 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 6.0 (TID 317)
[INFO] 2019-01-19 13:30:28,375 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 6.0 (TID 315) in 333 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 13:30:28,386 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:28,386 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:28,682 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 6.0 (TID 316). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,682 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 6.0 (TID 318, localhost, executor driver, partition 112, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,683 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 6.0 (TID 318)
[INFO] 2019-01-19 13:30:28,683 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 6.0 (TID 316) in 338 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 13:30:28,694 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:28,695 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:28,712 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 6.0 (TID 317). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,712 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 6.0 (TID 319, localhost, executor driver, partition 113, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,713 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 6.0 (TID 319)
[INFO] 2019-01-19 13:30:28,713 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 6.0 (TID 317) in 339 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 13:30:28,723 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:28,723 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:28,985 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 6.0 (TID 318). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:28,985 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 6.0 (TID 320, localhost, executor driver, partition 114, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:28,986 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 6.0 (TID 320)
[INFO] 2019-01-19 13:30:28,986 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 6.0 (TID 318) in 304 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 13:30:29,001 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,001 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:29,020 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 6.0 (TID 319). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,021 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 6.0 (TID 321, localhost, executor driver, partition 115, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,021 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 6.0 (TID 321)
[INFO] 2019-01-19 13:30:29,021 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 6.0 (TID 319) in 309 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 13:30:29,036 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,037 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:29,294 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 6.0 (TID 320). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,295 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 6.0 (TID 322, localhost, executor driver, partition 116, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,295 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 6.0 (TID 322)
[INFO] 2019-01-19 13:30:29,295 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 6.0 (TID 320) in 310 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 13:30:29,309 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,309 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:29,353 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 6.0 (TID 321). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,354 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 6.0 (TID 323, localhost, executor driver, partition 117, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,354 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 6.0 (TID 323)
[INFO] 2019-01-19 13:30:29,354 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 6.0 (TID 321) in 333 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 13:30:29,367 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,367 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:29,620 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 6.0 (TID 322). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,621 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 6.0 (TID 324, localhost, executor driver, partition 118, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,621 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 6.0 (TID 324)
[INFO] 2019-01-19 13:30:29,621 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 6.0 (TID 322) in 326 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 13:30:29,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:29,673 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 6.0 (TID 323). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,673 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 6.0 (TID 325, localhost, executor driver, partition 119, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,673 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 6.0 (TID 325)
[INFO] 2019-01-19 13:30:29,673 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 6.0 (TID 323) in 320 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 13:30:29,683 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,683 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:29,926 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 6.0 (TID 324). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,926 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 6.0 (TID 326, localhost, executor driver, partition 120, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,926 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 6.0 (TID 326)
[INFO] 2019-01-19 13:30:29,926 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 6.0 (TID 324) in 305 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 13:30:29,936 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,936 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:29,968 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 6.0 (TID 325). 4118 bytes result sent to driver
[INFO] 2019-01-19 13:30:29,968 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 6.0 (TID 327, localhost, executor driver, partition 121, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:29,968 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 6.0 (TID 327)
[INFO] 2019-01-19 13:30:29,968 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 6.0 (TID 325) in 295 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 13:30:29,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:29,979 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:30,226 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 6.0 (TID 326). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:30,226 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 6.0 (TID 328, localhost, executor driver, partition 122, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:30,227 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 6.0 (TID 326) in 300 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 13:30:30,227 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 6.0 (TID 328)
[INFO] 2019-01-19 13:30:30,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:30,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:30,269 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 6.0 (TID 327). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:30,269 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 6.0 (TID 329, localhost, executor driver, partition 123, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:30,270 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 6.0 (TID 329)
[INFO] 2019-01-19 13:30:30,270 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 6.0 (TID 327) in 302 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 13:30:30,279 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:30,279 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:30,537 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 6.0 (TID 328). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:30,537 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 6.0 (TID 330, localhost, executor driver, partition 124, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:30,538 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 6.0 (TID 330)
[INFO] 2019-01-19 13:30:30,538 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 6.0 (TID 328) in 312 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 13:30:30,547 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:30,547 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:30,576 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 6.0 (TID 329). 4031 bytes result sent to driver
[INFO] 2019-01-19 13:30:30,576 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 6.0 (TID 331, localhost, executor driver, partition 125, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:30,577 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 6.0 (TID 331)
[INFO] 2019-01-19 13:30:30,577 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 6.0 (TID 329) in 308 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 13:30:30,591 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:30,591 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:30,861 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 6.0 (TID 330). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:30,862 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 6.0 (TID 332, localhost, executor driver, partition 126, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:30,862 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 6.0 (TID 332)
[INFO] 2019-01-19 13:30:30,862 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 6.0 (TID 330) in 325 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 13:30:30,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:30,877 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:30,902 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 6.0 (TID 331). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:30,902 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 6.0 (TID 333, localhost, executor driver, partition 127, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:30,903 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 6.0 (TID 333)
[INFO] 2019-01-19 13:30:30,903 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 6.0 (TID 331) in 327 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 13:30:30,914 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:30,914 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:31,191 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 6.0 (TID 332). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:31,192 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 6.0 (TID 334, localhost, executor driver, partition 128, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:31,192 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 6.0 (TID 334)
[INFO] 2019-01-19 13:30:31,192 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 6.0 (TID 332) in 331 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 13:30:31,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:31,207 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:31,232 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 6.0 (TID 333). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:31,232 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 6.0 (TID 335, localhost, executor driver, partition 129, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:31,233 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 6.0 (TID 335)
[INFO] 2019-01-19 13:30:31,233 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 6.0 (TID 333) in 331 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 13:30:31,243 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:31,243 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:31,523 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 6.0 (TID 334). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:31,524 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 6.0 (TID 336, localhost, executor driver, partition 130, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:31,524 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 6.0 (TID 336)
[INFO] 2019-01-19 13:30:31,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 6.0 (TID 334) in 332 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 13:30:31,537 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:31,537 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:31,550 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 6.0 (TID 335). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:31,550 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 6.0 (TID 337, localhost, executor driver, partition 131, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:31,550 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 6.0 (TID 337)
[INFO] 2019-01-19 13:30:31,550 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 6.0 (TID 335) in 318 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 13:30:31,562 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:31,562 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:31,866 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 6.0 (TID 336). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:31,866 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 6.0 (TID 338, localhost, executor driver, partition 132, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:31,866 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 6.0 (TID 338)
[INFO] 2019-01-19 13:30:31,866 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 6.0 (TID 336) in 343 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 13:30:31,881 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:31,881 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:31,885 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 6.0 (TID 337). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:31,885 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 6.0 (TID 339, localhost, executor driver, partition 133, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:31,886 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 6.0 (TID 339)
[INFO] 2019-01-19 13:30:31,886 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 6.0 (TID 337) in 336 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 13:30:31,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:31,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:32,176 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 6.0 (TID 338). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:32,177 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 6.0 (TID 340, localhost, executor driver, partition 134, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:32,177 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 6.0 (TID 340)
[INFO] 2019-01-19 13:30:32,177 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 6.0 (TID 338) in 311 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 13:30:32,190 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:32,190 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:32,191 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 6.0 (TID 339). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:32,192 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 6.0 (TID 341, localhost, executor driver, partition 135, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:32,192 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 6.0 (TID 341)
[INFO] 2019-01-19 13:30:32,192 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 6.0 (TID 339) in 307 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 13:30:32,201 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:32,201 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:32,495 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 6.0 (TID 340). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:32,496 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 6.0 (TID 342, localhost, executor driver, partition 136, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:32,496 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 6.0 (TID 342)
[INFO] 2019-01-19 13:30:32,496 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 6.0 (TID 340) in 319 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 13:30:32,510 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:32,510 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:32,510 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 6.0 (TID 341). 4031 bytes result sent to driver
[INFO] 2019-01-19 13:30:32,511 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 6.0 (TID 343, localhost, executor driver, partition 137, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:32,511 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 6.0 (TID 343)
[INFO] 2019-01-19 13:30:32,511 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 6.0 (TID 341) in 320 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 13:30:32,525 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:32,525 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:32,807 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 6.0 (TID 342). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:32,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 6.0 (TID 344, localhost, executor driver, partition 138, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:32,808 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 6.0 (TID 344)
[INFO] 2019-01-19 13:30:32,808 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 6.0 (TID 342) in 313 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 13:30:32,820 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:32,820 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:32,821 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 6.0 (TID 343). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:32,822 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 6.0 (TID 345, localhost, executor driver, partition 139, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:32,822 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 6.0 (TID 345)
[INFO] 2019-01-19 13:30:32,822 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 6.0 (TID 343) in 312 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 13:30:32,834 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:32,834 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:33,138 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 6.0 (TID 344). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:33,138 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 6.0 (TID 346, localhost, executor driver, partition 140, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:33,139 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 6.0 (TID 346)
[INFO] 2019-01-19 13:30:33,139 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 6.0 (TID 344) in 331 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 13:30:33,143 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 6.0 (TID 345). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:33,143 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 6.0 (TID 347, localhost, executor driver, partition 141, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:33,143 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 6.0 (TID 347)
[INFO] 2019-01-19 13:30:33,143 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 6.0 (TID 345) in 321 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 13:30:33,154 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:33,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:33,160 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:33,160 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:33,523 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 6.0 (TID 346). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:33,523 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 6.0 (TID 348, localhost, executor driver, partition 142, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:33,523 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 6.0 (TID 348)
[INFO] 2019-01-19 13:30:33,523 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 6.0 (TID 346) in 385 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 13:30:33,528 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 6.0 (TID 347). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:33,529 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 6.0 (TID 349, localhost, executor driver, partition 143, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:33,529 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 6.0 (TID 349)
[INFO] 2019-01-19 13:30:33,529 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 6.0 (TID 347) in 386 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 13:30:33,539 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:33,539 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:33,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:33,542 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:33,836 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 6.0 (TID 348). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:33,837 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 6.0 (TID 350, localhost, executor driver, partition 144, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:33,837 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 6.0 (TID 350)
[INFO] 2019-01-19 13:30:33,837 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 6.0 (TID 348) in 314 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 13:30:33,851 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:33,851 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:33,853 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 6.0 (TID 349). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:33,853 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 6.0 (TID 351, localhost, executor driver, partition 145, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:33,853 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 6.0 (TID 351)
[INFO] 2019-01-19 13:30:33,854 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 6.0 (TID 349) in 325 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 13:30:33,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:33,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:34,141 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 6.0 (TID 350). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:34,141 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 6.0 (TID 352, localhost, executor driver, partition 146, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:34,141 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 6.0 (TID 352)
[INFO] 2019-01-19 13:30:34,142 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 6.0 (TID 350) in 306 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 13:30:34,157 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:34,157 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:34,158 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 6.0 (TID 351). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:34,159 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 6.0 (TID 353, localhost, executor driver, partition 147, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:34,159 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 6.0 (TID 353)
[INFO] 2019-01-19 13:30:34,159 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 6.0 (TID 351) in 306 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 13:30:34,171 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:34,171 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:34,456 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 6.0 (TID 352). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:34,457 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 6.0 (TID 354, localhost, executor driver, partition 148, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:34,457 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 6.0 (TID 354)
[INFO] 2019-01-19 13:30:34,457 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 6.0 (TID 352) in 316 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 13:30:34,470 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 6.0 (TID 353). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:34,470 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 6.0 (TID 355, localhost, executor driver, partition 149, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:34,470 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 6.0 (TID 355)
[INFO] 2019-01-19 13:30:34,470 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 6.0 (TID 353) in 312 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 13:30:34,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:34,472 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:34,482 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:34,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:34,772 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 6.0 (TID 354). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:34,772 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 6.0 (TID 356, localhost, executor driver, partition 150, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:34,773 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 6.0 (TID 356)
[INFO] 2019-01-19 13:30:34,773 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 6.0 (TID 354) in 317 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 13:30:34,781 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 6.0 (TID 355). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:34,781 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 6.0 (TID 357, localhost, executor driver, partition 151, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:34,781 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 6.0 (TID 357)
[INFO] 2019-01-19 13:30:34,782 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 6.0 (TID 355) in 311 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 13:30:34,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:34,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:34,794 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:34,794 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:35,079 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 6.0 (TID 356). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:35,080 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 6.0 (TID 358, localhost, executor driver, partition 152, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:35,080 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 6.0 (TID 358)
[INFO] 2019-01-19 13:30:35,081 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 6.0 (TID 356) in 308 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 13:30:35,093 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 6.0 (TID 357). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:35,093 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 6.0 (TID 359, localhost, executor driver, partition 153, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:35,094 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 6.0 (TID 359)
[INFO] 2019-01-19 13:30:35,094 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 6.0 (TID 357) in 313 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 13:30:35,095 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:35,096 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:35,108 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:35,108 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:35,410 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 6.0 (TID 358). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:35,412 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 6.0 (TID 360, localhost, executor driver, partition 154, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:35,413 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 6.0 (TID 358) in 334 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 13:30:35,413 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 6.0 (TID 360)
[INFO] 2019-01-19 13:30:35,418 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 6.0 (TID 359). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:35,419 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 6.0 (TID 361, localhost, executor driver, partition 155, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:35,419 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 6.0 (TID 359) in 326 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 13:30:35,420 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 6.0 (TID 361)
[INFO] 2019-01-19 13:30:35,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:35,429 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:35,433 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:35,433 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:35,720 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 6.0 (TID 360). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:35,721 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 6.0 (TID 362, localhost, executor driver, partition 156, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:35,721 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 6.0 (TID 362)
[INFO] 2019-01-19 13:30:35,721 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 6.0 (TID 360) in 310 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 13:30:35,735 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 6.0 (TID 361). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:35,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:35,735 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 6.0 (TID 363, localhost, executor driver, partition 157, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:35,735 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:35,735 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 6.0 (TID 363)
[INFO] 2019-01-19 13:30:35,735 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 6.0 (TID 361) in 317 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 13:30:35,749 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:35,749 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,019 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 6.0 (TID 362). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,020 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 6.0 (TID 364, localhost, executor driver, partition 158, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,020 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 6.0 (TID 364)
[INFO] 2019-01-19 13:30:36,020 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 6.0 (TID 362) in 299 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 13:30:36,032 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 6.0 (TID 363). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,032 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 6.0 (TID 365, localhost, executor driver, partition 159, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,032 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 6.0 (TID 365)
[INFO] 2019-01-19 13:30:36,032 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 6.0 (TID 363) in 297 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 13:30:36,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,041 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,332 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 6.0 (TID 364). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,333 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 6.0 (TID 366, localhost, executor driver, partition 160, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,333 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 6.0 (TID 366)
[INFO] 2019-01-19 13:30:36,333 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 6.0 (TID 364) in 314 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 13:30:36,336 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 6.0 (TID 365). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,337 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 6.0 (TID 367, localhost, executor driver, partition 161, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,337 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 6.0 (TID 367)
[INFO] 2019-01-19 13:30:36,337 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 6.0 (TID 365) in 305 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 13:30:36,342 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,342 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,645 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 6.0 (TID 366). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,646 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 6.0 (TID 368, localhost, executor driver, partition 162, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,646 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 6.0 (TID 368)
[INFO] 2019-01-19 13:30:36,646 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 6.0 (TID 366) in 313 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 13:30:36,656 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 6.0 (TID 367). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,656 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 6.0 (TID 369, localhost, executor driver, partition 163, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,657 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 6.0 (TID 367) in 321 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 13:30:36,657 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 6.0 (TID 369)
[INFO] 2019-01-19 13:30:36,661 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,661 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,671 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,671 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,965 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 6.0 (TID 368). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,965 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 6.0 (TID 370, localhost, executor driver, partition 164, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,965 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 6.0 (TID 370)
[INFO] 2019-01-19 13:30:36,966 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 6.0 (TID 368) in 319 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 13:30:36,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:36,978 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:36,989 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 6.0 (TID 369). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:36,990 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 6.0 (TID 371, localhost, executor driver, partition 165, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:36,990 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 6.0 (TID 371)
[INFO] 2019-01-19 13:30:36,990 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 6.0 (TID 369) in 334 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 13:30:37,003 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,003 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:37,264 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 6.0 (TID 370). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:37,264 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 6.0 (TID 372, localhost, executor driver, partition 166, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:37,265 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 6.0 (TID 372)
[INFO] 2019-01-19 13:30:37,265 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 6.0 (TID 370) in 300 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 13:30:37,280 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,280 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:37,289 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 6.0 (TID 371). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:37,290 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 6.0 (TID 373, localhost, executor driver, partition 167, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:37,290 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 6.0 (TID 373)
[INFO] 2019-01-19 13:30:37,290 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 6.0 (TID 371) in 300 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 13:30:37,306 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,306 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:37,587 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 6.0 (TID 372). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:37,587 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 6.0 (TID 374, localhost, executor driver, partition 168, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:37,588 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 6.0 (TID 374)
[INFO] 2019-01-19 13:30:37,588 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 6.0 (TID 372) in 324 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 13:30:37,600 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,601 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:37,602 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 6.0 (TID 373). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:37,603 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 6.0 (TID 375, localhost, executor driver, partition 169, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:37,603 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 6.0 (TID 375)
[INFO] 2019-01-19 13:30:37,603 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 6.0 (TID 373) in 314 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 13:30:37,614 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,614 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:37,903 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 6.0 (TID 374). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:37,904 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 6.0 (TID 376, localhost, executor driver, partition 170, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:37,904 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 6.0 (TID 376)
[INFO] 2019-01-19 13:30:37,904 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 6.0 (TID 374) in 317 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 13:30:37,919 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,919 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:37,921 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 6.0 (TID 375). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:37,921 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 6.0 (TID 377, localhost, executor driver, partition 171, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:37,921 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 6.0 (TID 377)
[INFO] 2019-01-19 13:30:37,921 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 6.0 (TID 375) in 318 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 13:30:37,935 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:37,935 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:38,213 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 6.0 (TID 376). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:38,213 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 6.0 (TID 378, localhost, executor driver, partition 172, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:38,214 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 6.0 (TID 378)
[INFO] 2019-01-19 13:30:38,214 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 6.0 (TID 376) in 310 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 13:30:38,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:38,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:38,232 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 6.0 (TID 377). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:38,233 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 6.0 (TID 379, localhost, executor driver, partition 173, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:38,233 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 6.0 (TID 379)
[INFO] 2019-01-19 13:30:38,233 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 6.0 (TID 377) in 312 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 13:30:38,245 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:38,245 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:38,522 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 6.0 (TID 378). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:38,522 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 6.0 (TID 380, localhost, executor driver, partition 174, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:38,522 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 6.0 (TID 380)
[INFO] 2019-01-19 13:30:38,523 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 6.0 (TID 378) in 309 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 13:30:38,535 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:38,535 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:38,539 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 6.0 (TID 379). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:38,539 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 6.0 (TID 381, localhost, executor driver, partition 175, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:38,539 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 6.0 (TID 381)
[INFO] 2019-01-19 13:30:38,539 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 6.0 (TID 379) in 306 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 13:30:38,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:38,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:38,834 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 6.0 (TID 380). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:38,835 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 6.0 (TID 382, localhost, executor driver, partition 176, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:38,835 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 6.0 (TID 382)
[INFO] 2019-01-19 13:30:38,835 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 6.0 (TID 380) in 313 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 13:30:38,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:38,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:38,854 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 6.0 (TID 381). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:38,854 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 6.0 (TID 383, localhost, executor driver, partition 177, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:38,854 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 6.0 (TID 383)
[INFO] 2019-01-19 13:30:38,854 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 6.0 (TID 381) in 315 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 13:30:38,869 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:38,869 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:39,135 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 6.0 (TID 382). 4281 bytes result sent to driver
[INFO] 2019-01-19 13:30:39,135 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 6.0 (TID 384, localhost, executor driver, partition 178, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:39,136 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 6.0 (TID 382) in 302 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 13:30:39,136 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 6.0 (TID 384)
[INFO] 2019-01-19 13:30:39,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:39,151 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:39,179 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 6.0 (TID 383). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:39,179 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 6.0 (TID 385, localhost, executor driver, partition 179, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:39,179 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 6.0 (TID 385)
[INFO] 2019-01-19 13:30:39,180 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 6.0 (TID 383) in 326 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 13:30:39,190 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:39,191 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:39,447 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 6.0 (TID 384). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:39,447 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 6.0 (TID 386, localhost, executor driver, partition 180, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:39,447 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 6.0 (TID 386)
[INFO] 2019-01-19 13:30:39,447 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 6.0 (TID 384) in 312 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 13:30:39,463 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:39,463 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:39,496 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 6.0 (TID 385). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:39,497 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 6.0 (TID 387, localhost, executor driver, partition 181, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:39,497 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 6.0 (TID 387)
[INFO] 2019-01-19 13:30:39,497 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 6.0 (TID 385) in 318 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 13:30:39,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:39,507 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:39,740 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 6.0 (TID 386). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:39,740 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 6.0 (TID 388, localhost, executor driver, partition 182, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:39,740 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 6.0 (TID 388)
[INFO] 2019-01-19 13:30:39,740 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 6.0 (TID 386) in 293 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 13:30:39,751 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:39,751 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:39,789 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 6.0 (TID 387). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:39,789 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 6.0 (TID 389, localhost, executor driver, partition 183, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:39,790 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 6.0 (TID 389)
[INFO] 2019-01-19 13:30:39,790 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 6.0 (TID 387) in 294 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 13:30:39,801 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:39,801 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:40,045 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 6.0 (TID 388). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:40,045 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 6.0 (TID 390, localhost, executor driver, partition 184, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:40,045 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 6.0 (TID 390)
[INFO] 2019-01-19 13:30:40,045 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 6.0 (TID 388) in 305 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 13:30:40,059 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:40,059 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:40,089 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 6.0 (TID 389). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:40,090 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 6.0 (TID 391, localhost, executor driver, partition 185, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:40,090 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 6.0 (TID 391)
[INFO] 2019-01-19 13:30:40,090 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 6.0 (TID 389) in 301 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 13:30:40,102 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:40,103 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:40,355 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 6.0 (TID 390). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:40,355 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 6.0 (TID 392, localhost, executor driver, partition 186, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:40,355 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 6.0 (TID 392)
[INFO] 2019-01-19 13:30:40,355 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 6.0 (TID 390) in 310 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 13:30:40,367 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:40,368 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:40,400 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 6.0 (TID 391). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:40,400 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 6.0 (TID 393, localhost, executor driver, partition 187, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:40,400 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 6.0 (TID 393)
[INFO] 2019-01-19 13:30:40,400 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 6.0 (TID 391) in 310 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 13:30:40,411 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:40,411 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:40,674 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 6.0 (TID 392). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:40,675 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 6.0 (TID 394, localhost, executor driver, partition 188, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:40,675 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 6.0 (TID 394)
[INFO] 2019-01-19 13:30:40,675 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 6.0 (TID 392) in 320 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 13:30:40,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:40,691 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:40,710 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 6.0 (TID 393). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:40,710 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 6.0 (TID 395, localhost, executor driver, partition 189, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:40,711 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 6.0 (TID 395)
[INFO] 2019-01-19 13:30:40,711 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 6.0 (TID 393) in 311 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 13:30:40,728 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:40,729 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:41,056 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 6.0 (TID 394). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:41,056 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 6.0 (TID 396, localhost, executor driver, partition 190, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:41,057 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 6.0 (TID 396)
[INFO] 2019-01-19 13:30:41,057 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 6.0 (TID 394) in 382 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 13:30:41,066 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 6.0 (TID 395). 4104 bytes result sent to driver
[INFO] 2019-01-19 13:30:41,066 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 6.0 (TID 397, localhost, executor driver, partition 191, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:41,067 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 6.0 (TID 397)
[INFO] 2019-01-19 13:30:41,067 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 6.0 (TID 395) in 357 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 13:30:41,068 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:41,068 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:41,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:41,082 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:41,439 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 6.0 (TID 396). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:41,441 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 6.0 (TID 398, localhost, executor driver, partition 192, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:41,441 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 6.0 (TID 396) in 385 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 13:30:41,441 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 6.0 (TID 398)
[INFO] 2019-01-19 13:30:41,458 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:41,458 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:41,476 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 6.0 (TID 397). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:41,476 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 6.0 (TID 399, localhost, executor driver, partition 193, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:41,476 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 6.0 (TID 399)
[INFO] 2019-01-19 13:30:41,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 6.0 (TID 397) in 410 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 13:30:41,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:41,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:41,787 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 6.0 (TID 398). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:41,788 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 6.0 (TID 400, localhost, executor driver, partition 194, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:41,789 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 6.0 (TID 398) in 349 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 13:30:41,789 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 6.0 (TID 400)
[INFO] 2019-01-19 13:30:41,803 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:41,804 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:41,832 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 6.0 (TID 399). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:41,832 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 6.0 (TID 401, localhost, executor driver, partition 195, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:41,833 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 6.0 (TID 399) in 357 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 13:30:41,833 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 6.0 (TID 401)
[INFO] 2019-01-19 13:30:41,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:41,849 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:42,147 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 6.0 (TID 400). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:42,148 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 6.0 (TID 402, localhost, executor driver, partition 196, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:42,148 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 6.0 (TID 402)
[INFO] 2019-01-19 13:30:42,148 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 6.0 (TID 400) in 360 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 13:30:42,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:42,161 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:42,179 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 6.0 (TID 401). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:42,179 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 6.0 (TID 403, localhost, executor driver, partition 197, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:42,180 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 6.0 (TID 403)
[INFO] 2019-01-19 13:30:42,180 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 6.0 (TID 401) in 348 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 13:30:42,188 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:42,189 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:42,474 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 6.0 (TID 402). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:42,475 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 6.0 (TID 404, localhost, executor driver, partition 198, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:42,475 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 6.0 (TID 404)
[INFO] 2019-01-19 13:30:42,475 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 6.0 (TID 402) in 327 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 13:30:42,488 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:42,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:42,496 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 6.0 (TID 403). 4121 bytes result sent to driver
[INFO] 2019-01-19 13:30:42,496 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 6.0 (TID 405, localhost, executor driver, partition 199, ANY, 5789 bytes)
[INFO] 2019-01-19 13:30:42,496 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 6.0 (TID 405)
[INFO] 2019-01-19 13:30:42,496 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 6.0 (TID 403) in 317 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 13:30:42,505 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:42,505 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:42,773 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 6.0 (TID 404). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:42,773 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 6.0 (TID 404) in 298 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 13:30:42,799 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 6.0 (TID 405). 4194 bytes result sent to driver
[INFO] 2019-01-19 13:30:42,800 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 6.0 (TID 405) in 304 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 13:30:42,800 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:42,800 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 6 (head at DecoupJson.scala:139) finished in 33.883 s
[INFO] 2019-01-19 13:30:42,800 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:42,800 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:42,801 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 7)
[INFO] 2019-01-19 13:30:42,801 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:42,801 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 7 (MapPartitionsRDD[32] at head at DecoupJson.scala:139), which has no missing parents
[INFO] 2019-01-19 13:30:42,822 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10 stored as values in memory (estimated size 647.9 KB, free 1989.5 MB)
[INFO] 2019-01-19 13:30:42,824 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10_piece0 stored as bytes in memory (estimated size 150.8 KB, free 1989.4 MB)
[INFO] 2019-01-19 13:30:42,825 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_10_piece0 in memory on 192.168.99.1:57904 (size: 150.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:42,826 org.apache.spark.SparkContext logInfo - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:42,826 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at head at DecoupJson.scala:139)
[INFO] 2019-01-19 13:30:42,827 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 7.0 with 1 tasks
[INFO] 2019-01-19 13:30:42,827 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 7.0 (TID 406, localhost, executor driver, partition 0, ANY, 5800 bytes)
[INFO] 2019-01-19 13:30:42,828 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 7.0 (TID 406)
[INFO] 2019-01-19 13:30:42,838 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 200 non-empty blocks out of 200 blocks
[INFO] 2019-01-19 13:30:42,839 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:43,106 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 132.71623 ms
[INFO] 2019-01-19 13:30:43,236 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 44.437149 ms
[INFO] 2019-01-19 13:30:43,336 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 59.896938 ms
[INFO] 2019-01-19 13:30:43,422 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 68.72682 ms
[INFO] 2019-01-19 13:30:43,540 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 7.0 (TID 406). 8225 bytes result sent to driver
[INFO] 2019-01-19 13:30:43,541 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 7.0 (TID 406) in 714 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:43,541 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:43,541 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 7 (head at DecoupJson.scala:139) finished in 0.714 s
[INFO] 2019-01-19 13:30:43,543 org.apache.spark.scheduler.DAGScheduler logInfo - Job 2 finished: head at DecoupJson.scala:139, took 39.565026 s
[INFO] 2019-01-19 13:30:43,618 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 55.42399 ms
[INFO] 2019-01-19 13:30:43,729 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:43,730 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:30:43,731 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:43,731 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:30:43,732 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:43,733 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:30:43,734 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:43,734 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:30:43,820 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 36.99164 ms
[INFO] 2019-01-19 13:30:43,887 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 44.364158 ms
[INFO] 2019-01-19 13:30:43,905 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11 stored as values in memory (estimated size 292.7 KB, free 1989.1 MB)
[INFO] 2019-01-19 13:30:43,915 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1989.0 MB)
[INFO] 2019-01-19 13:30:43,916 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_11_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:43,916 org.apache.spark.SparkContext logInfo - Created broadcast 11 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 13:30:43,917 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:43,945 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12 stored as values in memory (estimated size 292.7 KB, free 1988.8 MB)
[INFO] 2019-01-19 13:30:43,954 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:30:43,955 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_12_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:43,955 org.apache.spark.SparkContext logInfo - Created broadcast 12 from rdd at DecoupJson.scala:146
[INFO] 2019-01-19 13:30:43,956 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:44,016 org.apache.spark.SparkContext logInfo - Starting job: first at DecoupJson.scala:146
[INFO] 2019-01-19 13:30:44,017 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 35 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,017 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 40 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,017 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 45 (rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,017 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 3 (first at DecoupJson.scala:146) with 1 output partitions
[INFO] 2019-01-19 13:30:44,017 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 11 (first at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,017 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 10)
[INFO] 2019-01-19 13:30:44,018 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 10)
[INFO] 2019-01-19 13:30:44,018 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 8 (MapPartitionsRDD[35] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:30:44,019 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13 stored as values in memory (estimated size 39.7 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:30:44,021 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1988.7 MB)
[INFO] 2019-01-19 13:30:44,022 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_13_piece0 in memory on 192.168.99.1:57904 (size: 12.3 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,022 org.apache.spark.SparkContext logInfo - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,023 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[35] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,023 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 8.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,023 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 9 (MapPartitionsRDD[40] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:30:44,025 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14 stored as values in memory (estimated size 39.6 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,027 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,029 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_14_piece0 in memory on 192.168.99.1:57904 (size: 12.3 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,030 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 8.0 (TID 407, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 13:30:44,030 org.apache.spark.SparkContext logInfo - Created broadcast 14 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,030 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 8.0 (TID 407)
[INFO] 2019-01-19 13:30:44,030 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[40] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,030 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 9.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,031 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 9.0 (TID 408, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
[INFO] 2019-01-19 13:30:44,031 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 9.0 (TID 408)
[INFO] 2019-01-19 13:30:44,032 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:44,036 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:44,059 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:30:44,118 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:30:44,213 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 9.0 (TID 408). 2023 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,213 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 9.0 (TID 408) in 182 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,213 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,213 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 9 (rdd at DecoupJson.scala:146) finished in 0.183 s
[INFO] 2019-01-19 13:30:44,214 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,214 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 8)
[INFO] 2019-01-19 13:30:44,214 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 13:30:44,214 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,217 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 8.0 (TID 407). 2026 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,217 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 8.0 (TID 407) in 189 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 8 (rdd at DecoupJson.scala:146) finished in 0.195 s
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 10, ResultStage 11)
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,218 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 10 (MapPartitionsRDD[45] at rdd at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:30:44,219 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15 stored as values in memory (estimated size 111.9 KB, free 1988.5 MB)
[INFO] 2019-01-19 13:30:44,221 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.7 KB, free 1988.5 MB)
[INFO] 2019-01-19 13:30:44,221 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_15_piece0 in memory on 192.168.99.1:57904 (size: 29.7 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,222 org.apache.spark.SparkContext logInfo - Created broadcast 15 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,222 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[45] at rdd at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,222 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 10.0 with 2 tasks
[INFO] 2019-01-19 13:30:44,223 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 10.0 (TID 409, localhost, executor driver, partition 0, ANY, 5967 bytes)
[INFO] 2019-01-19 13:30:44,223 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 10.0 (TID 410, localhost, executor driver, partition 1, ANY, 5967 bytes)
[INFO] 2019-01-19 13:30:44,223 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 10.0 (TID 409)
[INFO] 2019-01-19 13:30:44,223 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 10.0 (TID 410)
[INFO] 2019-01-19 13:30:44,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:44,226 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:44,227 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:44,227 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:44,277 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 10.0 (TID 409). 2571 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,278 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 10.0 (TID 409) in 56 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:30:44,285 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 10.0 (TID 410). 2571 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,285 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 10.0 (TID 410) in 62 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:30:44,285 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,286 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 10 (rdd at DecoupJson.scala:146) finished in 0.064 s
[INFO] 2019-01-19 13:30:44,286 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,286 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:44,286 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 11)
[INFO] 2019-01-19 13:30:44,286 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,286 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 11 (MapPartitionsRDD[50] at map at DecoupJson.scala:146), which has no missing parents
[INFO] 2019-01-19 13:30:44,289 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16 stored as values in memory (estimated size 130.9 KB, free 1988.4 MB)
[INFO] 2019-01-19 13:30:44,297 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_16_piece0 stored as bytes in memory (estimated size 39.6 KB, free 1988.3 MB)
[INFO] 2019-01-19 13:30:44,298 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_16_piece0 in memory on 192.168.99.1:57904 (size: 39.6 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,299 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_10_piece0 on 192.168.99.1:57904 in memory (size: 150.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,299 org.apache.spark.SparkContext logInfo - Created broadcast 16 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,299 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at DecoupJson.scala:146)
[INFO] 2019-01-19 13:30:44,299 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 11.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,300 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 11.0 (TID 411, localhost, executor driver, partition 0, ANY, 5869 bytes)
[INFO] 2019-01-19 13:30:44,300 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10005
[INFO] 2019-01-19 13:30:44,300 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10006
[INFO] 2019-01-19 13:30:44,300 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 10007
[INFO] 2019-01-19 13:30:44,300 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 11.0 (TID 411)
[INFO] 2019-01-19 13:30:44,302 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_13_piece0 on 192.168.99.1:57904 in memory (size: 12.3 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,304 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_14_piece0 on 192.168.99.1:57904 in memory (size: 12.3 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,305 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:44,306 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 13:30:44,317 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 6.84077 ms
[INFO] 2019-01-19 13:30:44,322 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 11.0 (TID 411). 4068 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,322 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 11.0 (TID 411) in 23 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,322 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 11.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,322 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 11 (first at DecoupJson.scala:146) finished in 0.023 s
[INFO] 2019-01-19 13:30:44,323 org.apache.spark.scheduler.DAGScheduler logInfo - Job 3 finished: first at DecoupJson.scala:146, took 0.306751 s
[INFO] 2019-01-19 13:30:44,369 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:44,370 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:30:44,371 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:30:44,371 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:30:44,372 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:44,373 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:30:44,374 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<samp_flag: int>
[INFO] 2019-01-19 13:30:44,374 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:30:44,393 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.141861 ms
[INFO] 2019-01-19 13:30:44,399 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 4.160881 ms
[INFO] 2019-01-19 13:30:44,403 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.591757 ms
[INFO] 2019-01-19 13:30:44,410 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.482842 ms
[INFO] 2019-01-19 13:30:44,415 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17 stored as values in memory (estimated size 278.7 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:30:44,436 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1988.9 MB)
[INFO] 2019-01-19 13:30:44,437 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_17_piece0 in memory on 192.168.99.1:57904 (size: 23.7 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,440 org.apache.spark.SparkContext logInfo - Created broadcast 17 from count at DecoupJson.scala:75
[INFO] 2019-01-19 13:30:44,441 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:44,468 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 6.565729 ms
[INFO] 2019-01-19 13:30:44,472 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18 stored as values in memory (estimated size 278.7 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,489 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,492 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_18_piece0 in memory on 192.168.99.1:57904 (size: 23.7 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,493 org.apache.spark.SparkContext logInfo - Created broadcast 18 from count at DecoupJson.scala:75
[INFO] 2019-01-19 13:30:44,493 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:44,522 org.apache.spark.SparkContext logInfo - Starting job: count at DecoupJson.scala:75
[INFO] 2019-01-19 13:30:44,522 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 58 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,523 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 53 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,523 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 63 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,523 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 4 (count at DecoupJson.scala:75) with 1 output partitions
[INFO] 2019-01-19 13:30:44,524 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 15 (count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,525 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 14)
[INFO] 2019-01-19 13:30:44,525 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 14)
[INFO] 2019-01-19 13:30:44,526 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:30:44,527 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19 stored as values in memory (estimated size 12.1 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,529 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,530 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_19_piece0 in memory on 192.168.99.1:57904 (size: 5.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,531 org.apache.spark.SparkContext logInfo - Created broadcast 19 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,531 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,531 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 12.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,531 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 13 (MapPartitionsRDD[53] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:30:44,532 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 12.0 (TID 412, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:30:44,532 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 12.0 (TID 412)
[INFO] 2019-01-19 13:30:44,533 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20 stored as values in memory (estimated size 12.1 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,534 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,535 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_20_piece0 in memory on 192.168.99.1:57904 (size: 5.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,536 org.apache.spark.SparkContext logInfo - Created broadcast 20 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,536 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[53] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,536 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 13.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,536 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:44,537 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 13.0 (TID 413, localhost, executor driver, partition 0, PROCESS_LOCAL, 6652 bytes)
[INFO] 2019-01-19 13:30:44,537 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 13.0 (TID 413)
[INFO] 2019-01-19 13:30:44,541 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:44,549 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:30:44,555 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:30:44,581 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 12.0 (TID 412). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,582 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 12.0 (TID 412) in 51 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,583 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 12.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,583 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 12 (count at DecoupJson.scala:75) finished in 0.052 s
[INFO] 2019-01-19 13:30:44,583 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,584 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 13)
[INFO] 2019-01-19 13:30:44,584 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15, ShuffleMapStage 14)
[INFO] 2019-01-19 13:30:44,584 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,587 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 13.0 (TID 413). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,587 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 13.0 (TID 413) in 51 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,587 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 13.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,587 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 13 (count at DecoupJson.scala:75) finished in 0.051 s
[INFO] 2019-01-19 13:30:44,587 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,588 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:44,588 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15, ShuffleMapStage 14)
[INFO] 2019-01-19 13:30:44,588 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,588 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 14 (MapPartitionsRDD[63] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:30:44,589 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21 stored as values in memory (estimated size 11.1 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,591 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,592 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_21_piece0 in memory on 192.168.99.1:57904 (size: 4.9 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,592 org.apache.spark.SparkContext logInfo - Created broadcast 21 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,592 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[63] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,592 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 14.0 with 2 tasks
[INFO] 2019-01-19 13:30:44,593 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 14.0 (TID 414, localhost, executor driver, partition 0, ANY, 5998 bytes)
[INFO] 2019-01-19 13:30:44,594 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 14.0 (TID 415, localhost, executor driver, partition 1, ANY, 5998 bytes)
[INFO] 2019-01-19 13:30:44,594 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 14.0 (TID 414)
[INFO] 2019-01-19 13:30:44,594 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 14.0 (TID 415)
[INFO] 2019-01-19 13:30:44,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:44,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:44,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:44,595 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:44,611 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 14.0 (TID 414). 2571 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,611 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 14.0 (TID 414) in 18 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:30:44,615 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 14.0 (TID 415). 2405 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 14.0 (TID 415) in 23 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 14.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 14 (count at DecoupJson.scala:75) finished in 0.023 s
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 15)
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,616 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 15 (MapPartitionsRDD[66] at count at DecoupJson.scala:75), which has no missing parents
[INFO] 2019-01-19 13:30:44,617 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22 stored as values in memory (estimated size 7.0 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,618 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1988.6 MB)
[INFO] 2019-01-19 13:30:44,619 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_22_piece0 in memory on 192.168.99.1:57904 (size: 3.7 KB, free: 1991.6 MB)
[INFO] 2019-01-19 13:30:44,619 org.apache.spark.SparkContext logInfo - Created broadcast 22 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,619 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[66] at count at DecoupJson.scala:75)
[INFO] 2019-01-19 13:30:44,619 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 15.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,620 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 15.0 (TID 416, localhost, executor driver, partition 0, ANY, 5900 bytes)
[INFO] 2019-01-19 13:30:44,620 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 15.0 (TID 416)
[INFO] 2019-01-19 13:30:44,621 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:44,621 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:44,624 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 15.0 (TID 416). 1952 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,624 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 15.0 (TID 416) in 4 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,625 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 15.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,625 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 15 (count at DecoupJson.scala:75) finished in 0.006 s
[INFO] 2019-01-19 13:30:44,625 org.apache.spark.scheduler.DAGScheduler logInfo - Job 4 finished: count at DecoupJson.scala:75, took 0.102567 s
[INFO] 2019-01-19 13:30:44,630 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 3.021223 ms
[INFO] 2019-01-19 13:30:44,682 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:44,683 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:30:44,684 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:44,684 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:30:44,685 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:44,693 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:30:44,693 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:44,694 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:30:44,715 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.675833 ms
[INFO] 2019-01-19 13:30:44,728 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.393387 ms
[INFO] 2019-01-19 13:30:44,746 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.112373 ms
[INFO] 2019-01-19 13:30:44,752 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23 stored as values in memory (estimated size 292.7 KB, free 1988.3 MB)
[INFO] 2019-01-19 13:30:44,764 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_23_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.2 MB)
[INFO] 2019-01-19 13:30:44,765 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_23_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,766 org.apache.spark.SparkContext logInfo - Created broadcast 23 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 13:30:44,766 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:44,792 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 11.580296 ms
[INFO] 2019-01-19 13:30:44,799 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24 stored as values in memory (estimated size 292.7 KB, free 1988.0 MB)
[INFO] 2019-01-19 13:30:44,813 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_24_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:30:44,813 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_24_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,814 org.apache.spark.SparkContext logInfo - Created broadcast 24 from rdd at DecoupJson.scala:95
[INFO] 2019-01-19 13:30:44,815 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:44,842 org.apache.spark.SparkContext logInfo - Starting job: collect at DecoupJson.scala:95
[INFO] 2019-01-19 13:30:44,843 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 73 (rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:30:44,843 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 5 (collect at DecoupJson.scala:95) with 1 output partitions
[INFO] 2019-01-19 13:30:44,843 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 17 (collect at DecoupJson.scala:95)
[INFO] 2019-01-19 13:30:44,843 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 16)
[INFO] 2019-01-19 13:30:44,844 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 16)
[INFO] 2019-01-19 13:30:44,844 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 16 (MapPartitionsRDD[73] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 13:30:44,845 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25 stored as values in memory (estimated size 83.9 KB, free 1987.9 MB)
[INFO] 2019-01-19 13:30:44,847 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_25_piece0 stored as bytes in memory (estimated size 22.3 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:30:44,848 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_25_piece0 in memory on 192.168.99.1:57904 (size: 22.3 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,848 org.apache.spark.SparkContext logInfo - Created broadcast 25 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,848 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[73] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:30:44,849 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 16.0 with 2 tasks
[INFO] 2019-01-19 13:30:44,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 16.0 (TID 417, localhost, executor driver, partition 0, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 13:30:44,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 16.0 (TID 418, localhost, executor driver, partition 1, PROCESS_LOCAL, 6732 bytes)
[INFO] 2019-01-19 13:30:44,850 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 16.0 (TID 418)
[INFO] 2019-01-19 13:30:44,850 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 16.0 (TID 417)
[INFO] 2019-01-19 13:30:44,856 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:44,856 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:44,864 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:30:44,895 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:30:44,949 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 16.0 (TID 418). 2393 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,950 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 16.0 (TID 418) in 100 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:30:44,956 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 16.0 (TID 417). 2393 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,957 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 16.0 (TID 417) in 108 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:30:44,958 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 16.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,958 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 16 (rdd at DecoupJson.scala:95) finished in 0.109 s
[INFO] 2019-01-19 13:30:44,958 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:44,958 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:44,958 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 17)
[INFO] 2019-01-19 13:30:44,958 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:44,959 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 17 (MapPartitionsRDD[77] at rdd at DecoupJson.scala:95), which has no missing parents
[INFO] 2019-01-19 13:30:44,960 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26 stored as values in memory (estimated size 41.5 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:30:44,962 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_26_piece0 stored as bytes in memory (estimated size 14.9 KB, free 1987.8 MB)
[INFO] 2019-01-19 13:30:44,963 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_26_piece0 in memory on 192.168.99.1:57904 (size: 14.9 KB, free: 1991.5 MB)
[INFO] 2019-01-19 13:30:44,964 org.apache.spark.SparkContext logInfo - Created broadcast 26 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:44,964 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[77] at rdd at DecoupJson.scala:95)
[INFO] 2019-01-19 13:30:44,964 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 17.0 with 1 tasks
[INFO] 2019-01-19 13:30:44,965 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 17.0 (TID 419, localhost, executor driver, partition 0, ANY, 5871 bytes)
[INFO] 2019-01-19 13:30:44,965 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 17.0 (TID 419)
[INFO] 2019-01-19 13:30:44,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 2 non-empty blocks out of 2 blocks
[INFO] 2019-01-19 13:30:44,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:44,983 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 7.5185 ms
[INFO] 2019-01-19 13:30:44,990 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 17.0 (TID 419). 7325 bytes result sent to driver
[INFO] 2019-01-19 13:30:44,993 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 17.0 (TID 419) in 28 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:44,993 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 17.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:44,993 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 17 (collect at DecoupJson.scala:95) finished in 0.028 s
[INFO] 2019-01-19 13:30:44,993 org.apache.spark.scheduler.DAGScheduler logInfo - Job 5 finished: collect at DecoupJson.scala:95, took 0.150384 s
[INFO] 2019-01-19 13:30:45,018 myLogger setOutputDataTable - outputPath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train22
[INFO] 2019-01-19 13:30:45,076 org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat logInfo - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,091 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:45,092 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 0)
[INFO] 2019-01-19 13:30:45,093 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:45,093 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,0)
[INFO] 2019-01-19 13:30:45,094 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 13:30:45,095 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: isnotnull(samp_flag#23),(samp_flag#23 = 1)
[INFO] 2019-01-19 13:30:45,095 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 13:30:45,096 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: IsNotNull(samp_flag),EqualTo(samp_flag,1)
[INFO] 2019-01-19 13:30:45,110 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO] 2019-01-19 13:30:45,110 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO] 2019-01-19 13:30:45,111 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO] 2019-01-19 13:30:45,111 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO] 2019-01-19 13:30:45,111 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO] 2019-01-19 13:30:45,112 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:30:45,114 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,114 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:30:45,116 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,133 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27 stored as values in memory (estimated size 292.7 KB, free 1987.5 MB)
[INFO] 2019-01-19 13:30:45,147 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_27_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.5 MB)
[INFO] 2019-01-19 13:30:45,148 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_27_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:30:45,148 org.apache.spark.SparkContext logInfo - Created broadcast 27 from save at DecoupJson.scala:166
[INFO] 2019-01-19 13:30:45,150 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:45,180 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28 stored as values in memory (estimated size 292.7 KB, free 1987.2 MB)
[INFO] 2019-01-19 13:30:45,195 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1987.2 MB)
[INFO] 2019-01-19 13:30:45,196 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_28_piece0 in memory on 192.168.99.1:57904 (size: 25.4 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:30:45,198 org.apache.spark.SparkContext logInfo - Created broadcast 28 from save at DecoupJson.scala:166
[INFO] 2019-01-19 13:30:45,199 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 13:30:45,230 org.apache.spark.SparkContext logInfo - Starting job: save at DecoupJson.scala:166
[INFO] 2019-01-19 13:30:45,231 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 85 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:30:45,231 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 80 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:30:45,232 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 6 (save at DecoupJson.scala:166) with 2 output partitions
[INFO] 2019-01-19 13:30:45,232 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 20 (save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:30:45,232 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 18)
[INFO] 2019-01-19 13:30:45,232 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 19, ShuffleMapStage 18)
[INFO] 2019-01-19 13:30:45,232 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 18 (MapPartitionsRDD[85] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:30:45,233 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29 stored as values in memory (estimated size 39.6 KB, free 1987.1 MB)
[INFO] 2019-01-19 13:30:45,235 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1987.1 MB)
[INFO] 2019-01-19 13:30:45,236 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_29_piece0 in memory on 192.168.99.1:57904 (size: 12.3 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:30:45,237 org.apache.spark.SparkContext logInfo - Created broadcast 29 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:45,237 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[85] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:30:45,237 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 18.0 with 1 tasks
[INFO] 2019-01-19 13:30:45,238 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 19 (MapPartitionsRDD[80] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:30:45,238 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 18.0 (TID 420, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 13:30:45,239 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30 stored as values in memory (estimated size 39.7 KB, free 1987.1 MB)
[INFO] 2019-01-19 13:30:45,239 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 18.0 (TID 420)
[INFO] 2019-01-19 13:30:45,241 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_30_piece0 stored as bytes in memory (estimated size 12.3 KB, free 1987.1 MB)
[INFO] 2019-01-19 13:30:45,242 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_30_piece0 in memory on 192.168.99.1:57904 (size: 12.3 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:30:45,242 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:45,243 org.apache.spark.SparkContext logInfo - Created broadcast 30 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:45,243 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[80] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:30:45,243 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 19.0 with 1 tasks
[INFO] 2019-01-19 13:30:45,246 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 19.0 (TID 421, localhost, executor driver, partition 0, PROCESS_LOCAL, 6660 bytes)
[INFO] 2019-01-19 13:30:45,249 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 19.0 (TID 421)
[INFO] 2019-01-19 13:30:45,251 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 13:30:45,253 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 1))
[INFO] 2019-01-19 13:30:45,272 org.apache.parquet.filter2.compat.FilterCompat info - Filtering using predicate: and(noteq(samp_flag, null), eq(samp_flag, 0))
[INFO] 2019-01-19 13:30:45,336 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 18.0 (TID 420). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:30:45,336 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 18.0 (TID 420) in 98 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:45,337 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 18.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:45,337 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 18 (save at DecoupJson.scala:166) finished in 0.099 s
[INFO] 2019-01-19 13:30:45,337 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:45,337 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set(ShuffleMapStage 19)
[INFO] 2019-01-19 13:30:45,337 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 20)
[INFO] 2019-01-19 13:30:45,337 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:45,342 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 19.0 (TID 421). 1936 bytes result sent to driver
[INFO] 2019-01-19 13:30:45,342 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 19.0 (TID 421) in 96 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:30:45,342 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 19.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:45,342 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 19 (save at DecoupJson.scala:166) finished in 0.099 s
[INFO] 2019-01-19 13:30:45,343 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 13:30:45,343 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 13:30:45,343 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 20)
[INFO] 2019-01-19 13:30:45,344 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 13:30:45,344 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 20 (UnionRDD[88] at save at DecoupJson.scala:166), which has no missing parents
[INFO] 2019-01-19 13:30:45,354 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31 stored as values in memory (estimated size 116.7 KB, free 1986.9 MB)
[INFO] 2019-01-19 13:30:45,355 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_31_piece0 stored as bytes in memory (estimated size 35.7 KB, free 1986.9 MB)
[INFO] 2019-01-19 13:30:45,356 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_31_piece0 in memory on 192.168.99.1:57904 (size: 35.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 13:30:45,356 org.apache.spark.SparkContext logInfo - Created broadcast 31 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:30:45,356 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 2 missing tasks from ResultStage 20 (UnionRDD[88] at save at DecoupJson.scala:166)
[INFO] 2019-01-19 13:30:45,357 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 20.0 with 2 tasks
[INFO] 2019-01-19 13:30:45,358 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 20.0 (TID 422, localhost, executor driver, partition 0, ANY, 6017 bytes)
[INFO] 2019-01-19 13:30:45,359 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 20.0 (TID 423, localhost, executor driver, partition 1, ANY, 6017 bytes)
[INFO] 2019-01-19 13:30:45,359 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 20.0 (TID 422)
[INFO] 2019-01-19 13:30:45,359 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 20.0 (TID 423)
[INFO] 2019-01-19 13:30:45,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:45,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:45,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 13:30:45,376 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 13:30:45,376 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:30:45,377 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,377 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:30:45,378 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:30:45,378 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,379 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,379 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 13:30:45,379 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 13:30:45,382 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:30:45,384 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:30:45,385 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:30:45,385 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 13:30:45,400 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 13:30:45,401 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 13:30:45,419 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 13:30:45,420 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 13:30:45,445 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 13:30:45,445 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 13:30:45,526 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 32,589
[INFO] 2019-01-19 13:30:45,528 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 32,602
[INFO] 2019-01-19 13:30:45,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 1,578B for [crm_cust_no] BINARY: 111 values, 3,226B raw, 1,500B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [stat_mth] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:30:45,567 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 188B for [crm_cust_no] BINARY: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 72 entries, 2,088B raw, 72B comp}
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [ast_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 90 entries, 720B raw, 90B comp}
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [stat_mth] INT32: 111 values, 65B raw, 64B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 763B for [std_cred_curr_bal] DOUBLE: 111 values, 895B raw, 719B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 154B for [ast_curr_bal] DOUBLE: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 71 entries, 568B raw, 71B comp}
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 764B for [std_cred_curr_bal] DOUBLE: 111 values, 895B raw, 720B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,568 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 758B for [std_cred_bill_amt] DOUBLE: 111 values, 895B raw, 714B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,569 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [std_cred_limit] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:30:45,569 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 123B for [ln_curr_bal] DOUBLE: 111 values, 79B raw, 79B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 26 entries, 208B raw, 26B comp}
[INFO] 2019-01-19 13:30:45,569 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 760B for [std_cred_bill_amt] DOUBLE: 111 values, 895B raw, 716B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,569 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [ln_curr_bal] DOUBLE: 111 values, 71B raw, 74B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 26 entries, 208B raw, 26B comp}
[INFO] 2019-01-19 13:30:45,569 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [l3m_ln_davg_bal] DOUBLE: 111 values, 71B raw, 74B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 27 entries, 216B raw, 27B comp}
[INFO] 2019-01-19 13:30:45,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 138B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 93B raw, 94B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 36 entries, 288B raw, 36B comp}
[INFO] 2019-01-19 13:30:45,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 123B for [l3m_ln_davg_bal] DOUBLE: 111 values, 79B raw, 79B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 224B raw, 28B comp}
[INFO] 2019-01-19 13:30:45,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 148B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 83 entries, 1,070B raw, 83B comp}
[INFO] 2019-01-19 13:30:45,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 140B for [l3m_std_cred_qzamt] DOUBLE: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 35 entries, 280B raw, 35B comp}
[INFO] 2019-01-19 13:30:45,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 58B for [std_cred_auto_repay_flag] INT32: 111 values, 22B raw, 24B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:30:45,570 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 148B for [l3m_std_cred_xfamt_pct] BINARY: 111 values, 107B raw, 110B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 88 entries, 1,129B raw, 88B comp}
[INFO] 2019-01-19 13:30:45,571 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 476B for [std_cred_1st_biz_days] INT32: 111 values, 451B raw, 440B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,571 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 62B for [std_cred_auto_repay_flag] INT32: 111 values, 26B raw, 28B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:30:45,571 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [std_cred_lst_biz_days] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 68B raw, 17B comp}
[INFO] 2019-01-19 13:30:45,571 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 485B for [std_cred_1st_biz_days] INT32: 111 values, 451B raw, 449B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,571 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 84B for [std_cred_1stbiz_op_days] BINARY: 111 values, 54B raw, 54B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 59B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,571 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [std_cred_lst_biz_days] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 20 entries, 80B raw, 20B comp}
[INFO] 2019-01-19 13:30:45,572 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 80B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 48B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,572 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 77B for [std_cred_1stbiz_op_days] BINARY: 111 values, 44B raw, 46B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 12 entries, 75B raw, 12B comp}
[INFO] 2019-01-19 13:30:45,572 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 645B for [l3m_std_cred_znamt] DOUBLE: 111 values, 895B raw, 601B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,572 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 74B for [std_cred_mp_appl_bal] DOUBLE: 111 values, 30B raw, 32B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 40B raw, 5B comp}
[INFO] 2019-01-19 13:30:45,573 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 119B for [l3m_std_cred_znamt] DOUBLE: 111 values, 77B raw, 75B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 29 entries, 232B raw, 29B comp}
[INFO] 2019-01-19 13:30:45,574 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 654B for [l6m_std_cred_znamt] DOUBLE: 111 values, 895B raw, 610B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,574 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 132B for [l6m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 88B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 39 entries, 312B raw, 39B comp}
[INFO] 2019-01-19 13:30:45,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 657B for [l12m_std_cred_znamt] DOUBLE: 111 values, 895B raw, 613B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 13:30:45,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 139B for [l12m_std_cred_znamt] DOUBLE: 111 values, 93B raw, 95B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 47 entries, 376B raw, 47B comp}
[INFO] 2019-01-19 13:30:45,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 73B for [l3m_ln_ovd_days_bm] INT32: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:30:45,575 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 50B for [l3m_ln_ovd_days_bm] INT32: 111 values, 14B raw, 16B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:30:45,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 73B for [l12m_ln_ovd_days_bm] INT32: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:30:45,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 54B for [l12m_ln_ovd_days_bm] INT32: 111 values, 18B raw, 20B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 12B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 67B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 31B raw, 33B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 13:30:45,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 54B for [l12m_ln_max_ovd_days_bm] INT32: 111 values, 18B raw, 20B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 12B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:30:45,576 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 50B for [l12m_ln_min_ovd_days_bm] INT32: 111 values, 14B raw, 16B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 13:30:45,577 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 54B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 18B raw, 20B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 12B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,578 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 73B for [l12m_ln_ovd_mths_bm] INT32: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:30:45,579 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 69B for [nty] BINARY: 111 values, 38B raw, 40B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 35B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,580 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 58B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,581 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 46B for [samp_flag] INT32: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 4B raw, 1B comp}
[INFO] 2019-01-19 13:30:45,582 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [nty] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 17B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,582 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [mrg] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 35B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,582 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 100B for [study_exp] BINARY: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 58B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,583 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 45B for [yg_flag] BINARY: 111 values, 14B raw, 16B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 11B raw, 2B comp}
[INFO] 2019-01-19 13:30:45,583 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:30:45,584 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [house_stt] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:30:45,584 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [yg_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:30:45,584 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [work_years] INT32: 111 values, 63B raw, 62B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 12 entries, 48B raw, 12B comp}
[INFO] 2019-01-19 13:30:45,584 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 42B for [gd_flag] BINARY: 111 values, 10B raw, 12B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 13:30:45,584 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 70B for [unit_kind] BINARY: 111 values, 33B raw, 35B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 24B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,584 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [house_stt] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,585 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [title] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:30:45,585 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 81B for [work_years] INT32: 111 values, 47B raw, 47B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 24B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,585 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 85B for [occp] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 17 entries, 145B raw, 17B comp}
[INFO] 2019-01-19 13:30:45,585 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 70B for [unit_kind] BINARY: 111 values, 33B raw, 35B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 3 entries, 24B raw, 3B comp}
[INFO] 2019-01-19 13:30:45,585 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 13:30:45,585 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 68B for [title] BINARY: 111 values, 37B raw, 39B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 21B raw, 4B comp}
[INFO] 2019-01-19 13:30:45,586 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 75B for [occp] BINARY: 111 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 68B raw, 8B comp}
[INFO] 2019-01-19 13:30:45,587 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 82B for [duty] BINARY: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5 entries, 26B raw, 5B comp}
[INFO] 2019-01-19 13:30:45,587 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 96B for [idy] BINARY: 111 values, 62B raw, 65B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 60B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,586 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 113B for [idy] BINARY: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 18 entries, 105B raw, 18B comp}
[INFO] 2019-01-19 13:30:45,588 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 152B raw, 19B comp}
[INFO] 2019-01-19 13:30:45,588 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 91B for [cp_y_income] BINARY: 111 values, 60B raw, 62B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 109B raw, 13B comp}
[INFO] 2019-01-19 13:30:45,588 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [zx_max_lns] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 18 entries, 72B raw, 18B comp}
[INFO] 2019-01-19 13:30:45,594 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 13:30:45,594 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ovd_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,595 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 132B for [zx_ln_max_ovd_amt] INT32: 111 values, 93B raw, 96B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 35 entries, 140B raw, 35B comp}
[INFO] 2019-01-19 13:30:45,596 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 126B for [y_income] DOUBLE: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 25 entries, 200B raw, 25B comp}
[INFO] 2019-01-19 13:30:45,596 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [cp_y_income] BINARY: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 19 entries, 166B raw, 19B comp}
[INFO] 2019-01-19 13:30:45,596 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 15 entries, 60B raw, 15B comp}
[INFO] 2019-01-19 13:30:45,597 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ln_banks] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:30:45,597 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_ovd_lns] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:30:45,597 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 108B for [zx_ln_max_ovd_amt] INT32: 111 values, 69B raw, 72B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 32 entries, 128B raw, 32B comp}
[INFO] 2019-01-19 13:30:45,597 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [zx_ln_tot_ovd_mths] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 24 entries, 96B raw, 24B comp}
[INFO] 2019-01-19 13:30:45,598 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:30:45,598 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 118B for [zx_ln_tot_ovd_mths] INT32: 111 values, 79B raw, 82B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 24 entries, 96B raw, 24B comp}
[INFO] 2019-01-19 13:30:45,598 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 104B for [zx_max_creds] INT32: 111 values, 65B raw, 68B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,598 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_ln_max_ovd_duration] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:30:45,599 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 95B for [zx_max_creds] INT32: 111 values, 59B raw, 61B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 36B raw, 9B comp}
[INFO] 2019-01-19 13:30:45,599 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_cred_banks] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 13:30:45,599 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_max_ovd_creds] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:30:45,600 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 113B for [zx_cred_max_ovd_amt] INT64: 111 values, 66B raw, 69B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 20 entries, 160B raw, 20B comp}
[INFO] 2019-01-19 13:30:45,600 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 95B for [zx_cred_tot_ovd_mths] INT32: 111 values, 59B raw, 61B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 13:30:45,600 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 83B for [zx_cred_max_ovd_duration] INT32: 111 values, 47B raw, 49B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:30:45,605 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 87B for [zx_max_cred_banks] INT32: 111 values, 51B raw, 53B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:30:45,606 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 81B for [zx_max_ovd_creds] INT32: 111 values, 45B raw, 47B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 13:30:45,607 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 98B for [zx_cred_max_ovd_amt] INT64: 111 values, 54B raw, 56B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 104B raw, 13B comp}
[INFO] 2019-01-19 13:30:45,608 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 90B for [zx_cred_tot_ovd_mths] INT32: 111 values, 54B raw, 56B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 40B raw, 10B comp}
[INFO] 2019-01-19 13:30:45,608 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 72B for [zx_cred_max_ovd_duration] INT32: 111 values, 36B raw, 38B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4 entries, 16B raw, 4B comp}
[INFO] 2019-01-19 13:30:45,631 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119133045_0020_m_000001_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119133045_0020_m_000001
[INFO] 2019-01-19 13:30:45,631 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119133045_0020_m_000000_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119133045_0020_m_000000
[INFO] 2019-01-19 13:30:45,632 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119133045_0020_m_000000_0: Committed
[INFO] 2019-01-19 13:30:45,632 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119133045_0020_m_000001_0: Committed
[INFO] 2019-01-19 13:30:45,634 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 20.0 (TID 423). 2207 bytes result sent to driver
[INFO] 2019-01-19 13:30:45,634 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 20.0 (TID 422). 2207 bytes result sent to driver
[INFO] 2019-01-19 13:30:45,634 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 20.0 (TID 423) in 275 ms on localhost (executor driver) (1/2)
[INFO] 2019-01-19 13:30:45,635 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 20.0 (TID 422) in 278 ms on localhost (executor driver) (2/2)
[INFO] 2019-01-19 13:30:45,635 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 20.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:30:45,635 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 20 (save at DecoupJson.scala:166) finished in 0.278 s
[INFO] 2019-01-19 13:30:45,635 org.apache.spark.scheduler.DAGScheduler logInfo - Job 6 finished: save at DecoupJson.scala:166, took 0.404562 s
[WARN] 2019-01-19 13:30:45,654 org.apache.parquet.hadoop.ParquetOutputFormat warn - Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level
[INFO] 2019-01-19 13:30:45,659 org.apache.spark.sql.execution.datasources.FileFormatWriter logInfo - Job null committed.
[INFO] 2019-01-19 13:30:45,675 myLogger setOutputDataTable - summaryFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\summary
[INFO] 2019-01-19 13:30:45,676 myLogger main - alignedSample end
[INFO] 2019-01-19 13:30:45,678 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 13:30:45,686 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 13:30:45,695 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[ERROR] 2019-01-19 13:30:46,280 org.apache.spark.storage.DiskBlockManager logError - Exception while deleting local spark dir: C:\Users\dell\AppData\Local\Temp\blockmgr-b8d2347b-7f9c-4800-ad2d-e5bea8c31399
java.io.IOException: Failed to delete: C:\Users\dell\AppData\Local\Temp\blockmgr-b8d2347b-7f9c-4800-ad2d-e5bea8c31399
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:169)
	at org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1.apply(DiskBlockManager.scala:165)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:165)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:160)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1361)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:89)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
[INFO] 2019-01-19 13:30:46,284 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 13:30:46,284 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 13:30:46,285 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 13:30:46,287 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 13:30:46,291 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 13:30:46,291 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 13:30:46,292 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-acf03083-3ecf-48b6-bd14-acda3ad030b5
[INFO] 2019-01-19 13:56:21,780 myLogger main - SQL start
[INFO] 2019-01-19 13:56:23,102 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 13:56:23,605 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 13:56:23,607 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 13:56:23,607 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 13:56:23,671 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 13:56:23,672 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 13:56:23,672 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 13:56:23,673 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 13:56:23,674 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 13:56:24,356 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 58563.
[INFO] 2019-01-19 13:56:24,374 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 13:56:24,393 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 13:56:24,396 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 13:56:24,397 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 13:56:24,410 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-e2f1d3c1-b5bc-43af-b4e2-e635dd3264d1
[INFO] 2019-01-19 13:56:24,430 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 13:56:24,464 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 13:56:24,672 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 13:56:24,674 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 13:56:24,772 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 13:56:24,798 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58576.
[INFO] 2019-01-19 13:56:24,799 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:58576
[INFO] 2019-01-19 13:56:24,801 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 13:56:24,803 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 58576, None)
[INFO] 2019-01-19 13:56:24,805 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:58576 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 58576, None)
[INFO] 2019-01-19 13:56:24,809 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 58576, None)
[INFO] 2019-01-19 13:56:24,810 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 58576, None)
[INFO] 2019-01-19 13:56:25,068 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 13:56:25,281 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 13:56:25,926 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 13:56:25,947 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 13:56:25,947 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:56:25,948 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:56:25,949 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:56:25,957 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 13:56:26,065 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:56:26,119 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:56:26,123 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:58576 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:56:26,126 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:56:26,131 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:56:26,133 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 13:56:26,200 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 13:56:26,211 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 13:56:26,295 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 13:56:26,414 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 13:56:26,423 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 263 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:56:26,425 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:56:26,427 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.282 s
[INFO] 2019-01-19 13:56:26,432 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.505268 s
[INFO] 2019-01-19 13:56:26,869 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:58576 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:56:27,935 myLogger getInputDataTable - inputFilePath: None
[INFO] 2019-01-19 13:56:27,944 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 13:56:27,967 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 13:56:27,979 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2019-01-19 13:56:27,992 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 13:56:27,992 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 13:56:27,993 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 13:56:27,996 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 13:56:28,001 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 13:56:28,001 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 13:56:28,002 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-cb196a5d-e74d-4548-811a-4ca72d9346ec
[INFO] 2019-01-19 13:58:32,507 myLogger main - SQL start
[INFO] 2019-01-19 13:58:34,100 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 13:58:34,557 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 13:58:34,559 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 13:58:34,559 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 13:58:34,617 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 13:58:34,618 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 13:58:34,618 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 13:58:34,619 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 13:58:34,620 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 13:58:35,323 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 58643.
[INFO] 2019-01-19 13:58:35,341 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 13:58:35,360 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 13:58:35,363 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 13:58:35,364 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 13:58:35,376 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-76ebd825-7a61-4fd7-b904-e2a03d962cf8
[INFO] 2019-01-19 13:58:35,395 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 13:58:35,432 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 13:58:35,637 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 13:58:35,639 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 13:58:35,721 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 13:58:35,745 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58656.
[INFO] 2019-01-19 13:58:35,746 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:58656
[INFO] 2019-01-19 13:58:35,748 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 13:58:35,749 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 58656, None)
[INFO] 2019-01-19 13:58:35,751 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:58656 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 58656, None)
[INFO] 2019-01-19 13:58:35,754 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 58656, None)
[INFO] 2019-01-19 13:58:35,755 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 58656, None)
[INFO] 2019-01-19 13:58:35,992 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 13:58:36,215 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 13:58:36,899 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:64
[INFO] 2019-01-19 13:58:36,915 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:64) with 1 output partitions
[INFO] 2019-01-19 13:58:36,915 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:58:36,916 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 13:58:36,917 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 13:58:36,922 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64), which has no missing parents
[INFO] 2019-01-19 13:58:37,016 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:58:37,071 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 13:58:37,075 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:58656 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:58:37,078 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 13:58:37,082 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:64)
[INFO] 2019-01-19 13:58:37,084 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 13:58:37,141 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 13:58:37,149 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 13:58:37,238 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 13:58:37,352 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 13:58:37,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 250 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 13:58:37,363 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 13:58:37,366 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:64) finished in 0.270 s
[INFO] 2019-01-19 13:58:37,371 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:64, took 0.471718 s
[INFO] 2019-01-19 13:58:37,790 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:58656 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 13:58:38,851 myLogger getInputDataTable - inputFilePath: None
[INFO] 2019-01-19 13:58:38,872 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 13:58:38,882 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 13:58:38,891 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2019-01-19 13:58:38,906 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 13:58:38,906 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 13:58:38,908 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 13:58:38,910 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 13:58:38,915 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 13:58:38,916 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 13:58:38,917 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-3079ae76-bcc2-4a38-83b2-d0b7c1f7d71d
[INFO] 2019-01-19 14:01:16,017 myLogger main - SQL start
[INFO] 2019-01-19 14:01:17,565 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 14:01:18,005 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 14:01:18,007 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 14:01:18,007 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 14:01:18,062 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 14:01:18,062 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 14:01:18,063 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 14:01:18,063 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 14:01:18,064 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 14:01:18,796 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 58750.
[INFO] 2019-01-19 14:01:18,813 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 14:01:18,832 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 14:01:18,836 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 14:01:18,837 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 14:01:18,851 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-756a0f28-7ae2-4c3a-9114-3fe1f13728f4
[INFO] 2019-01-19 14:01:18,869 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 14:01:18,905 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 14:01:19,110 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 14:01:19,113 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 14:01:19,193 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 14:01:19,216 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58763.
[INFO] 2019-01-19 14:01:19,217 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:58763
[INFO] 2019-01-19 14:01:19,218 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 14:01:19,219 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 58763, None)
[INFO] 2019-01-19 14:01:19,222 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:58763 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 58763, None)
[INFO] 2019-01-19 14:01:19,225 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 58763, None)
[INFO] 2019-01-19 14:01:19,225 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 58763, None)
[INFO] 2019-01-19 14:01:19,460 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 14:01:19,672 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 14:01:20,338 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:66
[INFO] 2019-01-19 14:01:20,357 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:66) with 1 output partitions
[INFO] 2019-01-19 14:01:20,358 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:66)
[INFO] 2019-01-19 14:01:20,358 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 14:01:20,360 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 14:01:20,368 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:66), which has no missing parents
[INFO] 2019-01-19 14:01:20,473 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 14:01:20,523 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 14:01:20,528 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:58763 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 14:01:20,531 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:01:20,536 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:66)
[INFO] 2019-01-19 14:01:20,538 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 14:01:20,597 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 14:01:20,605 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 14:01:20,695 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 14:01:20,810 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 14:01:20,819 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 254 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:01:20,821 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:01:20,823 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:66) finished in 0.272 s
[INFO] 2019-01-19 14:01:20,829 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:66, took 0.489725 s
[INFO] 2019-01-19 14:01:21,235 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:58763 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 14:01:22,256 myLogger getInputDataTable - inputFilePath: None
[INFO] 2019-01-19 14:01:22,265 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 14:01:22,273 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 14:01:22,281 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2019-01-19 14:01:22,293 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 14:01:22,293 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 14:01:22,294 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 14:01:22,296 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 14:01:22,301 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 14:01:22,302 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 14:01:22,303 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-2203401f-286b-404a-b244-65e57141a93b
[INFO] 2019-01-19 14:07:32,554 myLogger main - SQL start
[INFO] 2019-01-19 14:07:33,364 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 14:07:33,870 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 14:07:33,872 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 14:07:33,873 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 14:07:33,974 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 14:07:33,975 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 14:07:33,976 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 14:07:33,977 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 14:07:33,977 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 14:07:34,806 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 58995.
[INFO] 2019-01-19 14:07:34,840 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 14:07:34,878 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 14:07:34,885 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 14:07:34,886 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 14:07:34,904 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-b31a6c09-66cd-451f-bbb0-142f961b8e67
[INFO] 2019-01-19 14:07:34,934 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 14:07:34,997 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 14:07:35,269 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 14:07:35,273 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 14:07:35,429 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 14:07:35,476 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59008.
[INFO] 2019-01-19 14:07:35,477 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:59008
[INFO] 2019-01-19 14:07:35,480 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 14:07:35,482 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 59008, None)
[INFO] 2019-01-19 14:07:35,487 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:59008 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 59008, None)
[INFO] 2019-01-19 14:07:35,494 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 59008, None)
[INFO] 2019-01-19 14:07:35,495 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 59008, None)
[INFO] 2019-01-19 14:07:35,864 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[WARN] 2019-01-19 14:09:13,438 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@1c41d954,BlockManagerId(driver, 192.168.99.1, 59008, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 15 more
[WARN] 2019-01-19 14:09:45,519 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored message: HeartbeatResponse(false)
[WARN] 2019-01-19 14:10:17,279 org.apache.spark.rpc.netty.NettyRpcEndpointRef logWarning - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@53b7f15f,BlockManagerId(driver, 192.168.99.1, 59008, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 10 seconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Failure.recover(Try.scala:216)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run$$$capture(Promise.scala:32)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run$$$capture(Promise.scala:32)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:239)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply in 10 seconds
	... 9 more
[WARN] 2019-01-19 14:10:17,290 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored message: HeartbeatResponse(false)
[WARN] 2019-01-19 14:11:06,304 org.apache.spark.rpc.netty.NettyRpcEnv logWarning - Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply in 10 seconds
[INFO] 2019-01-19 14:11:06,318 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 14:11:06,328 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 14:11:06,339 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2019-01-19 14:11:06,350 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 14:11:06,351 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 14:11:06,351 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 14:11:06,355 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 14:11:06,359 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 14:11:06,360 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 14:11:06,361 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-fdd25ec0-9a5f-44d6-8c9d-3722fb54a909
[INFO] 2019-01-19 14:11:25,446 myLogger main - SQL start
[INFO] 2019-01-19 14:11:27,111 org.apache.spark.SparkContext logInfo - Running Spark version 2.1.0
[WARN] 2019-01-19 14:11:27,601 org.apache.spark.SparkConf logWarning - 
SPARK_CLASSPATH was detected (set to 'F:\雅拓\大营销平台\spark\myjar').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
[WARN] 2019-01-19 14:11:27,602 org.apache.spark.SparkConf logWarning - Setting 'spark.executor.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[WARN] 2019-01-19 14:11:27,602 org.apache.spark.SparkConf logWarning - Setting 'spark.driver.extraClassPath' to 'F:\雅拓\大营销平台\spark\myjar' as a work-around.
[INFO] 2019-01-19 14:11:27,651 org.apache.spark.SecurityManager logInfo - Changing view acls to: dell
[INFO] 2019-01-19 14:11:27,651 org.apache.spark.SecurityManager logInfo - Changing modify acls to: dell
[INFO] 2019-01-19 14:11:27,652 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2019-01-19 14:11:27,652 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2019-01-19 14:11:27,653 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dell); groups with view permissions: Set(); users  with modify permissions: Set(dell); groups with modify permissions: Set()
[INFO] 2019-01-19 14:11:28,373 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 59089.
[INFO] 2019-01-19 14:11:28,392 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2019-01-19 14:11:28,410 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2019-01-19 14:11:28,413 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2019-01-19 14:11:28,414 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2019-01-19 14:11:28,427 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at C:\Users\dell\AppData\Local\Temp\blockmgr-8cda1d2b-0494-496e-aece-b57a6c1c9697
[INFO] 2019-01-19 14:11:28,447 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 1992.0 MB
[INFO] 2019-01-19 14:11:28,487 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2019-01-19 14:11:28,691 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2019-01-19 14:11:28,693 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://192.168.99.1:4040
[INFO] 2019-01-19 14:11:28,791 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2019-01-19 14:11:28,821 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59102.
[INFO] 2019-01-19 14:11:28,822 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 192.168.99.1:59102
[INFO] 2019-01-19 14:11:28,824 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2019-01-19 14:11:28,825 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 192.168.99.1, 59102, None)
[INFO] 2019-01-19 14:11:28,828 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 192.168.99.1:59102 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.99.1, 59102, None)
[INFO] 2019-01-19 14:11:28,832 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 192.168.99.1, 59102, None)
[INFO] 2019-01-19 14:11:28,832 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 192.168.99.1, 59102, None)
[INFO] 2019-01-19 14:11:29,089 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/F:/雅拓/算法平台/gitlab/lambda-mls/spark-warehouse/'.
[INFO] 2019-01-19 14:11:29,320 myLogger getInputDataTable - inputFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train
[INFO] 2019-01-19 14:11:29,963 org.apache.spark.SparkContext logInfo - Starting job: parquet at DecoupJson.scala:66
[INFO] 2019-01-19 14:11:29,979 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (parquet at DecoupJson.scala:66) with 1 output partitions
[INFO] 2019-01-19 14:11:29,980 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (parquet at DecoupJson.scala:66)
[INFO] 2019-01-19 14:11:29,980 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 14:11:29,981 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 14:11:29,987 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:66), which has no missing parents
[INFO] 2019-01-19 14:11:30,085 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 70.0 KB, free 1991.9 MB)
[INFO] 2019-01-19 14:11:30,132 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 1991.9 MB)
[INFO] 2019-01-19 14:11:30,134 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on 192.168.99.1:59102 (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 14:11:30,136 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:11:30,139 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at DecoupJson.scala:66)
[INFO] 2019-01-19 14:11:30,141 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2019-01-19 14:11:30,195 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6233 bytes)
[INFO] 2019-01-19 14:11:30,203 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2019-01-19 14:11:30,301 org.apache.parquet.hadoop.ParquetFileReader info - Initiating action with parallelism: 5
[INFO] 2019-01-19 14:11:30,425 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 4547 bytes result sent to driver
[INFO] 2019-01-19 14:11:30,435 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 273 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:11:30,437 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:11:30,439 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (parquet at DecoupJson.scala:66) finished in 0.289 s
[INFO] 2019-01-19 14:11:30,445 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: parquet at DecoupJson.scala:66, took 0.481820 s
[INFO] 2019-01-19 14:11:30,843 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_0_piece0 on 192.168.99.1:59102 in memory (size: 24.8 KB, free: 1992.0 MB)
[INFO] 2019-01-19 14:11:31,958 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: t1
[INFO] 2019-01-19 14:11:32,304 org.apache.spark.sql.execution.SparkSqlParser logInfo - Parsing command: select * from t1
[INFO] 2019-01-19 14:11:34,116 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 14:11:34,121 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 14:11:34,125 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 14:11:34,126 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[WARN] 2019-01-19 14:11:34,228 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2019-01-19 14:11:34,846 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 342.104094 ms
[INFO] 2019-01-19 14:11:34,893 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 292.7 KB, free 1991.7 MB)
[INFO] 2019-01-19 14:11:34,910 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1991.7 MB)
[INFO] 2019-01-19 14:11:34,911 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on 192.168.99.1:59102 (size: 25.4 KB, free: 1992.0 MB)
[INFO] 2019-01-19 14:11:34,913 org.apache.spark.SparkContext logInfo - Created broadcast 1 from head at DecoupJson.scala:144
[INFO] 2019-01-19 14:11:34,926 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 14:11:35,083 org.apache.spark.SparkContext logInfo - Starting job: head at DecoupJson.scala:144
[INFO] 2019-01-19 14:11:35,087 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 8 (head at DecoupJson.scala:144)
[INFO] 2019-01-19 14:11:35,088 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 13 (head at DecoupJson.scala:144)
[INFO] 2019-01-19 14:11:35,088 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (head at DecoupJson.scala:144) with 1 output partitions
[INFO] 2019-01-19 14:11:35,088 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 3 (head at DecoupJson.scala:144)
[INFO] 2019-01-19 14:11:35,088 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 2)
[INFO] 2019-01-19 14:11:35,089 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 2)
[INFO] 2019-01-19 14:11:35,090 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at head at DecoupJson.scala:144), which has no missing parents
[INFO] 2019-01-19 14:11:35,177 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2 stored as values in memory (estimated size 261.3 KB, free 1991.4 MB)
[INFO] 2019-01-19 14:11:35,181 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_2_piece0 stored as bytes in memory (estimated size 61.6 KB, free 1991.4 MB)
[INFO] 2019-01-19 14:11:35,184 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_2_piece0 in memory on 192.168.99.1:59102 (size: 61.6 KB, free: 1991.9 MB)
[INFO] 2019-01-19 14:11:35,185 org.apache.spark.SparkContext logInfo - Created broadcast 2 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:11:35,188 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at head at DecoupJson.scala:144)
[INFO] 2019-01-19 14:11:35,188 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2019-01-19 14:11:35,193 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6552 bytes)
[INFO] 2019-01-19 14:11:35,194 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2019-01-19 14:11:35,400 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 142.111005 ms
[INFO] 2019-01-19 14:11:35,443 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 32.820535 ms
[INFO] 2019-01-19 14:11:35,480 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 30.057427 ms
[INFO] 2019-01-19 14:11:35,513 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.339434 ms
[INFO] 2019-01-19 14:11:35,548 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 26.592612 ms
[INFO] 2019-01-19 14:11:35,584 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 28.725593 ms
[INFO] 2019-01-19 14:11:35,645 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 53.201445 ms
[INFO] 2019-01-19 14:11:35,676 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 25.642309 ms
[INFO] 2019-01-19 14:11:35,712 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 24.791798 ms
[INFO] 2019-01-19 14:11:35,742 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.177848 ms
[INFO] 2019-01-19 14:11:35,769 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.185913 ms
[INFO] 2019-01-19 14:11:35,799 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 22.079467 ms
[INFO] 2019-01-19 14:11:35,842 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 48
[INFO] 2019-01-19 14:11:35,845 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 40.151089 ms
[INFO] 2019-01-19 14:11:35,855 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 49
[INFO] 2019-01-19 14:11:35,877 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.074795 ms
[INFO] 2019-01-19 14:11:35,899 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.765529 ms
[INFO] 2019-01-19 14:11:35,921 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.464416 ms
[INFO] 2019-01-19 14:11:35,947 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 21.106597 ms
[INFO] 2019-01-19 14:11:35,969 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.149529 ms
[INFO] 2019-01-19 14:11:35,990 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.825121 ms
[INFO] 2019-01-19 14:11:36,011 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.09095 ms
[INFO] 2019-01-19 14:11:36,029 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.957287 ms
[INFO] 2019-01-19 14:11:36,048 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.239049 ms
[INFO] 2019-01-19 14:11:36,071 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.924603 ms
[INFO] 2019-01-19 14:11:36,095 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.84209 ms
[INFO] 2019-01-19 14:11:36,117 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.057496 ms
[INFO] 2019-01-19 14:11:36,142 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 19.476801 ms
[INFO] 2019-01-19 14:11:36,161 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.926631 ms
[INFO] 2019-01-19 14:11:36,187 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.797352 ms
[INFO] 2019-01-19 14:11:36,205 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.013352 ms
[INFO] 2019-01-19 14:11:36,224 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.664989 ms
[INFO] 2019-01-19 14:11:36,249 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 20.113274 ms
[INFO] 2019-01-19 14:11:36,269 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.628648 ms
[INFO] 2019-01-19 14:11:36,291 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 18.431291 ms
[INFO] 2019-01-19 14:11:36,314 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.314907 ms
[INFO] 2019-01-19 14:11:36,334 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.479556 ms
[INFO] 2019-01-19 14:11:36,356 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.855446 ms
[INFO] 2019-01-19 14:11:36,374 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.018289 ms
[INFO] 2019-01-19 14:11:36,397 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.829331 ms
[INFO] 2019-01-19 14:11:36,415 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.227766 ms
[INFO] 2019-01-19 14:11:36,435 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.590235 ms
[INFO] 2019-01-19 14:11:36,453 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.294741 ms
[INFO] 2019-01-19 14:11:36,473 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.03559 ms
[INFO] 2019-01-19 14:11:36,494 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.584989 ms
[INFO] 2019-01-19 14:11:36,514 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.680129 ms
[INFO] 2019-01-19 14:11:36,535 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.823358 ms
[INFO] 2019-01-19 14:11:36,554 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.007711 ms
[INFO] 2019-01-19 14:11:36,574 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.560636 ms
[INFO] 2019-01-19 14:11:36,595 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 16.027501 ms
[INFO] 2019-01-19 14:11:36,614 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.213287 ms
[INFO] 2019-01-19 14:11:36,632 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.496416 ms
[INFO] 2019-01-19 14:11:36,650 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.335292 ms
[INFO] 2019-01-19 14:11:36,743 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 78.307071 ms
[INFO] 2019-01-19 14:11:36,779 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 14.059194 ms
[INFO] 2019-01-19 14:11:36,794 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 14:11:36,951 org.apache.hadoop.io.compress.CodecPool getDecompressor - Got brand-new decompressor [.snappy]
[INFO] 2019-01-19 14:11:50,868 org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter spill - Thread 55 spilling sort data of 1984.0 MB to disk (0  time so far)
[INFO] 2019-01-19 14:12:01,858 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 45.768983 ms
[INFO] 2019-01-19 14:12:02,154 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 160.34201 ms
[INFO] 2019-01-19 14:12:02,199 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.615426 ms
[INFO] 2019-01-19 14:12:02,248 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 29.39486 ms
[INFO] 2019-01-19 14:12:02,280 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 15.598367 ms
[INFO] 2019-01-19 14:12:02,309 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 13.437177 ms
[INFO] 2019-01-19 14:13:10,498 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 2829 bytes result sent to driver
[INFO] 2019-01-19 14:13:10,501 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 95312 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:13:10,502 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:13:10,503 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 1 (head at DecoupJson.scala:144) finished in 95.314 s
[INFO] 2019-01-19 14:13:10,504 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 14:13:10,504 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 14:13:10,505 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ShuffleMapStage 2, ResultStage 3)
[INFO] 2019-01-19 14:13:10,506 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 14:13:10,510 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at head at DecoupJson.scala:144), which has no missing parents
[INFO] 2019-01-19 14:13:10,571 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3 stored as values in memory (estimated size 505.1 KB, free 1990.9 MB)
[INFO] 2019-01-19 14:13:10,574 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_3_piece0 stored as bytes in memory (estimated size 124.3 KB, free 1990.8 MB)
[INFO] 2019-01-19 14:13:10,575 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_3_piece0 in memory on 192.168.99.1:59102 (size: 124.3 KB, free: 1991.8 MB)
[INFO] 2019-01-19 14:13:10,576 org.apache.spark.SparkContext logInfo - Created broadcast 3 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:13:10,577 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 200 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at head at DecoupJson.scala:144)
[INFO] 2019-01-19 14:13:10,577 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 2.0 with 200 tasks
[INFO] 2019-01-19 14:13:10,582 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:10,582 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:10,582 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 2.0 (TID 2)
[INFO] 2019-01-19 14:13:10,583 org.apache.spark.executor.Executor logInfo - Running task 1.0 in stage 2.0 (TID 3)
[INFO] 2019-01-19 14:13:10,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:10,647 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:10,649 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 6 ms
[INFO] 2019-01-19 14:13:10,649 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 6 ms
[INFO] 2019-01-19 14:13:10,944 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 114.916123 ms
[INFO] 2019-01-19 14:13:11,116 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 78.61949 ms
[INFO] 2019-01-19 14:13:11,254 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 78.247479 ms
[INFO] 2019-01-19 14:13:11,321 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 44.087706 ms
[INFO] 2019-01-19 14:13:11,398 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 53.24658 ms
[INFO] 2019-01-19 14:13:11,901 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 168.407419 ms
[INFO] 2019-01-19 14:13:12,030 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 2.992661 ms
[INFO] 2019-01-19 14:13:12,173 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 91.906805 ms
[INFO] 2019-01-19 14:13:12,254 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 52.675693 ms
[INFO] 2019-01-19 14:13:13,517 org.apache.spark.executor.Executor logInfo - Finished task 1.0 in stage 2.0 (TID 3). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:13,518 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:13,519 org.apache.spark.executor.Executor logInfo - Running task 2.0 in stage 2.0 (TID 4)
[INFO] 2019-01-19 14:13:13,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 1.0 in stage 2.0 (TID 3) in 2941 ms on localhost (executor driver) (1/200)
[INFO] 2019-01-19 14:13:13,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:13,542 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:13,560 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 2.0 (TID 2). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:13,562 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:13,563 org.apache.spark.executor.Executor logInfo - Running task 3.0 in stage 2.0 (TID 5)
[INFO] 2019-01-19 14:13:13,586 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:13,587 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:13,602 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 2.0 (TID 2) in 3020 ms on localhost (executor driver) (2/200)
[INFO] 2019-01-19 14:13:14,882 org.apache.spark.executor.Executor logInfo - Finished task 2.0 in stage 2.0 (TID 4). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:14,883 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:14,884 org.apache.spark.executor.Executor logInfo - Running task 4.0 in stage 2.0 (TID 6)
[INFO] 2019-01-19 14:13:14,884 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 2.0 in stage 2.0 (TID 4) in 1366 ms on localhost (executor driver) (3/200)
[INFO] 2019-01-19 14:13:14,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:14,899 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:14,931 org.apache.spark.executor.Executor logInfo - Finished task 3.0 in stage 2.0 (TID 5). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:14,932 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:14,934 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 3.0 in stage 2.0 (TID 5) in 1374 ms on localhost (executor driver) (4/200)
[INFO] 2019-01-19 14:13:14,938 org.apache.spark.executor.Executor logInfo - Running task 5.0 in stage 2.0 (TID 7)
[INFO] 2019-01-19 14:13:14,967 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:14,968 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:16,195 org.apache.spark.executor.Executor logInfo - Finished task 4.0 in stage 2.0 (TID 6). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:16,196 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:16,196 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 4.0 in stage 2.0 (TID 6) in 1313 ms on localhost (executor driver) (5/200)
[INFO] 2019-01-19 14:13:16,197 org.apache.spark.executor.Executor logInfo - Running task 6.0 in stage 2.0 (TID 8)
[INFO] 2019-01-19 14:13:16,213 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:16,213 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:16,219 org.apache.spark.executor.Executor logInfo - Finished task 5.0 in stage 2.0 (TID 7). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:16,219 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:16,220 org.apache.spark.executor.Executor logInfo - Running task 7.0 in stage 2.0 (TID 9)
[INFO] 2019-01-19 14:13:16,220 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 5.0 in stage 2.0 (TID 7) in 1289 ms on localhost (executor driver) (6/200)
[INFO] 2019-01-19 14:13:16,235 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:16,235 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:17,689 org.apache.spark.executor.Executor logInfo - Finished task 6.0 in stage 2.0 (TID 8). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:17,693 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:17,695 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 6.0 in stage 2.0 (TID 8) in 1498 ms on localhost (executor driver) (7/200)
[INFO] 2019-01-19 14:13:17,698 org.apache.spark.executor.Executor logInfo - Running task 8.0 in stage 2.0 (TID 10)
[INFO] 2019-01-19 14:13:17,717 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:17,717 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:17,785 org.apache.spark.executor.Executor logInfo - Finished task 7.0 in stage 2.0 (TID 9). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:17,786 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:17,787 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 7.0 in stage 2.0 (TID 9) in 1567 ms on localhost (executor driver) (8/200)
[INFO] 2019-01-19 14:13:17,787 org.apache.spark.executor.Executor logInfo - Running task 9.0 in stage 2.0 (TID 11)
[INFO] 2019-01-19 14:13:17,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:17,802 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:19,121 org.apache.spark.executor.Executor logInfo - Finished task 8.0 in stage 2.0 (TID 10). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:19,122 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:19,123 org.apache.spark.executor.Executor logInfo - Running task 10.0 in stage 2.0 (TID 12)
[INFO] 2019-01-19 14:13:19,131 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 8.0 in stage 2.0 (TID 10) in 1437 ms on localhost (executor driver) (9/200)
[INFO] 2019-01-19 14:13:19,142 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:19,143 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:19,228 org.apache.spark.executor.Executor logInfo - Finished task 9.0 in stage 2.0 (TID 11). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:19,229 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:19,229 org.apache.spark.executor.Executor logInfo - Running task 11.0 in stage 2.0 (TID 13)
[INFO] 2019-01-19 14:13:19,229 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 9.0 in stage 2.0 (TID 11) in 1443 ms on localhost (executor driver) (10/200)
[INFO] 2019-01-19 14:13:19,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:19,246 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:20,468 org.apache.spark.executor.Executor logInfo - Finished task 10.0 in stage 2.0 (TID 12). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:20,469 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 12.0 in stage 2.0 (TID 14, localhost, executor driver, partition 12, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:20,470 org.apache.spark.executor.Executor logInfo - Running task 12.0 in stage 2.0 (TID 14)
[INFO] 2019-01-19 14:13:20,470 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 10.0 in stage 2.0 (TID 12) in 1348 ms on localhost (executor driver) (11/200)
[INFO] 2019-01-19 14:13:20,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:20,489 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:20,492 org.apache.spark.executor.Executor logInfo - Finished task 11.0 in stage 2.0 (TID 13). 3428 bytes result sent to driver
[INFO] 2019-01-19 14:13:20,494 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 13.0 in stage 2.0 (TID 15, localhost, executor driver, partition 13, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:20,494 org.apache.spark.executor.Executor logInfo - Running task 13.0 in stage 2.0 (TID 15)
[INFO] 2019-01-19 14:13:20,494 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 11.0 in stage 2.0 (TID 13) in 1266 ms on localhost (executor driver) (12/200)
[INFO] 2019-01-19 14:13:20,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:20,511 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:21,757 org.apache.spark.executor.Executor logInfo - Finished task 13.0 in stage 2.0 (TID 15). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:21,758 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 14.0 in stage 2.0 (TID 16, localhost, executor driver, partition 14, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:21,759 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 13.0 in stage 2.0 (TID 15) in 1266 ms on localhost (executor driver) (13/200)
[INFO] 2019-01-19 14:13:21,759 org.apache.spark.executor.Executor logInfo - Running task 14.0 in stage 2.0 (TID 16)
[INFO] 2019-01-19 14:13:21,768 org.apache.spark.executor.Executor logInfo - Finished task 12.0 in stage 2.0 (TID 14). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:21,770 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 15.0 in stage 2.0 (TID 17, localhost, executor driver, partition 15, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:21,770 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 12.0 in stage 2.0 (TID 14) in 1301 ms on localhost (executor driver) (14/200)
[INFO] 2019-01-19 14:13:21,771 org.apache.spark.executor.Executor logInfo - Running task 15.0 in stage 2.0 (TID 17)
[INFO] 2019-01-19 14:13:21,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:21,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:21,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:21,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:22,974 org.apache.spark.executor.Executor logInfo - Finished task 14.0 in stage 2.0 (TID 16). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:22,975 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 14.0 in stage 2.0 (TID 16) in 1218 ms on localhost (executor driver) (15/200)
[INFO] 2019-01-19 14:13:22,976 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 16.0 in stage 2.0 (TID 18, localhost, executor driver, partition 16, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:22,979 org.apache.spark.executor.Executor logInfo - Running task 16.0 in stage 2.0 (TID 18)
[INFO] 2019-01-19 14:13:22,995 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:22,995 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:23,014 org.apache.spark.executor.Executor logInfo - Finished task 15.0 in stage 2.0 (TID 17). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:23,016 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 17.0 in stage 2.0 (TID 19, localhost, executor driver, partition 17, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:23,016 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 15.0 in stage 2.0 (TID 17) in 1247 ms on localhost (executor driver) (16/200)
[INFO] 2019-01-19 14:13:23,017 org.apache.spark.executor.Executor logInfo - Running task 17.0 in stage 2.0 (TID 19)
[INFO] 2019-01-19 14:13:23,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:23,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:24,222 org.apache.spark.executor.Executor logInfo - Finished task 17.0 in stage 2.0 (TID 19). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:24,223 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 18.0 in stage 2.0 (TID 20, localhost, executor driver, partition 18, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:24,223 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 17.0 in stage 2.0 (TID 19) in 1208 ms on localhost (executor driver) (17/200)
[INFO] 2019-01-19 14:13:24,224 org.apache.spark.executor.Executor logInfo - Running task 18.0 in stage 2.0 (TID 20)
[INFO] 2019-01-19 14:13:24,239 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:24,240 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:24,274 org.apache.spark.executor.Executor logInfo - Finished task 16.0 in stage 2.0 (TID 18). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:24,275 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 19.0 in stage 2.0 (TID 21, localhost, executor driver, partition 19, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:24,276 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 16.0 in stage 2.0 (TID 18) in 1300 ms on localhost (executor driver) (18/200)
[INFO] 2019-01-19 14:13:24,276 org.apache.spark.executor.Executor logInfo - Running task 19.0 in stage 2.0 (TID 21)
[INFO] 2019-01-19 14:13:24,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:24,292 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:25,509 org.apache.spark.executor.Executor logInfo - Finished task 18.0 in stage 2.0 (TID 20). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:25,509 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 20.0 in stage 2.0 (TID 22, localhost, executor driver, partition 20, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:25,510 org.apache.spark.executor.Executor logInfo - Running task 20.0 in stage 2.0 (TID 22)
[INFO] 2019-01-19 14:13:25,510 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 18.0 in stage 2.0 (TID 20) in 1288 ms on localhost (executor driver) (19/200)
[INFO] 2019-01-19 14:13:25,528 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:25,529 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:25,549 org.apache.spark.executor.Executor logInfo - Finished task 19.0 in stage 2.0 (TID 21). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:25,550 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 21.0 in stage 2.0 (TID 23, localhost, executor driver, partition 21, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:25,550 org.apache.spark.executor.Executor logInfo - Running task 21.0 in stage 2.0 (TID 23)
[INFO] 2019-01-19 14:13:25,551 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 19.0 in stage 2.0 (TID 21) in 1277 ms on localhost (executor driver) (20/200)
[INFO] 2019-01-19 14:13:25,565 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:25,565 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:26,665 org.apache.spark.executor.Executor logInfo - Finished task 20.0 in stage 2.0 (TID 22). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:26,666 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 22.0 in stage 2.0 (TID 24, localhost, executor driver, partition 22, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:26,667 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 20.0 in stage 2.0 (TID 22) in 1158 ms on localhost (executor driver) (21/200)
[INFO] 2019-01-19 14:13:26,667 org.apache.spark.executor.Executor logInfo - Running task 22.0 in stage 2.0 (TID 24)
[INFO] 2019-01-19 14:13:26,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:26,685 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:26,725 org.apache.spark.executor.Executor logInfo - Finished task 21.0 in stage 2.0 (TID 23). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:26,726 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 23.0 in stage 2.0 (TID 25, localhost, executor driver, partition 23, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:26,726 org.apache.spark.executor.Executor logInfo - Running task 23.0 in stage 2.0 (TID 25)
[INFO] 2019-01-19 14:13:26,726 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 21.0 in stage 2.0 (TID 23) in 1176 ms on localhost (executor driver) (22/200)
[INFO] 2019-01-19 14:13:26,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:26,741 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:27,951 org.apache.spark.executor.Executor logInfo - Finished task 22.0 in stage 2.0 (TID 24). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:27,953 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 24.0 in stage 2.0 (TID 26, localhost, executor driver, partition 24, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:27,953 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 22.0 in stage 2.0 (TID 24) in 1288 ms on localhost (executor driver) (23/200)
[INFO] 2019-01-19 14:13:27,954 org.apache.spark.executor.Executor logInfo - Running task 24.0 in stage 2.0 (TID 26)
[INFO] 2019-01-19 14:13:27,972 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:27,973 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:27,989 org.apache.spark.executor.Executor logInfo - Finished task 23.0 in stage 2.0 (TID 25). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:27,990 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 25.0 in stage 2.0 (TID 27, localhost, executor driver, partition 25, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:27,990 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 23.0 in stage 2.0 (TID 25) in 1265 ms on localhost (executor driver) (24/200)
[INFO] 2019-01-19 14:13:27,991 org.apache.spark.executor.Executor logInfo - Running task 25.0 in stage 2.0 (TID 27)
[INFO] 2019-01-19 14:13:28,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:28,010 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:29,229 org.apache.spark.executor.Executor logInfo - Finished task 24.0 in stage 2.0 (TID 26). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:29,231 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 26.0 in stage 2.0 (TID 28, localhost, executor driver, partition 26, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:29,232 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 24.0 in stage 2.0 (TID 26) in 1280 ms on localhost (executor driver) (25/200)
[INFO] 2019-01-19 14:13:29,234 org.apache.spark.executor.Executor logInfo - Running task 26.0 in stage 2.0 (TID 28)
[INFO] 2019-01-19 14:13:29,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:29,253 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:29,304 org.apache.spark.executor.Executor logInfo - Finished task 25.0 in stage 2.0 (TID 27). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:29,305 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 27.0 in stage 2.0 (TID 29, localhost, executor driver, partition 27, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:29,306 org.apache.spark.executor.Executor logInfo - Running task 27.0 in stage 2.0 (TID 29)
[INFO] 2019-01-19 14:13:29,306 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 25.0 in stage 2.0 (TID 27) in 1317 ms on localhost (executor driver) (26/200)
[INFO] 2019-01-19 14:13:29,321 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:29,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:30,204 org.apache.spark.executor.Executor logInfo - Finished task 26.0 in stage 2.0 (TID 28). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:30,205 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 28.0 in stage 2.0 (TID 30, localhost, executor driver, partition 28, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:30,206 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 26.0 in stage 2.0 (TID 28) in 976 ms on localhost (executor driver) (27/200)
[INFO] 2019-01-19 14:13:30,207 org.apache.spark.executor.Executor logInfo - Running task 28.0 in stage 2.0 (TID 30)
[INFO] 2019-01-19 14:13:30,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:30,223 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:30,226 org.apache.spark.executor.Executor logInfo - Finished task 27.0 in stage 2.0 (TID 29). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:30,228 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 29.0 in stage 2.0 (TID 31, localhost, executor driver, partition 29, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:30,229 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 27.0 in stage 2.0 (TID 29) in 924 ms on localhost (executor driver) (28/200)
[INFO] 2019-01-19 14:13:30,230 org.apache.spark.executor.Executor logInfo - Running task 29.0 in stage 2.0 (TID 31)
[INFO] 2019-01-19 14:13:30,247 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:30,247 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:31,104 org.apache.spark.executor.Executor logInfo - Finished task 28.0 in stage 2.0 (TID 30). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:31,105 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 30.0 in stage 2.0 (TID 32, localhost, executor driver, partition 30, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:31,105 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 28.0 in stage 2.0 (TID 30) in 900 ms on localhost (executor driver) (29/200)
[INFO] 2019-01-19 14:13:31,105 org.apache.spark.executor.Executor logInfo - Running task 30.0 in stage 2.0 (TID 32)
[INFO] 2019-01-19 14:13:31,122 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:31,122 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:31,137 org.apache.spark.executor.Executor logInfo - Finished task 29.0 in stage 2.0 (TID 31). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:31,137 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 31.0 in stage 2.0 (TID 33, localhost, executor driver, partition 31, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:31,138 org.apache.spark.executor.Executor logInfo - Running task 31.0 in stage 2.0 (TID 33)
[INFO] 2019-01-19 14:13:31,138 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 29.0 in stage 2.0 (TID 31) in 911 ms on localhost (executor driver) (30/200)
[INFO] 2019-01-19 14:13:31,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:31,155 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:31,865 org.apache.spark.executor.Executor logInfo - Finished task 31.0 in stage 2.0 (TID 33). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:31,866 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 32.0 in stage 2.0 (TID 34, localhost, executor driver, partition 32, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:31,866 org.apache.spark.executor.Executor logInfo - Running task 32.0 in stage 2.0 (TID 34)
[INFO] 2019-01-19 14:13:31,866 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 31.0 in stage 2.0 (TID 33) in 729 ms on localhost (executor driver) (31/200)
[INFO] 2019-01-19 14:13:31,871 org.apache.spark.executor.Executor logInfo - Finished task 30.0 in stage 2.0 (TID 32). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:31,872 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 33.0 in stage 2.0 (TID 35, localhost, executor driver, partition 33, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:31,872 org.apache.spark.executor.Executor logInfo - Running task 33.0 in stage 2.0 (TID 35)
[INFO] 2019-01-19 14:13:31,872 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 30.0 in stage 2.0 (TID 32) in 768 ms on localhost (executor driver) (32/200)
[INFO] 2019-01-19 14:13:31,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:31,883 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:31,888 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:31,889 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:32,534 org.apache.spark.executor.Executor logInfo - Finished task 33.0 in stage 2.0 (TID 35). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:32,535 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 34.0 in stage 2.0 (TID 36, localhost, executor driver, partition 34, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:32,535 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 33.0 in stage 2.0 (TID 35) in 664 ms on localhost (executor driver) (33/200)
[INFO] 2019-01-19 14:13:32,535 org.apache.spark.executor.Executor logInfo - Running task 34.0 in stage 2.0 (TID 36)
[INFO] 2019-01-19 14:13:32,550 org.apache.spark.executor.Executor logInfo - Finished task 32.0 in stage 2.0 (TID 34). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:32,551 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 35.0 in stage 2.0 (TID 37, localhost, executor driver, partition 35, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:32,551 org.apache.spark.executor.Executor logInfo - Running task 35.0 in stage 2.0 (TID 37)
[INFO] 2019-01-19 14:13:32,551 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 32.0 in stage 2.0 (TID 34) in 686 ms on localhost (executor driver) (34/200)
[INFO] 2019-01-19 14:13:32,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:32,553 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:32,566 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:32,567 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:33,198 org.apache.spark.executor.Executor logInfo - Finished task 34.0 in stage 2.0 (TID 36). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:33,199 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 36.0 in stage 2.0 (TID 38, localhost, executor driver, partition 36, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:33,200 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 34.0 in stage 2.0 (TID 36) in 666 ms on localhost (executor driver) (35/200)
[INFO] 2019-01-19 14:13:33,201 org.apache.spark.executor.Executor logInfo - Running task 36.0 in stage 2.0 (TID 38)
[INFO] 2019-01-19 14:13:33,208 org.apache.spark.executor.Executor logInfo - Finished task 35.0 in stage 2.0 (TID 37). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:33,209 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 37.0 in stage 2.0 (TID 39, localhost, executor driver, partition 37, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:33,210 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 35.0 in stage 2.0 (TID 37) in 660 ms on localhost (executor driver) (36/200)
[INFO] 2019-01-19 14:13:33,210 org.apache.spark.executor.Executor logInfo - Running task 37.0 in stage 2.0 (TID 39)
[INFO] 2019-01-19 14:13:33,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:33,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:33,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:33,221 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:33,753 org.apache.spark.executor.Executor logInfo - Finished task 37.0 in stage 2.0 (TID 39). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:33,753 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 38.0 in stage 2.0 (TID 40, localhost, executor driver, partition 38, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:33,753 org.apache.spark.executor.Executor logInfo - Running task 38.0 in stage 2.0 (TID 40)
[INFO] 2019-01-19 14:13:33,753 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 37.0 in stage 2.0 (TID 39) in 544 ms on localhost (executor driver) (37/200)
[INFO] 2019-01-19 14:13:33,759 org.apache.spark.executor.Executor logInfo - Finished task 36.0 in stage 2.0 (TID 38). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:33,760 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 39.0 in stage 2.0 (TID 41, localhost, executor driver, partition 39, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:33,761 org.apache.spark.executor.Executor logInfo - Running task 39.0 in stage 2.0 (TID 41)
[INFO] 2019-01-19 14:13:33,761 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 36.0 in stage 2.0 (TID 38) in 562 ms on localhost (executor driver) (38/200)
[INFO] 2019-01-19 14:13:33,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:33,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:33,771 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:33,771 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:34,279 org.apache.spark.executor.Executor logInfo - Finished task 39.0 in stage 2.0 (TID 41). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:34,280 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 40.0 in stage 2.0 (TID 42, localhost, executor driver, partition 40, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:34,281 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 39.0 in stage 2.0 (TID 41) in 521 ms on localhost (executor driver) (39/200)
[INFO] 2019-01-19 14:13:34,281 org.apache.spark.executor.Executor logInfo - Running task 40.0 in stage 2.0 (TID 42)
[INFO] 2019-01-19 14:13:34,295 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:34,295 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:34,296 org.apache.spark.executor.Executor logInfo - Finished task 38.0 in stage 2.0 (TID 40). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:34,297 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 41.0 in stage 2.0 (TID 43, localhost, executor driver, partition 41, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:34,297 org.apache.spark.executor.Executor logInfo - Running task 41.0 in stage 2.0 (TID 43)
[INFO] 2019-01-19 14:13:34,297 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 38.0 in stage 2.0 (TID 40) in 544 ms on localhost (executor driver) (40/200)
[INFO] 2019-01-19 14:13:34,311 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:34,311 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:34,851 org.apache.spark.executor.Executor logInfo - Finished task 40.0 in stage 2.0 (TID 42). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:34,852 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 42.0 in stage 2.0 (TID 44, localhost, executor driver, partition 42, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:34,853 org.apache.spark.executor.Executor logInfo - Running task 42.0 in stage 2.0 (TID 44)
[INFO] 2019-01-19 14:13:34,854 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 40.0 in stage 2.0 (TID 42) in 573 ms on localhost (executor driver) (41/200)
[INFO] 2019-01-19 14:13:34,862 org.apache.spark.executor.Executor logInfo - Finished task 41.0 in stage 2.0 (TID 43). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:34,863 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 43.0 in stage 2.0 (TID 45, localhost, executor driver, partition 43, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:34,863 org.apache.spark.executor.Executor logInfo - Running task 43.0 in stage 2.0 (TID 45)
[INFO] 2019-01-19 14:13:34,863 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 41.0 in stage 2.0 (TID 43) in 567 ms on localhost (executor driver) (42/200)
[INFO] 2019-01-19 14:13:34,869 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:34,870 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:34,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:34,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:35,400 org.apache.spark.executor.Executor logInfo - Finished task 42.0 in stage 2.0 (TID 44). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:35,401 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 44.0 in stage 2.0 (TID 46, localhost, executor driver, partition 44, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:35,401 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 42.0 in stage 2.0 (TID 44) in 549 ms on localhost (executor driver) (43/200)
[INFO] 2019-01-19 14:13:35,402 org.apache.spark.executor.Executor logInfo - Running task 44.0 in stage 2.0 (TID 46)
[INFO] 2019-01-19 14:13:35,405 org.apache.spark.executor.Executor logInfo - Finished task 43.0 in stage 2.0 (TID 45). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:35,405 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 45.0 in stage 2.0 (TID 47, localhost, executor driver, partition 45, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:35,405 org.apache.spark.executor.Executor logInfo - Running task 45.0 in stage 2.0 (TID 47)
[INFO] 2019-01-19 14:13:35,406 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 43.0 in stage 2.0 (TID 45) in 542 ms on localhost (executor driver) (44/200)
[INFO] 2019-01-19 14:13:35,414 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:35,415 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:35,415 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:35,415 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:35,915 org.apache.spark.executor.Executor logInfo - Finished task 45.0 in stage 2.0 (TID 47). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:35,915 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 46.0 in stage 2.0 (TID 48, localhost, executor driver, partition 46, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:35,916 org.apache.spark.executor.Executor logInfo - Running task 46.0 in stage 2.0 (TID 48)
[INFO] 2019-01-19 14:13:35,916 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 45.0 in stage 2.0 (TID 47) in 511 ms on localhost (executor driver) (45/200)
[INFO] 2019-01-19 14:13:35,928 org.apache.spark.executor.Executor logInfo - Finished task 44.0 in stage 2.0 (TID 46). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:35,928 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 47.0 in stage 2.0 (TID 49, localhost, executor driver, partition 47, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:35,928 org.apache.spark.executor.Executor logInfo - Running task 47.0 in stage 2.0 (TID 49)
[INFO] 2019-01-19 14:13:35,928 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 44.0 in stage 2.0 (TID 46) in 527 ms on localhost (executor driver) (46/200)
[INFO] 2019-01-19 14:13:35,931 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:35,931 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:35,943 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:35,943 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:36,437 org.apache.spark.executor.Executor logInfo - Finished task 46.0 in stage 2.0 (TID 48). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:36,438 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 48.0 in stage 2.0 (TID 50, localhost, executor driver, partition 48, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:36,439 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 46.0 in stage 2.0 (TID 48) in 523 ms on localhost (executor driver) (47/200)
[INFO] 2019-01-19 14:13:36,439 org.apache.spark.executor.Executor logInfo - Running task 48.0 in stage 2.0 (TID 50)
[INFO] 2019-01-19 14:13:36,442 org.apache.spark.executor.Executor logInfo - Finished task 47.0 in stage 2.0 (TID 49). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:36,443 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 49.0 in stage 2.0 (TID 51, localhost, executor driver, partition 49, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:36,443 org.apache.spark.executor.Executor logInfo - Running task 49.0 in stage 2.0 (TID 51)
[INFO] 2019-01-19 14:13:36,443 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 47.0 in stage 2.0 (TID 49) in 515 ms on localhost (executor driver) (48/200)
[INFO] 2019-01-19 14:13:36,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:36,448 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:36,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:36,453 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:36,967 org.apache.spark.executor.Executor logInfo - Finished task 48.0 in stage 2.0 (TID 50). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:36,967 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 50.0 in stage 2.0 (TID 52, localhost, executor driver, partition 50, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:36,967 org.apache.spark.executor.Executor logInfo - Running task 50.0 in stage 2.0 (TID 52)
[INFO] 2019-01-19 14:13:36,968 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 48.0 in stage 2.0 (TID 50) in 530 ms on localhost (executor driver) (49/200)
[INFO] 2019-01-19 14:13:36,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:36,981 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:36,992 org.apache.spark.executor.Executor logInfo - Finished task 49.0 in stage 2.0 (TID 51). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:36,992 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 51.0 in stage 2.0 (TID 53, localhost, executor driver, partition 51, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:36,993 org.apache.spark.executor.Executor logInfo - Running task 51.0 in stage 2.0 (TID 53)
[INFO] 2019-01-19 14:13:36,993 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 49.0 in stage 2.0 (TID 51) in 551 ms on localhost (executor driver) (50/200)
[INFO] 2019-01-19 14:13:37,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:37,007 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:37,526 org.apache.spark.executor.Executor logInfo - Finished task 50.0 in stage 2.0 (TID 52). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:37,527 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 52.0 in stage 2.0 (TID 54, localhost, executor driver, partition 52, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:37,527 org.apache.spark.executor.Executor logInfo - Running task 52.0 in stage 2.0 (TID 54)
[INFO] 2019-01-19 14:13:37,527 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 50.0 in stage 2.0 (TID 52) in 560 ms on localhost (executor driver) (51/200)
[INFO] 2019-01-19 14:13:37,540 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:37,540 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:37,545 org.apache.spark.executor.Executor logInfo - Finished task 51.0 in stage 2.0 (TID 53). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:37,546 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 53.0 in stage 2.0 (TID 55, localhost, executor driver, partition 53, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:37,546 org.apache.spark.executor.Executor logInfo - Running task 53.0 in stage 2.0 (TID 55)
[INFO] 2019-01-19 14:13:37,546 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 51.0 in stage 2.0 (TID 53) in 554 ms on localhost (executor driver) (52/200)
[INFO] 2019-01-19 14:13:37,557 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:37,557 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:38,096 org.apache.spark.executor.Executor logInfo - Finished task 52.0 in stage 2.0 (TID 54). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:38,097 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 54.0 in stage 2.0 (TID 56, localhost, executor driver, partition 54, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:38,097 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 52.0 in stage 2.0 (TID 54) in 571 ms on localhost (executor driver) (53/200)
[INFO] 2019-01-19 14:13:38,098 org.apache.spark.executor.Executor logInfo - Running task 54.0 in stage 2.0 (TID 56)
[INFO] 2019-01-19 14:13:38,102 org.apache.spark.executor.Executor logInfo - Finished task 53.0 in stage 2.0 (TID 55). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:38,102 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 55.0 in stage 2.0 (TID 57, localhost, executor driver, partition 55, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:38,102 org.apache.spark.executor.Executor logInfo - Running task 55.0 in stage 2.0 (TID 57)
[INFO] 2019-01-19 14:13:38,103 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 53.0 in stage 2.0 (TID 55) in 557 ms on localhost (executor driver) (54/200)
[INFO] 2019-01-19 14:13:38,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:38,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:38,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:38,111 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:38,670 org.apache.spark.executor.Executor logInfo - Finished task 55.0 in stage 2.0 (TID 57). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:38,670 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 56.0 in stage 2.0 (TID 58, localhost, executor driver, partition 56, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:38,671 org.apache.spark.executor.Executor logInfo - Running task 56.0 in stage 2.0 (TID 58)
[INFO] 2019-01-19 14:13:38,671 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 55.0 in stage 2.0 (TID 57) in 569 ms on localhost (executor driver) (55/200)
[INFO] 2019-01-19 14:13:38,688 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:38,688 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:38,699 org.apache.spark.executor.Executor logInfo - Finished task 54.0 in stage 2.0 (TID 56). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:38,700 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 57.0 in stage 2.0 (TID 59, localhost, executor driver, partition 57, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:38,700 org.apache.spark.executor.Executor logInfo - Running task 57.0 in stage 2.0 (TID 59)
[INFO] 2019-01-19 14:13:38,701 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 54.0 in stage 2.0 (TID 56) in 603 ms on localhost (executor driver) (56/200)
[INFO] 2019-01-19 14:13:38,714 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:38,714 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:39,198 org.apache.spark.executor.Executor logInfo - Finished task 56.0 in stage 2.0 (TID 58). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:39,199 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 58.0 in stage 2.0 (TID 60, localhost, executor driver, partition 58, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:39,199 org.apache.spark.executor.Executor logInfo - Running task 58.0 in stage 2.0 (TID 60)
[INFO] 2019-01-19 14:13:39,199 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 56.0 in stage 2.0 (TID 58) in 529 ms on localhost (executor driver) (57/200)
[INFO] 2019-01-19 14:13:39,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:39,212 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:39,221 org.apache.spark.executor.Executor logInfo - Finished task 57.0 in stage 2.0 (TID 59). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:39,222 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 59.0 in stage 2.0 (TID 61, localhost, executor driver, partition 59, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:39,222 org.apache.spark.executor.Executor logInfo - Running task 59.0 in stage 2.0 (TID 61)
[INFO] 2019-01-19 14:13:39,222 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 57.0 in stage 2.0 (TID 59) in 522 ms on localhost (executor driver) (58/200)
[INFO] 2019-01-19 14:13:39,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:39,232 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:39,696 org.apache.spark.executor.Executor logInfo - Finished task 58.0 in stage 2.0 (TID 60). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:39,697 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 60.0 in stage 2.0 (TID 62, localhost, executor driver, partition 60, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:39,697 org.apache.spark.executor.Executor logInfo - Running task 60.0 in stage 2.0 (TID 62)
[INFO] 2019-01-19 14:13:39,697 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 58.0 in stage 2.0 (TID 60) in 499 ms on localhost (executor driver) (59/200)
[INFO] 2019-01-19 14:13:39,708 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:39,708 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:39,752 org.apache.spark.executor.Executor logInfo - Finished task 59.0 in stage 2.0 (TID 61). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:39,752 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 61.0 in stage 2.0 (TID 63, localhost, executor driver, partition 61, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:39,753 org.apache.spark.executor.Executor logInfo - Running task 61.0 in stage 2.0 (TID 63)
[INFO] 2019-01-19 14:13:39,753 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 59.0 in stage 2.0 (TID 61) in 531 ms on localhost (executor driver) (60/200)
[INFO] 2019-01-19 14:13:39,763 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:39,763 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:40,194 org.apache.spark.executor.Executor logInfo - Finished task 60.0 in stage 2.0 (TID 62). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:40,195 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 62.0 in stage 2.0 (TID 64, localhost, executor driver, partition 62, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:40,195 org.apache.spark.executor.Executor logInfo - Running task 62.0 in stage 2.0 (TID 64)
[INFO] 2019-01-19 14:13:40,195 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 60.0 in stage 2.0 (TID 62) in 499 ms on localhost (executor driver) (61/200)
[INFO] 2019-01-19 14:13:40,205 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:40,206 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:40,258 org.apache.spark.executor.Executor logInfo - Finished task 61.0 in stage 2.0 (TID 63). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:40,259 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 63.0 in stage 2.0 (TID 65, localhost, executor driver, partition 63, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:40,259 org.apache.spark.executor.Executor logInfo - Running task 63.0 in stage 2.0 (TID 65)
[INFO] 2019-01-19 14:13:40,259 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 61.0 in stage 2.0 (TID 63) in 507 ms on localhost (executor driver) (62/200)
[INFO] 2019-01-19 14:13:40,279 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:40,279 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:40,712 org.apache.spark.executor.Executor logInfo - Finished task 62.0 in stage 2.0 (TID 64). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:40,713 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 64.0 in stage 2.0 (TID 66, localhost, executor driver, partition 64, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:40,713 org.apache.spark.executor.Executor logInfo - Running task 64.0 in stage 2.0 (TID 66)
[INFO] 2019-01-19 14:13:40,713 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 62.0 in stage 2.0 (TID 64) in 519 ms on localhost (executor driver) (63/200)
[INFO] 2019-01-19 14:13:40,725 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:40,725 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:40,772 org.apache.spark.executor.Executor logInfo - Finished task 63.0 in stage 2.0 (TID 65). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:40,772 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 65.0 in stage 2.0 (TID 67, localhost, executor driver, partition 65, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:40,773 org.apache.spark.executor.Executor logInfo - Running task 65.0 in stage 2.0 (TID 67)
[INFO] 2019-01-19 14:13:40,773 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 63.0 in stage 2.0 (TID 65) in 514 ms on localhost (executor driver) (64/200)
[INFO] 2019-01-19 14:13:40,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:40,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:41,237 org.apache.spark.executor.Executor logInfo - Finished task 64.0 in stage 2.0 (TID 66). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:41,238 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 66.0 in stage 2.0 (TID 68, localhost, executor driver, partition 66, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:41,238 org.apache.spark.executor.Executor logInfo - Running task 66.0 in stage 2.0 (TID 68)
[INFO] 2019-01-19 14:13:41,238 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 64.0 in stage 2.0 (TID 66) in 526 ms on localhost (executor driver) (65/200)
[INFO] 2019-01-19 14:13:41,248 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:41,248 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:41,288 org.apache.spark.executor.Executor logInfo - Finished task 65.0 in stage 2.0 (TID 67). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:41,289 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 67.0 in stage 2.0 (TID 69, localhost, executor driver, partition 67, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:41,289 org.apache.spark.executor.Executor logInfo - Running task 67.0 in stage 2.0 (TID 69)
[INFO] 2019-01-19 14:13:41,289 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 65.0 in stage 2.0 (TID 67) in 517 ms on localhost (executor driver) (66/200)
[INFO] 2019-01-19 14:13:41,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:41,299 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:41,773 org.apache.spark.executor.Executor logInfo - Finished task 66.0 in stage 2.0 (TID 68). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:41,773 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 68.0 in stage 2.0 (TID 70, localhost, executor driver, partition 68, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:41,774 org.apache.spark.executor.Executor logInfo - Running task 68.0 in stage 2.0 (TID 70)
[INFO] 2019-01-19 14:13:41,774 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 66.0 in stage 2.0 (TID 68) in 536 ms on localhost (executor driver) (67/200)
[INFO] 2019-01-19 14:13:41,787 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:41,788 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:41,833 org.apache.spark.executor.Executor logInfo - Finished task 67.0 in stage 2.0 (TID 69). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:41,834 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 69.0 in stage 2.0 (TID 71, localhost, executor driver, partition 69, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:41,834 org.apache.spark.executor.Executor logInfo - Running task 69.0 in stage 2.0 (TID 71)
[INFO] 2019-01-19 14:13:41,834 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 67.0 in stage 2.0 (TID 69) in 546 ms on localhost (executor driver) (68/200)
[INFO] 2019-01-19 14:13:41,844 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:41,844 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:42,311 org.apache.spark.executor.Executor logInfo - Finished task 68.0 in stage 2.0 (TID 70). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:42,312 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 70.0 in stage 2.0 (TID 72, localhost, executor driver, partition 70, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:42,312 org.apache.spark.executor.Executor logInfo - Running task 70.0 in stage 2.0 (TID 72)
[INFO] 2019-01-19 14:13:42,312 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 68.0 in stage 2.0 (TID 70) in 539 ms on localhost (executor driver) (69/200)
[INFO] 2019-01-19 14:13:42,322 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:42,323 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:42,336 org.apache.spark.executor.Executor logInfo - Finished task 69.0 in stage 2.0 (TID 71). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:42,337 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 71.0 in stage 2.0 (TID 73, localhost, executor driver, partition 71, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:42,337 org.apache.spark.executor.Executor logInfo - Running task 71.0 in stage 2.0 (TID 73)
[INFO] 2019-01-19 14:13:42,337 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 69.0 in stage 2.0 (TID 71) in 503 ms on localhost (executor driver) (70/200)
[INFO] 2019-01-19 14:13:42,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:42,347 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:42,836 org.apache.spark.executor.Executor logInfo - Finished task 70.0 in stage 2.0 (TID 72). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:42,836 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 72.0 in stage 2.0 (TID 74, localhost, executor driver, partition 72, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:42,837 org.apache.spark.executor.Executor logInfo - Running task 72.0 in stage 2.0 (TID 74)
[INFO] 2019-01-19 14:13:42,837 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 70.0 in stage 2.0 (TID 72) in 525 ms on localhost (executor driver) (71/200)
[INFO] 2019-01-19 14:13:42,850 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:42,850 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:42,855 org.apache.spark.executor.Executor logInfo - Finished task 71.0 in stage 2.0 (TID 73). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:42,856 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 73.0 in stage 2.0 (TID 75, localhost, executor driver, partition 73, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:42,856 org.apache.spark.executor.Executor logInfo - Running task 73.0 in stage 2.0 (TID 75)
[INFO] 2019-01-19 14:13:42,856 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 71.0 in stage 2.0 (TID 73) in 520 ms on localhost (executor driver) (72/200)
[INFO] 2019-01-19 14:13:42,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:42,864 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:43,333 org.apache.spark.executor.Executor logInfo - Finished task 72.0 in stage 2.0 (TID 74). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:43,333 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 74.0 in stage 2.0 (TID 76, localhost, executor driver, partition 74, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:43,334 org.apache.spark.executor.Executor logInfo - Running task 74.0 in stage 2.0 (TID 76)
[INFO] 2019-01-19 14:13:43,334 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 72.0 in stage 2.0 (TID 74) in 498 ms on localhost (executor driver) (73/200)
[INFO] 2019-01-19 14:13:43,346 org.apache.spark.executor.Executor logInfo - Finished task 73.0 in stage 2.0 (TID 75). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:43,347 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 75.0 in stage 2.0 (TID 77, localhost, executor driver, partition 75, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:43,347 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 73.0 in stage 2.0 (TID 75) in 492 ms on localhost (executor driver) (74/200)
[INFO] 2019-01-19 14:13:43,349 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:43,349 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:43,362 org.apache.spark.executor.Executor logInfo - Running task 75.0 in stage 2.0 (TID 77)
[INFO] 2019-01-19 14:13:43,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:43,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:43,844 org.apache.spark.executor.Executor logInfo - Finished task 74.0 in stage 2.0 (TID 76). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:43,844 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 76.0 in stage 2.0 (TID 78, localhost, executor driver, partition 76, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:43,845 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 74.0 in stage 2.0 (TID 76) in 512 ms on localhost (executor driver) (75/200)
[INFO] 2019-01-19 14:13:43,845 org.apache.spark.executor.Executor logInfo - Running task 76.0 in stage 2.0 (TID 78)
[INFO] 2019-01-19 14:13:43,849 org.apache.spark.executor.Executor logInfo - Finished task 75.0 in stage 2.0 (TID 77). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:43,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 77.0 in stage 2.0 (TID 79, localhost, executor driver, partition 77, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:43,850 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 75.0 in stage 2.0 (TID 77) in 504 ms on localhost (executor driver) (76/200)
[INFO] 2019-01-19 14:13:43,851 org.apache.spark.executor.Executor logInfo - Running task 77.0 in stage 2.0 (TID 79)
[INFO] 2019-01-19 14:13:43,855 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:43,855 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:43,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:43,865 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:44,319 org.apache.spark.executor.Executor logInfo - Finished task 76.0 in stage 2.0 (TID 78). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:44,320 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 78.0 in stage 2.0 (TID 80, localhost, executor driver, partition 78, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:44,320 org.apache.spark.executor.Executor logInfo - Running task 78.0 in stage 2.0 (TID 80)
[INFO] 2019-01-19 14:13:44,320 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 76.0 in stage 2.0 (TID 78) in 476 ms on localhost (executor driver) (77/200)
[INFO] 2019-01-19 14:13:44,324 org.apache.spark.executor.Executor logInfo - Finished task 77.0 in stage 2.0 (TID 79). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:44,325 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 79.0 in stage 2.0 (TID 81, localhost, executor driver, partition 79, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:44,325 org.apache.spark.executor.Executor logInfo - Running task 79.0 in stage 2.0 (TID 81)
[INFO] 2019-01-19 14:13:44,325 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 77.0 in stage 2.0 (TID 79) in 476 ms on localhost (executor driver) (78/200)
[INFO] 2019-01-19 14:13:44,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:44,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:44,334 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:44,335 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:44,826 org.apache.spark.executor.Executor logInfo - Finished task 78.0 in stage 2.0 (TID 80). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:44,827 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 80.0 in stage 2.0 (TID 82, localhost, executor driver, partition 80, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:44,827 org.apache.spark.executor.Executor logInfo - Running task 80.0 in stage 2.0 (TID 82)
[INFO] 2019-01-19 14:13:44,827 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 78.0 in stage 2.0 (TID 80) in 507 ms on localhost (executor driver) (79/200)
[INFO] 2019-01-19 14:13:44,839 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:44,839 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:44,849 org.apache.spark.executor.Executor logInfo - Finished task 79.0 in stage 2.0 (TID 81). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:44,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 81.0 in stage 2.0 (TID 83, localhost, executor driver, partition 81, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:44,850 org.apache.spark.executor.Executor logInfo - Running task 81.0 in stage 2.0 (TID 83)
[INFO] 2019-01-19 14:13:44,850 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 79.0 in stage 2.0 (TID 81) in 525 ms on localhost (executor driver) (80/200)
[INFO] 2019-01-19 14:13:44,858 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:44,859 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:45,327 org.apache.spark.executor.Executor logInfo - Finished task 80.0 in stage 2.0 (TID 82). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:45,328 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 82.0 in stage 2.0 (TID 84, localhost, executor driver, partition 82, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:45,328 org.apache.spark.executor.Executor logInfo - Running task 82.0 in stage 2.0 (TID 84)
[INFO] 2019-01-19 14:13:45,328 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 80.0 in stage 2.0 (TID 82) in 501 ms on localhost (executor driver) (81/200)
[INFO] 2019-01-19 14:13:45,338 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:45,338 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:45,345 org.apache.spark.executor.Executor logInfo - Finished task 81.0 in stage 2.0 (TID 83). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:45,345 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 83.0 in stage 2.0 (TID 85, localhost, executor driver, partition 83, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:45,345 org.apache.spark.executor.Executor logInfo - Running task 83.0 in stage 2.0 (TID 85)
[INFO] 2019-01-19 14:13:45,345 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 81.0 in stage 2.0 (TID 83) in 495 ms on localhost (executor driver) (82/200)
[INFO] 2019-01-19 14:13:45,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:45,356 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:45,819 org.apache.spark.executor.Executor logInfo - Finished task 82.0 in stage 2.0 (TID 84). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:45,820 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 84.0 in stage 2.0 (TID 86, localhost, executor driver, partition 84, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:45,820 org.apache.spark.executor.Executor logInfo - Running task 84.0 in stage 2.0 (TID 86)
[INFO] 2019-01-19 14:13:45,820 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 82.0 in stage 2.0 (TID 84) in 493 ms on localhost (executor driver) (83/200)
[INFO] 2019-01-19 14:13:45,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:45,829 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:45,836 org.apache.spark.executor.Executor logInfo - Finished task 83.0 in stage 2.0 (TID 85). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:45,837 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 85.0 in stage 2.0 (TID 87, localhost, executor driver, partition 85, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:45,837 org.apache.spark.executor.Executor logInfo - Running task 85.0 in stage 2.0 (TID 87)
[INFO] 2019-01-19 14:13:45,837 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 83.0 in stage 2.0 (TID 85) in 492 ms on localhost (executor driver) (84/200)
[INFO] 2019-01-19 14:13:45,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:45,847 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:46,317 org.apache.spark.executor.Executor logInfo - Finished task 84.0 in stage 2.0 (TID 86). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:46,318 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 86.0 in stage 2.0 (TID 88, localhost, executor driver, partition 86, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:46,318 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 84.0 in stage 2.0 (TID 86) in 499 ms on localhost (executor driver) (85/200)
[INFO] 2019-01-19 14:13:46,318 org.apache.spark.executor.Executor logInfo - Running task 86.0 in stage 2.0 (TID 88)
[INFO] 2019-01-19 14:13:46,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:46,332 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:46,369 org.apache.spark.executor.Executor logInfo - Finished task 85.0 in stage 2.0 (TID 87). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:46,369 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 87.0 in stage 2.0 (TID 89, localhost, executor driver, partition 87, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:46,370 org.apache.spark.executor.Executor logInfo - Running task 87.0 in stage 2.0 (TID 89)
[INFO] 2019-01-19 14:13:46,370 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 85.0 in stage 2.0 (TID 87) in 534 ms on localhost (executor driver) (86/200)
[INFO] 2019-01-19 14:13:46,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:46,380 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:46,887 org.apache.spark.executor.Executor logInfo - Finished task 86.0 in stage 2.0 (TID 88). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:46,887 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 88.0 in stage 2.0 (TID 90, localhost, executor driver, partition 88, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:46,888 org.apache.spark.executor.Executor logInfo - Running task 88.0 in stage 2.0 (TID 90)
[INFO] 2019-01-19 14:13:46,888 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 86.0 in stage 2.0 (TID 88) in 571 ms on localhost (executor driver) (87/200)
[INFO] 2019-01-19 14:13:46,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:46,898 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:46,930 org.apache.spark.executor.Executor logInfo - Finished task 87.0 in stage 2.0 (TID 89). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:46,930 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 89.0 in stage 2.0 (TID 91, localhost, executor driver, partition 89, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:46,931 org.apache.spark.executor.Executor logInfo - Running task 89.0 in stage 2.0 (TID 91)
[INFO] 2019-01-19 14:13:46,931 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 87.0 in stage 2.0 (TID 89) in 562 ms on localhost (executor driver) (88/200)
[INFO] 2019-01-19 14:13:46,940 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:46,940 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:47,397 org.apache.spark.executor.Executor logInfo - Finished task 88.0 in stage 2.0 (TID 90). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:47,398 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 90.0 in stage 2.0 (TID 92, localhost, executor driver, partition 90, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:47,398 org.apache.spark.executor.Executor logInfo - Running task 90.0 in stage 2.0 (TID 92)
[INFO] 2019-01-19 14:13:47,398 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 88.0 in stage 2.0 (TID 90) in 511 ms on localhost (executor driver) (89/200)
[INFO] 2019-01-19 14:13:47,409 org.apache.spark.executor.Executor logInfo - Finished task 89.0 in stage 2.0 (TID 91). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:47,410 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 91.0 in stage 2.0 (TID 93, localhost, executor driver, partition 91, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:47,410 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 89.0 in stage 2.0 (TID 91) in 480 ms on localhost (executor driver) (90/200)
[INFO] 2019-01-19 14:13:47,411 org.apache.spark.executor.Executor logInfo - Running task 91.0 in stage 2.0 (TID 93)
[INFO] 2019-01-19 14:13:47,412 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:47,413 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:47,422 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:47,422 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:47,888 org.apache.spark.executor.Executor logInfo - Finished task 90.0 in stage 2.0 (TID 92). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:47,889 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 92.0 in stage 2.0 (TID 94, localhost, executor driver, partition 92, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:47,889 org.apache.spark.executor.Executor logInfo - Running task 92.0 in stage 2.0 (TID 94)
[INFO] 2019-01-19 14:13:47,889 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 90.0 in stage 2.0 (TID 92) in 492 ms on localhost (executor driver) (91/200)
[INFO] 2019-01-19 14:13:47,894 org.apache.spark.executor.Executor logInfo - Finished task 91.0 in stage 2.0 (TID 93). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:47,895 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 93.0 in stage 2.0 (TID 95, localhost, executor driver, partition 93, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:47,895 org.apache.spark.executor.Executor logInfo - Running task 93.0 in stage 2.0 (TID 95)
[INFO] 2019-01-19 14:13:47,895 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 91.0 in stage 2.0 (TID 93) in 485 ms on localhost (executor driver) (92/200)
[INFO] 2019-01-19 14:13:47,900 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:47,900 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:47,908 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:47,908 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:48,383 org.apache.spark.executor.Executor logInfo - Finished task 93.0 in stage 2.0 (TID 95). 3355 bytes result sent to driver
[INFO] 2019-01-19 14:13:48,383 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 94.0 in stage 2.0 (TID 96, localhost, executor driver, partition 94, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:48,383 org.apache.spark.executor.Executor logInfo - Running task 94.0 in stage 2.0 (TID 96)
[INFO] 2019-01-19 14:13:48,383 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 93.0 in stage 2.0 (TID 95) in 488 ms on localhost (executor driver) (93/200)
[INFO] 2019-01-19 14:13:48,390 org.apache.spark.executor.Executor logInfo - Finished task 92.0 in stage 2.0 (TID 94). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:48,391 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 95.0 in stage 2.0 (TID 97, localhost, executor driver, partition 95, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:48,391 org.apache.spark.executor.Executor logInfo - Running task 95.0 in stage 2.0 (TID 97)
[INFO] 2019-01-19 14:13:48,391 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 92.0 in stage 2.0 (TID 94) in 502 ms on localhost (executor driver) (94/200)
[INFO] 2019-01-19 14:13:48,392 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:48,393 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:48,401 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:48,401 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:48,874 org.apache.spark.executor.Executor logInfo - Finished task 95.0 in stage 2.0 (TID 97). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:48,875 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 96.0 in stage 2.0 (TID 98, localhost, executor driver, partition 96, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:48,875 org.apache.spark.executor.Executor logInfo - Running task 96.0 in stage 2.0 (TID 98)
[INFO] 2019-01-19 14:13:48,875 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 95.0 in stage 2.0 (TID 97) in 484 ms on localhost (executor driver) (95/200)
[INFO] 2019-01-19 14:13:48,879 org.apache.spark.executor.Executor logInfo - Finished task 94.0 in stage 2.0 (TID 96). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:48,880 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 97.0 in stage 2.0 (TID 99, localhost, executor driver, partition 97, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:48,880 org.apache.spark.executor.Executor logInfo - Running task 97.0 in stage 2.0 (TID 99)
[INFO] 2019-01-19 14:13:48,880 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 94.0 in stage 2.0 (TID 96) in 497 ms on localhost (executor driver) (96/200)
[INFO] 2019-01-19 14:13:48,885 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:48,885 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:48,892 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:48,892 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:49,354 org.apache.spark.executor.Executor logInfo - Finished task 96.0 in stage 2.0 (TID 98). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:49,355 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 98.0 in stage 2.0 (TID 100, localhost, executor driver, partition 98, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:49,355 org.apache.spark.executor.Executor logInfo - Running task 98.0 in stage 2.0 (TID 100)
[INFO] 2019-01-19 14:13:49,355 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 96.0 in stage 2.0 (TID 98) in 480 ms on localhost (executor driver) (97/200)
[INFO] 2019-01-19 14:13:49,361 org.apache.spark.executor.Executor logInfo - Finished task 97.0 in stage 2.0 (TID 99). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:49,362 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 99.0 in stage 2.0 (TID 101, localhost, executor driver, partition 99, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:49,362 org.apache.spark.executor.Executor logInfo - Running task 99.0 in stage 2.0 (TID 101)
[INFO] 2019-01-19 14:13:49,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 97.0 in stage 2.0 (TID 99) in 483 ms on localhost (executor driver) (98/200)
[INFO] 2019-01-19 14:13:49,364 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:49,364 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:49,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:49,370 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:49,832 org.apache.spark.executor.Executor logInfo - Finished task 98.0 in stage 2.0 (TID 100). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:49,833 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 100.0 in stage 2.0 (TID 102, localhost, executor driver, partition 100, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:49,833 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 98.0 in stage 2.0 (TID 100) in 478 ms on localhost (executor driver) (99/200)
[INFO] 2019-01-19 14:13:49,833 org.apache.spark.executor.Executor logInfo - Running task 100.0 in stage 2.0 (TID 102)
[INFO] 2019-01-19 14:13:49,846 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:49,846 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:49,860 org.apache.spark.executor.Executor logInfo - Finished task 99.0 in stage 2.0 (TID 101). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:49,860 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 101.0 in stage 2.0 (TID 103, localhost, executor driver, partition 101, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:49,861 org.apache.spark.executor.Executor logInfo - Running task 101.0 in stage 2.0 (TID 103)
[INFO] 2019-01-19 14:13:49,861 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 99.0 in stage 2.0 (TID 101) in 500 ms on localhost (executor driver) (100/200)
[INFO] 2019-01-19 14:13:49,871 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:49,871 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:50,326 org.apache.spark.executor.Executor logInfo - Finished task 100.0 in stage 2.0 (TID 102). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:50,327 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 102.0 in stage 2.0 (TID 104, localhost, executor driver, partition 102, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:50,327 org.apache.spark.executor.Executor logInfo - Running task 102.0 in stage 2.0 (TID 104)
[INFO] 2019-01-19 14:13:50,327 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 100.0 in stage 2.0 (TID 102) in 495 ms on localhost (executor driver) (101/200)
[INFO] 2019-01-19 14:13:50,336 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:50,337 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:50,371 org.apache.spark.executor.Executor logInfo - Finished task 101.0 in stage 2.0 (TID 103). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:50,371 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 103.0 in stage 2.0 (TID 105, localhost, executor driver, partition 103, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:50,372 org.apache.spark.executor.Executor logInfo - Running task 103.0 in stage 2.0 (TID 105)
[INFO] 2019-01-19 14:13:50,372 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 101.0 in stage 2.0 (TID 103) in 512 ms on localhost (executor driver) (102/200)
[INFO] 2019-01-19 14:13:50,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:50,384 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:50,837 org.apache.spark.executor.Executor logInfo - Finished task 102.0 in stage 2.0 (TID 104). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:50,837 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 104.0 in stage 2.0 (TID 106, localhost, executor driver, partition 104, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:50,837 org.apache.spark.executor.Executor logInfo - Running task 104.0 in stage 2.0 (TID 106)
[INFO] 2019-01-19 14:13:50,837 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 102.0 in stage 2.0 (TID 104) in 510 ms on localhost (executor driver) (103/200)
[INFO] 2019-01-19 14:13:50,848 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:50,848 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:50,897 org.apache.spark.executor.Executor logInfo - Finished task 103.0 in stage 2.0 (TID 105). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:50,907 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 105.0 in stage 2.0 (TID 107, localhost, executor driver, partition 105, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:50,907 org.apache.spark.executor.Executor logInfo - Running task 105.0 in stage 2.0 (TID 107)
[INFO] 2019-01-19 14:13:50,907 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 103.0 in stage 2.0 (TID 105) in 536 ms on localhost (executor driver) (104/200)
[INFO] 2019-01-19 14:13:50,919 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:50,919 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:51,347 org.apache.spark.executor.Executor logInfo - Finished task 104.0 in stage 2.0 (TID 106). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:51,348 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 106.0 in stage 2.0 (TID 108, localhost, executor driver, partition 106, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:51,348 org.apache.spark.executor.Executor logInfo - Running task 106.0 in stage 2.0 (TID 108)
[INFO] 2019-01-19 14:13:51,348 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 104.0 in stage 2.0 (TID 106) in 511 ms on localhost (executor driver) (105/200)
[INFO] 2019-01-19 14:13:51,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:51,362 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:51,428 org.apache.spark.executor.Executor logInfo - Finished task 105.0 in stage 2.0 (TID 107). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:51,429 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 107.0 in stage 2.0 (TID 109, localhost, executor driver, partition 107, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:51,429 org.apache.spark.executor.Executor logInfo - Running task 107.0 in stage 2.0 (TID 109)
[INFO] 2019-01-19 14:13:51,429 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 105.0 in stage 2.0 (TID 107) in 522 ms on localhost (executor driver) (106/200)
[INFO] 2019-01-19 14:13:51,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:51,439 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:51,937 org.apache.spark.executor.Executor logInfo - Finished task 106.0 in stage 2.0 (TID 108). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:51,937 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 108.0 in stage 2.0 (TID 110, localhost, executor driver, partition 108, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:51,938 org.apache.spark.executor.Executor logInfo - Running task 108.0 in stage 2.0 (TID 110)
[INFO] 2019-01-19 14:13:51,938 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 106.0 in stage 2.0 (TID 108) in 590 ms on localhost (executor driver) (107/200)
[INFO] 2019-01-19 14:13:51,948 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:51,948 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:52,049 org.apache.spark.executor.Executor logInfo - Finished task 107.0 in stage 2.0 (TID 109). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:52,049 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 109.0 in stage 2.0 (TID 111, localhost, executor driver, partition 109, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:52,050 org.apache.spark.executor.Executor logInfo - Running task 109.0 in stage 2.0 (TID 111)
[INFO] 2019-01-19 14:13:52,050 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 107.0 in stage 2.0 (TID 109) in 621 ms on localhost (executor driver) (108/200)
[INFO] 2019-01-19 14:13:52,062 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:52,062 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:52,504 org.apache.spark.executor.Executor logInfo - Finished task 108.0 in stage 2.0 (TID 110). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:52,505 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 110.0 in stage 2.0 (TID 112, localhost, executor driver, partition 110, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:52,505 org.apache.spark.executor.Executor logInfo - Running task 110.0 in stage 2.0 (TID 112)
[INFO] 2019-01-19 14:13:52,505 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 108.0 in stage 2.0 (TID 110) in 568 ms on localhost (executor driver) (109/200)
[INFO] 2019-01-19 14:13:52,517 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:52,517 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:52,600 org.apache.spark.executor.Executor logInfo - Finished task 109.0 in stage 2.0 (TID 111). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:52,601 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 111.0 in stage 2.0 (TID 113, localhost, executor driver, partition 111, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:52,601 org.apache.spark.executor.Executor logInfo - Running task 111.0 in stage 2.0 (TID 113)
[INFO] 2019-01-19 14:13:52,601 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 109.0 in stage 2.0 (TID 111) in 552 ms on localhost (executor driver) (110/200)
[INFO] 2019-01-19 14:13:52,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:52,613 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:53,030 org.apache.spark.executor.Executor logInfo - Finished task 110.0 in stage 2.0 (TID 112). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:53,031 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 112.0 in stage 2.0 (TID 114, localhost, executor driver, partition 112, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:53,031 org.apache.spark.executor.Executor logInfo - Running task 112.0 in stage 2.0 (TID 114)
[INFO] 2019-01-19 14:13:53,031 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 110.0 in stage 2.0 (TID 112) in 527 ms on localhost (executor driver) (111/200)
[INFO] 2019-01-19 14:13:53,042 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:53,042 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:53,123 org.apache.spark.executor.Executor logInfo - Finished task 111.0 in stage 2.0 (TID 113). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:53,124 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 113.0 in stage 2.0 (TID 115, localhost, executor driver, partition 113, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:53,124 org.apache.spark.executor.Executor logInfo - Running task 113.0 in stage 2.0 (TID 115)
[INFO] 2019-01-19 14:13:53,124 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 111.0 in stage 2.0 (TID 113) in 524 ms on localhost (executor driver) (112/200)
[INFO] 2019-01-19 14:13:53,138 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:53,138 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:53,523 org.apache.spark.executor.Executor logInfo - Finished task 112.0 in stage 2.0 (TID 114). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:53,524 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 114.0 in stage 2.0 (TID 116, localhost, executor driver, partition 114, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:53,524 org.apache.spark.executor.Executor logInfo - Running task 114.0 in stage 2.0 (TID 116)
[INFO] 2019-01-19 14:13:53,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 112.0 in stage 2.0 (TID 114) in 493 ms on localhost (executor driver) (113/200)
[INFO] 2019-01-19 14:13:53,533 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:53,534 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:53,652 org.apache.spark.executor.Executor logInfo - Finished task 113.0 in stage 2.0 (TID 115). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:53,653 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 115.0 in stage 2.0 (TID 117, localhost, executor driver, partition 115, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:53,653 org.apache.spark.executor.Executor logInfo - Running task 115.0 in stage 2.0 (TID 117)
[INFO] 2019-01-19 14:13:53,653 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 113.0 in stage 2.0 (TID 115) in 530 ms on localhost (executor driver) (114/200)
[INFO] 2019-01-19 14:13:53,664 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:53,664 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:54,068 org.apache.spark.executor.Executor logInfo - Finished task 114.0 in stage 2.0 (TID 116). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:54,068 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 116.0 in stage 2.0 (TID 118, localhost, executor driver, partition 116, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:54,069 org.apache.spark.executor.Executor logInfo - Running task 116.0 in stage 2.0 (TID 118)
[INFO] 2019-01-19 14:13:54,069 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 114.0 in stage 2.0 (TID 116) in 546 ms on localhost (executor driver) (115/200)
[INFO] 2019-01-19 14:13:54,081 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:54,081 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:54,204 org.apache.spark.executor.Executor logInfo - Finished task 115.0 in stage 2.0 (TID 117). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:54,205 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 117.0 in stage 2.0 (TID 119, localhost, executor driver, partition 117, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:54,205 org.apache.spark.executor.Executor logInfo - Running task 117.0 in stage 2.0 (TID 119)
[INFO] 2019-01-19 14:13:54,205 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 115.0 in stage 2.0 (TID 117) in 552 ms on localhost (executor driver) (116/200)
[INFO] 2019-01-19 14:13:54,217 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:54,217 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:54,570 org.apache.spark.executor.Executor logInfo - Finished task 116.0 in stage 2.0 (TID 118). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:54,570 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 118.0 in stage 2.0 (TID 120, localhost, executor driver, partition 118, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:54,571 org.apache.spark.executor.Executor logInfo - Running task 118.0 in stage 2.0 (TID 120)
[INFO] 2019-01-19 14:13:54,571 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 116.0 in stage 2.0 (TID 118) in 503 ms on localhost (executor driver) (117/200)
[INFO] 2019-01-19 14:13:54,582 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:54,582 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:54,715 org.apache.spark.executor.Executor logInfo - Finished task 117.0 in stage 2.0 (TID 119). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:54,716 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 119.0 in stage 2.0 (TID 121, localhost, executor driver, partition 119, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:54,716 org.apache.spark.executor.Executor logInfo - Running task 119.0 in stage 2.0 (TID 121)
[INFO] 2019-01-19 14:13:54,716 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 117.0 in stage 2.0 (TID 119) in 512 ms on localhost (executor driver) (118/200)
[INFO] 2019-01-19 14:13:54,728 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:54,728 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:55,106 org.apache.spark.executor.Executor logInfo - Finished task 118.0 in stage 2.0 (TID 120). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:55,106 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 120.0 in stage 2.0 (TID 122, localhost, executor driver, partition 120, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:55,107 org.apache.spark.executor.Executor logInfo - Running task 120.0 in stage 2.0 (TID 122)
[INFO] 2019-01-19 14:13:55,107 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 118.0 in stage 2.0 (TID 120) in 537 ms on localhost (executor driver) (119/200)
[INFO] 2019-01-19 14:13:55,119 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:55,119 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:55,225 org.apache.spark.executor.Executor logInfo - Finished task 119.0 in stage 2.0 (TID 121). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:55,225 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 121.0 in stage 2.0 (TID 123, localhost, executor driver, partition 121, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:55,226 org.apache.spark.executor.Executor logInfo - Running task 121.0 in stage 2.0 (TID 123)
[INFO] 2019-01-19 14:13:55,226 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 119.0 in stage 2.0 (TID 121) in 511 ms on localhost (executor driver) (120/200)
[INFO] 2019-01-19 14:13:55,236 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:55,237 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:55,628 org.apache.spark.executor.Executor logInfo - Finished task 120.0 in stage 2.0 (TID 122). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:55,629 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 122.0 in stage 2.0 (TID 124, localhost, executor driver, partition 122, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:55,629 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 120.0 in stage 2.0 (TID 122) in 523 ms on localhost (executor driver) (121/200)
[INFO] 2019-01-19 14:13:55,630 org.apache.spark.executor.Executor logInfo - Running task 122.0 in stage 2.0 (TID 124)
[INFO] 2019-01-19 14:13:55,642 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:55,642 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:55,743 org.apache.spark.executor.Executor logInfo - Finished task 121.0 in stage 2.0 (TID 123). 3428 bytes result sent to driver
[INFO] 2019-01-19 14:13:55,743 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 123.0 in stage 2.0 (TID 125, localhost, executor driver, partition 123, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:55,744 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 121.0 in stage 2.0 (TID 123) in 519 ms on localhost (executor driver) (122/200)
[INFO] 2019-01-19 14:13:55,744 org.apache.spark.executor.Executor logInfo - Running task 123.0 in stage 2.0 (TID 125)
[INFO] 2019-01-19 14:13:55,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:55,758 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:56,164 org.apache.spark.executor.Executor logInfo - Finished task 122.0 in stage 2.0 (TID 124). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:56,164 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 124.0 in stage 2.0 (TID 126, localhost, executor driver, partition 124, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:56,165 org.apache.spark.executor.Executor logInfo - Running task 124.0 in stage 2.0 (TID 126)
[INFO] 2019-01-19 14:13:56,165 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 122.0 in stage 2.0 (TID 124) in 535 ms on localhost (executor driver) (123/200)
[INFO] 2019-01-19 14:13:56,175 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:56,175 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:56,269 org.apache.spark.executor.Executor logInfo - Finished task 123.0 in stage 2.0 (TID 125). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:56,279 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 125.0 in stage 2.0 (TID 127, localhost, executor driver, partition 125, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:56,279 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 123.0 in stage 2.0 (TID 125) in 536 ms on localhost (executor driver) (124/200)
[INFO] 2019-01-19 14:13:56,280 org.apache.spark.executor.Executor logInfo - Running task 125.0 in stage 2.0 (TID 127)
[INFO] 2019-01-19 14:13:56,289 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:56,289 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:56,670 org.apache.spark.executor.Executor logInfo - Finished task 124.0 in stage 2.0 (TID 126). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:56,671 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 126.0 in stage 2.0 (TID 128, localhost, executor driver, partition 126, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:56,672 org.apache.spark.executor.Executor logInfo - Running task 126.0 in stage 2.0 (TID 128)
[INFO] 2019-01-19 14:13:56,672 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 124.0 in stage 2.0 (TID 126) in 508 ms on localhost (executor driver) (125/200)
[INFO] 2019-01-19 14:13:56,686 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:56,686 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:56,801 org.apache.spark.executor.Executor logInfo - Finished task 125.0 in stage 2.0 (TID 127). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:56,801 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 127.0 in stage 2.0 (TID 129, localhost, executor driver, partition 127, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:56,802 org.apache.spark.executor.Executor logInfo - Running task 127.0 in stage 2.0 (TID 129)
[INFO] 2019-01-19 14:13:56,802 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 125.0 in stage 2.0 (TID 127) in 523 ms on localhost (executor driver) (126/200)
[INFO] 2019-01-19 14:13:56,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:56,811 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:57,219 org.apache.spark.executor.Executor logInfo - Finished task 126.0 in stage 2.0 (TID 128). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:57,219 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 128.0 in stage 2.0 (TID 130, localhost, executor driver, partition 128, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:57,220 org.apache.spark.executor.Executor logInfo - Running task 128.0 in stage 2.0 (TID 130)
[INFO] 2019-01-19 14:13:57,220 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 126.0 in stage 2.0 (TID 128) in 549 ms on localhost (executor driver) (127/200)
[INFO] 2019-01-19 14:13:57,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:57,231 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:57,319 org.apache.spark.executor.Executor logInfo - Finished task 127.0 in stage 2.0 (TID 129). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:57,320 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 129.0 in stage 2.0 (TID 131, localhost, executor driver, partition 129, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:57,320 org.apache.spark.executor.Executor logInfo - Running task 129.0 in stage 2.0 (TID 131)
[INFO] 2019-01-19 14:13:57,320 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 127.0 in stage 2.0 (TID 129) in 519 ms on localhost (executor driver) (128/200)
[INFO] 2019-01-19 14:13:57,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:57,331 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:57,764 org.apache.spark.executor.Executor logInfo - Finished task 128.0 in stage 2.0 (TID 130). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:57,764 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 130.0 in stage 2.0 (TID 132, localhost, executor driver, partition 130, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:57,764 org.apache.spark.executor.Executor logInfo - Running task 130.0 in stage 2.0 (TID 132)
[INFO] 2019-01-19 14:13:57,765 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 128.0 in stage 2.0 (TID 130) in 545 ms on localhost (executor driver) (129/200)
[INFO] 2019-01-19 14:13:57,774 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:57,774 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:57,850 org.apache.spark.executor.Executor logInfo - Finished task 129.0 in stage 2.0 (TID 131). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:57,851 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 131.0 in stage 2.0 (TID 133, localhost, executor driver, partition 131, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:57,851 org.apache.spark.executor.Executor logInfo - Running task 131.0 in stage 2.0 (TID 133)
[INFO] 2019-01-19 14:13:57,851 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 129.0 in stage 2.0 (TID 131) in 532 ms on localhost (executor driver) (130/200)
[INFO] 2019-01-19 14:13:57,860 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:57,861 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:58,280 org.apache.spark.executor.Executor logInfo - Finished task 130.0 in stage 2.0 (TID 132). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:58,280 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 132.0 in stage 2.0 (TID 134, localhost, executor driver, partition 132, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:58,281 org.apache.spark.executor.Executor logInfo - Running task 132.0 in stage 2.0 (TID 134)
[INFO] 2019-01-19 14:13:58,281 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 130.0 in stage 2.0 (TID 132) in 517 ms on localhost (executor driver) (131/200)
[INFO] 2019-01-19 14:13:58,290 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:58,290 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:58,369 org.apache.spark.executor.Executor logInfo - Finished task 131.0 in stage 2.0 (TID 133). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:58,370 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 133.0 in stage 2.0 (TID 135, localhost, executor driver, partition 133, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:58,370 org.apache.spark.executor.Executor logInfo - Running task 133.0 in stage 2.0 (TID 135)
[INFO] 2019-01-19 14:13:58,370 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 131.0 in stage 2.0 (TID 133) in 520 ms on localhost (executor driver) (132/200)
[INFO] 2019-01-19 14:13:58,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:58,382 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:58,780 org.apache.spark.executor.Executor logInfo - Finished task 132.0 in stage 2.0 (TID 134). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:13:58,781 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 134.0 in stage 2.0 (TID 136, localhost, executor driver, partition 134, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:58,781 org.apache.spark.executor.Executor logInfo - Running task 134.0 in stage 2.0 (TID 136)
[INFO] 2019-01-19 14:13:58,781 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 132.0 in stage 2.0 (TID 134) in 501 ms on localhost (executor driver) (133/200)
[INFO] 2019-01-19 14:13:58,790 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:58,791 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:58,864 org.apache.spark.executor.Executor logInfo - Finished task 133.0 in stage 2.0 (TID 135). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:13:58,865 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 135.0 in stage 2.0 (TID 137, localhost, executor driver, partition 135, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:58,865 org.apache.spark.executor.Executor logInfo - Running task 135.0 in stage 2.0 (TID 137)
[INFO] 2019-01-19 14:13:58,865 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 133.0 in stage 2.0 (TID 135) in 495 ms on localhost (executor driver) (134/200)
[INFO] 2019-01-19 14:13:58,875 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:58,875 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:59,290 org.apache.spark.executor.Executor logInfo - Finished task 134.0 in stage 2.0 (TID 136). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:59,291 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 136.0 in stage 2.0 (TID 138, localhost, executor driver, partition 136, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:59,291 org.apache.spark.executor.Executor logInfo - Running task 136.0 in stage 2.0 (TID 138)
[INFO] 2019-01-19 14:13:59,291 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 134.0 in stage 2.0 (TID 136) in 511 ms on localhost (executor driver) (135/200)
[INFO] 2019-01-19 14:13:59,301 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:59,302 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:13:59,393 org.apache.spark.executor.Executor logInfo - Finished task 135.0 in stage 2.0 (TID 137). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:59,394 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 137.0 in stage 2.0 (TID 139, localhost, executor driver, partition 137, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:59,394 org.apache.spark.executor.Executor logInfo - Running task 137.0 in stage 2.0 (TID 139)
[INFO] 2019-01-19 14:13:59,394 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 135.0 in stage 2.0 (TID 137) in 529 ms on localhost (executor driver) (136/200)
[INFO] 2019-01-19 14:13:59,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:59,403 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:59,808 org.apache.spark.executor.Executor logInfo - Finished task 136.0 in stage 2.0 (TID 138). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:13:59,808 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 138.0 in stage 2.0 (TID 140, localhost, executor driver, partition 138, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:59,809 org.apache.spark.executor.Executor logInfo - Running task 138.0 in stage 2.0 (TID 140)
[INFO] 2019-01-19 14:13:59,809 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 136.0 in stage 2.0 (TID 138) in 518 ms on localhost (executor driver) (137/200)
[INFO] 2019-01-19 14:13:59,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:59,818 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:13:59,906 org.apache.spark.executor.Executor logInfo - Finished task 137.0 in stage 2.0 (TID 139). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:13:59,906 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 139.0 in stage 2.0 (TID 141, localhost, executor driver, partition 139, ANY, 5789 bytes)
[INFO] 2019-01-19 14:13:59,907 org.apache.spark.executor.Executor logInfo - Running task 139.0 in stage 2.0 (TID 141)
[INFO] 2019-01-19 14:13:59,907 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 137.0 in stage 2.0 (TID 139) in 513 ms on localhost (executor driver) (138/200)
[INFO] 2019-01-19 14:13:59,916 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:13:59,917 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:00,338 org.apache.spark.executor.Executor logInfo - Finished task 138.0 in stage 2.0 (TID 140). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:00,339 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 140.0 in stage 2.0 (TID 142, localhost, executor driver, partition 140, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:00,339 org.apache.spark.executor.Executor logInfo - Running task 140.0 in stage 2.0 (TID 142)
[INFO] 2019-01-19 14:14:00,339 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 138.0 in stage 2.0 (TID 140) in 531 ms on localhost (executor driver) (139/200)
[INFO] 2019-01-19 14:14:00,351 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:00,351 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:00,433 org.apache.spark.executor.Executor logInfo - Finished task 139.0 in stage 2.0 (TID 141). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:00,434 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 141.0 in stage 2.0 (TID 143, localhost, executor driver, partition 141, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:00,434 org.apache.spark.executor.Executor logInfo - Running task 141.0 in stage 2.0 (TID 143)
[INFO] 2019-01-19 14:14:00,434 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 139.0 in stage 2.0 (TID 141) in 528 ms on localhost (executor driver) (140/200)
[INFO] 2019-01-19 14:14:00,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:00,444 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:00,849 org.apache.spark.executor.Executor logInfo - Finished task 140.0 in stage 2.0 (TID 142). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:00,850 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 142.0 in stage 2.0 (TID 144, localhost, executor driver, partition 142, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:00,850 org.apache.spark.executor.Executor logInfo - Running task 142.0 in stage 2.0 (TID 144)
[INFO] 2019-01-19 14:14:00,850 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 140.0 in stage 2.0 (TID 142) in 511 ms on localhost (executor driver) (141/200)
[INFO] 2019-01-19 14:14:00,859 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:00,859 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:00,929 org.apache.spark.executor.Executor logInfo - Finished task 141.0 in stage 2.0 (TID 143). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:00,929 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 143.0 in stage 2.0 (TID 145, localhost, executor driver, partition 143, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:00,930 org.apache.spark.executor.Executor logInfo - Running task 143.0 in stage 2.0 (TID 145)
[INFO] 2019-01-19 14:14:00,930 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 141.0 in stage 2.0 (TID 143) in 496 ms on localhost (executor driver) (142/200)
[INFO] 2019-01-19 14:14:00,940 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:00,940 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:01,343 org.apache.spark.executor.Executor logInfo - Finished task 142.0 in stage 2.0 (TID 144). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:01,344 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 144.0 in stage 2.0 (TID 146, localhost, executor driver, partition 144, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:01,344 org.apache.spark.executor.Executor logInfo - Running task 144.0 in stage 2.0 (TID 146)
[INFO] 2019-01-19 14:14:01,344 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 142.0 in stage 2.0 (TID 144) in 495 ms on localhost (executor driver) (143/200)
[INFO] 2019-01-19 14:14:01,355 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:01,355 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:01,426 org.apache.spark.executor.Executor logInfo - Finished task 143.0 in stage 2.0 (TID 145). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:01,426 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 145.0 in stage 2.0 (TID 147, localhost, executor driver, partition 145, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:01,426 org.apache.spark.executor.Executor logInfo - Running task 145.0 in stage 2.0 (TID 147)
[INFO] 2019-01-19 14:14:01,426 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 143.0 in stage 2.0 (TID 145) in 497 ms on localhost (executor driver) (144/200)
[INFO] 2019-01-19 14:14:01,436 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:01,437 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:01,859 org.apache.spark.executor.Executor logInfo - Finished task 144.0 in stage 2.0 (TID 146). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:01,860 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 146.0 in stage 2.0 (TID 148, localhost, executor driver, partition 146, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:01,860 org.apache.spark.executor.Executor logInfo - Running task 146.0 in stage 2.0 (TID 148)
[INFO] 2019-01-19 14:14:01,860 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 144.0 in stage 2.0 (TID 146) in 517 ms on localhost (executor driver) (145/200)
[INFO] 2019-01-19 14:14:01,869 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:01,869 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:01,929 org.apache.spark.executor.Executor logInfo - Finished task 145.0 in stage 2.0 (TID 147). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:01,930 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 147.0 in stage 2.0 (TID 149, localhost, executor driver, partition 147, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:01,930 org.apache.spark.executor.Executor logInfo - Running task 147.0 in stage 2.0 (TID 149)
[INFO] 2019-01-19 14:14:01,930 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 145.0 in stage 2.0 (TID 147) in 504 ms on localhost (executor driver) (146/200)
[INFO] 2019-01-19 14:14:01,940 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:01,940 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:02,368 org.apache.spark.executor.Executor logInfo - Finished task 146.0 in stage 2.0 (TID 148). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:02,369 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 148.0 in stage 2.0 (TID 150, localhost, executor driver, partition 148, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:02,369 org.apache.spark.executor.Executor logInfo - Running task 148.0 in stage 2.0 (TID 150)
[INFO] 2019-01-19 14:14:02,369 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 146.0 in stage 2.0 (TID 148) in 509 ms on localhost (executor driver) (147/200)
[INFO] 2019-01-19 14:14:02,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:02,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:02,454 org.apache.spark.executor.Executor logInfo - Finished task 147.0 in stage 2.0 (TID 149). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:02,456 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 149.0 in stage 2.0 (TID 151, localhost, executor driver, partition 149, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:02,456 org.apache.spark.executor.Executor logInfo - Running task 149.0 in stage 2.0 (TID 151)
[INFO] 2019-01-19 14:14:02,456 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 147.0 in stage 2.0 (TID 149) in 526 ms on localhost (executor driver) (148/200)
[INFO] 2019-01-19 14:14:02,469 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:02,469 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:02,872 org.apache.spark.executor.Executor logInfo - Finished task 148.0 in stage 2.0 (TID 150). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:02,872 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 150.0 in stage 2.0 (TID 152, localhost, executor driver, partition 150, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:02,873 org.apache.spark.executor.Executor logInfo - Running task 150.0 in stage 2.0 (TID 152)
[INFO] 2019-01-19 14:14:02,873 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 148.0 in stage 2.0 (TID 150) in 504 ms on localhost (executor driver) (149/200)
[INFO] 2019-01-19 14:14:02,882 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:02,882 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:02,961 org.apache.spark.executor.Executor logInfo - Finished task 149.0 in stage 2.0 (TID 151). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:02,962 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 151.0 in stage 2.0 (TID 153, localhost, executor driver, partition 151, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:02,962 org.apache.spark.executor.Executor logInfo - Running task 151.0 in stage 2.0 (TID 153)
[INFO] 2019-01-19 14:14:02,962 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 149.0 in stage 2.0 (TID 151) in 506 ms on localhost (executor driver) (150/200)
[INFO] 2019-01-19 14:14:02,971 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:02,971 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:03,363 org.apache.spark.executor.Executor logInfo - Finished task 150.0 in stage 2.0 (TID 152). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:03,363 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 152.0 in stage 2.0 (TID 154, localhost, executor driver, partition 152, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:03,364 org.apache.spark.executor.Executor logInfo - Running task 152.0 in stage 2.0 (TID 154)
[INFO] 2019-01-19 14:14:03,364 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 150.0 in stage 2.0 (TID 152) in 492 ms on localhost (executor driver) (151/200)
[INFO] 2019-01-19 14:14:03,374 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:03,374 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:03,468 org.apache.spark.executor.Executor logInfo - Finished task 151.0 in stage 2.0 (TID 153). 3428 bytes result sent to driver
[INFO] 2019-01-19 14:14:03,468 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 153.0 in stage 2.0 (TID 155, localhost, executor driver, partition 153, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:03,468 org.apache.spark.executor.Executor logInfo - Running task 153.0 in stage 2.0 (TID 155)
[INFO] 2019-01-19 14:14:03,468 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 151.0 in stage 2.0 (TID 153) in 507 ms on localhost (executor driver) (152/200)
[INFO] 2019-01-19 14:14:03,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:03,481 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:03,874 org.apache.spark.executor.Executor logInfo - Finished task 152.0 in stage 2.0 (TID 154). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:03,875 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 154.0 in stage 2.0 (TID 156, localhost, executor driver, partition 154, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:03,875 org.apache.spark.executor.Executor logInfo - Running task 154.0 in stage 2.0 (TID 156)
[INFO] 2019-01-19 14:14:03,875 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 152.0 in stage 2.0 (TID 154) in 512 ms on localhost (executor driver) (153/200)
[INFO] 2019-01-19 14:14:03,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:03,884 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:03,948 org.apache.spark.executor.Executor logInfo - Finished task 153.0 in stage 2.0 (TID 155). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:14:03,948 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 155.0 in stage 2.0 (TID 157, localhost, executor driver, partition 155, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:03,948 org.apache.spark.executor.Executor logInfo - Running task 155.0 in stage 2.0 (TID 157)
[INFO] 2019-01-19 14:14:03,948 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 153.0 in stage 2.0 (TID 155) in 480 ms on localhost (executor driver) (154/200)
[INFO] 2019-01-19 14:14:03,958 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:03,958 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:04,361 org.apache.spark.executor.Executor logInfo - Finished task 154.0 in stage 2.0 (TID 156). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:04,361 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 156.0 in stage 2.0 (TID 158, localhost, executor driver, partition 156, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:04,362 org.apache.spark.executor.Executor logInfo - Running task 156.0 in stage 2.0 (TID 158)
[INFO] 2019-01-19 14:14:04,362 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 154.0 in stage 2.0 (TID 156) in 487 ms on localhost (executor driver) (155/200)
[INFO] 2019-01-19 14:14:04,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:04,372 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:04,444 org.apache.spark.executor.Executor logInfo - Finished task 155.0 in stage 2.0 (TID 157). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:04,445 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 157.0 in stage 2.0 (TID 159, localhost, executor driver, partition 157, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:04,445 org.apache.spark.executor.Executor logInfo - Running task 157.0 in stage 2.0 (TID 159)
[INFO] 2019-01-19 14:14:04,445 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 155.0 in stage 2.0 (TID 157) in 497 ms on localhost (executor driver) (156/200)
[INFO] 2019-01-19 14:14:04,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:04,456 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:04,867 org.apache.spark.executor.Executor logInfo - Finished task 156.0 in stage 2.0 (TID 158). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:04,868 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 158.0 in stage 2.0 (TID 160, localhost, executor driver, partition 158, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:04,868 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 156.0 in stage 2.0 (TID 158) in 507 ms on localhost (executor driver) (157/200)
[INFO] 2019-01-19 14:14:04,868 org.apache.spark.executor.Executor logInfo - Running task 158.0 in stage 2.0 (TID 160)
[INFO] 2019-01-19 14:14:04,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:04,879 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:04,947 org.apache.spark.executor.Executor logInfo - Finished task 157.0 in stage 2.0 (TID 159). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:04,948 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 159.0 in stage 2.0 (TID 161, localhost, executor driver, partition 159, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:04,948 org.apache.spark.executor.Executor logInfo - Running task 159.0 in stage 2.0 (TID 161)
[INFO] 2019-01-19 14:14:04,948 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 157.0 in stage 2.0 (TID 159) in 504 ms on localhost (executor driver) (158/200)
[INFO] 2019-01-19 14:14:04,956 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:04,956 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:05,385 org.apache.spark.executor.Executor logInfo - Finished task 158.0 in stage 2.0 (TID 160). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:05,386 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 160.0 in stage 2.0 (TID 162, localhost, executor driver, partition 160, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:05,386 org.apache.spark.executor.Executor logInfo - Running task 160.0 in stage 2.0 (TID 162)
[INFO] 2019-01-19 14:14:05,386 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 158.0 in stage 2.0 (TID 160) in 518 ms on localhost (executor driver) (159/200)
[INFO] 2019-01-19 14:14:05,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:05,396 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:05,474 org.apache.spark.executor.Executor logInfo - Finished task 159.0 in stage 2.0 (TID 161). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:05,475 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 161.0 in stage 2.0 (TID 163, localhost, executor driver, partition 161, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:05,475 org.apache.spark.executor.Executor logInfo - Running task 161.0 in stage 2.0 (TID 163)
[INFO] 2019-01-19 14:14:05,475 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 159.0 in stage 2.0 (TID 161) in 527 ms on localhost (executor driver) (160/200)
[INFO] 2019-01-19 14:14:05,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:05,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:05,861 org.apache.spark.executor.Executor logInfo - Finished task 160.0 in stage 2.0 (TID 162). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:05,862 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 162.0 in stage 2.0 (TID 164, localhost, executor driver, partition 162, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:05,862 org.apache.spark.executor.Executor logInfo - Running task 162.0 in stage 2.0 (TID 164)
[INFO] 2019-01-19 14:14:05,862 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 160.0 in stage 2.0 (TID 162) in 476 ms on localhost (executor driver) (161/200)
[INFO] 2019-01-19 14:14:05,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:05,872 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:05,969 org.apache.spark.executor.Executor logInfo - Finished task 161.0 in stage 2.0 (TID 163). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:05,969 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 163.0 in stage 2.0 (TID 165, localhost, executor driver, partition 163, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:05,969 org.apache.spark.executor.Executor logInfo - Running task 163.0 in stage 2.0 (TID 165)
[INFO] 2019-01-19 14:14:05,969 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 161.0 in stage 2.0 (TID 163) in 494 ms on localhost (executor driver) (162/200)
[INFO] 2019-01-19 14:14:05,987 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:05,987 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:06,370 org.apache.spark.executor.Executor logInfo - Finished task 162.0 in stage 2.0 (TID 164). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:06,370 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 164.0 in stage 2.0 (TID 166, localhost, executor driver, partition 164, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:06,371 org.apache.spark.executor.Executor logInfo - Running task 164.0 in stage 2.0 (TID 166)
[INFO] 2019-01-19 14:14:06,371 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 162.0 in stage 2.0 (TID 164) in 509 ms on localhost (executor driver) (163/200)
[INFO] 2019-01-19 14:14:06,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:06,381 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:06,487 org.apache.spark.executor.Executor logInfo - Finished task 163.0 in stage 2.0 (TID 165). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:06,488 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 165.0 in stage 2.0 (TID 167, localhost, executor driver, partition 165, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:06,488 org.apache.spark.executor.Executor logInfo - Running task 165.0 in stage 2.0 (TID 167)
[INFO] 2019-01-19 14:14:06,488 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 163.0 in stage 2.0 (TID 165) in 519 ms on localhost (executor driver) (164/200)
[INFO] 2019-01-19 14:14:06,498 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:06,499 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:06,892 org.apache.spark.executor.Executor logInfo - Finished task 164.0 in stage 2.0 (TID 166). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:06,893 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 166.0 in stage 2.0 (TID 168, localhost, executor driver, partition 166, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:06,893 org.apache.spark.executor.Executor logInfo - Running task 166.0 in stage 2.0 (TID 168)
[INFO] 2019-01-19 14:14:06,893 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 164.0 in stage 2.0 (TID 166) in 523 ms on localhost (executor driver) (165/200)
[INFO] 2019-01-19 14:14:06,904 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:06,904 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:07,020 org.apache.spark.executor.Executor logInfo - Finished task 165.0 in stage 2.0 (TID 167). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:07,021 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 167.0 in stage 2.0 (TID 169, localhost, executor driver, partition 167, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:07,021 org.apache.spark.executor.Executor logInfo - Running task 167.0 in stage 2.0 (TID 169)
[INFO] 2019-01-19 14:14:07,021 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 165.0 in stage 2.0 (TID 167) in 533 ms on localhost (executor driver) (166/200)
[INFO] 2019-01-19 14:14:07,032 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:07,033 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:07,411 org.apache.spark.executor.Executor logInfo - Finished task 166.0 in stage 2.0 (TID 168). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:07,412 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 168.0 in stage 2.0 (TID 170, localhost, executor driver, partition 168, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:07,412 org.apache.spark.executor.Executor logInfo - Running task 168.0 in stage 2.0 (TID 170)
[INFO] 2019-01-19 14:14:07,412 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 166.0 in stage 2.0 (TID 168) in 520 ms on localhost (executor driver) (167/200)
[INFO] 2019-01-19 14:14:07,422 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:07,422 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:07,523 org.apache.spark.executor.Executor logInfo - Finished task 167.0 in stage 2.0 (TID 169). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:07,523 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 169.0 in stage 2.0 (TID 171, localhost, executor driver, partition 169, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:07,524 org.apache.spark.executor.Executor logInfo - Running task 169.0 in stage 2.0 (TID 171)
[INFO] 2019-01-19 14:14:07,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 167.0 in stage 2.0 (TID 169) in 503 ms on localhost (executor driver) (168/200)
[INFO] 2019-01-19 14:14:07,533 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:07,533 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:07,916 org.apache.spark.executor.Executor logInfo - Finished task 168.0 in stage 2.0 (TID 170). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:07,916 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 170.0 in stage 2.0 (TID 172, localhost, executor driver, partition 170, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:07,917 org.apache.spark.executor.Executor logInfo - Running task 170.0 in stage 2.0 (TID 172)
[INFO] 2019-01-19 14:14:07,917 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 168.0 in stage 2.0 (TID 170) in 505 ms on localhost (executor driver) (169/200)
[INFO] 2019-01-19 14:14:07,928 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:07,928 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:08,028 org.apache.spark.executor.Executor logInfo - Finished task 169.0 in stage 2.0 (TID 171). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:08,029 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 171.0 in stage 2.0 (TID 173, localhost, executor driver, partition 171, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:08,029 org.apache.spark.executor.Executor logInfo - Running task 171.0 in stage 2.0 (TID 173)
[INFO] 2019-01-19 14:14:08,029 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 169.0 in stage 2.0 (TID 171) in 506 ms on localhost (executor driver) (170/200)
[INFO] 2019-01-19 14:14:08,037 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:08,037 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:08,440 org.apache.spark.executor.Executor logInfo - Finished task 170.0 in stage 2.0 (TID 172). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:08,440 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 172.0 in stage 2.0 (TID 174, localhost, executor driver, partition 172, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:08,440 org.apache.spark.executor.Executor logInfo - Running task 172.0 in stage 2.0 (TID 174)
[INFO] 2019-01-19 14:14:08,441 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 170.0 in stage 2.0 (TID 172) in 525 ms on localhost (executor driver) (171/200)
[INFO] 2019-01-19 14:14:08,451 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:08,451 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:08,523 org.apache.spark.executor.Executor logInfo - Finished task 171.0 in stage 2.0 (TID 173). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:08,524 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 173.0 in stage 2.0 (TID 175, localhost, executor driver, partition 173, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:08,524 org.apache.spark.executor.Executor logInfo - Running task 173.0 in stage 2.0 (TID 175)
[INFO] 2019-01-19 14:14:08,524 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 171.0 in stage 2.0 (TID 173) in 495 ms on localhost (executor driver) (172/200)
[INFO] 2019-01-19 14:14:08,538 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:08,538 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:08,952 org.apache.spark.executor.Executor logInfo - Finished task 172.0 in stage 2.0 (TID 174). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:08,952 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 174.0 in stage 2.0 (TID 176, localhost, executor driver, partition 174, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:08,953 org.apache.spark.executor.Executor logInfo - Running task 174.0 in stage 2.0 (TID 176)
[INFO] 2019-01-19 14:14:08,953 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 172.0 in stage 2.0 (TID 174) in 513 ms on localhost (executor driver) (173/200)
[INFO] 2019-01-19 14:14:08,963 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:08,963 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:09,039 org.apache.spark.executor.Executor logInfo - Finished task 173.0 in stage 2.0 (TID 175). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:09,040 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 175.0 in stage 2.0 (TID 177, localhost, executor driver, partition 175, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:09,040 org.apache.spark.executor.Executor logInfo - Running task 175.0 in stage 2.0 (TID 177)
[INFO] 2019-01-19 14:14:09,040 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 173.0 in stage 2.0 (TID 175) in 516 ms on localhost (executor driver) (174/200)
[INFO] 2019-01-19 14:14:09,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:09,051 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:09,471 org.apache.spark.executor.Executor logInfo - Finished task 174.0 in stage 2.0 (TID 176). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:09,471 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 176.0 in stage 2.0 (TID 178, localhost, executor driver, partition 176, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:09,472 org.apache.spark.executor.Executor logInfo - Running task 176.0 in stage 2.0 (TID 178)
[INFO] 2019-01-19 14:14:09,472 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 174.0 in stage 2.0 (TID 176) in 520 ms on localhost (executor driver) (175/200)
[INFO] 2019-01-19 14:14:09,482 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:09,483 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:09,556 org.apache.spark.executor.Executor logInfo - Finished task 175.0 in stage 2.0 (TID 177). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:09,556 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 177.0 in stage 2.0 (TID 179, localhost, executor driver, partition 177, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:09,557 org.apache.spark.executor.Executor logInfo - Running task 177.0 in stage 2.0 (TID 179)
[INFO] 2019-01-19 14:14:09,557 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 175.0 in stage 2.0 (TID 177) in 518 ms on localhost (executor driver) (176/200)
[INFO] 2019-01-19 14:14:09,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:09,569 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:09,987 org.apache.spark.executor.Executor logInfo - Finished task 176.0 in stage 2.0 (TID 178). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:09,987 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 178.0 in stage 2.0 (TID 180, localhost, executor driver, partition 178, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:09,987 org.apache.spark.executor.Executor logInfo - Running task 178.0 in stage 2.0 (TID 180)
[INFO] 2019-01-19 14:14:09,987 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 176.0 in stage 2.0 (TID 178) in 516 ms on localhost (executor driver) (177/200)
[INFO] 2019-01-19 14:14:09,998 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:09,998 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:10,043 org.apache.spark.executor.Executor logInfo - Finished task 177.0 in stage 2.0 (TID 179). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:10,043 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 179.0 in stage 2.0 (TID 181, localhost, executor driver, partition 179, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:10,044 org.apache.spark.executor.Executor logInfo - Running task 179.0 in stage 2.0 (TID 181)
[INFO] 2019-01-19 14:14:10,044 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 177.0 in stage 2.0 (TID 179) in 488 ms on localhost (executor driver) (178/200)
[INFO] 2019-01-19 14:14:10,055 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:10,055 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:10,476 org.apache.spark.executor.Executor logInfo - Finished task 178.0 in stage 2.0 (TID 180). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:14:10,476 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 180.0 in stage 2.0 (TID 182, localhost, executor driver, partition 180, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:10,476 org.apache.spark.executor.Executor logInfo - Running task 180.0 in stage 2.0 (TID 182)
[INFO] 2019-01-19 14:14:10,477 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 178.0 in stage 2.0 (TID 180) in 489 ms on localhost (executor driver) (179/200)
[INFO] 2019-01-19 14:14:10,486 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:10,487 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:10,549 org.apache.spark.executor.Executor logInfo - Finished task 179.0 in stage 2.0 (TID 181). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:10,550 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 181.0 in stage 2.0 (TID 183, localhost, executor driver, partition 181, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:10,550 org.apache.spark.executor.Executor logInfo - Running task 181.0 in stage 2.0 (TID 183)
[INFO] 2019-01-19 14:14:10,550 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 179.0 in stage 2.0 (TID 181) in 507 ms on localhost (executor driver) (180/200)
[INFO] 2019-01-19 14:14:10,571 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:10,571 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:11,005 org.apache.spark.executor.Executor logInfo - Finished task 180.0 in stage 2.0 (TID 182). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:11,006 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 182.0 in stage 2.0 (TID 184, localhost, executor driver, partition 182, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:11,006 org.apache.spark.executor.Executor logInfo - Running task 182.0 in stage 2.0 (TID 184)
[INFO] 2019-01-19 14:14:11,006 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 180.0 in stage 2.0 (TID 182) in 530 ms on localhost (executor driver) (181/200)
[INFO] 2019-01-19 14:14:11,016 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:11,016 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:11,064 org.apache.spark.executor.Executor logInfo - Finished task 181.0 in stage 2.0 (TID 183). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:11,064 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 183.0 in stage 2.0 (TID 185, localhost, executor driver, partition 183, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:11,065 org.apache.spark.executor.Executor logInfo - Running task 183.0 in stage 2.0 (TID 185)
[INFO] 2019-01-19 14:14:11,065 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 181.0 in stage 2.0 (TID 183) in 515 ms on localhost (executor driver) (182/200)
[INFO] 2019-01-19 14:14:11,076 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:11,076 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:11,505 org.apache.spark.executor.Executor logInfo - Finished task 182.0 in stage 2.0 (TID 184). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:11,505 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 184.0 in stage 2.0 (TID 186, localhost, executor driver, partition 184, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:11,505 org.apache.spark.executor.Executor logInfo - Running task 184.0 in stage 2.0 (TID 186)
[INFO] 2019-01-19 14:14:11,505 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 182.0 in stage 2.0 (TID 184) in 500 ms on localhost (executor driver) (183/200)
[INFO] 2019-01-19 14:14:11,517 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:11,517 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:11,600 org.apache.spark.executor.Executor logInfo - Finished task 183.0 in stage 2.0 (TID 185). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:11,600 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 185.0 in stage 2.0 (TID 187, localhost, executor driver, partition 185, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:11,601 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 183.0 in stage 2.0 (TID 185) in 537 ms on localhost (executor driver) (184/200)
[INFO] 2019-01-19 14:14:11,601 org.apache.spark.executor.Executor logInfo - Running task 185.0 in stage 2.0 (TID 187)
[INFO] 2019-01-19 14:14:11,611 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:11,612 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:12,019 org.apache.spark.executor.Executor logInfo - Finished task 184.0 in stage 2.0 (TID 186). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:12,020 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 186.0 in stage 2.0 (TID 188, localhost, executor driver, partition 186, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:12,020 org.apache.spark.executor.Executor logInfo - Running task 186.0 in stage 2.0 (TID 188)
[INFO] 2019-01-19 14:14:12,020 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 184.0 in stage 2.0 (TID 186) in 515 ms on localhost (executor driver) (185/200)
[INFO] 2019-01-19 14:14:12,029 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:12,029 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:12,103 org.apache.spark.executor.Executor logInfo - Finished task 185.0 in stage 2.0 (TID 187). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:12,104 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 187.0 in stage 2.0 (TID 189, localhost, executor driver, partition 187, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:12,104 org.apache.spark.executor.Executor logInfo - Running task 187.0 in stage 2.0 (TID 189)
[INFO] 2019-01-19 14:14:12,104 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 185.0 in stage 2.0 (TID 187) in 504 ms on localhost (executor driver) (186/200)
[INFO] 2019-01-19 14:14:12,114 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:12,114 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:12,528 org.apache.spark.executor.Executor logInfo - Finished task 186.0 in stage 2.0 (TID 188). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:12,528 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 188.0 in stage 2.0 (TID 190, localhost, executor driver, partition 188, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:12,529 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 186.0 in stage 2.0 (TID 188) in 510 ms on localhost (executor driver) (187/200)
[INFO] 2019-01-19 14:14:12,529 org.apache.spark.executor.Executor logInfo - Running task 188.0 in stage 2.0 (TID 190)
[INFO] 2019-01-19 14:14:12,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:12,541 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:12,610 org.apache.spark.executor.Executor logInfo - Finished task 187.0 in stage 2.0 (TID 189). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:12,611 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 189.0 in stage 2.0 (TID 191, localhost, executor driver, partition 189, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:12,611 org.apache.spark.executor.Executor logInfo - Running task 189.0 in stage 2.0 (TID 191)
[INFO] 2019-01-19 14:14:12,611 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 187.0 in stage 2.0 (TID 189) in 507 ms on localhost (executor driver) (188/200)
[INFO] 2019-01-19 14:14:12,621 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:12,621 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:13,031 org.apache.spark.executor.Executor logInfo - Finished task 188.0 in stage 2.0 (TID 190). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:13,032 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 190.0 in stage 2.0 (TID 192, localhost, executor driver, partition 190, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:13,032 org.apache.spark.executor.Executor logInfo - Running task 190.0 in stage 2.0 (TID 192)
[INFO] 2019-01-19 14:14:13,032 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 188.0 in stage 2.0 (TID 190) in 504 ms on localhost (executor driver) (189/200)
[INFO] 2019-01-19 14:14:13,043 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:13,044 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:13,114 org.apache.spark.executor.Executor logInfo - Finished task 189.0 in stage 2.0 (TID 191). 3178 bytes result sent to driver
[INFO] 2019-01-19 14:14:13,115 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 191.0 in stage 2.0 (TID 193, localhost, executor driver, partition 191, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:13,115 org.apache.spark.executor.Executor logInfo - Running task 191.0 in stage 2.0 (TID 193)
[INFO] 2019-01-19 14:14:13,115 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 189.0 in stage 2.0 (TID 191) in 504 ms on localhost (executor driver) (190/200)
[INFO] 2019-01-19 14:14:13,124 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:13,124 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:13,898 org.apache.spark.executor.Executor logInfo - Finished task 190.0 in stage 2.0 (TID 192). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:13,898 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 192.0 in stage 2.0 (TID 194, localhost, executor driver, partition 192, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:13,899 org.apache.spark.executor.Executor logInfo - Running task 192.0 in stage 2.0 (TID 194)
[INFO] 2019-01-19 14:14:13,899 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 190.0 in stage 2.0 (TID 192) in 867 ms on localhost (executor driver) (191/200)
[INFO] 2019-01-19 14:14:13,910 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:13,910 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:14,666 org.apache.spark.executor.Executor logInfo - Finished task 191.0 in stage 2.0 (TID 193). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:14,667 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 193.0 in stage 2.0 (TID 195, localhost, executor driver, partition 193, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:14,667 org.apache.spark.executor.Executor logInfo - Running task 193.0 in stage 2.0 (TID 195)
[INFO] 2019-01-19 14:14:14,667 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 191.0 in stage 2.0 (TID 193) in 1552 ms on localhost (executor driver) (192/200)
[INFO] 2019-01-19 14:14:14,678 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:14,678 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:15,204 org.apache.spark.executor.Executor logInfo - Finished task 192.0 in stage 2.0 (TID 194). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:15,205 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 194.0 in stage 2.0 (TID 196, localhost, executor driver, partition 194, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:15,205 org.apache.spark.executor.Executor logInfo - Running task 194.0 in stage 2.0 (TID 196)
[INFO] 2019-01-19 14:14:15,205 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 192.0 in stage 2.0 (TID 194) in 1307 ms on localhost (executor driver) (193/200)
[INFO] 2019-01-19 14:14:15,215 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:15,216 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:15,755 org.apache.spark.executor.Executor logInfo - Finished task 193.0 in stage 2.0 (TID 195). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:15,756 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 195.0 in stage 2.0 (TID 197, localhost, executor driver, partition 195, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:15,756 org.apache.spark.executor.Executor logInfo - Running task 195.0 in stage 2.0 (TID 197)
[INFO] 2019-01-19 14:14:15,756 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 193.0 in stage 2.0 (TID 195) in 1089 ms on localhost (executor driver) (194/200)
[INFO] 2019-01-19 14:14:15,767 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:15,768 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 1 ms
[INFO] 2019-01-19 14:14:16,240 org.apache.spark.executor.Executor logInfo - Finished task 194.0 in stage 2.0 (TID 196). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:16,241 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 196.0 in stage 2.0 (TID 198, localhost, executor driver, partition 196, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:16,241 org.apache.spark.executor.Executor logInfo - Running task 196.0 in stage 2.0 (TID 198)
[INFO] 2019-01-19 14:14:16,241 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 194.0 in stage 2.0 (TID 196) in 1037 ms on localhost (executor driver) (195/200)
[INFO] 2019-01-19 14:14:16,251 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:16,251 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:16,920 org.apache.spark.executor.Executor logInfo - Finished task 195.0 in stage 2.0 (TID 197). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:16,921 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 197.0 in stage 2.0 (TID 199, localhost, executor driver, partition 197, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:16,921 org.apache.spark.executor.Executor logInfo - Running task 197.0 in stage 2.0 (TID 199)
[INFO] 2019-01-19 14:14:16,921 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 195.0 in stage 2.0 (TID 197) in 1165 ms on localhost (executor driver) (196/200)
[INFO] 2019-01-19 14:14:16,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:16,934 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:17,533 org.apache.spark.executor.Executor logInfo - Finished task 196.0 in stage 2.0 (TID 198). 3341 bytes result sent to driver
[INFO] 2019-01-19 14:14:17,533 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 198.0 in stage 2.0 (TID 200, localhost, executor driver, partition 198, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:17,534 org.apache.spark.executor.Executor logInfo - Running task 198.0 in stage 2.0 (TID 200)
[INFO] 2019-01-19 14:14:17,534 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 196.0 in stage 2.0 (TID 198) in 1294 ms on localhost (executor driver) (197/200)
[INFO] 2019-01-19 14:14:17,549 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:17,549 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:18,396 org.apache.spark.executor.Executor logInfo - Finished task 197.0 in stage 2.0 (TID 199). 3251 bytes result sent to driver
[INFO] 2019-01-19 14:14:18,397 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 199.0 in stage 2.0 (TID 201, localhost, executor driver, partition 199, ANY, 5789 bytes)
[INFO] 2019-01-19 14:14:18,397 org.apache.spark.executor.Executor logInfo - Running task 199.0 in stage 2.0 (TID 201)
[INFO] 2019-01-19 14:14:18,397 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 197.0 in stage 2.0 (TID 199) in 1476 ms on localhost (executor driver) (198/200)
[INFO] 2019-01-19 14:14:18,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:18,410 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:18,943 org.apache.spark.executor.Executor logInfo - Finished task 198.0 in stage 2.0 (TID 200). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:18,944 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 198.0 in stage 2.0 (TID 200) in 1411 ms on localhost (executor driver) (199/200)
[INFO] 2019-01-19 14:14:19,596 org.apache.spark.executor.Executor logInfo - Finished task 199.0 in stage 2.0 (TID 201). 3268 bytes result sent to driver
[INFO] 2019-01-19 14:14:19,596 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 199.0 in stage 2.0 (TID 201) in 1200 ms on localhost (executor driver) (200/200)
[INFO] 2019-01-19 14:14:19,596 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 2.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:19,597 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 2 (head at DecoupJson.scala:144) finished in 69.016 s
[INFO] 2019-01-19 14:14:19,597 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 14:14:19,597 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 14:14:19,597 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 3)
[INFO] 2019-01-19 14:14:19,597 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 14:14:19,597 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 3 (MapPartitionsRDD[16] at head at DecoupJson.scala:144), which has no missing parents
[INFO] 2019-01-19 14:14:19,623 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4 stored as values in memory (estimated size 648.2 KB, free 1990.1 MB)
[INFO] 2019-01-19 14:14:19,626 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_4_piece0 stored as bytes in memory (estimated size 150.8 KB, free 1990.0 MB)
[INFO] 2019-01-19 14:14:19,626 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_4_piece0 in memory on 192.168.99.1:59102 (size: 150.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 14:14:19,627 org.apache.spark.SparkContext logInfo - Created broadcast 4 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:19,627 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at head at DecoupJson.scala:144)
[INFO] 2019-01-19 14:14:19,627 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 3.0 with 1 tasks
[INFO] 2019-01-19 14:14:19,628 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 0, ANY, 5800 bytes)
[INFO] 2019-01-19 14:14:19,628 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 3.0 (TID 202)
[INFO] 2019-01-19 14:14:19,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 200 non-empty blocks out of 200 blocks
[INFO] 2019-01-19 14:14:19,638 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:19,965 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 182.950403 ms
[INFO] 2019-01-19 14:14:20,102 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 48.346614 ms
[INFO] 2019-01-19 14:14:20,191 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 48.711573 ms
[INFO] 2019-01-19 14:14:20,271 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 66.053983 ms
[INFO] 2019-01-19 14:14:20,475 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 3.0 (TID 202). 7702 bytes result sent to driver
[INFO] 2019-01-19 14:14:20,476 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 3.0 (TID 202) in 849 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:20,476 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 3.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:20,476 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 3 (head at DecoupJson.scala:144) finished in 0.849 s
[INFO] 2019-01-19 14:14:20,477 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: head at DecoupJson.scala:144, took 165.393810 s
[INFO] 2019-01-19 14:14:20,563 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 60.303858 ms
[INFO] 2019-01-19 14:14:20,694 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 14:14:20,695 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 14:14:20,696 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 14:14:20,696 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 14:14:20,779 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 35.598099 ms
[INFO] 2019-01-19 14:14:20,832 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 33.709129 ms
[INFO] 2019-01-19 14:14:20,843 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5 stored as values in memory (estimated size 292.7 KB, free 1989.7 MB)
[INFO] 2019-01-19 14:14:20,858 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1989.7 MB)
[INFO] 2019-01-19 14:14:20,859 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_5_piece0 in memory on 192.168.99.1:59102 (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 14:14:20,859 org.apache.spark.SparkContext logInfo - Created broadcast 5 from rdd at DecoupJson.scala:151
[INFO] 2019-01-19 14:14:20,860 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 14:14:20,937 org.apache.spark.SparkContext logInfo - Starting job: first at DecoupJson.scala:151
[INFO] 2019-01-19 14:14:20,938 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 19 (rdd at DecoupJson.scala:151)
[INFO] 2019-01-19 14:14:20,939 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 2 (first at DecoupJson.scala:151) with 1 output partitions
[INFO] 2019-01-19 14:14:20,939 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 5 (first at DecoupJson.scala:151)
[INFO] 2019-01-19 14:14:20,939 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 4)
[INFO] 2019-01-19 14:14:20,939 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 4)
[INFO] 2019-01-19 14:14:20,940 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 4 (MapPartitionsRDD[19] at rdd at DecoupJson.scala:151), which has no missing parents
[INFO] 2019-01-19 14:14:20,942 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6 stored as values in memory (estimated size 91.2 KB, free 1989.6 MB)
[INFO] 2019-01-19 14:14:20,943 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.1 KB, free 1989.6 MB)
[INFO] 2019-01-19 14:14:20,944 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_6_piece0 in memory on 192.168.99.1:59102 (size: 28.1 KB, free: 1991.6 MB)
[INFO] 2019-01-19 14:14:20,945 org.apache.spark.SparkContext logInfo - Created broadcast 6 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:20,945 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[19] at rdd at DecoupJson.scala:151)
[INFO] 2019-01-19 14:14:20,945 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 4.0 with 1 tasks
[INFO] 2019-01-19 14:14:20,946 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 4.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 6620 bytes)
[INFO] 2019-01-19 14:14:20,947 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 4.0 (TID 203)
[INFO] 2019-01-19 14:14:20,960 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 14:14:22,099 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 4.0 (TID 203). 1970 bytes result sent to driver
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 4.0 (TID 203) in 1155 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 4.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 4 (rdd at DecoupJson.scala:151) finished in 1.155 s
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 5)
[INFO] 2019-01-19 14:14:22,100 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 14:14:22,101 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 5 (MapPartitionsRDD[24] at map at DecoupJson.scala:151), which has no missing parents
[INFO] 2019-01-19 14:14:22,103 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7 stored as values in memory (estimated size 125.3 KB, free 1989.4 MB)
[INFO] 2019-01-19 14:14:22,104 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_7_piece0 stored as bytes in memory (estimated size 37.8 KB, free 1989.4 MB)
[INFO] 2019-01-19 14:14:22,105 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_7_piece0 in memory on 192.168.99.1:59102 (size: 37.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 14:14:22,105 org.apache.spark.SparkContext logInfo - Created broadcast 7 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:22,105 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at map at DecoupJson.scala:151)
[INFO] 2019-01-19 14:14:22,105 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 5.0 with 1 tasks
[INFO] 2019-01-19 14:14:22,106 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 5.0 (TID 204, localhost, executor driver, partition 0, ANY, 5868 bytes)
[INFO] 2019-01-19 14:14:22,106 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 5.0 (TID 204)
[INFO] 2019-01-19 14:14:22,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:22,109 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:22,123 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 9.229045 ms
[INFO] 2019-01-19 14:14:22,128 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 5.0 (TID 204). 3128 bytes result sent to driver
[INFO] 2019-01-19 14:14:22,129 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 5.0 (TID 204) in 24 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:22,129 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 5.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:22,129 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 5 (first at DecoupJson.scala:151) finished in 0.024 s
[INFO] 2019-01-19 14:14:22,129 org.apache.spark.scheduler.DAGScheduler logInfo - Job 2 finished: first at DecoupJson.scala:151, took 1.191666 s
[INFO] 2019-01-19 14:14:22,157 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 14:14:22,158 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 14:14:22,159 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<>
[INFO] 2019-01-19 14:14:22,159 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 14:14:22,171 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.269861 ms
[INFO] 2019-01-19 14:14:22,178 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 5.712396 ms
[INFO] 2019-01-19 14:14:22,183 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8 stored as values in memory (estimated size 278.4 KB, free 1989.1 MB)
[INFO] 2019-01-19 14:14:22,197 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1989.1 MB)
[INFO] 2019-01-19 14:14:22,198 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_8_piece0 in memory on 192.168.99.1:59102 (size: 23.7 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,199 org.apache.spark.SparkContext logInfo - Created broadcast 8 from count at DecoupJson.scala:80
[INFO] 2019-01-19 14:14:22,200 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 14:14:22,221 org.apache.spark.SparkContext logInfo - Starting job: count at DecoupJson.scala:80
[INFO] 2019-01-19 14:14:22,221 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 27 (count at DecoupJson.scala:80)
[INFO] 2019-01-19 14:14:22,222 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 3 (count at DecoupJson.scala:80) with 1 output partitions
[INFO] 2019-01-19 14:14:22,222 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 7 (count at DecoupJson.scala:80)
[INFO] 2019-01-19 14:14:22,222 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 6)
[INFO] 2019-01-19 14:14:22,222 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 6)
[INFO] 2019-01-19 14:14:22,222 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 6 (MapPartitionsRDD[27] at count at DecoupJson.scala:80), which has no missing parents
[INFO] 2019-01-19 14:14:22,224 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9 stored as values in memory (estimated size 10.5 KB, free 1989.1 MB)
[INFO] 2019-01-19 14:14:22,226 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.3 KB, free 1989.1 MB)
[INFO] 2019-01-19 14:14:22,227 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_9_piece0 in memory on 192.168.99.1:59102 (size: 5.3 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,227 org.apache.spark.SparkContext logInfo - Created broadcast 9 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:22,227 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[27] at count at DecoupJson.scala:80)
[INFO] 2019-01-19 14:14:22,228 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 6.0 with 1 tasks
[INFO] 2019-01-19 14:14:22,228 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 6.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
[INFO] 2019-01-19 14:14:22,229 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 6.0 (TID 205)
[INFO] 2019-01-19 14:14:22,232 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 14:14:22,253 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 6.0 (TID 205). 1970 bytes result sent to driver
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 6.0 (TID 205) in 26 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 6.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 6 (count at DecoupJson.scala:80) finished in 0.026 s
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 7)
[INFO] 2019-01-19 14:14:22,254 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 14:14:22,255 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 7 (MapPartitionsRDD[30] at count at DecoupJson.scala:80), which has no missing parents
[INFO] 2019-01-19 14:14:22,256 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 1989.1 MB)
[INFO] 2019-01-19 14:14:22,257 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1989.1 MB)
[INFO] 2019-01-19 14:14:22,258 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_10_piece0 in memory on 192.168.99.1:59102 (size: 3.7 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,259 org.apache.spark.SparkContext logInfo - Created broadcast 10 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:22,259 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at count at DecoupJson.scala:80)
[INFO] 2019-01-19 14:14:22,259 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 7.0 with 1 tasks
[INFO] 2019-01-19 14:14:22,260 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 7.0 (TID 206, localhost, executor driver, partition 0, ANY, 5899 bytes)
[INFO] 2019-01-19 14:14:22,260 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 7.0 (TID 206)
[INFO] 2019-01-19 14:14:22,262 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:22,262 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:22,264 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 7.0 (TID 206). 1873 bytes result sent to driver
[INFO] 2019-01-19 14:14:22,265 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 7.0 (TID 206) in 5 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:22,265 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 7.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:22,265 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 7 (count at DecoupJson.scala:80) finished in 0.006 s
[INFO] 2019-01-19 14:14:22,265 org.apache.spark.scheduler.DAGScheduler logInfo - Job 3 finished: count at DecoupJson.scala:80, took 0.044355 s
[INFO] 2019-01-19 14:14:22,270 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 2.654501 ms
[INFO] 2019-01-19 14:14:22,286 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 14:14:22,287 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 14:14:22,287 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 14:14:22,287 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 14:14:22,302 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 10.646565 ms
[INFO] 2019-01-19 14:14:22,328 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 17.610399 ms
[INFO] 2019-01-19 14:14:22,338 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11 stored as values in memory (estimated size 292.7 KB, free 1988.8 MB)
[INFO] 2019-01-19 14:14:22,352 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_11_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.8 MB)
[INFO] 2019-01-19 14:14:22,353 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_11_piece0 in memory on 192.168.99.1:59102 (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,355 org.apache.spark.SparkContext logInfo - Created broadcast 11 from rdd at DecoupJson.scala:100
[INFO] 2019-01-19 14:14:22,357 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 14:14:22,396 org.apache.spark.SparkContext logInfo - Starting job: collect at DecoupJson.scala:100
[INFO] 2019-01-19 14:14:22,396 org.apache.spark.scheduler.DAGScheduler logInfo - Registering RDD 33 (rdd at DecoupJson.scala:100)
[INFO] 2019-01-19 14:14:22,397 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 4 (collect at DecoupJson.scala:100) with 1 output partitions
[INFO] 2019-01-19 14:14:22,397 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 9 (collect at DecoupJson.scala:100)
[INFO] 2019-01-19 14:14:22,397 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List(ShuffleMapStage 8)
[INFO] 2019-01-19 14:14:22,397 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List(ShuffleMapStage 8)
[INFO] 2019-01-19 14:14:22,397 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at rdd at DecoupJson.scala:100), which has no missing parents
[INFO] 2019-01-19 14:14:22,398 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12 stored as values in memory (estimated size 36.1 KB, free 1988.7 MB)
[INFO] 2019-01-19 14:14:22,400 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.0 KB, free 1988.7 MB)
[INFO] 2019-01-19 14:14:22,401 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_12_piece0 in memory on 192.168.99.1:59102 (size: 11.0 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,401 org.apache.spark.SparkContext logInfo - Created broadcast 12 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:22,402 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at rdd at DecoupJson.scala:100)
[INFO] 2019-01-19 14:14:22,402 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 8.0 with 1 tasks
[INFO] 2019-01-19 14:14:22,403 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 8.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 6622 bytes)
[INFO] 2019-01-19 14:14:22,403 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 8.0 (TID 207)
[INFO] 2019-01-19 14:14:22,409 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 14:14:22,455 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 8.0 (TID 207). 1812 bytes result sent to driver
[INFO] 2019-01-19 14:14:22,455 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 8.0 (TID 207) in 53 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:22,455 org.apache.spark.scheduler.DAGScheduler logInfo - ShuffleMapStage 8 (rdd at DecoupJson.scala:100) finished in 0.053 s
[INFO] 2019-01-19 14:14:22,455 org.apache.spark.scheduler.DAGScheduler logInfo - looking for newly runnable stages
[INFO] 2019-01-19 14:14:22,455 org.apache.spark.scheduler.DAGScheduler logInfo - running: Set()
[INFO] 2019-01-19 14:14:22,456 org.apache.spark.scheduler.DAGScheduler logInfo - waiting: Set(ResultStage 9)
[INFO] 2019-01-19 14:14:22,456 org.apache.spark.scheduler.DAGScheduler logInfo - failed: Set()
[INFO] 2019-01-19 14:14:22,455 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 8.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:22,456 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 9 (MapPartitionsRDD[37] at rdd at DecoupJson.scala:100), which has no missing parents
[INFO] 2019-01-19 14:14:22,457 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13 stored as values in memory (estimated size 36.8 KB, free 1988.7 MB)
[INFO] 2019-01-19 14:14:22,458 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.8 KB, free 1988.7 MB)
[INFO] 2019-01-19 14:14:22,459 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_13_piece0 in memory on 192.168.99.1:59102 (size: 12.8 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,459 org.apache.spark.SparkContext logInfo - Created broadcast 13 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:22,460 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at rdd at DecoupJson.scala:100)
[INFO] 2019-01-19 14:14:22,460 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 9.0 with 1 tasks
[INFO] 2019-01-19 14:14:22,460 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 9.0 (TID 208, localhost, executor driver, partition 0, ANY, 5870 bytes)
[INFO] 2019-01-19 14:14:22,461 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 9.0 (TID 208)
[INFO] 2019-01-19 14:14:22,463 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Getting 1 non-empty blocks out of 1 blocks
[INFO] 2019-01-19 14:14:22,463 org.apache.spark.storage.ShuffleBlockFetcherIterator logInfo - Started 0 remote fetches in 0 ms
[INFO] 2019-01-19 14:14:22,476 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 8.511117 ms
[INFO] 2019-01-19 14:14:22,482 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 9.0 (TID 208). 7152 bytes result sent to driver
[INFO] 2019-01-19 14:14:22,484 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 9.0 (TID 208) in 24 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:22,484 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 9.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:22,484 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 9 (collect at DecoupJson.scala:100) finished in 0.024 s
[INFO] 2019-01-19 14:14:22,484 org.apache.spark.scheduler.DAGScheduler logInfo - Job 4 finished: collect at DecoupJson.scala:100, took 0.088237 s
[INFO] 2019-01-19 14:14:22,515 myLogger setOutputDataTable - outputPath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\yatop_train22
[INFO] 2019-01-19 14:14:22,586 org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat logInfo - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 14:14:22,599 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pruning directories with: 
[INFO] 2019-01-19 14:14:22,600 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Post-Scan Filters: 
[INFO] 2019-01-19 14:14:22,600 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Output Data Schema: struct<crm_cust_no: string, stat_mth: int, ast_curr_bal: double, std_cred_curr_bal: double, std_cred_limit: decimal(6,0) ... 48 more fields>
[INFO] 2019-01-19 14:14:22,601 org.apache.spark.sql.execution.datasources.FileSourceStrategy logInfo - Pushed Filters: 
[INFO] 2019-01-19 14:14:22,603 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.job.id is deprecated. Instead, use mapreduce.job.id
[INFO] 2019-01-19 14:14:22,604 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
[INFO] 2019-01-19 14:14:22,604 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
[INFO] 2019-01-19 14:14:22,604 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
[INFO] 2019-01-19 14:14:22,605 org.apache.hadoop.conf.Configuration.deprecation warnOnceIfDeprecated - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
[INFO] 2019-01-19 14:14:22,606 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 14:14:22,607 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 14:14:22,608 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 14:14:22,609 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 14:14:22,620 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14 stored as values in memory (estimated size 292.7 KB, free 1988.4 MB)
[INFO] 2019-01-19 14:14:22,631 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.4 KB, free 1988.4 MB)
[INFO] 2019-01-19 14:14:22,632 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_14_piece0 in memory on 192.168.99.1:59102 (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:22,632 org.apache.spark.SparkContext logInfo - Created broadcast 14 from save at DecoupJson.scala:171
[INFO] 2019-01-19 14:14:22,633 org.apache.spark.sql.execution.FileSourceScanExec logInfo - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[INFO] 2019-01-19 14:14:22,660 org.apache.spark.SparkContext logInfo - Starting job: save at DecoupJson.scala:171
[INFO] 2019-01-19 14:14:22,661 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 5 (save at DecoupJson.scala:171) with 1 output partitions
[INFO] 2019-01-19 14:14:22,661 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 10 (save at DecoupJson.scala:171)
[INFO] 2019-01-19 14:14:22,661 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2019-01-19 14:14:22,661 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2019-01-19 14:14:22,661 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 10 (MapPartitionsRDD[39] at save at DecoupJson.scala:171), which has no missing parents
[INFO] 2019-01-19 14:14:22,675 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15 stored as values in memory (estimated size 108.7 KB, free 1988.3 MB)
[INFO] 2019-01-19 14:14:22,677 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_15_piece0 stored as bytes in memory (estimated size 36.2 KB, free 1988.2 MB)
[INFO] 2019-01-19 14:14:22,677 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_15_piece0 in memory on 192.168.99.1:59102 (size: 36.2 KB, free: 1991.4 MB)
[INFO] 2019-01-19 14:14:22,678 org.apache.spark.SparkContext logInfo - Created broadcast 15 from broadcast at DAGScheduler.scala:996
[INFO] 2019-01-19 14:14:22,678 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[39] at save at DecoupJson.scala:171)
[INFO] 2019-01-19 14:14:22,678 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 10.0 with 1 tasks
[INFO] 2019-01-19 14:14:22,679 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 10.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
[INFO] 2019-01-19 14:14:22,679 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 10.0 (TID 209)
[INFO] 2019-01-19 14:14:22,690 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 14:14:22,691 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 14:14:22,691 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <init> - File Output Committer Algorithm version is 1
[INFO] 2019-01-19 14:14:22,692 org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol logInfo - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[INFO] 2019-01-19 14:14:22,694 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 14:14:22,697 org.apache.parquet.hadoop.codec.CodecConfig info - Compression: SNAPPY
[INFO] 2019-01-19 14:14:22,709 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet block size to 134217728
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet page size to 1048576
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Parquet dictionary page size to 1048576
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Dictionary is on
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Validation is off
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Writer version is: PARQUET_1_0
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Maximum row group padding size is 0 bytes
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Page size checking is: estimated
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Min row count for page size check is: 100
[INFO] 2019-01-19 14:14:22,710 org.apache.parquet.hadoop.ParquetOutputFormat info - Max row count for page size check is: 10000
[INFO] 2019-01-19 14:14:22,731 org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport logInfo - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "crm_cust_no",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "stat_mth",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ast_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_limit",
    "type" : "decimal(6,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_bill_amt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ln_curr_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_davg_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_qzamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_xfamt_pct",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_auto_repay_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1st_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_lst_biz_days",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_1stbiz_op_days",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "std_cred_mp_appl_bal",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l6m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_std_cred_znamt",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l3m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_max_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_min_ovd_days_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "l12m_ln_ovd_mths_bm",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "samp_flag",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "nty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "mrg",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "study_exp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "yg_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gd_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "house_stt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "work_years",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "unit_kind",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "title",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "occp",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "duty",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "idy",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "y_income",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_y_income",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ln_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_lns",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_amt",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_ln_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_cred_banks",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_max_ovd_creds",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_amt",
    "type" : "decimal(10,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_tot_ovd_mths",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "zx_cred_max_ovd_duration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary crm_cust_no (UTF8);
  optional int32 stat_mth;
  optional double ast_curr_bal;
  optional double std_cred_curr_bal;
  optional int32 std_cred_limit (DECIMAL(6,0));
  optional double std_cred_bill_amt;
  optional double ln_curr_bal;
  optional double l3m_ln_davg_bal;
  optional double l3m_std_cred_qzamt;
  optional binary l3m_std_cred_xfamt_pct (UTF8);
  optional int32 std_cred_auto_repay_flag;
  optional int32 std_cred_1st_biz_days;
  optional int32 std_cred_lst_biz_days;
  optional binary std_cred_1stbiz_op_days (UTF8);
  optional double std_cred_mp_appl_bal;
  optional double l3m_std_cred_znamt;
  optional double l6m_std_cred_znamt;
  optional double l12m_std_cred_znamt;
  optional int32 l3m_ln_ovd_days_bm;
  optional int32 l12m_ln_ovd_days_bm;
  optional int32 l12m_ln_max_ovd_days_bm;
  optional int32 l12m_ln_min_ovd_days_bm;
  optional int32 l12m_ln_ovd_mths_bm;
  optional int32 samp_flag;
  optional binary nty (UTF8);
  optional binary mrg (UTF8);
  optional binary study_exp (UTF8);
  optional binary yg_flag (UTF8);
  optional binary gd_flag (UTF8);
  optional binary house_stt (UTF8);
  optional int32 work_years;
  optional binary unit_kind (UTF8);
  optional binary title (UTF8);
  optional binary occp (UTF8);
  optional binary duty (UTF8);
  optional binary idy (UTF8);
  optional double y_income;
  optional binary cp_y_income (UTF8);
  optional int32 zx_max_lns;
  optional int32 zx_max_ln_banks;
  optional int32 zx_max_ovd_lns;
  optional int32 zx_ln_max_ovd_amt;
  optional int32 zx_ln_tot_ovd_mths;
  optional int32 zx_ln_max_ovd_duration;
  optional int32 zx_max_creds;
  optional int32 zx_max_cred_banks;
  optional int32 zx_max_ovd_creds;
  optional int64 zx_cred_max_ovd_amt (DECIMAL(10,0));
  optional int32 zx_cred_tot_ovd_mths;
  optional int32 zx_cred_max_ovd_duration;
}

       
[INFO] 2019-01-19 14:14:22,753 org.apache.hadoop.io.compress.CodecPool getCompressor - Got brand-new compressor [.snappy]
[INFO] 2019-01-19 14:14:22,818 org.apache.spark.sql.execution.datasources.FileScanRDD logInfo - Reading File path: file:///F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train/part-00000-676a6f96-8506-4ed2-84ed-d5e8cdf0989c-c000.snappy.parquet, range: 0-2396145, partition values: [empty row]
[INFO] 2019-01-19 14:14:23,792 org.apache.parquet.hadoop.InternalParquetRecordWriter info - Flushing mem columnStore to file. allocated memory: 11,137,230
[INFO] 2019-01-19 14:14:23,850 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_9_piece0 on 192.168.99.1:59102 in memory (size: 5.3 KB, free: 1991.4 MB)
[INFO] 2019-01-19 14:14:23,854 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_10_piece0 on 192.168.99.1:59102 in memory (size: 3.7 KB, free: 1991.4 MB)
[INFO] 2019-01-19 14:14:23,855 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5206
[INFO] 2019-01-19 14:14:23,855 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5207
[INFO] 2019-01-19 14:14:23,855 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5208
[INFO] 2019-01-19 14:14:23,856 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5209
[INFO] 2019-01-19 14:14:23,856 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5210
[INFO] 2019-01-19 14:14:23,856 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5211
[INFO] 2019-01-19 14:14:23,858 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_11_piece0 on 192.168.99.1:59102 in memory (size: 25.4 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:23,864 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 4
[INFO] 2019-01-19 14:14:23,867 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_12_piece0 on 192.168.99.1:59102 in memory (size: 11.0 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:23,873 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_13_piece0 on 192.168.99.1:59102 in memory (size: 12.8 KB, free: 1991.5 MB)
[INFO] 2019-01-19 14:14:23,876 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_4_piece0 on 192.168.99.1:59102 in memory (size: 150.8 KB, free: 1991.6 MB)
[INFO] 2019-01-19 14:14:23,876 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4986
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4987
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4988
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4989
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4990
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4991
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4992
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4993
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4994
[INFO] 2019-01-19 14:14:23,877 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4995
[INFO] 2019-01-19 14:14:23,878 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4996
[INFO] 2019-01-19 14:14:23,878 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4997
[INFO] 2019-01-19 14:14:23,878 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4998
[INFO] 2019-01-19 14:14:23,878 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 4999
[INFO] 2019-01-19 14:14:23,879 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_5_piece0 on 192.168.99.1:59102 in memory (size: 25.4 KB, free: 1991.6 MB)
[INFO] 2019-01-19 14:14:23,881 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 2
[INFO] 2019-01-19 14:14:23,883 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_6_piece0 on 192.168.99.1:59102 in memory (size: 28.1 KB, free: 1991.7 MB)
[INFO] 2019-01-19 14:14:23,890 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_7_piece0 on 192.168.99.1:59102 in memory (size: 37.8 KB, free: 1991.7 MB)
[INFO] 2019-01-19 14:14:23,891 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5096
[INFO] 2019-01-19 14:14:23,891 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5097
[INFO] 2019-01-19 14:14:23,891 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5098
[INFO] 2019-01-19 14:14:23,891 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5099
[INFO] 2019-01-19 14:14:23,891 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5100
[INFO] 2019-01-19 14:14:23,891 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5101
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5102
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5103
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5104
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5105
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5106
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5107
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5108
[INFO] 2019-01-19 14:14:23,892 org.apache.spark.ContextCleaner logInfo - Cleaned accumulator 5109
[INFO] 2019-01-19 14:14:23,893 org.apache.spark.storage.BlockManagerInfo logInfo - Removed broadcast_8_piece0 on 192.168.99.1:59102 in memory (size: 23.7 KB, free: 1991.7 MB)
[INFO] 2019-01-19 14:14:23,894 org.apache.spark.ContextCleaner logInfo - Cleaned shuffle 3
[INFO] 2019-01-19 14:14:24,044 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 78,288B for [crm_cust_no] BINARY: 47,996 values, 78,114B raw, 78,126B comp, 2 pages, encodings: [PLAIN_DICTIONARY], dic { 6,359 entries, 184,411B raw, 6,359B comp}
[INFO] 2019-01-19 14:14:24,046 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 436B for [stat_mth] INT32: 47,996 values, 405B raw, 399B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 14:14:24,048 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 89,613B for [ast_curr_bal] DOUBLE: 47,996 values, 90,105B raw, 89,566B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 26,213 entries, 209,704B raw, 26,213B comp}
[INFO] 2019-01-19 14:14:24,050 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 273,418B for [std_cred_curr_bal] DOUBLE: 47,996 values, 383,976B raw, 273,371B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 14:14:24,050 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 33,212B for [std_cred_limit] INT32: 47,996 values, 36,105B raw, 33,173B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 47 entries, 188B raw, 47B comp}
[INFO] 2019-01-19 14:14:24,052 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 272,224B for [std_cred_bill_amt] DOUBLE: 47,996 values, 383,976B raw, 272,177B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 14:14:24,052 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 34,338B for [ln_curr_bal] DOUBLE: 47,996 values, 57,786B raw, 34,291B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2,254 entries, 18,032B raw, 2,254B comp}
[INFO] 2019-01-19 14:14:24,053 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 41,124B for [l3m_ln_davg_bal] DOUBLE: 47,996 values, 63,063B raw, 41,077B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 4,182 entries, 33,456B raw, 4,182B comp}
[INFO] 2019-01-19 14:14:24,055 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 54,154B for [l3m_std_cred_qzamt] DOUBLE: 47,996 values, 60,085B raw, 54,107B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 800 entries, 6,400B raw, 800B comp}
[INFO] 2019-01-19 14:14:24,056 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 285,246B for [l3m_std_cred_xfamt_pct] BINARY: 47,996 values, 528,414B raw, 285,212B comp, 1 pages, encodings: [PLAIN]
[INFO] 2019-01-19 14:14:24,058 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 6,888B for [std_cred_auto_repay_flag] INT32: 47,996 values, 6,843B raw, 6,851B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 14:14:24,060 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 66,153B for [std_cred_1st_biz_days] INT32: 47,996 values, 66,105B raw, 66,114B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1,482 entries, 5,928B raw, 1,482B comp}
[INFO] 2019-01-19 14:14:24,061 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 30,145B for [std_cred_lst_biz_days] INT32: 47,996 values, 30,100B raw, 30,106B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 31 entries, 124B raw, 31B comp}
[INFO] 2019-01-19 14:14:24,061 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 25,854B for [std_cred_1stbiz_op_days] BINARY: 47,996 values, 40,966B raw, 25,819B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 420 entries, 2,975B raw, 420B comp}
[INFO] 2019-01-19 14:14:24,062 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 17,175B for [std_cred_mp_appl_bal] DOUBLE: 47,996 values, 32,754B raw, 17,128B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2,735 entries, 21,880B raw, 2,735B comp}
[INFO] 2019-01-19 14:14:24,062 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 43,102B for [l3m_std_cred_znamt] DOUBLE: 47,996 values, 68,228B raw, 43,055B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 5,791 entries, 46,328B raw, 5,791B comp}
[INFO] 2019-01-19 14:14:24,063 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 51,412B for [l6m_std_cred_znamt] DOUBLE: 47,996 values, 73,739B raw, 51,365B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6,720 entries, 53,760B raw, 6,720B comp}
[INFO] 2019-01-19 14:14:24,064 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 58,945B for [l12m_std_cred_znamt] DOUBLE: 47,996 values, 76,551B raw, 58,898B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7,469 entries, 59,752B raw, 7,469B comp}
[INFO] 2019-01-19 14:14:24,064 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 1,992B for [l3m_ln_ovd_days_bm] INT32: 47,996 values, 3,651B raw, 1,955B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 59 entries, 236B raw, 59B comp}
[INFO] 2019-01-19 14:14:24,065 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 3,152B for [l12m_ln_ovd_days_bm] INT32: 47,996 values, 6,032B raw, 3,115B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 162 entries, 648B raw, 162B comp}
[INFO] 2019-01-19 14:14:24,065 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 2,246B for [l12m_ln_max_ovd_days_bm] INT32: 47,996 values, 4,403B raw, 2,209B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 26 entries, 104B raw, 26B comp}
[INFO] 2019-01-19 14:14:24,066 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 704B for [l12m_ln_min_ovd_days_bm] INT32: 47,996 values, 997B raw, 667B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 7 entries, 28B raw, 7B comp}
[INFO] 2019-01-19 14:14:24,066 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 2,349B for [l12m_ln_ovd_mths_bm] INT32: 47,996 values, 3,860B raw, 2,312B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 13 entries, 52B raw, 13B comp}
[INFO] 2019-01-19 14:14:24,066 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 1,387B for [samp_flag] INT32: 47,996 values, 1,900B raw, 1,350B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 8B raw, 2B comp}
[INFO] 2019-01-19 14:14:24,067 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 15,926B for [nty] BINARY: 47,996 values, 17,225B raw, 15,892B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 34B raw, 6B comp}
[INFO] 2019-01-19 14:14:24,067 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 21,029B for [mrg] BINARY: 47,996 values, 22,977B raw, 20,995B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 10 entries, 56B raw, 10B comp}
[INFO] 2019-01-19 14:14:24,068 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 24,159B for [study_exp] BINARY: 47,996 values, 24,102B raw, 24,125B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 16 entries, 91B raw, 16B comp}
[INFO] 2019-01-19 14:14:24,068 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 652B for [yg_flag] BINARY: 47,996 values, 766B raw, 620B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 2 entries, 11B raw, 2B comp}
[INFO] 2019-01-19 14:14:24,073 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 45B for [gd_flag] BINARY: 47,996 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1 entries, 6B raw, 1B comp}
[INFO] 2019-01-19 14:14:24,073 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 14,238B for [house_stt] BINARY: 47,996 values, 22,235B raw, 14,204B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 9 entries, 46B raw, 9B comp}
[INFO] 2019-01-19 14:14:24,074 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 17,308B for [work_years] INT32: 47,996 values, 26,622B raw, 17,269B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 38 entries, 152B raw, 38B comp}
[INFO] 2019-01-19 14:14:24,074 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 11,744B for [unit_kind] BINARY: 47,996 values, 12,878B raw, 11,705B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 60B raw, 8B comp}
[INFO] 2019-01-19 14:14:24,075 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 17,018B for [title] BINARY: 47,996 values, 17,882B raw, 16,984B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 14:14:24,075 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 21,301B for [occp] BINARY: 47,996 values, 21,256B raw, 21,262B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 55 entries, 485B raw, 55B comp}
[INFO] 2019-01-19 14:14:24,075 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 18,139B for [duty] BINARY: 47,996 values, 18,099B raw, 18,105B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 6 entries, 31B raw, 6B comp}
[INFO] 2019-01-19 14:14:24,076 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 33,464B for [idy] BINARY: 47,996 values, 40,625B raw, 33,430B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 85 entries, 508B raw, 85B comp}
[INFO] 2019-01-19 14:14:24,076 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 44,247B for [y_income] DOUBLE: 47,996 values, 48,105B raw, 44,200B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 151 entries, 1,208B raw, 151B comp}
[INFO] 2019-01-19 14:14:24,079 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 19,507B for [cp_y_income] BINARY: 47,996 values, 26,289B raw, 19,473B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 145 entries, 1,272B raw, 145B comp}
[INFO] 2019-01-19 14:14:24,079 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 30,118B for [zx_max_lns] INT32: 47,996 values, 30,068B raw, 30,079B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 32 entries, 128B raw, 32B comp}
[INFO] 2019-01-19 14:14:24,080 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 29,718B for [zx_max_ln_banks] INT32: 47,996 values, 30,068B raw, 29,679B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 18 entries, 72B raw, 18B comp}
[INFO] 2019-01-19 14:14:24,080 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 20,257B for [zx_max_ovd_lns] INT32: 47,996 values, 23,576B raw, 20,218B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 14 entries, 56B raw, 14B comp}
[INFO] 2019-01-19 14:14:24,085 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 45,085B for [zx_ln_max_ovd_amt] INT32: 47,996 values, 60,835B raw, 45,046B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 1,338 entries, 5,352B raw, 1,338B comp}
[INFO] 2019-01-19 14:14:24,086 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 33,114B for [zx_ln_tot_ovd_mths] INT32: 47,996 values, 40,722B raw, 33,075B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 86 entries, 344B raw, 86B comp}
[INFO] 2019-01-19 14:14:24,086 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 17,052B for [zx_ln_max_ovd_duration] INT32: 47,996 values, 17,830B raw, 17,013B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 14:14:24,087 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 23,533B for [zx_max_creds] INT32: 47,996 values, 29,122B raw, 23,494B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 28 entries, 112B raw, 28B comp}
[INFO] 2019-01-19 14:14:24,088 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 18,829B for [zx_max_cred_banks] INT32: 47,996 values, 23,450B raw, 18,790B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 11 entries, 44B raw, 11B comp}
[INFO] 2019-01-19 14:14:24,088 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 9,464B for [zx_max_ovd_creds] INT32: 47,996 values, 16,121B raw, 9,425B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 12 entries, 48B raw, 12B comp}
[INFO] 2019-01-19 14:14:24,089 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 16,145B for [zx_cred_max_ovd_amt] INT64: 47,996 values, 29,214B raw, 16,098B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 459 entries, 3,672B raw, 459B comp}
[INFO] 2019-01-19 14:14:24,089 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 12,134B for [zx_cred_tot_ovd_mths] INT32: 47,996 values, 21,316B raw, 12,095B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 39 entries, 156B raw, 39B comp}
[INFO] 2019-01-19 14:14:24,090 org.apache.parquet.hadoop.ColumnChunkPageWriteStore info - written 8,803B for [zx_cred_max_ovd_duration] INT32: 47,996 values, 12,661B raw, 8,764B comp, 1 pages, encodings: [PLAIN_DICTIONARY], dic { 8 entries, 32B raw, 8B comp}
[INFO] 2019-01-19 14:14:24,108 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask - Saved output of task 'attempt_20190119141422_0010_m_000000_0' to file:/F:/雅拓/算法平台/gitlab/lambda-mls/lambda-component/src/main/testDataSet/yatop_train22/_temporary/0/task_20190119141422_0010_m_000000
[INFO] 2019-01-19 14:14:24,109 org.apache.spark.mapred.SparkHadoopMapRedUtil logInfo - attempt_20190119141422_0010_m_000000_0: Committed
[INFO] 2019-01-19 14:14:24,111 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 10.0 (TID 209). 1877 bytes result sent to driver
[INFO] 2019-01-19 14:14:24,111 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 10.0 (TID 209) in 1433 ms on localhost (executor driver) (1/1)
[INFO] 2019-01-19 14:14:24,111 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 10.0, whose tasks have all completed, from pool 
[INFO] 2019-01-19 14:14:24,112 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 10 (save at DecoupJson.scala:171) finished in 1.433 s
[INFO] 2019-01-19 14:14:24,112 org.apache.spark.scheduler.DAGScheduler logInfo - Job 5 finished: save at DecoupJson.scala:171, took 1.450335 s
[WARN] 2019-01-19 14:14:24,133 org.apache.parquet.hadoop.ParquetOutputFormat warn - Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level
[INFO] 2019-01-19 14:14:24,138 org.apache.spark.sql.execution.datasources.FileFormatWriter logInfo - Job null committed.
[INFO] 2019-01-19 14:14:24,158 myLogger setOutputDataTable - summaryFilePath: F:\雅拓\算法平台\gitlab\lambda-mls\lambda-component\src\main\testDataSet\summary
[INFO] 2019-01-19 14:14:24,160 myLogger main - SQL end
[INFO] 2019-01-19 14:14:24,163 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2019-01-19 14:14:24,175 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://192.168.99.1:4040
[INFO] 2019-01-19 14:14:24,189 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2019-01-19 14:14:24,869 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2019-01-19 14:14:24,870 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2019-01-19 14:14:24,870 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2019-01-19 14:14:24,872 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2019-01-19 14:14:24,877 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2019-01-19 14:14:24,877 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2019-01-19 14:14:24,878 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory C:\Users\dell\AppData\Local\Temp\spark-6f57558b-9b56-4609-ab02-4ebcf6d68c87
